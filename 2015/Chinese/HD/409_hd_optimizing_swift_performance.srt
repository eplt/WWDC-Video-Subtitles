1
00:00:19,720 --> 00:00:24,424
Swift性能优化


2
00:00:33,267 --> 00:00:36,236
早上好 欢迎来到
“Swift性能优化”演讲现场 


3
00:00:36,537 --> 00:00:39,673
我的名字是那達夫我将与
我的同事迈克尔


4
00:00:39,840 --> 00:00:41,775
和乔一起向大家展示如何


5
00:00:41,842 --> 00:00:43,443
优化你的Swift程序


6
00:00:44,344 --> 00:00:49,950
现在我们编译器团队的工程师
热衷于让代码运行得快


7
00:00:50,284 --> 00:00:52,586
我们相信如果你的app得到高度优化


8
00:00:52,653 --> 00:00:54,221
你可以创造出令人叹为观止的作品


9
00:00:54,421 --> 00:00:57,491
如果你有同样的看法
那么这个演讲适合你听


10
00:01:01,929 --> 00:01:04,031
今天我首先要讲一讲在过去的几年中


11
00:01:04,096 --> 00:01:07,301
我们对编译器所做的一些新的优化


12
00:01:08,001 --> 00:01:11,738
之后迈克尔将描述
Swift语言的底层实现


13
00:01:11,805 --> 00:01:13,507
并就如何编写高性能的


14
00:01:13,740 --> 00:01:15,442
Swift代码给大家一些建议


15
00:01:15,943 --> 00:01:20,547
最后乔将演示如何使用工具来识别


16
00:01:20,948 --> 00:01:23,984
和分析你的Swift
代码中的性能瓶颈


17
00:01:26,720 --> 00:01:31,558
Swift是一个灵活
并且安全的编程语言


18
00:01:31,625 --> 00:01:36,129
有很多的功能包括闭环 协议 泛化


19
00:01:36,430 --> 00:01:38,532
当然还有自动引用计数


20
00:01:38,999 --> 00:01:42,603
现在你们中有些人可能把
这些特性与运行缓慢联系在一起


21
00:01:42,836 --> 00:01:46,907
因为程序必须做更多的工作
来实现这些高级功能


22
00:01:47,608 --> 00:01:50,744
但Swift是一种
非常快速的编程语言


23
00:01:50,811 --> 00:01:53,080
可以编译为高度优化的本地代码


24
00:01:54,081 --> 00:01:56,517
那么我们如何让Swift迅速运行呢?


25
00:01:57,217 --> 00:01:59,753
好 我们将编译器优化的


26
00:02:00,053 --> 00:02:05,392
目标设定为所有的这些
高级功能实现了这些目标


27
00:02:05,859 --> 00:02:12,499
就可以确保那些高级
功能造成的负担是最小的


28
00:02:14,468 --> 00:02:16,904
现在 我们有很多编译器优化


29
00:02:16,970 --> 00:02:19,373
但是我们没有足够的时间去逐一回顾


30
00:02:19,673 --> 00:02:23,544
所以我决定给你们举一个
编译器优化的例子


31
00:02:24,111 --> 00:02:26,980
这种优化称为消除边界检查


32
00:02:29,650 --> 00:02:31,919
在屏幕上你们可以看到
一个非常简单的循环


33
00:02:32,186 --> 00:02:34,087
这个循环用数字13对阵列中的所有


34
00:02:34,354 --> 00:02:37,658
元素进行扫描
从而对阵列的内容进行加密


35
00:02:37,891 --> 00:02:39,059
这种加密方式并不好


36
00:02:39,860 --> 00:02:43,096
在阵列边界以外进行读写


37
00:02:43,163 --> 00:02:45,032
是一个严重的错误


38
00:02:45,499 --> 00:02:47,401
也可能有安全隐患


39
00:02:48,101 --> 00:02:52,472
而Swift则可以对你的
程序进行保护它添加了一些代码


40
00:02:52,539 --> 00:02:55,442
能够检查阻止程序
在阵列边界以外进行读写


41
00:02:56,109 --> 00:03:00,047
现在 问题是这种检查
会拖慢代码的运行速度


42
00:03:02,182 --> 00:03:05,319
另一个问题是它会阻挡其他优化


43
00:03:05,385 --> 00:03:07,988
例如在运行这种检查时


44
00:03:08,355 --> 00:03:09,656
我们就不能将这段代码向量化


45
00:03:10,524 --> 00:03:13,193
所以我们已经实现了一个编译器优化


46
00:03:13,627 --> 00:03:16,964
以便将这种检查置于
循环之外使检查的代价


47
00:03:17,030 --> 00:03:21,468
可以忽略不计因为我们并不是
对阵列边界以内遇到的


48
00:03:21,802 --> 00:03:24,037
循环中的每次迭代都进行检查


49
00:03:24,271 --> 00:03:26,673
我们只在进入阵列时进行一次检查


50
00:03:27,174 --> 00:03:28,942
所以这是一个非常强大的优化


51
00:03:29,443 --> 00:03:31,044
它使得数字代码运行得更快


52
00:03:33,080 --> 00:03:36,316
好吧 这是一个优化的一个例子


53
00:03:36,617 --> 00:03:38,619
而我们有很多优化


54
00:03:39,319 --> 00:03:41,021
我们知道这些优化起到了作用


55
00:03:41,221 --> 00:03:44,825
而且非常有效因为我们
正在跟踪数以百计的程序


56
00:03:44,892 --> 00:03:47,594
和基准测试程序在过去的一年里


57
00:03:47,828 --> 00:03:50,931
我们注意到这些程序的
运行速度显著加快


58
00:03:51,398 --> 00:03:53,567
每次我们添加一个新的优化


59
00:03:53,934 --> 00:03:57,171
每次我们对现有的优化进行改进


60
00:03:57,471 --> 00:03:59,640
我们都会注意到这些程序变得更快


61
00:04:00,774 --> 00:04:03,510
现在大家不会有兴趣逐一了解


62
00:04:03,577 --> 00:04:06,947
这些程序所以我决定介绍其中的五个


63
00:04:08,282 --> 00:04:12,619
现在大家在我身后的屏幕上
看到的程序来自多个领域


64
00:04:13,287 --> 00:04:15,956
一个是面向对象的程序


65
00:04:16,055 --> 00:04:19,159
另一个是数字型的 另一个是函数型的


66
00:04:20,459 --> 00:04:22,763
我相信这些程序代表了


67
00:04:22,829 --> 00:04:25,399
如今用户以Swift语言
编写的代码类型


68
00:04:26,333 --> 00:04:28,001
正如大家所见在过去的一年


69
00:04:28,569 --> 00:04:30,304
这些程序明显运行得更快


70
00:04:30,370 --> 00:04:33,040
加快了两到八倍之间这非常了不起


71
00:04:33,707 --> 00:04:36,310
现在这些程序在发布模式下进行了优化


72
00:04:37,211 --> 00:04:39,947
但我知道你们也关心未优化的


73
00:04:40,314 --> 00:04:43,150
程序的性能因为你们花费大量的时间


74
00:04:43,617 --> 00:04:46,320
编写代码进行调试并将其在模拟器运行


75
00:04:46,453 --> 00:04:48,388
所以你们关心未优化程序的性能


76
00:04:49,556 --> 00:04:54,061
所以这五个项目是相同的
均处在调试模式


77
00:04:54,528 --> 00:04:55,462
他们都未经优化


78
00:04:55,996 --> 00:04:58,632
所以你们可能会问自己 等等


79
00:04:58,732 --> 00:05:04,304
对优化器的改进是如何提高
未优化代码的性能的


80
00:05:04,638 --> 00:05:09,042
对吧 我们做了两件事
使未优化的代码运行得更快


81
00:05:09,409 --> 00:05:12,513
首先 我们改进了
Swift的运行时组件


82
00:05:12,813 --> 00:05:16,984
运行时组件负责分配内存


83
00:05:17,050 --> 00:05:19,386
访问元数据以及类似这样的事情


84
00:05:19,453 --> 00:05:20,554
所以我们对它进行了优化


85
00:05:20,954 --> 00:05:24,424
我们做的第二件事是现在我们能够


86
00:05:24,491 --> 00:05:26,927
更好地优化Swift标准库


87
00:05:27,060 --> 00:05:31,965
标准库是含有阵列实现
代码词典和设置的组件


88
00:05:32,299 --> 00:05:35,769
所以通过更好地优化标准库


89
00:05:36,069 --> 00:05:39,706
我们能够提升未优化程序的性能


90
00:05:40,674 --> 00:05:45,145
我们知道在过去的一年经过优化


91
00:05:45,479 --> 00:05:48,882
和未经优化的程序的性能都显著增强


92
00:05:49,449 --> 00:05:51,518
但是为了了解全部的情况
我想给大家做一个


93
00:05:51,585 --> 00:05:53,787
Swift与
Objective-C语言的比较


94
00:05:55,055 --> 00:05:58,859
现在在屏幕上你可以看到
两个非常著名的基准测试程序


95
00:05:59,126 --> 00:06:01,361
这是Richards
和DeltaBlue


96
00:06:01,428 --> 00:06:02,829
都是以面向对象的风格编写的


97
00:06:03,230 --> 00:06:04,331
根据这两个程序的测试


98
00:06:04,531 --> 00:06:06,800
Swift要比
Objective-C快得多


99
00:06:07,467 --> 00:06:09,136
在演讲的这个阶段


100
00:06:09,203 --> 00:06:12,239
我不会告诉你们为什么Swift
要比Objective-C快


101
00:06:12,673 --> 00:06:14,842
但是我向诸位保证
我们还会回到这张幻灯片


102
00:06:15,242 --> 00:06:17,077
而且我们将谈到为什么Swift更快


103
00:06:19,413 --> 00:06:22,549
好 现在我要讲些不一样的东西


104
00:06:23,116 --> 00:06:25,819
我想谈谈一个新的编译器优化模式


105
00:06:25,953 --> 00:06:28,121
叫做“模块整体优化” 


106
00:06:28,388 --> 00:06:30,691
它可以让你的程序运行速度明显加快


107
00:06:31,525 --> 00:06:35,896
但在那之前我想谈谈
Xcode编译文件的方式


108
00:06:38,065 --> 00:06:41,435
Xcode是单独编译每个文件的


109
00:06:42,169 --> 00:06:44,137
这是一个很好的理念


110
00:06:44,471 --> 00:06:47,641
因为它可以在计算机的多个
核心中并行编译很多文件


111
00:06:48,108 --> 00:06:48,942
这样很好


112
00:06:49,042 --> 00:06:52,846
它也可以重新编译
需要更新的只读文件


113
00:06:53,380 --> 00:06:54,214
所以很好


114
00:06:54,548 --> 00:06:59,086
但问题是这种优化器的
处理范围仅限于一个文件


115
00:07:01,555 --> 00:07:05,058
有了模块整体优化模式编译器能够


116
00:07:05,125 --> 00:07:09,029
一次优化整个模块这样的优势很明显


117
00:07:09,129 --> 00:07:11,031
因为它可以分析所有数据


118
00:07:11,632 --> 00:07:12,933
并进行积极的优化


119
00:07:13,567 --> 00:07:17,271
现在 构建整体优化
模式需要更长的时间


120
00:07:19,106 --> 00:07:22,242
但生成的二进制代码通常运行得更快


121
00:07:24,645 --> 00:07:27,181
在Swift 2中我们对
模块整体优化模式


122
00:07:27,247 --> 00:07:28,515
进行了两个主要的改进


123
00:07:28,582 --> 00:07:33,020
首先们添加了新的依靠模块整体


124
00:07:33,520 --> 00:07:35,088
优化模式的优化


125
00:07:36,223 --> 00:07:38,258
所以你们的程序有可能运行得更快


126
00:07:38,992 --> 00:07:44,331
第二我们能够实现编译管道
某些部分并行


127
00:07:44,831 --> 00:07:49,837
所以在模块整体优化模式中的
编译组件应该使用更短的时间


128
00:07:53,106 --> 00:07:55,209
在我身后的屏幕上你可以看到两个程序


129
00:07:55,275 --> 00:07:57,911
它们在模块整体优化模式下运行得更快


130
00:07:58,045 --> 00:08:00,981
因为编译器能够做出更好的决策


131
00:08:01,048 --> 00:08:07,387
它能分析整个模块的信息
并据此做出更积极的优化


132
00:08:10,123 --> 00:08:13,694
在Xcode 7中
我们对优化级别菜单进行了一些更改


133
00:08:14,194 --> 00:08:18,665
现在模块整体优化是你们可以
选择的选项之一


134
00:08:19,233 --> 00:08:21,435
所以我鼓励你们在你们的程序中尝试


135
00:08:21,802 --> 00:08:22,636
模块整体优化模式


136
00:08:23,537 --> 00:08:25,906
说到这一点我想邀请迈克尔上台


137
00:08:25,973 --> 00:08:28,609
给大家讲解Swift代码的底层实现


138
00:08:28,675 --> 00:08:32,179
并给大家一些关于编写高性能
Swift代码的建议


139
00:08:32,379 --> 00:08:33,212
谢谢大家


140
00:08:44,191 --> 00:08:45,025
谢谢 那達夫


141
00:08:46,193 --> 00:08:47,861
今天我想跟大家谈谈


142
00:08:48,195 --> 00:08:53,133
Swift编程语言及其性能
特征的三个不同方面


143
00:08:53,800 --> 00:08:57,271
对于每个方面我都会给出具体的技术
大家可以用它们


144
00:08:57,404 --> 00:08:59,773
来提高你们的app的性能


145
00:09:01,575 --> 00:09:04,111
让我们首先说说引用计数


146
00:09:04,745 --> 00:09:09,616
一般来说编译器可以消除大部分引用
计数的负担不需要任何帮助


147
00:09:10,450 --> 00:09:14,988
但是有时候你还是会发现由于
引用计数的负担造成的代码减速


148
00:09:15,956 --> 00:09:19,593
今天我将展示两种技术 你们可以利用


149
00:09:19,860 --> 00:09:22,095
它们来减少甚至消除这种负担


150
00:09:23,530 --> 00:09:26,033
让我们首先看看引用计数和类的关系


151
00:09:26,366 --> 00:09:29,169
从而了解引用计数的基础知识


152
00:09:30,971 --> 00:09:32,873
这里有一个代码块


153
00:09:33,106 --> 00:09:36,243
它包含一个C类一个包含一个


154
00:09:36,310 --> 00:09:39,146
可选C的函数和几个变量定义


155
00:09:39,613 --> 00:09:41,915
让我们逐行看看代码执行情况


156
00:09:44,084 --> 00:09:46,720
首先我们从分配C类的新实例开始


157
00:09:46,787 --> 00:09:48,822
并将其分配给变量X


158
00:09:49,790 --> 00:09:53,360
注意在类别实例的顶部
有一个包含数字1的框


159
00:09:53,560 --> 00:09:56,230
它代表了类实例的引用计数


160
00:09:56,997 --> 00:10:01,869
当然这是1 因为目前只有一个
类实例的引用 即x


161
00:10:02,903 --> 00:10:05,873
然后我们将X分配给变量y


162
00:10:06,006 --> 00:10:08,041
这将创建一个新的类实例的引用


163
00:10:08,342 --> 00:10:13,614
导致我们增加类实例的引用计数
给我们一个引用计数 2


164
00:10:14,848 --> 00:10:16,583
然后我们中止了y并打开了foo


165
00:10:16,650 --> 00:10:18,719
但是实际上我们并没有中止y本身


166
00:10:18,785 --> 00:10:24,691
相反我们创建了一个临时的C
并把y赋值到C


167
00:10:25,192 --> 00:10:29,263
它可以充当类别实例的第三个引用


168
00:10:29,530 --> 00:10:32,799
这可以导致我们再一次增加
类别实例的引用计数


169
00:10:33,901 --> 00:10:39,473
然后当foo退出时C被摧毁
导致我们减少类别实例的引用计数


170
00:10:39,706 --> 00:10:42,109
使引用计数为2


171
00:10:42,342 --> 00:10:45,445
最后我们赋值零到y和x


172
00:10:45,846 --> 00:10:48,182
使类别实例的引用计数为零


173
00:10:48,448 --> 00:10:49,883
然后它被收回


174
00:10:51,652 --> 00:10:55,255
注意每次我们做了一个任务


175
00:10:55,556 --> 00:10:58,058
我们必须执行引用计数操作


176
00:10:58,225 --> 00:11:00,360
来保持类别实例的引用计数


177
00:11:01,261 --> 00:11:04,364
这是很重要的因为
我们必须一直保持记忆安全


178
00:11:05,866 --> 00:11:09,303
现在对于熟知
Objective-C的你们来说


179
00:11:09,369 --> 00:11:11,872
当然没有什么新的情况发生


180
00:11:12,306 --> 00:11:17,010
减量和增量被谨慎的保留


181
00:11:17,678 --> 00:11:18,545
和解除


182
00:11:19,246 --> 00:11:21,181
但是现在我想告诉你


183
00:11:21,248 --> 00:11:24,451
一些也许更独特更新奇的事情


184
00:11:24,852 --> 00:11:28,088
也就是说结构是如何
引用计数相互影响的


185
00:11:29,356 --> 00:11:35,162
我要开始了...让我们开始讨论
先观察一个不包含引用的类别


186
00:11:36,697 --> 00:11:37,865
这里有一个类别点


187
00:11:38,298 --> 00:11:40,000
当然 它不包含任何引用


188
00:11:40,434 --> 00:11:43,770
但是它有两个特性x和y都是浮点数


189
00:11:44,705 --> 00:11:47,040
如果我存储其中一个点在一个数组中


190
00:11:47,474 --> 00:11:50,711
当然因为它是一个类别
所以我不会把它直接存储在数组中


191
00:11:51,011 --> 00:11:53,714
相反我把参照点存储在数组中


192
00:11:55,015 --> 00:11:56,917
所以当我对该数组进行迭代


193
00:11:57,184 --> 00:12:01,355
并初始化循环变量p的时候


194
00:12:01,421 --> 00:12:04,892
我实际上创建了一个
到类别实例的新的引用


195
00:12:05,292 --> 00:12:07,928
这意味着我必须执行引用计数的增加


196
00:12:08,962 --> 00:12:11,732
然后,当P在循环变量的
最后被摧毁的时候


197
00:12:11,798 --> 00:12:14,168
我必须减少引用计数


198
00:12:15,302 --> 00:12:17,804
在Objective-C中
我们必须时常地


199
00:12:17,971 --> 00:12:20,507
做简单的数据结构比如点


200
00:12:20,574 --> 00:12:24,211
一个你可以使用来自Foundation
像NSRA数据结构的类别


201
00:12:24,978 --> 00:12:27,614
然后无论你何时操作简单的数据结构


202
00:12:27,781 --> 00:12:29,883
你将会使类别产生负荷


203
00:12:30,751 --> 00:12:33,520
在Swift里
我们可以使用结构...


204
00:12:33,587 --> 00:12:36,023
在这种情况下我们可以
使用结构解决问题


205
00:12:36,089 --> 00:12:37,658
而不是一个类别


206
00:12:38,792 --> 00:12:40,994
所以让我们把点做成结构


207
00:12:41,562 --> 00:12:44,898
现在我们能够将各个点
直接存储到这个数组中


208
00:12:44,965 --> 00:12:47,267
因为Swift数组能够
直接存储结构组


209
00:12:47,734 --> 00:12:54,174
更重要的是因为一个结构本身不需要
引用计数 而且这个结构的属性


210
00:12:54,508 --> 00:12:57,144
也不需要引用计数


211
00:12:57,377 --> 00:13:01,315
所以我们可以直接舍弃之前
所有引用的计数在循环中


212
00:13:03,116 --> 00:13:06,453
现在让我们思考一个更加复杂的例子


213
00:13:06,520 --> 00:13:09,656
假设一个结构中包含一个引用的参数


214
00:13:13,093 --> 00:13:17,564
虽然一个结构其本身在
任务中并不需要引用计数变量


215
00:13:17,631 --> 00:13:21,001
就像我之前提到的
但是它确实需要这种变量


216
00:13:21,068 --> 00:13:22,970
如果一个结构中包含了一个引用参数


217
00:13:23,837 --> 00:13:25,939
这是因为分配一个结构


218
00:13:26,240 --> 00:13:30,177
和独立分配每一个属性是等价的


219
00:13:31,278 --> 00:13:33,614
所以考虑到我们之前
看到的关于结构的点


220
00:13:35,082 --> 00:13:38,752
它能够很有效的被复制
当我们分配它的时候就没有引用的计数


221
00:13:39,152 --> 00:13:42,623
假设有一天我在我的app上工作


222
00:13:42,689 --> 00:13:44,691
我决定... 好吧我想要使每一个点


223
00:13:44,758 --> 00:13:47,461
都能被画成不同的颜色


224
00:13:47,661 --> 00:13:51,598
所以我在我的结构中
添加了一个UI颜色属性


225
00:13:52,099 --> 00:13:55,769
当然 Ui颜色是一个类这实际上是在
我的结构中添加了一个参数


226
00:13:57,271 --> 00:14:00,774
现在这就意味着在任何时刻
我要分配这个结构


227
00:14:01,341 --> 00:14:04,344
和独立分配这个结构中的UI颜色


228
00:14:04,912 --> 00:14:08,882
都是等价的这就意味着
我必须执行一个对计数参数的修改


229
00:14:10,317 --> 00:14:14,521
现在虽然使用一个
包含计数参数的结构的代价并不高


230
00:14:14,588 --> 00:14:19,359
我的意思是 我们通常使用类
并且类也有相同的特性


231
00:14:19,893 --> 00:14:23,730
现在我想给你们展示
一个更加极端的例子


232
00:14:24,298 --> 00:14:27,568
即一个包含很多计数字段参数的结构


233
00:14:29,036 --> 00:14:33,340
这里我有一个结构用户我将使用它
来模拟用户在一个我写的app中


234
00:14:33,707 --> 00:14:37,044
并且每个用户都有一些
跟它相关联的数据 即


235
00:14:37,144 --> 00:14:40,781
三个字符串 一个作为用户的名字


236
00:14:41,381 --> 00:14:43,550
一个作为用户的姓氏


237
00:14:43,951 --> 00:14:45,752
一个作为用户的地址


238
00:14:46,887 --> 00:14:49,823
我也有一个空间
来存储数组和一个字典


239
00:14:49,890 --> 00:14:52,759
来存储与用户相关的特定的app数据


240
00:14:54,361 --> 00:14:57,698
即使这些所有的参数都是数值类型的


241
00:14:58,599 --> 00:15:02,002
在其内部 包含一个类


242
00:15:02,402 --> 00:15:05,772
这个类用来管理内部数据的生命周期


243
00:15:06,974 --> 00:15:10,077
这就意味着每次我分配
这些结构中的一个参数


244
00:15:11,411 --> 00:15:14,381
每次我都要将这个参数
推送到一个函数中


245
00:15:14,448 --> 00:15:17,784
事实上我不得不进行
五次计数参数的修改工作


246
00:15:19,219 --> 00:15:22,289
好 我们可以使用包装函式类来操作


247
00:15:23,423 --> 00:15:25,325
这里我再次使用用户结构


248
00:15:25,559 --> 00:15:27,694
但是这次不是只依靠它自己


249
00:15:28,028 --> 00:15:29,730
它包含在一个包装函式类中


250
00:15:30,130 --> 00:15:32,966
我还可以使用类引用来操作这个结构


251
00:15:33,367 --> 00:15:36,303
更重要的是如果我把这个
引用当作一个函数


252
00:15:36,503 --> 00:15:38,305
或我声明-或我签名-


253
00:15:38,372 --> 00:15:39,806
用这个引用来初始化一个变量


254
00:15:39,873 --> 00:15:43,143
我只是在做一个引用计数增量


255
00:15:44,478 --> 00:15:46,847
现在 重要的是要注意到


256
00:15:47,481 --> 00:15:49,683
这里语义有了变化


257
00:15:50,350 --> 00:15:54,388
我们已经从使用真值语义


258
00:15:54,855 --> 00:15:57,191
改变为引用语义


259
00:15:58,358 --> 00:16:02,229
这样就会导致意想不到的
数据共享可能会导致


260
00:16:02,296 --> 00:16:04,798
不可思议的结果或你没想到的事情


261
00:16:06,099 --> 00:16:08,635
但是有一种方式


262
00:16:08,702 --> 00:16:13,574
你可以具有真值语义
并且从这个最优化中受益


263
00:16:14,608 --> 00:16:15,976
如果你想了解更多


264
00:16:16,109 --> 00:16:20,214
请进入用值类型来构建
更好的应用程序的讲座


265
00:16:20,280 --> 00:16:22,382
在Swift明天的任务中


266
00:16:22,449 --> 00:16:24,685
在下午2:30它将是一场精彩的讲座


267
00:16:24,852 --> 00:16:26,286
我真的建议你去


268
00:16:29,690 --> 00:16:32,092
现在我们已经谈论了引用计数


269
00:16:32,860 --> 00:16:36,663
我想继续讨论有关通用型的内容


270
00:16:40,000 --> 00:16:41,802
这里我有一个通用函数min


271
00:16:41,969 --> 00:16:47,274
它是通过类型T的通用性 符合
Swift标准库的比较协议


272
00:16:47,774 --> 00:16:49,476
从源程序的角度来看


273
00:16:49,743 --> 00:16:52,412
这看起来不那么大
我的意思是它只有三行


274
00:16:53,146 --> 00:16:57,351
但是实际上 幕后要比想的多的多


275
00:16:57,918 --> 00:17:00,721
例如这里实际发出的代码


276
00:17:00,888 --> 00:17:04,191
这里我还是使用伪-Swift
来代表编译器发出的代码


277
00:17:04,992 --> 00:17:09,363
编译器发出的代码不是这三行 而是这


278
00:17:10,998 --> 00:17:15,068
首先要注意编译器在使用间接法
来比较X和Y


279
00:17:15,502 --> 00:17:18,137
这是因为我们可以输入两个整数


280
00:17:18,204 --> 00:17:22,108
到min函数或者我们
可以输入两个浮点数


281
00:17:22,175 --> 00:17:24,711
或是两个字符串或我们可以
输入任何可比较类型


282
00:17:24,778 --> 00:17:27,647
这样编译器在所有的情况下都是正确的


283
00:17:27,714 --> 00:17:29,149
并且能够处理它们中的任何一个


284
00:17:30,117 --> 00:17:32,786
另外因为编译器不知道


285
00:17:32,986 --> 00:17:35,689
是否T要求引用计数更改


286
00:17:35,923 --> 00:17:37,791
它必须插入另外的间接法


287
00:17:38,091 --> 00:17:41,595
这样min T函数就
能处理两种类型T


288
00:17:41,762 --> 00:17:45,832
要求引用计数和
不要求引用计数的类型T


289
00:17:46,099 --> 00:17:51,104
例如 对于整数而言
Swift运行时内仅未进行上行调用


290
00:17:52,706 --> 00:17:55,909
在这两种情况下编译器都处于保守模式


291
00:17:56,109 --> 00:18:00,147
因为在这种模式下编译器须能
处理任一T类系统数据


292
00:18:01,548 --> 00:18:06,019
幸运的是编译器优化
能够帮助我们消除重载


293
00:18:06,720 --> 00:18:09,790
编译器优化也称为泛型特殊化


294
00:18:10,891 --> 00:18:15,229
本文中的函数foo将两个整数
传递给泛型函数min-T


295
00:18:15,996 --> 00:18:18,732
执行泛型特殊化时


296
00:18:19,066 --> 00:18:21,702
编译器首先调用了函数min和foo


297
00:18:22,336 --> 00:18:25,405
并且发现两个整数被传递给了
本文中的泛型函数min-T


298
00:18:26,273 --> 00:18:28,742
编译器可以查看


299
00:18:28,809 --> 00:18:33,313
泛型函数min-T的定义
因此其能够克隆函数min-T


300
00:18:34,081 --> 00:18:36,316
并且将克隆的函数进行特殊化处理


301
00:18:36,383 --> 00:18:41,421
方法是将泛型类型T
替换为特殊化类型Int


302
00:18:42,589 --> 00:18:45,158
随后针对函数Int优化特殊函数


303
00:18:45,692 --> 00:18:49,029
并消除与这个函数相关的所有重载


304
00:18:49,096 --> 00:18:52,466
因此这样会删除所有引用计数
即不必要的引用计数调用


305
00:18:52,533 --> 00:18:54,868
并且我们可以
直接对这两个整数进行比较


306
00:18:56,637 --> 00:19:00,040
最后 编译器将泛型函数
min-T的调用替换为


307
00:19:00,374 --> 00:19:04,077
特殊函数min Int的调用


308
00:19:04,311 --> 00:19:06,046
以便进行进一步的优化


309
00:19:08,148 --> 00:19:11,752
泛型特殊化
是一个非常强大的优化方法


310
00:19:12,452 --> 00:19:18,392
但其也有一个不足之处 即
泛型定义的可见性


311
00:19:18,592 --> 00:19:21,628
这类例子包括本文中函数
min-T的泛型定义


312
00:19:23,297 --> 00:19:27,167
这里我们对包含两个整数的
泛型函数min-T进行计算


313
00:19:27,901 --> 00:19:31,772
在这种情况下我们可以执行
泛型特殊化吗？


314
00:19:32,573 --> 00:19:35,475
即使由于我们分别对文件
1.Swift和文件2.Swift


315
00:19:35,542 --> 00:19:37,711
进行编译编译器可以看到
两个整数被传递给了


316
00:19:38,345 --> 00:19:40,414
泛型函数min-T


317
00:19:41,048 --> 00:19:44,685
但当编译器编译文件1时


318
00:19:44,751 --> 00:19:47,521
文件2中函数的定义


319
00:19:47,688 --> 00:19:49,957
对编译器来说不可见


320
00:19:50,123 --> 00:19:54,194
因此当编译文件1时


321
00:19:54,361 --> 00:19:57,531
编译器不能查看
泛型函数min-T的定义


322
00:19:57,831 --> 00:20:01,201
因此我们必须调用泛型函数min-T


323
00:20:02,870 --> 00:20:06,473
但是如果我们启用了全模块优化
情况会是怎样的呢？


324
00:20:07,841 --> 00:20:10,878
如果我们启用了全模块优化


325
00:20:11,211 --> 00:20:15,549
就会同时对文件1.Swift和文件
2.Swift进行编译


326
00:20:16,049 --> 00:20:19,987
这意味着当同时编译文件1或文件2时


327
00:20:20,053 --> 00:20:22,623
文件1和文件2中的定义都是可见的


328
00:20:22,689 --> 00:20:28,061
所以基本上这就意味着
即使min-T泛型函数在文件2中


329
00:20:29,062 --> 00:20:32,599
我们编译文件1的时候可以看到它


330
00:20:33,734 --> 00:20:36,703
因此我们能够将min-T
泛型函数具体化为Min int


331
00:20:36,770 --> 00:20:41,241
并用min int替换调用
min-T的命令


332
00:20:42,409 --> 00:20:46,480
这是能较为明显地体现出
模块优选的整体作用的第二个案例


333
00:20:47,181 --> 00:20:51,051
这个案例中编译器能进行
类属指明的唯一


334
00:20:51,118 --> 00:20:54,154
原因是启动整个模块优化时


335
00:20:54,221 --> 00:20:56,857
编译器能得到附加信息


336
00:21:01,195 --> 00:21:05,465
既然已经讲过了泛型那我想再讲讲


337
00:21:05,899 --> 00:21:08,669
动态调度技术以作总结


338
00:21:11,572 --> 00:21:14,174
这里我有一个宠物类的类层次结构


339
00:21:15,209 --> 00:21:19,713
可以注意到宠物类具有
方法噪声 属类型


340
00:21:20,113 --> 00:21:24,051
以及一个方法噪声处理法
用以处理方法噪声


341
00:21:24,685 --> 00:21:29,590
还可以注意到宠物类的
一个子类狗类可以覆盖噪声


342
00:21:30,190 --> 00:21:32,526
现在再考虑产生噪声的函数


343
00:21:33,126 --> 00:21:34,528
这是一个很简单的函数


344
00:21:34,661 --> 00:21:37,531
它带有一个参数p
这是宠物类的一个特征


345
00:21:38,899 --> 00:21:42,803
即使这个大括号里牵涉的信源不多


346
00:21:44,071 --> 00:21:46,573
但后台的运行却比我们想象得要多


347
00:21:46,874 --> 00:21:51,278
比如下面的Swift伪码
并不是编译器发出的


348
00:21:51,845 --> 00:21:53,780
名称和噪声不是直接被调用的


349
00:21:53,881 --> 00:21:56,450
而是通过编译器发出代码


350
00:21:57,184 --> 00:21:58,952
注意此处调用


351
00:21:59,019 --> 00:22:02,256
名称getter方法
和方法噪声的间接性


352
00:22:02,422 --> 00:22:04,525
编译器必须插入这一间接性


353
00:22:04,825 --> 00:22:08,028
因为它不知道在当前的类层次结构下


354
00:22:08,095 --> 00:22:13,467
属类名和方法噪声是否应该被子类覆盖


355
00:22:14,601 --> 00:22:17,304
这一案例中的编译器只会发出--


356
00:22:17,871 --> 00:22:24,545
如果能够证明没有
名称或者噪声的子类的覆盖的话


357
00:22:24,745 --> 00:22:27,548
只会发出直接调用命令


358
00:22:28,782 --> 00:22:32,052
在噪声的案例中这恰恰就是我们想要的


359
00:22:32,452 --> 00:22:35,856
我们想要噪声能够被这个
应用程序编程接口中的子类覆盖


360
00:22:36,390 --> 00:22:38,792
我们想形成这种效果
就是在一个宠物类的案例中真的


361
00:22:38,892 --> 00:22:42,629
有子类狗类的话如果我
调用噪声这只狗会叫


362
00:22:43,230 --> 00:22:45,933
而在一个真正的宠物类的案例中


363
00:22:46,233 --> 00:22:48,001
如果我调用噪声我们会听到猫叫


364
00:22:48,235 --> 00:22:49,436
这完全是合理的


365
00:22:50,637 --> 00:22:54,641
但在名称的案例中
这实际上是不合需要的


366
00:22:55,342 --> 00:22:56,977
这是因为在这个应用程序编程接口中


367
00:22:57,211 --> 00:23:00,981
名称不是...永远不是被覆盖的


368
00:23:01,048 --> 00:23:02,683
对名称进行覆盖是不必要的


369
00:23:03,217 --> 00:23:06,753
我们可以通过约束这个应用程序
编程接口的类层次结构来建立模型


370
00:23:08,188 --> 00:23:10,057
我今天要向你们介绍


371
00:23:10,123 --> 00:23:13,627
可以用来约束你们的API类
层次结构的两种Swift 语言特征


372
00:23:14,027 --> 00:23:15,696
其一是对继承的约束


373
00:23:16,163 --> 00:23:19,533
其二是通过存取控制约束存取


374
00:23:20,334 --> 00:23:25,138
让我们先谈谈继承约束
也就是最后一个关键词


375
00:23:27,107 --> 00:23:29,476
当某API包含的一项声明上


376
00:23:29,543 --> 00:23:31,044
有最后一个关键词时


377
00:23:31,311 --> 00:23:35,749
该API即传递着一个信息
该声明在任何时候都不会被子类覆写


378
00:23:36,850 --> 00:23:38,485
举一个声音制作的例子


379
00:23:38,986 --> 00:23:42,022
默认情况下编译程序一定会采用间接法


380
00:23:42,456 --> 00:23:44,191
调用getter 以给出名称


381
00:23:44,591 --> 00:23:49,096
因为如果没有更多信息则无法知道


382
00:23:49,329 --> 00:23:51,231
名称是否被子类覆写


383
00:23:51,632 --> 00:23:56,036
但是我们知道在该API中
名称在任何时候都不会被覆写


384
00:23:56,103 --> 00:23:58,472
我们也知道在该API中


385
00:23:59,640 --> 00:24:02,042
并不是要名称能够被覆写


386
00:24:02,242 --> 00:24:04,811
那么我们就可以通过
对名称附上最后一个关键词


387
00:24:05,012 --> 00:24:07,514
对此进行执行和传达


388
00:24:08,949 --> 00:24:12,586
之后编译程序会看名称并意识到 哦


389
00:24:12,653 --> 00:24:14,555
这个在任何时候都不会被子类覆写


390
00:24:14,621 --> 00:24:17,691
而动态分配即间接法可被删除


391
00:24:19,493 --> 00:24:22,863
既然我们已经讲了继承约束


392
00:24:22,930 --> 00:24:25,098
我就要稍微介绍一下存取控制


393
00:24:26,300 --> 00:24:30,771
该API中证明pet
和dog均在单独的文件中


394
00:24:31,071 --> 00:24:35,042
即在pet.Swift和dog.Swift中
但是属于相同的模块 即模块A


395
00:24:35,542 --> 00:24:39,046
除此之外还有一个
叫做Cat的pet子类


396
00:24:39,379 --> 00:24:42,182
它属于另一个模块
但是在文件cat.Swift中


397
00:24:42,583 --> 00:24:43,717
我要问的问题是


398
00:24:43,784 --> 00:24:47,487
编译程序能够向noiseimpl
发出直接调用指令吗？


399
00:24:49,022 --> 00:24:50,457
默认情况下不能


400
00:24:51,158 --> 00:24:53,527
这是因为在默认情况下
编译程序必须假定


401
00:24:53,594 --> 00:24:56,163
该API是要noiseimpl


402
00:24:56,230 --> 00:24:58,899
在Cat 和Dog
这样的子类中被覆写


403
00:24:59,900 --> 00:25:02,503
但是我们知道事实上并非如此


404
00:25:02,803 --> 00:25:06,940
我们知道noiseimpl是
pet.Swift私有实现详细信息


405
00:25:07,374 --> 00:25:11,745
在pet.swift以外不应可见


406
00:25:12,713 --> 00:25:16,016
我们可以通过在noiseimpl上
附上这个私有关键词


407
00:25:16,250 --> 00:25:17,084
从而实现该目的


408
00:25:18,051 --> 00:25:20,454
一旦我们在noiseimpl上
附上这个私有关键词


409
00:25:20,521 --> 00:25:23,690
noiseimpl在
pet.Swift以外不再可见


410
00:25:24,424 --> 00:25:26,760
这意味着编译程序可立即知道


411
00:25:27,027 --> 00:25:30,397
在cat或者dog中
不会出现任何覆写情况


412
00:25:30,464 --> 00:25:32,999
因为它们均不在pet.Swift中


413
00:25:33,333 --> 00:25:39,006
并且在pet.Swift中只有
一个执行noiseimpl的分类即Pet


414
00:25:39,406 --> 00:25:43,177
此时编译程序可向noiseimpl
发出直接调用的指令


415
00:25:44,545 --> 00:25:46,213
我们已经讨论过private


416
00:25:46,747 --> 00:25:50,984
下面来讨论全模块优化与
访问控制间的交互作用


417
00:25:53,320 --> 00:25:57,157
Pet类我们已谈论很多
接下来我们将谈论dog子类


418
00:25:58,025 --> 00:26:01,195
谨记Dog类是Pet类的子类


419
00:26:01,261 --> 00:26:04,865
它包含内部访问但不含公共访问


420
00:26:05,966 --> 00:26:08,368
如果我们调用
Dog类中的noise函数


421
00:26:08,802 --> 00:26:12,105
没有更多信息编译器必须间接嵌入


422
00:26:12,739 --> 00:26:16,810
因为编译器不知道模A不同文档中
是否存在Dog子类


423
00:26:17,911 --> 00:26:20,314
当全模块优化生效时


424
00:26:21,014 --> 00:26:23,450
编译器了获得了模宽的可视度


425
00:26:23,984 --> 00:26:26,420
可以看到模型中所有文档


426
00:26:27,020 --> 00:26:31,425
当然编译器也能看到dog类没有子类


427
00:26:31,758 --> 00:26:34,928
因此编译器可以直接调用


428
00:26:34,995 --> 00:26:36,797
Dog类实例中的noise函数


429
00:26:37,097 --> 00:26:42,035
需要特别关注的是
你必须开启全模型优化模式


430
00:26:42,536 --> 00:26:44,938
却不用改变任何代码


431
00:26:45,706 --> 00:26:47,841
通过给编译器提供更多的信息


432
00:26:48,242 --> 00:26:50,878
使编译器理解类层次体系


433
00:26:51,178 --> 00:26:54,214
更多的信息实现了免费优化


434
00:26:54,414 --> 00:26:57,084
却不增加我的工作量


435
00:26:59,520 --> 00:27:02,689
现在让我们回顾那達夫之前介绍的图表


436
00:27:03,490 --> 00:27:10,297
在面向对象基准测试中


437
00:27:11,298 --> 00:27:13,800
为什么Swift
比Objective-C快很多？


438
00:27:16,937 --> 00:27:20,007
为什么Objective-C中


439
00:27:20,841 --> 00:27:24,878
的编译器不能通过
Ob-C信息发送消除动态分配


440
00:27:25,112 --> 00:27:27,714
不能通过它进行内联 不能进行分析


441
00:27:27,814 --> 00:27:30,217
编译器必须假设


442
00:27:30,350 --> 00:27:32,052
Ob-C另一侧存在信息发送


443
00:27:32,886 --> 00:27:35,923
但在Swift中 编译器有更多信息


444
00:27:36,223 --> 00:27:39,459
它可以看到另一侧的确定信息


445
00:27:39,526 --> 00:27:42,162
能够消除大量实例中的动态分配


446
00:27:43,230 --> 00:27:44,998
这类实例中


447
00:27:45,399 --> 00:27:47,467
显著快速的代码


448
00:27:47,734 --> 00:27:49,770
带来更多运行结果


449
00:27:51,638 --> 00:27:55,375
因此请使用final关键字


450
00:27:55,442 --> 00:27:57,144
与API's intent进行通讯


451
00:27:57,678 --> 00:28:00,414
这有助于编译器理解你的类层次体系


452
00:28:01,315 --> 00:28:03,817
并实现额外优化


453
00:28:04,017 --> 00:28:07,821
但是应谨记根据变化情况


454
00:28:07,888 --> 00:28:09,990
对现有客户进行更新


455
00:28:10,591 --> 00:28:12,993
并在已发布版本中试用全模型优化


456
00:28:13,460 --> 00:28:16,363
这一工具可以优化编译器性能


457
00:28:16,463 --> 00:28:18,465
比如让它变得更加强劲和专业化


458
00:28:18,732 --> 00:28:23,003
通过让编译器能更好得理解
你的应用程序接口中的类继承体系


459
00:28:23,303 --> 00:28:25,606
你不需要做什么


460
00:28:25,672 --> 00:28:29,142
就可以体会到更及时的
动态内存清空的好处


461
00:28:30,410 --> 00:28:32,713
现在有请乔来做介绍


462
00:28:32,980 --> 00:28:35,215
他将为你们展示该
如何使用这些技术和工具


463
00:28:35,282 --> 00:28:37,384
来让你们的应用程序


464
00:28:37,618 --> 00:28:39,386
获得更好的性能体验


465
00:28:47,828 --> 00:28:48,662
谢谢你 迈克尔


466
00:28:48,762 --> 00:28:51,398
我叫乔是这个工具团队里的一名工程师


467
00:28:51,532 --> 00:28:55,169
今天我将要给你们演示这一工具
通过一个运行起来有些慢的程序


468
00:28:55,602 --> 00:28:56,703
来 让我们开始吧


469
00:29:09,049 --> 00:29:11,618
好 现在我们的快速
应用程序正在缓缓得启动


470
00:29:11,685 --> 00:29:14,855
我要做的就是接着继续点击运行按钮


471
00:29:14,922 --> 00:29:17,157
在其下拉列表中选择Profile


472
00:29:17,758 --> 00:29:19,426
这会使我们的应用
在发布模式下运行


473
00:29:19,626 --> 00:29:21,328
然后再以模板选择器的形式启动工具


474
00:29:21,395 --> 00:29:23,063
以便于我们可以好好的描述一下它


475
00:29:23,363 --> 00:29:27,067
鉴于它还在缓缓运行
让我们从时间分析模板开始


476
00:29:28,602 --> 00:29:30,304
在工具界面中只需点击 录制


477
00:29:30,804 --> 00:29:35,075
当你的应用开始启动本工具
会自动在后台开始录制记录它的动作


478
00:29:35,676 --> 00:29:38,612
在这里可以看到我们所运行的程序
在我做任何目标操作之前


479
00:29:38,912 --> 00:29:41,248
它正以60帧每秒的速率运行


480
00:29:41,648 --> 00:29:43,450
一旦我把这些粒子加入屏幕中


481
00:29:43,550 --> 00:29:45,085
它们四处扩散 彼此躲避


482
00:29:45,152 --> 00:29:47,221
正如我想要的那样
这时我们的程序运行速度


483
00:29:47,287 --> 00:29:48,622
变成了每秒38帧


484
00:29:48,689 --> 00:29:50,290
我们失去了接近三分之一的效率


485
00:29:50,891 --> 00:29:52,226
现在我们正视这一问题


486
00:29:52,659 --> 00:29:55,295
退出原来的应用 回到本工具中


487
00:29:56,096 --> 00:29:58,098
让我们来放大一下以便看清发生了什么


488
00:29:58,832 --> 00:30:01,602
只需要拖动这个 向这边拖动


489
00:30:01,802 --> 00:30:05,138
就可以非常便捷得进入视图快速跟
踪模式把你的数据加入水平时间轨


490
00:30:05,839 --> 00:30:06,807
然后呢？


491
00:30:07,307 --> 00:30:10,077
在跟踪视图中可以看到
我们这个应用的CPU使用情况


492
00:30:10,544 --> 00:30:13,380
在我做任何操作之前
我们看左边CPU使用率非常低


493
00:30:13,747 --> 00:30:16,250
当我加入这些粒子CPU变得很高


494
00:30:16,650 --> 00:30:18,752
你们可以看到通过移动你的鼠标


495
00:30:18,819 --> 00:30:21,021
并停悬在这个ruler视图以内
这些取值是什么


496
00:30:21,221 --> 00:30:24,291
你们可以看到我们先是
大约10%左右没有做更多


497
00:30:24,658 --> 00:30:28,328
随后大约100%
所以我们的CPU达到饱和


498
00:30:28,662 --> 00:30:30,597
为了提升我们的性能


499
00:30:30,831 --> 00:30:32,533
我们需要将目前的工作量减少多少


500
00:30:33,166 --> 00:30:34,434
那么我们正在做哪些工作？


501
00:30:34,835 --> 00:30:37,237
下面的该详细信息面板由此进入


502
00:30:38,505 --> 00:30:39,840
所以这是我们所有的线程


503
00:30:40,240 --> 00:30:41,608
继续将此再开启一点


504
00:30:41,875 --> 00:30:46,046
你们可能从调试程序中的Xcode
内侧看到起就熟悉这个调用栈


505
00:30:46,313 --> 00:30:49,816
Start、calls main、calls NS
application main等等


506
00:30:49,917 --> 00:30:52,986
但是Instruments
要告诉你们的是你在该功能内


507
00:30:53,287 --> 00:30:55,455
包括其子功能内 要花费多少时间


508
00:30:55,856 --> 00:30:57,457
即第一栏的Running Time


509
00:30:57,558 --> 00:31:01,428
我们可以看到有11,220毫秒
或者说我们99%的时间


510
00:31:01,795 --> 00:31:04,531
花在了NSApplicationMain
或者其调用的程序上


511
00:31:04,665 --> 00:31:08,135
第二栏 即Self是从功能本身取
instrument的时间


512
00:31:08,468 --> 00:31:10,003
因此不包括其子功能


513
00:31:10,871 --> 00:31:13,173
所以我要做的是看看
self数在哪里变大


514
00:31:13,407 --> 00:31:15,576
即该功能实际在哪里进行大量工作


515
00:31:16,109 --> 00:31:18,545
你可以继续逐一开启 搜寻


516
00:31:18,612 --> 00:31:19,680
但是需要花点时间


517
00:31:20,447 --> 00:31:22,616
我们倒是建议你由此向右


518
00:31:22,816 --> 00:31:24,084
这样放大了详细信息视图


519
00:31:24,751 --> 00:31:28,188
而Instruments将在你的
应用程序中显示最重的那一个堆栈踪迹


520
00:31:28,255 --> 00:31:29,723
在这里所取次数最多


521
00:31:30,190 --> 00:31:33,994
在此你可以再次看到我们的主线程
用了11,229毫秒


522
00:31:35,128 --> 00:31:37,998
从Start开始灰色符号为系统框架


523
00:31:38,265 --> 00:31:40,601
黑色符号如Main是你的代码


524
00:31:41,235 --> 00:31:42,936
我要做的只是向下看这个列表


525
00:31:43,003 --> 00:31:45,772
看它是否有大一些的跳跃
即大约此时有我们感兴趣的事情发生


526
00:31:46,573 --> 00:31:49,042
如果我向下扫过该列表数字慢慢变小


527
00:31:49,109 --> 00:31:52,012
但是在我到这里看到从大约
9000到大约4000的跳跃之前


528
00:31:52,112 --> 00:31:54,648
没有出现大的跳跃


529
00:31:54,715 --> 00:31:57,551
那么那里有事情发生
我打算继续进行点击我的代码


530
00:31:58,185 --> 00:32:00,687
而Instruments
已经自动扩展了左侧调用树


531
00:32:00,754 --> 00:32:02,389
这样你就能看到你刚刚点击了什么


532
00:32:03,557 --> 00:32:04,791
让我将此框起来


533
00:32:06,226 --> 00:32:07,194
这里在发生什么？


534
00:32:07,828 --> 00:32:09,429
好,让我往回来一点


535
00:32:09,496 --> 00:32:14,168
这是NSFiretimer调用
驱动我的仿真速率是60帧/s


536
00:32:14,735 --> 00:32:18,772
这是我的粒子
Sim.app代理更新程序


537
00:32:19,106 --> 00:32:20,841
驱动仿真的Swift程序


538
00:32:21,441 --> 00:32:25,012
在它们之间是个
古怪的类似objc的东西


539
00:32:25,579 --> 00:32:30,817
这只是个thunk
本质上,它是嵌入式函数的解释器


540
00:32:30,884 --> 00:32:34,021
可以使我的代码在SWIFT


541
00:32:34,454 --> 00:32:36,957
的NSFiretime中
进入Objective-C


542
00:32:37,291 --> 00:32:38,892
这就是它的作用 另外我们可以忽略它


543
00:32:39,560 --> 00:32:43,030
现在我们看到更新
程序占有89%系统时间


544
00:32:43,463 --> 00:32:45,666
所以我们需要继续优化这个程序


545
00:32:46,133 --> 00:32:48,068
其它东西我不关心


546
00:32:48,569 --> 00:32:51,905
接下来我将会把它隐藏起来
专注于这个更新程序


547
00:32:51,972 --> 00:32:53,574
通过点击右边的这个箭头


548
00:32:54,541 --> 00:32:56,109
你看 这个周围的东西都隐藏了


549
00:32:56,543 --> 00:32:59,313
运行时间已重置为100%


550
00:32:59,379 --> 00:33:01,114
只是帮你做些心理数学


551
00:33:02,349 --> 00:33:04,151
仔细看看这个函数做了哪些工作


552
00:33:04,218 --> 00:33:06,620
更新Phase Avoid调用
找到最近的邻居


553
00:33:07,087 --> 00:33:09,423
这里进入到非常有意思的部分了


554
00:33:09,857 --> 00:33:12,960
看Swift release
占用40%系统时间


555
00:33:13,026 --> 00:33:15,996
Swift retain
占用35%系统时间


556
00:33:16,396 --> 00:33:20,334
只是这两个函数 我们就
占用了3/4的系统时间


557
00:33:20,400 --> 00:33:22,870
仅仅是个管理引用计数的更新程序


558
00:33:23,604 --> 00:33:24,538
差的远


559
00:33:24,638 --> 00:33:26,039
接下来干啥？


560
00:33:26,573 --> 00:33:28,675
恩 如果我双击寻找最近的邻居程序


561
00:33:29,676 --> 00:33:31,378
这调用了那些
retains和release


562
00:33:31,445 --> 00:33:33,146
Instruments将显示源代码


563
00:33:33,247 --> 00:33:35,716
然而Swift是自动引用计数语言


564
00:33:35,782 --> 00:33:38,552
所以你不会直接看到
这些release和retain


565
00:33:39,219 --> 00:33:41,955
但你能如果你翻到反编译视图


566
00:33:42,623 --> 00:33:43,657
点击按钮


567
00:33:44,191 --> 00:33:46,693
Instruments将会显示
编译器实际产生的代码


568
00:33:46,860 --> 00:33:49,630
你可以在这找找这里有很多的调用


569
00:33:49,997 --> 00:33:52,432
这个release占用了23%时间


570
00:33:52,733 --> 00:33:54,735
这里有更多的
retain和release


571
00:33:54,801 --> 00:33:56,336
这是另一个release


572
00:33:56,403 --> 00:33:58,672
它们到处都是对于这我们该怎么做？


573
00:33:59,840 --> 00:34:04,178
让我们回到代码找到粒子文件


574
00:34:04,311 --> 00:34:05,579
这是类粒子


575
00:34:05,646 --> 00:34:07,047
所以它是一个默认的内部类


576
00:34:07,381 --> 00:34:09,315
它符合协作协议


577
00:34:09,683 --> 00:34:10,516
好的


578
00:34:11,251 --> 00:34:15,289
下面是...这是寻找最近的邻居程序
之前它会占用所有的时间


579
00:34:15,956 --> 00:34:18,225
现在我知道当更新时间器启动时


580
00:34:18,292 --> 00:34:21,795
代码会在屏幕上每一个
粒子上去调用寻找最近的邻居程序


581
00:34:22,663 --> 00:34:24,831
那么这个内部循环开始


582
00:34:24,898 --> 00:34:26,934
遍历屏幕上的每一个粒子


583
00:34:27,067 --> 00:34:30,404
这里我们有一个N2算法


584
00:34:30,469 --> 00:34:33,806
循环的工作是产生非常巨量的时间值


585
00:34:34,440 --> 00:34:37,210
我们所做的优化工作将有很大作用


586
00:34:37,844 --> 00:34:38,679
看，发生了什么？


587
00:34:39,012 --> 00:34:40,447
在我们访问这些粒子时


588
00:34:40,514 --> 00:34:43,750
我们有循环了有一些retain
和release的开销


589
00:34:44,418 --> 00:34:47,888
这是正在调用的属性getter
这个.ID属性


590
00:34:48,255 --> 00:34:49,356
前面迈克尔说过的


591
00:34:49,422 --> 00:34:50,690
既然这是一个内部类


592
00:34:50,757 --> 00:34:52,226
这里应该有一些


593
00:34:52,292 --> 00:34:54,761
跨越这些属性getter的
Swift文件


594
00:34:54,828 --> 00:34:56,563
我们执行这些属性getter


595
00:34:56,797 --> 00:35:00,100
的动态调度这些属性getter
都有retain/release开销


596
00:35:00,968 --> 00:35:03,103
接下来是一个求距离平方的函数调用


597
00:35:03,604 --> 00:35:06,573
事实上它有十几个源代码行


598
00:35:06,640 --> 00:35:10,410
我们再一次去做动态调用程序


599
00:35:10,744 --> 00:35:13,247
所有的开销和retain
 release开销都一样


600
00:35:14,047 --> 00:35:16,083
对这个代码我们能做点什么


601
00:35:16,350 --> 00:35:18,018
恩 这是个完整代码


602
00:35:18,318 --> 00:35:20,020
这是我写的 我完了


603
00:35:20,087 --> 00:35:23,357
我的粒子类是完整的 不需要子类


604
00:35:23,590 --> 00:35:25,559
我应该通过把这个类标记为final


605
00:35:25,626 --> 00:35:28,195
把我的意图告诉编译器


606
00:35:31,131 --> 00:35:34,601
就是这么一点改变让我们继续 
再次配置应用 看看


607
00:35:36,837 --> 00:35:39,339
现在编译器能够编译这个文件了


608
00:35:39,406 --> 00:35:41,808
也知道这个粒子文件


609
00:35:41,875 --> 00:35:44,444
没有其它的子类了 抱歉


610
00:35:44,878 --> 00:35:48,615
这意味着它能够进行其它的优化了


611
00:35:48,849 --> 00:35:50,517
可以直接调用这些函数


612
00:35:50,584 --> 00:35:53,387
甚至让它们内部联结或者其它的优化


613
00:35:53,620 --> 00:35:55,789
这可以减少我们之前的开销


614
00:35:56,590 --> 00:36:00,260
打开记录 这次加载这些粒子


615
00:36:00,661 --> 00:36:03,497
看看这次它们以60帧/s的速度运行


616
00:36:03,564 --> 00:36:06,667
让我们回到优化前的每秒20帧


617
00:36:07,301 --> 00:36:08,235
不错


618
00:36:08,468 --> 00:36:09,903
然而你可能会猜到


619
00:36:09,970 --> 00:36:13,540
第二节是冲突当我们换一个算法


620
00:36:13,607 --> 00:36:14,942
现在它们相互冲突了


621
00:36:15,242 --> 00:36:19,346
帧速率下降了25%回到了45帧/s


622
00:36:19,980 --> 00:36:23,083
我们再次面临性能问题
回到Instruments


623
00:36:23,250 --> 00:36:24,918
看看 发生了什么


624
00:36:25,419 --> 00:36:28,488
我们将把之前做的再做一遍
把这个放大一点


625
00:36:29,022 --> 00:36:31,825
点击Snap Track to Fit
现在怎么样？


626
00:36:32,259 --> 00:36:35,462
看左边 这是回避阶段


627
00:36:35,562 --> 00:36:39,433
变好了 提升了大约30%到40%


628
00:36:39,499 --> 00:36:41,602
这是我们每秒60帧的原因


629
00:36:42,369 --> 00:36:45,172
看右边这是冲突阶段


630
00:36:45,239 --> 00:36:48,475
现在这会占有100%的CPU性能


631
00:36:48,742 --> 00:36:50,277
帧速率又下来了


632
00:36:50,978 --> 00:36:54,948
再做一次刚才做的事调用数据树


633
00:36:55,015 --> 00:36:57,618
仔细看看这个窗口中有


634
00:36:57,684 --> 00:36:59,653
回避阶段的数据运行良好


635
00:36:59,953 --> 00:37:03,457
也有冲突数据这是
需要我真正去关注解决的


636
00:37:04,124 --> 00:37:08,161
回避阶段的样本会平滑我们的结果


637
00:37:08,529 --> 00:37:11,932
所以我将设置一个时间
过滤器让我能只看冲突阶段


638
00:37:12,299 --> 00:37:13,567
很简单


639
00:37:13,734 --> 00:37:15,502
只需要在时间线中点击和拖拽就行


640
00:37:16,069 --> 00:37:17,571
现在我们的细节窗格更新了


641
00:37:17,638 --> 00:37:19,907
只显示我们的冲突阶段了


642
00:37:20,841 --> 00:37:22,476
现在我们再做一次


643
00:37:23,310 --> 00:37:24,778
从头回到我们的扩展细节视图


644
00:37:25,712 --> 00:37:28,782
向下看这个列表看有跳跃的地方


645
00:37:29,216 --> 00:37:32,619
有趣的事情发生了从8000毫秒


646
00:37:32,686 --> 00:37:33,921
到2000毫秒


647
00:37:34,288 --> 00:37:36,623
所以我去点这里的冲突检测类


648
00:37:37,691 --> 00:37:40,894
Instruments
再次自动展开了调用树


649
00:37:41,628 --> 00:37:43,397
让我们看看这里发生了什么


650
00:37:43,530 --> 00:37:48,368
88%的时间花在了这里的
运行时间步进程序很好的挖掘点


651
00:37:48,936 --> 00:37:52,005
再来一次 点右边这个关注箭头


652
00:37:52,673 --> 00:37:54,575
现在我们只看运行时间步进程序


653
00:37:55,309 --> 00:37:56,410
看看它在做什么


654
00:37:57,277 --> 00:37:59,680
好 25%的时间用在了


655
00:37:59,746 --> 00:38:02,683
Swift.array.underscore
返回元素节点这个项目上


656
00:38:02,816 --> 00:38:05,719
当你看这个三角括号里的A时


657
00:38:05,819 --> 00:38:10,157
意味之你正在调用函数的
通用格式和所有需要的开销


658
00:38:10,791 --> 00:38:15,429
你会再次在Swift数组的
三角括号里的A这个位置看到


659
00:38:15,729 --> 00:38:17,631
这是个有效的子脚本


660
00:38:18,031 --> 00:38:20,834
当你把三角括号换成方括号也是一样的


661
00:38:20,901 --> 00:38:23,437
所以我们正在调用的
是通用属性getter


662
00:38:24,104 --> 00:38:26,240
在这三个通用函数之间


663
00:38:26,306 --> 00:38:32,112
我们看到大约50%的时间用在了
这三个通用函数


664
00:38:32,446 --> 00:38:34,715
我们怎么做才能消除这些开销呢


665
00:38:35,582 --> 00:38:37,217
好 回到Xcode


666
00:38:38,752 --> 00:38:40,320
这是我的冲突检测文件


667
00:38:40,854 --> 00:38:44,591
这是冲突协议我的粒子会服从这些协议


668
00:38:45,025 --> 00:38:47,361
这是通用类 类检测


669
00:38:47,661 --> 00:38:50,230
T类型会符合一个冲突协议


670
00:38:50,764 --> 00:38:54,801
它做的是它的冲突数组
这是通用的T类型


671
00:38:55,435 --> 00:38:58,305
下面的是我们的运行时间步进程序


672
00:38:59,072 --> 00:39:00,574
这是我们开销的地方


673
00:39:00,974 --> 00:39:02,276
这个函数做了什么


674
00:39:02,643 --> 00:39:05,779
恩 它遍历了我们所有的冲突
从一个数组访问了一个冲突


675
00:39:05,846 --> 00:39:09,716
调用了大量的属性getter


676
00:39:10,017 --> 00:39:10,851
这里更多


677
00:39:11,051 --> 00:39:14,488
这是个内部循环调用
像前面我们做的一样


678
00:39:14,555 --> 00:39:16,423
我们把另一个冲突从数组中拉出来


679
00:39:16,723 --> 00:39:18,392
然后是所有的属性getter


680
00:39:18,559 --> 00:39:23,630
我们做了很多的通用操作我们应该
把这些都干掉我们怎么做呢？


681
00:39:24,164 --> 00:39:29,736
这次你可以看我的冲突检测类
就在Swift文件里


682
00:39:30,103 --> 00:39:36,210
然而这个用户在用这个类的App代理


683
00:39:36,276 --> 00:39:39,479
程序中这个Swift文件的粒子
它在这个模型的另一部分


684
00:39:39,847 --> 00:39:42,382
我们要转到 Whole 
Module Optimization


685
00:39:42,716 --> 00:39:45,152
很简单点工程


686
00:39:46,353 --> 00:39:48,222
在build设置参数中


687
00:39:48,622 --> 00:39:52,893
确定是所有的在
build设置参数找到优化


688
00:39:54,061 --> 00:39:56,997
这是优化参数那達夫之前演示过的


689
00:39:57,231 --> 00:40:00,367
你只要把你的release生成参数
切换到全模型优化


690
00:40:01,034 --> 00:40:02,135
现在当我们配置的时候


691
00:40:02,736 --> 00:40:07,241
编译器正在查看所有的文件
创建一个更优的二进制文件


692
00:40:07,441 --> 00:40:08,642
但是让我们看看会发生什么


693
00:40:09,276 --> 00:40:11,311
我们将第三次运行时间分析器


694
00:40:12,012 --> 00:40:15,749
开始记录 60帧/s


695
00:40:16,149 --> 00:40:19,720
添加粒子冲突的阶段仍在运行
以60帧/s的速率


696
00:40:19,887 --> 00:40:22,422
好 我希望这没什么变化一直很好


697
00:40:23,056 --> 00:40:24,892
然后我们转到冲突阶段


698
00:40:24,992 --> 00:40:27,661
现在它仍运行在60帧/s


699
00:40:28,028 --> 00:40:30,330
所有的配置只需几分钟


700
00:40:30,397 --> 00:40:31,632
和一些小的调整


701
00:40:31,732 --> 00:40:33,500
我们让程序变得快多了


702
00:40:42,709 --> 00:40:44,211
好的 归纳一下我们今天看到的


703
00:40:44,578 --> 00:40:47,014
我们知道Swift是
一种灵活的编程语言


704
00:40:47,281 --> 00:40:51,652
使用安全的自动引用计数完成内存管理


705
00:40:51,952 --> 00:40:53,921
这些强大的功能让人


706
00:40:53,987 --> 00:40:56,423
愉悦的编写代码
虽然这带来一些额外i的开销


707
00:40:56,590 --> 00:40:59,426
我们想做的是让你
专注于你的APIs和代码


708
00:40:59,493 --> 00:41:01,862
当你在编写它们时保持高效思维


709
00:41:02,296 --> 00:41:04,331
你怎么确定额外开销呢


710
00:41:04,665 --> 00:41:06,533
在Instruments
分析你的应用程序


711
00:41:06,600 --> 00:41:09,102
在开发代码的全生命周期里


712
00:41:09,469 --> 00:41:11,071
当你发现问题时都需要这样做


713
00:41:11,138 --> 00:41:13,540
你会更快更准更容易的定位问题的原因


714
00:41:13,607 --> 00:41:16,076
尤其是你的APIs发生变化时


715
00:41:17,811 --> 00:41:22,149
有些在线文档当然你可以去
Developer Forums


716
00:41:22,216 --> 00:41:25,085
得到Swift问题的答案和解决方案


717
00:41:26,320 --> 00:41:31,024
说到解决方案今天3:30在
Mission有一个深度案例分析


718
00:41:31,091 --> 00:41:35,963
专门讨论时间分析器比
我们今天讲的更深入


719
00:41:36,396 --> 00:41:40,100
像之前迈克尔提到过的使用Swift
的数值类型可以建立更好的应用


720
00:41:40,434 --> 00:41:43,937
如你今天所看到的谢谢你们

