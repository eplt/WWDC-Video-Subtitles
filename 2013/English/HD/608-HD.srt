1
00:00:00,506 --> 00:00:10,236
[ Silence ]


2
00:00:10,736 --> 00:00:11,466
>> Kevin: Hello.


3
00:00:11,466 --> 00:00:13,556
This is section 608, Preparing


4
00:00:13,556 --> 00:00:16,076
and Presenting Media
for Accessibility.


5
00:00:16,746 --> 00:00:18,856
Welcome. We think
that you're here


6
00:00:19,326 --> 00:00:21,846
because you are a
content provider involved


7
00:00:21,846 --> 00:00:23,876
in the production of
content and you're ready


8
00:00:23,876 --> 00:00:27,136
to make your content more
useful, more accessible


9
00:00:27,546 --> 00:00:29,516
to more users in
more situations,


10
00:00:29,746 --> 00:00:32,156
or you're an app
developer and you also want


11
00:00:32,156 --> 00:00:35,006
to make your app more useful to
more users in more situations.


12
00:00:35,316 --> 00:00:38,286
We think that's great stuff, and
we have technology that's going


13
00:00:38,376 --> 00:00:40,236
to help, and we're
going to cover it


14
00:00:40,236 --> 00:00:41,736
in this session right now.


15
00:00:42,426 --> 00:00:44,426
We're going to talk about
accessibility options


16
00:00:44,426 --> 00:00:47,776
for time media that take the
form of subtitles and captions.


17
00:00:48,126 --> 00:00:50,196
We're going to touch upon
accessibility options


18
00:00:50,196 --> 00:00:53,096
that take other forms as
well, such as audio forms.


19
00:00:53,806 --> 00:00:57,006
We know that some of you may
be motivated to hear this talk


20
00:00:57,276 --> 00:01:00,266
because you believe that
legislation may apply to you,


21
00:01:00,266 --> 00:01:03,926
in particular in the U.S., that
the 21st Century Communications


22
00:01:03,926 --> 00:01:07,166
and Video Accessibility
Act and the FCC rules


23
00:01:07,166 --> 00:01:08,796
that are established
to implement


24
00:01:08,796 --> 00:01:10,616
that act may apply to you.


25
00:01:11,136 --> 00:01:12,956
We want to tell you up
front that the presenters


26
00:01:12,956 --> 00:01:14,706
in this session are not lawyers,


27
00:01:15,066 --> 00:01:17,476
and we're not the appropriate
people to review this law


28
00:01:17,476 --> 00:01:19,466
and tell you how it
may apply to you.


29
00:01:19,796 --> 00:01:22,686
We encourage you to perform
that review on your own.


30
00:01:23,476 --> 00:01:25,476
But we believe that
we do have technology


31
00:01:25,476 --> 00:01:28,026
that can help you meet
your responsibility


32
00:01:28,026 --> 00:01:30,026
under that law if
it applies to you.


33
00:01:30,526 --> 00:01:33,476
So, more about what we will
talk about in this session,


34
00:01:33,476 --> 00:01:35,566
since we're not lawyers
but software developers:


35
00:01:35,836 --> 00:01:39,886
we're going to talk about how
Apple's platforms, OS X and iOS,


36
00:01:40,426 --> 00:01:43,226
support accessibility
options for time media


37
00:01:43,446 --> 00:01:46,406
with built-in features,
support for user preferences


38
00:01:46,676 --> 00:01:49,186
and automatic application
of those user preferences.


39
00:01:49,596 --> 00:01:52,076
We're going to tell you, if
you're one of the developers


40
00:01:52,256 --> 00:01:54,866
who needs to - we don't think
that's all of you, but for those


41
00:01:54,866 --> 00:01:58,756
of you who do need to implement
user interface that allows users


42
00:01:58,756 --> 00:02:01,596
to select specific media
options for playback -


43
00:02:01,596 --> 00:02:03,436
we're going to talk about
how you can do that,


44
00:02:04,306 --> 00:02:06,696
and for content providers,
we're going to talk


45
00:02:06,696 --> 00:02:10,496
about multiple options that
you have to package your media,


46
00:02:10,496 --> 00:02:13,726
your audio and video, together
with accessibility options.


47
00:02:13,726 --> 00:02:15,796
In particular, we're
going to talk about HTML5,


48
00:02:15,846 --> 00:02:18,576
we're going to talk
about HTTP Live Streaming


49
00:02:18,576 --> 00:02:20,746
and what you can do
there, we're going to talk


50
00:02:20,746 --> 00:02:22,716
about the QuickTime
movie file format


51
00:02:22,716 --> 00:02:24,996
and its closely allied
format, MPEG4.


52
00:02:25,136 --> 00:02:29,366
We're even going to go as far as
to show the API you need to use


53
00:02:29,366 --> 00:02:32,996
to add subtitles to existing
movie and MPEG4 files.


54
00:02:33,566 --> 00:02:36,776
Finally, for the very
few developers who need


55
00:02:36,776 --> 00:02:40,406
to mediate the rendering
of text during playback,


56
00:02:40,646 --> 00:02:43,196
we're going to touch upon
the API's we have available


57
00:02:43,376 --> 00:02:44,536
if you need to do that.


58
00:02:44,626 --> 00:02:45,646
So, lots of content.


59
00:02:46,776 --> 00:02:49,576
Before we move on
let's talk about where


60
00:02:49,576 --> 00:02:51,826
in the technology stack
we're focusing our attention


61
00:02:51,826 --> 00:02:52,516
in this session.


62
00:02:52,856 --> 00:02:55,946
When we talk about API's here
we're going to be talking


63
00:02:55,946 --> 00:02:58,726
about application programming
interfaces that are available


64
00:02:59,066 --> 00:03:02,506
in the AV Foundation framework,
Apple's foundational framework


65
00:03:02,506 --> 00:03:04,556
for the control of
audio visual media.


66
00:03:04,846 --> 00:03:07,956
It sits in iOS below
the view system,


67
00:03:08,036 --> 00:03:09,726
above some of the
core frameworks.


68
00:03:09,976 --> 00:03:13,086
One of the frameworks that it
supports, I want to call out,


69
00:03:13,306 --> 00:03:14,796
is the Media Player framework.


70
00:03:15,066 --> 00:03:17,906
That's an important framework to
mention in this session as well


71
00:03:18,176 --> 00:03:20,816
because it provides
standard user interface


72
00:03:21,266 --> 00:03:23,706
and standard behavior
for the control


73
00:03:23,706 --> 00:03:25,496
of multimedia playback on iOS.


74
00:03:25,496 --> 00:03:30,216
AV Foundation sits in
a similar place on OS X


75
00:03:30,286 --> 00:03:31,316
in the technology stack.


76
00:03:31,316 --> 00:03:32,716
It's a cross-platform framework.


77
00:03:32,716 --> 00:03:35,776
The same set of API's are
available on both platforms.


78
00:03:36,776 --> 00:03:38,576
Again it sits underneath
the view system


79
00:03:38,576 --> 00:03:40,916
and supports a framework
that's new


80
00:03:41,026 --> 00:03:45,626
in OS X Mavericks called AVKit,
which is the analog for OS X


81
00:03:45,926 --> 00:03:47,946
to the Media Player
framework on iOS.


82
00:03:48,146 --> 00:03:52,686
AVKit provides standard user
interface and standard behavior


83
00:03:52,906 --> 00:03:54,696
for the control of
multimedia playback,


84
00:03:54,696 --> 00:03:57,996
and if you adopt it all of that
standard behavior can be part


85
00:03:57,996 --> 00:03:59,026
of your app as well.


86
00:04:01,056 --> 00:04:04,266
So we need to define some terms
before we get into the meat,


87
00:04:04,266 --> 00:04:05,506
so let's do that real quickly.


88
00:04:05,736 --> 00:04:09,456
When I talk about multimedia,
timed media, audio visual media


89
00:04:09,456 --> 00:04:11,436
in this session, what
am I referring to?


90
00:04:11,676 --> 00:04:14,816
Well, I'm referring to the big
revolution that occurred now


91
00:04:14,816 --> 00:04:18,166
over 20 years ago when
digital devices first began


92
00:04:18,166 --> 00:04:21,065
to play video and
audio and even text


93
00:04:21,346 --> 00:04:22,606
in synchronization
with each other.


94
00:04:22,606 --> 00:04:24,146
This is not news to any of us.


95
00:04:24,286 --> 00:04:27,946
We take this feature for granted
in our digital devices nowadays.


96
00:04:29,556 --> 00:04:32,866
But I want to point it out
that there are multiple pieces


97
00:04:32,866 --> 00:04:36,646
of media being synchronized
together, and therefore


98
00:04:36,646 --> 00:04:39,306
when a content provider
creates a piece of multimedia,


99
00:04:39,586 --> 00:04:43,996
there must implicitly be some
decision, some partitioning


100
00:04:43,996 --> 00:04:46,126
of the information that's
going to be conveyed


101
00:04:46,276 --> 00:04:48,036
into the different media types.


102
00:04:48,366 --> 00:04:51,396
What information is going
to be presented visually


103
00:04:51,396 --> 00:04:53,046
and available as
part of the video?


104
00:04:53,406 --> 00:04:56,326
What information is going to
be conveyed aurally or audibly


105
00:04:56,506 --> 00:04:57,786
and be part of the soundtrack?


106
00:04:58,086 --> 00:05:00,926
And what information is going
to be provided in text form?


107
00:05:02,376 --> 00:05:04,776
Most content providers
understand that even though


108
00:05:04,776 --> 00:05:07,486
if they have a default
partitioning of this information


109
00:05:07,486 --> 00:05:10,006
in mind, that default
partitioning is not going


110
00:05:10,006 --> 00:05:13,116
to be suitable for all of the
users that they want to reach.


111
00:05:13,646 --> 00:05:15,556
For example, there
might be some users


112
00:05:15,556 --> 00:05:17,846
who don't understand the
language that's being spoken


113
00:05:17,846 --> 00:05:21,876
in the soundtrack who might
want subtitles for translation.


114
00:05:22,306 --> 00:05:24,586
Those users might be able
to hear the soundtrack


115
00:05:25,176 --> 00:05:27,716
and receive all of the other
information that's being


116
00:05:27,716 --> 00:05:30,726
conveyed, either via music
or via sound effects.


117
00:05:31,116 --> 00:05:33,416
They can even hear the
speech that's being spoken


118
00:05:33,626 --> 00:05:35,866
and can identify the
speakers who are speaking;


119
00:05:36,166 --> 00:05:38,316
they just don't understand the
words that are being spoken.


120
00:05:38,566 --> 00:05:41,866
They're going to want
timed text in translation


121
00:05:41,866 --> 00:05:43,386
so that they can
understand the speech.


122
00:05:43,596 --> 00:05:46,936
Well, let's go a little bit
further and imagine a user


123
00:05:46,936 --> 00:05:50,826
who doesn't have access to
that audio content at all,


124
00:05:50,996 --> 00:05:54,536
either because of deafness,
because of hardness of hearing,


125
00:05:54,676 --> 00:05:57,976
or because of the situation
that the user happens to be in.


126
00:05:58,176 --> 00:06:00,946
For example, imagine a user
who's sitting in the back


127
00:06:00,946 --> 00:06:04,226
of an airplane, near a noisy
engine, and has brought an iPad


128
00:06:04,226 --> 00:06:07,976
on board and wants to watch a
video but doesn't have access


129
00:06:07,976 --> 00:06:10,486
to the audio without cranking
the volume up really high


130
00:06:10,486 --> 00:06:12,826
in the ear buds and
doesn't want to do that.


131
00:06:13,196 --> 00:06:14,466
How can that information


132
00:06:14,466 --> 00:06:17,876
that the content provider
originally decided to partition


133
00:06:17,926 --> 00:06:19,636
into the audio content,


134
00:06:19,636 --> 00:06:21,656
how could that information
be made available


135
00:06:21,816 --> 00:06:23,146
to users like that?


136
00:06:23,736 --> 00:06:27,776
Well typically it's done via
an alternative type of media,


137
00:06:28,116 --> 00:06:29,986
usually via timed text.


138
00:06:31,006 --> 00:06:34,366
So multimedia can
have the ability


139
00:06:34,366 --> 00:06:37,366
to carry not just a
single text option


140
00:06:37,656 --> 00:06:39,666
but multiple timed text options


141
00:06:39,936 --> 00:06:42,376
to provide different
features for different users.


142
00:06:42,556 --> 00:06:45,706
There can be subtitles for
translation, for example.


143
00:06:46,246 --> 00:06:49,686
There can be subtitles
for accessibility.


144
00:06:50,176 --> 00:06:53,456
A term that's commonly used
for subtitles for accessibility


145
00:06:53,886 --> 00:06:57,316
in the Blu-ray domain and
others is subtitles for the deaf


146
00:06:57,316 --> 00:07:00,086
or hard of hearing,
abbreviated as SDH.


147
00:07:00,426 --> 00:07:02,606
So here I've got a picture
of a piece of multimedia


148
00:07:02,606 --> 00:07:03,806
that has audio, video


149
00:07:04,066 --> 00:07:07,036
and multiple text options
for different users.


150
00:07:07,466 --> 00:07:11,176
It's important to remember the
distinction between timed text


151
00:07:11,226 --> 00:07:14,146
for accessibility and
timed text for translation.


152
00:07:14,536 --> 00:07:17,876
The difference is the additional
information that the timed text


153
00:07:17,876 --> 00:07:20,636
for accessibility carries,
exactly those things


154
00:07:20,636 --> 00:07:21,546
that we just mentioned.


155
00:07:21,936 --> 00:07:24,146
Identification of
speakers is important,


156
00:07:24,786 --> 00:07:27,406
description of stuff going
on in the soundtrack other


157
00:07:27,406 --> 00:07:29,566
than the speech, such
as sound effects.


158
00:07:29,856 --> 00:07:32,596
Do all the characters in the
frame suddenly turn to look


159
00:07:32,876 --> 00:07:34,566
because of the sound
of a breaking glass,


160
00:07:34,996 --> 00:07:36,666
or the thud of a falling body?


161
00:07:37,246 --> 00:07:40,276
How would you know if the
SDH subtitles don't tell you?


162
00:07:40,656 --> 00:07:42,196
It's important to
describe those things.


163
00:07:43,036 --> 00:07:48,496
So, the same is true for
other types of information


164
00:07:48,496 --> 00:07:49,596
in the soundtrack as well.


165
00:07:50,096 --> 00:07:53,626
It's not good enough just to
supply multiple text options,


166
00:07:53,926 --> 00:07:56,116
it's also necessary to make sure


167
00:07:56,116 --> 00:07:57,556
that they are appropriately
labeled


168
00:07:57,816 --> 00:08:01,476
so the user can choose the one
that's more appropriate for him


169
00:08:01,476 --> 00:08:05,606
or her: the language that
the text use, the features


170
00:08:05,606 --> 00:08:06,506
that the text carries.


171
00:08:06,576 --> 00:08:08,716
Is it just a transcription
of the dialog


172
00:08:08,716 --> 00:08:14,256
or does it also include this
other information as well?


173
00:08:14,456 --> 00:08:17,306
Other users might require
other accessibility options.


174
00:08:17,526 --> 00:08:20,766
For example, imagine a
user who lacks access


175
00:08:20,946 --> 00:08:23,336
to the visual portion of
the multimedia content.


176
00:08:23,936 --> 00:08:26,236
Such a user will want
to know what's going on,


177
00:08:26,416 --> 00:08:29,306
what's depicted, in the
visual portion of the content


178
00:08:29,476 --> 00:08:30,986
but requires that information


179
00:08:30,986 --> 00:08:33,236
to be conveyed via
an alternative means.


180
00:08:33,456 --> 00:08:34,916
What can be done in that case?


181
00:08:35,256 --> 00:08:37,186
Well what's often
done in that case is


182
00:08:37,186 --> 00:08:40,596
to include the information in
an alternative audio option


183
00:08:40,885 --> 00:08:43,976
that includes a narration,
a description of the setting


184
00:08:43,976 --> 00:08:47,796
and the action that's
important for the user


185
00:08:47,796 --> 00:08:49,356
to follow what's going on.


186
00:08:50,136 --> 00:08:54,246
So again, the idea is we can
supply multiple audio options


187
00:08:54,246 --> 00:08:55,926
that are suitable
for different users.


188
00:08:56,036 --> 00:08:59,926
We can supply dubbed audio for
those users who simply want


189
00:08:59,926 --> 00:09:04,286
to hear the text, the speech
spoken, in translation.


190
00:09:04,516 --> 00:09:07,686
A re-recording of the dialog
mixed in with the music


191
00:09:08,026 --> 00:09:10,046
and the sound effects.


192
00:09:10,426 --> 00:09:12,866
But we also might want to
provide an audio option


193
00:09:12,866 --> 00:09:15,626
that includes what I just
mentioned, a narration,


194
00:09:16,206 --> 00:09:18,616
descriptive audio,
often called DVS


195
00:09:18,836 --> 00:09:21,986
or descriptive video services
in some parts of the world.


196
00:09:22,386 --> 00:09:24,036
This audio will include
a narration


197
00:09:24,036 --> 00:09:26,296
that makes the visual
content accessible.


198
00:09:26,776 --> 00:09:31,206
Again the audio options that
are made available would have


199
00:09:31,206 --> 00:09:33,946
to be appropriately labeled:
what language do they use,


200
00:09:34,006 --> 00:09:35,206
what features do they have,


201
00:09:35,206 --> 00:09:37,906
so that the user can
either choose one manually


202
00:09:38,176 --> 00:09:41,316
that best suits his or her
needs, or even more conveniently


203
00:09:41,556 --> 00:09:44,736
so that the software itself can
choose an appropriate option


204
00:09:44,736 --> 00:09:47,316
automatically according to
stored user preferences.


205
00:09:47,836 --> 00:09:52,326
All right, so that's basically
the terminology we're going


206
00:09:52,326 --> 00:09:54,056
to use to talk about
accessibility options.


207
00:09:54,326 --> 00:09:58,566
Let's get into how iOS and OS
X are incorporating support


208
00:09:58,746 --> 00:10:02,796
for accessibility options
in iOS 7and OS X Mavericks.


209
00:10:03,346 --> 00:10:04,986
If you look at system
preferences


210
00:10:04,986 --> 00:10:06,876
in OS X Mavericks you'll note


211
00:10:06,936 --> 00:10:11,186
that in the Accessibility pane
there is now a Captions area


212
00:10:11,336 --> 00:10:13,946
which exposes two
different sets of preferences


213
00:10:13,946 --> 00:10:15,156
that the user can configure.


214
00:10:15,846 --> 00:10:19,836
The first set is about the
appearance of timed text


215
00:10:19,836 --> 00:10:22,126
when it's played during
multimedia playback.


216
00:10:22,416 --> 00:10:24,776
Remember the timed
text is essential


217
00:10:24,776 --> 00:10:26,986
for conveying vital
information to the user,


218
00:10:27,156 --> 00:10:29,316
and so it's very important
for the user to be able


219
00:10:29,316 --> 00:10:32,386
to configure its display so
that it's actually legible.


220
00:10:32,386 --> 00:10:35,436
If the user needs a larger
font it should be possible


221
00:10:35,436 --> 00:10:36,286
to specify that.


222
00:10:36,686 --> 00:10:39,926
If the user needs a greater
contrast between the color used


223
00:10:39,926 --> 00:10:43,016
for the characters and the
color used for the backdrop


224
00:10:43,186 --> 00:10:46,336
that offsets the text area
from whatever is behind it,


225
00:10:46,576 --> 00:10:48,696
then it should be possible
to configure that as well.


226
00:10:49,036 --> 00:10:50,456
Those preferences are here.


227
00:10:50,806 --> 00:10:52,766
In fact, if you drill
down and look at this


228
00:10:52,766 --> 00:10:55,886
in the seed release, you'll note
that there's sufficient control


229
00:10:56,126 --> 00:10:58,306
to cover all of the
characteristics of text


230
00:10:58,736 --> 00:11:01,736
that are supposed to be
customizable under the FCC rules


231
00:11:01,736 --> 00:11:04,226
that I mentioned in
connection with U.S. law.


232
00:11:05,266 --> 00:11:08,466
The second preference that's
available here pertains


233
00:11:08,466 --> 00:11:12,296
to how multimedia content should
automatically be configured


234
00:11:12,606 --> 00:11:16,126
so that it presents options that
are appropriate for the user


235
00:11:16,126 --> 00:11:17,656
without the user
having to intervene.


236
00:11:18,036 --> 00:11:20,566
The option here at the
bottom of this panel is


237
00:11:20,906 --> 00:11:23,386
"Prefer Closed Captions
and SDH".


238
00:11:23,726 --> 00:11:27,556
Those are the two common terms
for timed text for accessibility


239
00:11:27,766 --> 00:11:29,926
that users will recognize
from other domains,


240
00:11:30,316 --> 00:11:32,416
television, Blu-ray, and DVD.


241
00:11:33,136 --> 00:11:35,436
What this preference allows
the user to do is to say,


242
00:11:35,596 --> 00:11:37,846
whenever it's available
I want timed text


243
00:11:37,846 --> 00:11:40,456
for accessibility
automatically to be displayed.


244
00:11:41,956 --> 00:11:44,856
Similarly the same
preferences are now available


245
00:11:44,856 --> 00:11:47,256
for the user's configuration
on iOS 7.


246
00:11:47,666 --> 00:11:50,946
If you go into Settings and
drill down through General


247
00:11:50,946 --> 00:11:53,986
and Accessibility into
Subtitles and Captioning,


248
00:11:54,266 --> 00:11:57,636
the very same preferences
are there.


249
00:11:57,806 --> 00:12:01,156
So now that they're there, if
you're an application developer


250
00:12:01,156 --> 00:12:02,586
of course your natural
question is,


251
00:12:03,046 --> 00:12:07,006
how can my app automatically
honor those preferences?


252
00:12:07,236 --> 00:12:09,926
And the answer is, well,
you don't have to do much


253
00:12:09,926 --> 00:12:11,756
to make sure that
happens and many


254
00:12:11,756 --> 00:12:13,896
of you need not do
anything at all.


255
00:12:14,476 --> 00:12:15,966
Let's talk about the
two different sets


256
00:12:15,966 --> 00:12:17,056
of preferences separately.


257
00:12:17,056 --> 00:12:19,356
First, the text styling
preferences


258
00:12:19,726 --> 00:12:22,086
when timed text is
being displayed together


259
00:12:22,086 --> 00:12:22,956
with multimedia.


260
00:12:23,666 --> 00:12:27,346
Apps don't need to do anything
in order for that timed text


261
00:12:27,346 --> 00:12:32,356
to honor the user's preferences,
except to allow AV Foundation


262
00:12:32,356 --> 00:12:33,576
to perform the rendering.


263
00:12:33,576 --> 00:12:36,506
So in other words,
don't do extra work


264
00:12:36,506 --> 00:12:38,976
to do the rendering yourself
and you're guaranteed


265
00:12:39,226 --> 00:12:41,906
that the user preferences for
text styling will be honored.


266
00:12:42,566 --> 00:12:43,266
End of story.


267
00:12:43,546 --> 00:12:46,246
There may be other styling
information associated


268
00:12:46,286 --> 00:12:50,306
with the text, either in the
media itself or perhaps applied


269
00:12:50,306 --> 00:12:54,106
by an API that we have available
for you, but you should note


270
00:12:54,706 --> 00:12:57,396
that the most important thing
is for the text to be legible


271
00:12:57,596 --> 00:13:01,396
by the actual user, and so the
user's preferences trump all


272
00:13:01,396 --> 00:13:03,656
of the styling information
and will be honored


273
00:13:03,946 --> 00:13:05,136
when we render it for you.


274
00:13:05,626 --> 00:13:09,756
OK, the other set of preference
I mentioned was the preference


275
00:13:09,756 --> 00:13:13,026
regarding how media should be
configured by default in order


276
00:13:13,026 --> 00:13:15,826
to honor the user's
preference for a particular type


277
00:13:15,826 --> 00:13:17,066
of accessibility option.


278
00:13:17,466 --> 00:13:18,686
The "Prefer Closed Captions


279
00:13:18,686 --> 00:13:20,996
and SDH" checkbox is what
I'm talking about here.


280
00:13:21,496 --> 00:13:23,166
To honor that preference, again,


281
00:13:23,466 --> 00:13:25,176
many apps don't need
to do anything.


282
00:13:25,526 --> 00:13:27,296
If you're using high-level
frameworks


283
00:13:27,296 --> 00:13:29,946
such as an iOS
MPMoviePlayerController


284
00:13:29,946 --> 00:13:33,736
to control playback of your
media or on OS X Mavericks


285
00:13:33,736 --> 00:13:36,526
if you're using AVPlayerView
from AVKit,


286
00:13:37,186 --> 00:13:39,856
items will automatically
be configured to honor


287
00:13:39,856 --> 00:13:43,316
that preference and be displayed
by default with timed text


288
00:13:43,316 --> 00:13:45,396
for accessibility
whenever it's present.


289
00:13:46,786 --> 00:13:50,796
However, if you are supplying
your own user interface


290
00:13:51,416 --> 00:13:54,836
or if you are creating your
own instances of AVPlayer,


291
00:13:55,116 --> 00:13:57,746
you may have a little bit of
additional work to do in order


292
00:13:57,746 --> 00:14:00,726
to make sure that happens,
and we'll talk about that.


293
00:14:02,586 --> 00:14:05,896
In order for you to honor
that user preference


294
00:14:06,026 --> 00:14:08,696
for that particular
media option,


295
00:14:08,766 --> 00:14:11,416
timed text for accessibility,
"Prefer Closed Captions


296
00:14:11,456 --> 00:14:14,516
and SDH", in the seed that
you'll take home with you


297
00:14:14,516 --> 00:14:17,616
of iOS 7 and also in the
seed of OS X Mavericks,


298
00:14:17,976 --> 00:14:19,276
you need to do one thing.


299
00:14:19,706 --> 00:14:22,916
Call the AVPlayer method
-setAppliesMediaSelection


300
00:14:22,916 --> 00:14:25,576
CriteriaAutomatically:
and pass YES.


301
00:14:26,176 --> 00:14:27,876
And what that says
is you want to opt


302
00:14:27,876 --> 00:14:31,096
in for this automatic
selection behavior with respect


303
00:14:31,256 --> 00:14:34,336
for criteria derived
from user preferences.


304
00:14:35,066 --> 00:14:37,186
Even better news is
that after this seed,


305
00:14:37,186 --> 00:14:38,866
when we get the next
seeds to you


306
00:14:39,096 --> 00:14:41,316
and in the shipping versions,
you don't even have to do that,


307
00:14:41,886 --> 00:14:44,416
and we will opt your
application in automatically


308
00:14:44,416 --> 00:14:47,986
to this behavior if you merely
link against the new versions


309
00:14:47,986 --> 00:14:52,736
of the SDK's, the iOS 7
SDK or the OS X 10.9 SDK,


310
00:14:52,736 --> 00:14:56,016
and your AVPlayer instances
will automatically be opted


311
00:14:56,016 --> 00:14:57,786
in to this automatic behavior.


312
00:14:58,106 --> 00:15:01,386
Therefore when we get to that
point, if you have an app


313
00:15:01,726 --> 00:15:04,446
that doesn't want to offer the
typical playback experience,


314
00:15:04,446 --> 00:15:07,686
for example, if your app is
an authoring app but wants


315
00:15:07,686 --> 00:15:10,706
to allow its users to audit the
content that's being authored


316
00:15:11,026 --> 00:15:13,026
in any number of
states including those


317
00:15:13,026 --> 00:15:16,216
that don't correspond to current
user preference settings,


318
00:15:16,486 --> 00:15:17,936
you'll actually have to opt out.


319
00:15:17,936 --> 00:15:18,186
You'll have


320
00:15:18,186 --> 00:15:21,946
to say -setAppliesMediaSelection
CriteriaAutomatically:NO.


321
00:15:22,856 --> 00:15:24,996
Well, to summarize it
doesn't do any harm for you


322
00:15:24,996 --> 00:15:26,756
to call this method
and say what you want.


323
00:15:27,056 --> 00:15:29,866
YES, I want that automatic
behavior or NO, I don't.


324
00:15:30,736 --> 00:15:32,536
But in the subsequent
releases and when we get


325
00:15:32,536 --> 00:15:34,506
to the shipping release,
the GM release,


326
00:15:34,866 --> 00:15:37,146
if you want the automatic
behavior, there's no need


327
00:15:37,146 --> 00:15:38,076
to call anything at all.


328
00:15:38,546 --> 00:15:42,486
Next for API developers,


329
00:15:42,486 --> 00:15:45,796
if you need to implement
your own user interface


330
00:15:46,106 --> 00:15:47,306
to permit the selection


331
00:15:47,306 --> 00:15:48,946
of specific options
that are present.


332
00:15:48,946 --> 00:15:51,116
This is not the automatic
configuration of the item,


333
00:15:51,116 --> 00:15:54,306
but once something is
prepared for playback you want


334
00:15:54,306 --> 00:15:56,706
to make available all
of the various options


335
00:15:56,706 --> 00:15:58,766
that are present, all the
audio options and so forth,


336
00:15:59,056 --> 00:16:02,256
allow the user to pick one and
make that selection effective.


337
00:16:02,806 --> 00:16:03,476
How do you do that?


338
00:16:03,836 --> 00:16:06,476
Well, let's go back to a picture
of a piece of multimedia here


339
00:16:06,476 --> 00:16:09,136
with multiple audio
options, multiple captioning


340
00:16:09,136 --> 00:16:12,116
and subtitle options; some
of these options are related


341
00:16:12,116 --> 00:16:13,636
to accessibility
and some are not.


342
00:16:14,406 --> 00:16:15,916
How do you know that
they're there?


343
00:16:16,846 --> 00:16:21,326
In AV Foundation, each
of the groups of options


344
00:16:21,326 --> 00:16:23,696
that are present will be
represented by an instance


345
00:16:23,976 --> 00:16:26,406
of the class
AVMediaSelectionGroup,


346
00:16:27,056 --> 00:16:29,476
and each option in the
group that's present,


347
00:16:29,476 --> 00:16:31,856
intended to be treated as a
mutually exclusive option,


348
00:16:32,106 --> 00:16:33,716
will be represented
by an instance


349
00:16:33,716 --> 00:16:35,176
of AVMediaSelectionOption.


350
00:16:35,736 --> 00:16:38,346
And each of those
AVMediaSelectionOptions will


351
00:16:38,346 --> 00:16:41,526
have properties that describe
what the option is all about:


352
00:16:41,816 --> 00:16:45,876
what's its media type,
what language does it use,


353
00:16:45,936 --> 00:16:47,206
what features does it have.


354
00:16:47,266 --> 00:16:49,566
Is it for accessibility
or just for translation,


355
00:16:49,646 --> 00:16:51,456
for example in the
case of subtitles?


356
00:16:52,436 --> 00:16:54,166
How do you get access
to those things?


357
00:16:54,566 --> 00:16:55,826
Well, it's pretty simple.


358
00:16:55,826 --> 00:16:58,636
Like most operations in
AV Foundation you start


359
00:16:58,636 --> 00:17:02,836
with an instance of AVAsset,
probably an AVAsset initialized


360
00:17:02,836 --> 00:17:05,896
with a URL to the file in
the file system or something


361
00:17:05,896 --> 00:17:09,116
out on the network, and then to
get this information you start


362
00:17:09,116 --> 00:17:10,726
by loading the value
of the property,


363
00:17:10,996 --> 00:17:14,476
availableMediaCharacteristics
WithMediaSelectionOptions.


364
00:17:14,675 --> 00:17:16,786
You want to find out what
groups of options are present.


365
00:17:17,915 --> 00:17:20,816
The value of that
property, once it's loaded,


366
00:17:21,165 --> 00:17:23,366
is going to be an
array of strings,


367
00:17:23,606 --> 00:17:26,536
each of which represents
a media characteristic


368
00:17:26,776 --> 00:17:28,816
that has options
associated with it.


369
00:17:28,896 --> 00:17:29,816
For example,


370
00:17:29,816 --> 00:17:32,726
if AVMediaCharacteristicVisual
is present,


371
00:17:33,006 --> 00:17:34,456
you know that there
are video options.


372
00:17:34,616 --> 00:17:37,826
If AVMediaCharacteristicAudible
is present you know


373
00:17:37,826 --> 00:17:38,926
that there are audio options,


374
00:17:38,926 --> 00:17:41,126
and if
AVMediaCharacteristicLegible is


375
00:17:41,126 --> 00:17:43,356
present, you know that
there are captioning


376
00:17:43,396 --> 00:17:44,856
or subtitle options or both.


377
00:17:46,176 --> 00:17:49,266
Suppose you want to create
a menu that allows the user


378
00:17:49,266 --> 00:17:51,896
to choose any specific option
to enable it for playback.


379
00:17:52,306 --> 00:17:53,116
How do you do that?


380
00:17:53,326 --> 00:17:56,276
Well, you want to get the
specific AVMediaSelectionGroup


381
00:17:56,426 --> 00:17:58,826
for the characteristic
you're building the menu for.


382
00:17:59,116 --> 00:18:00,796
Suppose it's the
Legible characteristic.


383
00:18:01,246 --> 00:18:04,316
I'll say, AVAsset, give me
the media selection group


384
00:18:04,316 --> 00:18:07,886
for the media characteristic
AVMediaCharacteristicLegible,


385
00:18:08,806 --> 00:18:10,996
and the return value
of that method is going


386
00:18:10,996 --> 00:18:13,006
to be an instance of
AVMediaSelectionGroup


387
00:18:13,296 --> 00:18:15,856
which will have one or
more options present in it,


388
00:18:16,206 --> 00:18:18,416
each of which describes
options that are present.


389
00:18:18,776 --> 00:18:21,186
You can use those
to populate a menu.


390
00:18:21,186 --> 00:18:23,686
In fact you can use as the
name of each menu item,


391
00:18:23,986 --> 00:18:26,406
the displayName of each
media selection option.


392
00:18:27,476 --> 00:18:30,586
If you're playing this asset
- and of course in order to do


393
00:18:30,586 --> 00:18:33,016
so you have to create an
instance of AVPlayerItem


394
00:18:33,016 --> 00:18:35,196
and an instance of
AVPlayer to play it -


395
00:18:35,746 --> 00:18:39,606
and the user selects a specific
media option, suppose that one


396
00:18:39,606 --> 00:18:42,936
on the lower right, how do you
make that selection effective?


397
00:18:43,716 --> 00:18:46,896
You use the AVPlayerItem
method -selectMediaOption:


398
00:18:46,896 --> 00:18:50,456
inMediaSelectionGroup:, and
the effect of that will be


399
00:18:50,456 --> 00:18:54,036
to enable the option that's
selected and to disable all


400
00:18:54,036 --> 00:18:55,316
of the other options
in the group.


401
00:18:56,166 --> 00:18:58,966
So that's a high level
description of the API


402
00:18:58,966 --> 00:19:01,116
that you would use in order
to implement all this.


403
00:19:01,776 --> 00:19:04,906
Even better, we're providing a
code sample that you can read


404
00:19:05,016 --> 00:19:06,896
that goes through
exactly that process.


405
00:19:07,126 --> 00:19:09,346
And the code sample actually
does some interesting things


406
00:19:09,346 --> 00:19:10,416
as well, so we're going


407
00:19:10,416 --> 00:19:11,826
to demonstrate it
for you right now.


408
00:19:12,166 --> 00:19:14,136
Courtney Kennedy, one of
the Engineering Managers


409
00:19:14,136 --> 00:19:15,716
in Media Systems is
going to that for us.


410
00:19:16,426 --> 00:19:17,356
Courtney?


411
00:19:18,056 --> 00:19:19,176
>> Courtney Kennedy:
Thanks Kevin.


412
00:19:24,636 --> 00:19:28,226
[Applause] So I have an app
and a special movie here


413
00:19:28,226 --> 00:19:28,986
that I'm going to use


414
00:19:28,986 --> 00:19:32,496
to demonstrate how you can
use the Media Selection API's


415
00:19:32,526 --> 00:19:35,736
that Kevin has been describing
to both inspect the audio


416
00:19:35,736 --> 00:19:39,446
and legible options
in a particular movie


417
00:19:39,816 --> 00:19:43,106
and to select between them.


418
00:19:43,366 --> 00:19:46,316
So this app has four
different players in it,


419
00:19:46,496 --> 00:19:50,186
one in each quadrant, and I
have the same movie loaded


420
00:19:50,186 --> 00:19:51,376
up in each of them.


421
00:19:52,496 --> 00:19:56,726
In addition this app has
a menu on each player


422
00:19:58,316 --> 00:20:02,166
that shows both the
audio options available


423
00:20:02,616 --> 00:20:04,706
and the subtitle
options available.


424
00:20:04,776 --> 00:20:09,586
So you can see this particular
movie has both an English audio


425
00:20:09,586 --> 00:20:10,756
and a Hindi audio.


426
00:20:11,256 --> 00:20:13,176
To being with let's
select the English,


427
00:20:13,756 --> 00:20:18,136
and then we can also
select Subtitles


428
00:20:18,346 --> 00:20:20,056
for each of the four players.


429
00:20:20,056 --> 00:20:23,866
So you see we have quite a list
of subtitles to choose from here


430
00:20:24,706 --> 00:20:29,336
and just as with audio, they're
all listed by language and some


431
00:20:29,336 --> 00:20:32,086
of them include the
SDH label on them.


432
00:20:32,666 --> 00:20:35,506
As Kevin said, that
label indicates


433
00:20:35,686 --> 00:20:37,616
that there's additional
information


434
00:20:37,616 --> 00:20:40,636
in those subtitles beyond
just a simple translation.


435
00:20:41,346 --> 00:20:44,396
So in this particular
movie, for some languages,


436
00:20:44,396 --> 00:20:47,586
we have both regular translation
subtitles and we have SDH,


437
00:20:47,586 --> 00:20:50,946
and for some languages we
have only one or the other.


438
00:20:51,996 --> 00:20:54,766
So let's go through,
for each player,


439
00:20:54,766 --> 00:21:01,136
and just select some
different subtitles to play.


440
00:21:01,796 --> 00:21:05,736
And now let's play the
movie and see what we get


441
00:21:05,826 --> 00:21:14,046
for audio and subtitles.


442
00:21:14,046 --> 00:21:14,766
[ Movie Playing ]


443
00:21:14,766 --> 00:21:18,746
Okay so we can see that
our media selections made


444
00:21:18,746 --> 00:21:20,856
on AV Foundation were
honored during playback.


445
00:21:21,816 --> 00:21:27,306
And let's listen to a bit of
the Hindi and look at a few


446
00:21:27,306 --> 00:21:37,856
of the other subtitles
available in this movie.


447
00:21:37,856 --> 00:21:37,923
[ Background Sounds ]


448
00:21:37,923 --> 00:21:40,096
And play again.


449
00:21:40,096 --> 00:21:40,186
[ Movie Playing ]


450
00:21:40,186 --> 00:21:48,206
So if this is functionality
that's interesting to you


451
00:21:48,206 --> 00:21:51,236
and something that you want
to add to your media player,


452
00:21:51,876 --> 00:21:54,606
it's possible to do so
using AV Foundation.


453
00:21:54,916 --> 00:21:57,696
And if you want to see how
we did it as Kevin mentioned,


454
00:21:58,206 --> 00:22:01,286
both this app, which is called
AV Media Selection Demo,


455
00:22:01,796 --> 00:22:05,396
and this movie, which my Apple
engineering brethren helped me


456
00:22:05,396 --> 00:22:08,436
make and it's great test
content, they're both available


457
00:22:08,436 --> 00:22:11,586
as part of the sample
code for this years' show.


458
00:22:11,586 --> 00:22:12,936
[Applause]


459
00:22:12,936 --> 00:22:15,766
>> Kevin: Thanks, Courtney.


460
00:22:16,826 --> 00:22:19,406
OK, so we've talked
a lot about things


461
00:22:19,406 --> 00:22:21,586
that application developers
need to know in order


462
00:22:21,586 --> 00:22:23,696
to expose these options
in their applications,


463
00:22:24,086 --> 00:22:26,336
but you must be getting
nervous, application developers,


464
00:22:26,336 --> 00:22:29,236
because we haven't said anything
to the content providers


465
00:22:29,236 --> 00:22:30,526
and producers sitting around you


466
00:22:30,836 --> 00:22:32,566
about how they can
provide these options


467
00:22:32,786 --> 00:22:34,476
that your apps can
actually make available.


468
00:22:34,816 --> 00:22:37,146
Don't worry, we've got material
for those people as well.


469
00:22:37,426 --> 00:22:39,036
In fact we've got
multiple choices


470
00:22:39,036 --> 00:22:40,636
for those content
producers to use


471
00:22:40,956 --> 00:22:43,696
to package accessibility
options with their media.


472
00:22:44,226 --> 00:22:46,486
So let's go back to a picture
of a piece of multimedia


473
00:22:46,486 --> 00:22:49,216
with multiple video options,
multiple audio options,


474
00:22:49,526 --> 00:22:51,906
multiple timed text options
in the form of captions


475
00:22:51,906 --> 00:22:55,006
or subtitles, some of which
have accessibility features


476
00:22:55,006 --> 00:22:56,676
associated with them and
some of which do not.


477
00:22:57,076 --> 00:22:58,566
How do you make media like this?


478
00:22:59,256 --> 00:23:00,056e
Several choices.


479
00:22:59,256 --> 00:23:00,056
Several choices.


480
00:23:00,676 --> 00:23:04,136
You can choose HTML5 and
its support for text tracks.


481
00:23:04,526 --> 00:23:07,466
You can choose HTTP Live
streaming and its support


482
00:23:07,466 --> 00:23:11,086
for what it calls multiple
alternative renditions of media.


483
00:23:11,586 --> 00:23:13,916
Or you can use the
QuickTime movie file format


484
00:23:13,916 --> 00:23:16,426
or its closely allied
format MPEG-4;


485
00:23:16,696 --> 00:23:18,776
they have the same
features, and for the purposes


486
00:23:18,776 --> 00:23:21,066
of our talks though we're going
to treat them as a tandem here.


487
00:23:22,256 --> 00:23:25,796
Let's go through what the
features are of each one related


488
00:23:25,796 --> 00:23:27,026
to accessibility options.


489
00:23:27,026 --> 00:23:28,136
First, HTML5.


490
00:23:28,836 --> 00:23:31,516
The current revision of
the HTML5 spec allows you


491
00:23:31,516 --> 00:23:36,086
to include one or more text
tracks in your HTML markup.


492
00:23:36,576 --> 00:23:37,876
It does not currently allow you


493
00:23:37,876 --> 00:23:40,236
to have multiple audio
options declared in your markup


494
00:23:40,346 --> 00:23:42,846
or multiple video options,
but it does allow it for text.


495
00:23:44,036 --> 00:23:44,866
What does it look like?


496
00:23:45,486 --> 00:23:46,856
Well first of all
I should mention


497
00:23:46,856 --> 00:23:50,766
that in HTML5 parlance text
tracks like this are known


498
00:23:50,766 --> 00:23:53,596
as "out of band" text tracks,
and why are they called


499
00:23:53,596 --> 00:23:54,686
"out of band" text tracks?


500
00:23:54,686 --> 00:23:58,486
Well simply because the resource
that carries the timed text,


501
00:23:58,836 --> 00:24:02,126
the subtitles, is a
different resource from that


502
00:24:02,356 --> 00:24:04,236
that carries the
audio and the video.


503
00:24:04,436 --> 00:24:06,866
In the example markup in the
lower part of this slide,


504
00:24:07,166 --> 00:24:10,876
you'll see that the source of
the video element is an M4V file


505
00:24:11,826 --> 00:24:15,096
but the source of the
captions is a WebVTT file,


506
00:24:15,096 --> 00:24:17,786
so that is why these are called
"out of band" text tracks.


507
00:24:18,206 --> 00:24:21,116
That has the virtue of
allowing you to add text options


508
00:24:21,296 --> 00:24:24,046
without modifying your
audiovisual resources.


509
00:24:24,046 --> 00:24:26,246
You just declare more
text tracks in your markup


510
00:24:26,476 --> 00:24:28,306
as you have the text available.


511
00:24:29,226 --> 00:24:30,866
What does the rest of
this markup look like?


512
00:24:31,356 --> 00:24:34,586
Well first of all, this
example declares timed text


513
00:24:34,826 --> 00:24:36,086
for accessibility.


514
00:24:36,376 --> 00:24:39,156
It carries the additional
information - identification


515
00:24:39,156 --> 00:24:41,646
of speakers, description
of music and sound -


516
00:24:41,646 --> 00:24:44,686
that you would expect from
timed text for accessibility.


517
00:24:45,096 --> 00:24:48,946
The way that you
declare that in HTML5 is


518
00:24:48,946 --> 00:24:53,206
to give the text track a
kind, called "captions".


519
00:24:53,586 --> 00:24:56,616
"Captions" is the kind of
text track for accessibility.


520
00:24:56,806 --> 00:24:58,176
If it's simply a text track


521
00:24:58,266 --> 00:25:01,136
for translation purposes
you would give it a kind


522
00:25:01,136 --> 00:25:05,216
of "subtitles", so that's
how you indicate that.


523
00:25:05,556 --> 00:25:07,286
You want to indicate
the source language


524
00:25:07,286 --> 00:25:09,736
because it's really useful for
the user to pick a language


525
00:25:09,956 --> 00:25:11,926
that he or she can
actually read.


526
00:25:12,456 --> 00:25:15,246
I've mentioned the default
attribute here on my slide


527
00:25:15,246 --> 00:25:16,886
but I'm not using
it in my markup.


528
00:25:17,286 --> 00:25:21,306
Why? Well that's because if you
recall accessibility options are


529
00:25:21,306 --> 00:25:25,376
made available as an alternative
means to convey information


530
00:25:25,376 --> 00:25:28,116
that otherwise is conveyed
in the default partitioning


531
00:25:28,116 --> 00:25:30,296
of that information into
audio, video and text


532
00:25:30,296 --> 00:25:31,406
by the content provider.


533
00:25:31,806 --> 00:25:34,436
Because accessibility
options are alternatives,


534
00:25:34,656 --> 00:25:37,106
they are not typically
designated as something


535
00:25:37,106 --> 00:25:38,446
to be displayed by default.


536
00:25:38,666 --> 00:25:40,896
So I'm not using the
default attribute here.


537
00:25:41,516 --> 00:25:45,726
I am providing a user-readable
label so that if the user agent


538
00:25:45,726 --> 00:25:49,086
or the JavaScript provides
some way for the end user


539
00:25:49,086 --> 00:25:51,366
to select options
there's a useful,


540
00:25:51,696 --> 00:25:54,886
identifying label available
to use in the user's language.


541
00:25:56,206 --> 00:25:58,226
Okay, so what are the
highlights of HTML5?


542
00:25:58,866 --> 00:26:00,586
Well as I mentioned
there's no need


543
00:26:00,586 --> 00:26:03,476
to modify the main media
resource that's played


544
00:26:03,476 --> 00:26:06,076
by the media element, in
my case a video element


545
00:26:06,076 --> 00:26:07,846
in the example markup I showed,


546
00:26:08,336 --> 00:26:11,546
and because you're using an
HTML5-compliant user agent you


547
00:26:11,546 --> 00:26:17,546
have all of the other facilities
that are familiar from HTML.


548
00:26:17,696 --> 00:26:19,086
CSS styling will apply


549
00:26:19,086 --> 00:26:22,326
to the elements displaying the
timed text just as it applies


550
00:26:22,326 --> 00:26:24,786
to other elements as well,
so lots of power there.


551
00:26:25,286 --> 00:26:28,236
You have JavaScript available
for the control of timed text.


552
00:26:28,576 --> 00:26:32,426
There's a rich API defined for
JavaScript on these text tracks.


553
00:26:32,666 --> 00:26:36,406
You have access to the cues,
a cue list, for each track:


554
00:26:36,766 --> 00:26:38,436
the text that's going
to be displayed,


555
00:26:38,796 --> 00:26:41,016
the timing of that text
is available to you.


556
00:26:41,316 --> 00:26:45,096
And of course because you can
display the text in any element


557
00:26:45,096 --> 00:26:47,636
in the document you don't
have to place it right on top


558
00:26:47,636 --> 00:26:49,596
of the video, you can
put it somewhere else.


559
00:26:50,476 --> 00:26:54,106
But an important consideration
here is that if you choose HTML5


560
00:26:54,806 --> 00:26:58,416
to declare the availability
of your timed text,


561
00:26:58,836 --> 00:27:02,526
implicitly you require an
HTML5-compliant user agent


562
00:27:02,526 --> 00:27:05,926
to be available to present that
timed text during playback.


563
00:27:06,806 --> 00:27:07,896
And you should be aware


564
00:27:08,136 --> 00:27:12,426
that HTML5 user agents
possibly aren't present in all


565
00:27:12,426 --> 00:27:14,796
of the environments in which
you may wish your timed text


566
00:27:15,076 --> 00:27:16,026
to be made available.


567
00:27:16,106 --> 00:27:18,716
An important example
is Apple TV,


568
00:27:18,946 --> 00:27:21,726
when media resources are
played via AirPlay video.


569
00:27:21,726 --> 00:27:26,016
In the implementation of AirPlay
video the Apple TV has access


570
00:27:26,016 --> 00:27:28,116
only to the main media resource.


571
00:27:28,436 --> 00:27:31,766
It does not have access to
the surrounding HTML5 markup


572
00:27:32,256 --> 00:27:34,576
or to the timed text tracks
that are declared there.


573
00:27:34,896 --> 00:27:37,456
So if you play a media
resource via AirPlay video


574
00:27:37,456 --> 00:27:41,036
to an Apple TV, and you're only
making your timed text available


575
00:27:41,036 --> 00:27:44,076
via HTML5, those text
tracks are not going


576
00:27:44,076 --> 00:27:45,696
to be available on the Apple TV.


577
00:27:47,266 --> 00:27:51,676
OK, another choice that we want
to review, HTTP Live Streaming.


578
00:27:51,966 --> 00:27:52,856
Very flexible.


579
00:27:53,116 --> 00:27:56,846
HTTP Live Streaming supports
multiple alternative renditions


580
00:27:57,156 --> 00:27:59,666
for each of the media
types it supports.


581
00:27:59,666 --> 00:28:03,536
You can have multiple video
renditions, audio, subtitles,


582
00:28:03,536 --> 00:28:07,096
and, now for the first time
in iOS 7 and OS X Mavericks,


583
00:28:07,096 --> 00:28:09,116
you can have multiple
closed-caption renditions


584
00:28:09,416 --> 00:28:09,916
as well.


585
00:28:10,126 --> 00:28:12,416
Some of them for accessibility
purposes, some of them


586
00:28:12,416 --> 00:28:13,826
for translation and so forth.


587
00:28:14,866 --> 00:28:18,516
What does it look like
in your master playlist?


588
00:28:18,516 --> 00:28:21,106
Well like any other rendition
that you make available


589
00:28:21,106 --> 00:28:24,336
for HTTP Live Streaming, you
simply have to declare it


590
00:28:24,666 --> 00:28:25,876
in your master playlist.


591
00:28:26,306 --> 00:28:28,976
You do that by declaring
that you have something


592
00:28:28,976 --> 00:28:30,236
of a particular media type.


593
00:28:30,366 --> 00:28:34,036
If it's subtitles, you say its
TYPE is SUBTITLES and usually,


594
00:28:34,036 --> 00:28:36,426
though not always
depending on the media type,


595
00:28:36,746 --> 00:28:39,956
you have to declare the media
playlist that has references


596
00:28:39,956 --> 00:28:42,576
to the media segments that
actually carry the media data.


597
00:28:42,746 --> 00:28:45,376
Here in this example I'm
saying that the media segments


598
00:28:45,406 --> 00:28:50,456
that carry the subtitles are in
the URI, "webvtt/session.m3u8".


599
00:28:51,866 --> 00:28:55,056
This example, again, is
an example of subtitles


600
00:28:55,226 --> 00:28:58,416
for accessibility and
so we want to declare


601
00:28:58,526 --> 00:29:02,116
that these subtitles have the
accessibility characteristics.


602
00:29:02,696 --> 00:29:06,146
Those are, "transcribes spoken
dialog for accessibility",


603
00:29:06,496 --> 00:29:10,536
in the parlance of this dot
language, "public.accessibility.


604
00:29:10,536 --> 00:29:14,846
transcribes-spoken-dialog",
and also you want to declare


605
00:29:14,846 --> 00:29:16,986
that these subtitles
"describe music and sound",


606
00:29:16,986 --> 00:29:18,716
or "public.accessibility.


607
00:29:18,716 --> 00:29:20,216
describes-music-and-sound".


608
00:29:20,526 --> 00:29:22,946
And that's how, in your
master playlist, you say,


609
00:29:23,226 --> 00:29:26,266
"I have SDH subtitles,
I have timed text


610
00:29:26,576 --> 00:29:28,076
for accessibility purposes".


611
00:29:28,466 --> 00:29:30,006
Let's just run through some


612
00:29:30,006 --> 00:29:31,786
of the other attributes
for completeness.


613
00:29:32,296 --> 00:29:34,426
Declare the LANGUAGE
of the subtitles.


614
00:29:34,766 --> 00:29:35,646
It's written text.


615
00:29:35,826 --> 00:29:37,186
Users are going to want to know.


616
00:29:37,186 --> 00:29:38,286
Don't forget.


617
00:29:39,306 --> 00:29:42,336
Accessibility options, again,
are not typically marked


618
00:29:42,336 --> 00:29:44,086
as to be displayed by default


619
00:29:44,486 --> 00:29:46,296
since they're normally
constructed


620
00:29:46,426 --> 00:29:48,606
as an alternative means
to convey information,


621
00:29:49,206 --> 00:29:51,576
but we definitely do want
to make them available


622
00:29:51,576 --> 00:29:56,186
for automatic selection in case
an accessibility option matches


623
00:29:56,406 --> 00:29:57,806
the users preference best.


624
00:29:58,346 --> 00:30:00,926
We want the software to be
able to configure the display


625
00:30:00,926 --> 00:30:03,796
of the item to honor those
preferences automatically,


626
00:30:03,976 --> 00:30:06,816
so make your accessibility
options automatically


627
00:30:06,816 --> 00:30:07,866
selectable, please.


628
00:30:09,026 --> 00:30:11,926
Also for a manual selection,
for a user interface


629
00:30:11,926 --> 00:30:13,166
that allows the user to do that,


630
00:30:13,486 --> 00:30:16,866
it's handy to supply
a user-readable NAME.


631
00:30:19,326 --> 00:30:20,916
Similarly for closed-captions.


632
00:30:21,576 --> 00:30:22,686
First of all you want to mention


633
00:30:22,686 --> 00:30:24,936
that you have closed-captioned
media and you do


634
00:30:24,936 --> 00:30:27,116
so by declaring the
TYPE as CLOSED-CAPTIONS.


635
00:30:27,856 --> 00:30:29,416
But in the case of
CLOSED-CAPTIONS,


636
00:30:29,956 --> 00:30:31,886
that media is not
actually carried


637
00:30:32,336 --> 00:30:34,216
in independent media segments.


638
00:30:34,496 --> 00:30:37,466
Closed-captions in HTTP
Live Streaming are carried


639
00:30:37,596 --> 00:30:40,046
in the video substream,
in fact according


640
00:30:40,046 --> 00:30:42,076
to the ATSC specification.


641
00:30:43,126 --> 00:30:45,436
So how do we declare their
presence and where they are?


642
00:30:45,686 --> 00:30:48,986
What you say is not what the
URI or the media playlist is -


643
00:30:48,986 --> 00:30:51,066
you don't need one because
they're going to be carried


644
00:30:51,066 --> 00:30:53,656
in the video and the media
playlist for the video is going


645
00:30:53,656 --> 00:30:54,666
to tell you where that is.


646
00:30:55,486 --> 00:30:58,996
But you do want to declare what
closed-caption channel you're


647
00:30:58,996 --> 00:31:00,396
making this declaration for,


648
00:31:00,766 --> 00:31:03,496
closed-caption channel
1, 2, 3 or 4.


649
00:31:03,846 --> 00:31:07,576
In this case I've got English
closed-captions in CC channel 1


650
00:31:07,636 --> 00:31:10,946
so that's what I'm declaring
using the INSTREAM-ID attribute.


651
00:31:11,706 --> 00:31:15,126
I want to mention also
that closed-captions,


652
00:31:15,126 --> 00:31:18,356
because that they were devised
specifically for the purpose


653
00:31:18,356 --> 00:31:21,206
of accessibility,
our software assumes


654
00:31:21,206 --> 00:31:24,056
that all closed-caption
media has the characteristics


655
00:31:24,386 --> 00:31:26,536
"transcribes spoken
dialog for accessibility"


656
00:31:26,566 --> 00:31:29,096
and "describes music and
sound for accessibility".


657
00:31:29,096 --> 00:31:32,146
So this declaration is here
for illustrative purposes only.


658
00:31:32,416 --> 00:31:35,196
It's closed-captions, it's
intended for accessibility,


659
00:31:35,426 --> 00:31:37,316
so we assume they have
those characteristics.


660
00:31:37,656 --> 00:31:41,506
Declare the LANGUAGE,
don't forget.


661
00:31:42,596 --> 00:31:45,526
Again, accessibility options
not typically the DEFAULT,


662
00:31:45,526 --> 00:31:46,346
but we do want them


663
00:31:46,346 --> 00:31:49,706
to be automatically
selectable, and a name is handy.


664
00:31:51,336 --> 00:31:52,956
Finally, we haven't
seen this before,


665
00:31:52,956 --> 00:31:55,026
an example of this
before; what about audio?


666
00:31:56,026 --> 00:31:58,656
I mentioned earlier that
accessibility options


667
00:31:58,656 --> 00:32:02,646
that take the form of audio
media are greatly appreciated


668
00:32:02,646 --> 00:32:03,276
when present.


669
00:32:03,876 --> 00:32:07,446
Here's an example of one such
accessibility option in audio.


670
00:32:07,896 --> 00:32:11,156
This particular one, this audio
rendition that I'm declaring


671
00:32:11,156 --> 00:32:12,146
with a TYPE of AUDIO,


672
00:32:12,146 --> 00:32:14,236
and of course I'm also
declaring its media playlist,


673
00:32:14,756 --> 00:32:17,656
has the characteristic
"public.accessibility.


674
00:32:17,656 --> 00:32:18,676
describes-video".


675
00:32:19,006 --> 00:32:23,616
That means that that narration,
that description of the setting


676
00:32:23,686 --> 00:32:25,666
and action that's
depicted visually,


677
00:32:25,906 --> 00:32:28,316
is present in this
audio rendition.


678
00:32:28,616 --> 00:32:32,496
It's mixed in together with
the speech and the music


679
00:32:32,496 --> 00:32:33,446
and the sound effects.


680
00:32:33,446 --> 00:32:36,396
Again I want to declare
the LANGUAGE,


681
00:32:36,846 --> 00:32:38,986
accessibility option not
typically the DEFAULT,


682
00:32:39,346 --> 00:32:41,166
but do make it selectable
automatically,


683
00:32:41,876 --> 00:32:42,966
and a name can be handy.


684
00:32:43,506 --> 00:32:48,476
So there you go for audio,
closed-captions and subtitles.


685
00:32:48,776 --> 00:32:49,886
By the way, the additions


686
00:32:49,886 --> 00:32:52,786
to the HTTP Live
Streaming specification


687
00:32:53,076 --> 00:32:53,986
that you've witnessed here,


688
00:32:53,986 --> 00:32:55,676
the ability to declare
closed-captions,


689
00:32:56,046 --> 00:33:00,826
those are in this draft of the
specification that's available


690
00:33:00,826 --> 00:33:02,056
through the developer program


691
00:33:02,396 --> 00:33:03,996
that we intend to
finalize by fall.


692
00:33:05,126 --> 00:33:07,366
So highlights of
HTTP Live Streaming.


693
00:33:07,366 --> 00:33:10,266
It has a similar
virtue to that of HTML5.


694
00:33:10,826 --> 00:33:12,856
You can add accessibility
options


695
00:33:13,136 --> 00:33:15,226
without modifying
existing media,


696
00:33:15,546 --> 00:33:17,486
without modifying
existing portions


697
00:33:17,486 --> 00:33:18,726
of your master playlist.


698
00:33:19,046 --> 00:33:21,556
You simply declare the
additional renditions


699
00:33:21,556 --> 00:33:22,136
that you have.


700
00:33:22,616 --> 00:33:24,526
You provide the media playlist


701
00:33:24,526 --> 00:33:26,796
where appropriate,
and you're done.


702
00:33:27,506 --> 00:33:29,656
Another point about
HTTP Live Streaming,


703
00:33:29,656 --> 00:33:32,686
though we do have a feature that
allows you to specify styling


704
00:33:33,026 --> 00:33:38,006
of subtitles in HTTP Live
Streaming that take the form


705
00:33:38,006 --> 00:33:42,576
of WebVTT documents, your
styling that you apply


706
00:33:42,576 --> 00:33:45,256
by the API that I'm
mentioning here, textStyleRules,


707
00:33:45,446 --> 00:33:49,056
remember that will be overridden
if the user has set preference


708
00:33:49,056 --> 00:33:52,506
for the appearance of text.


709
00:33:52,716 --> 00:33:54,516
All right, so let's turn
our attention to the third


710
00:33:54,516 --> 00:33:55,546
of these three options.


711
00:33:55,866 --> 00:33:58,366
From HTML5 to HTTP
Live Streaming,


712
00:33:58,366 --> 00:34:02,216
now to the QuickTime Movie file
format and MPEG-4 file format.


713
00:34:02,736 --> 00:34:04,536
The good news about
these file formats is


714
00:34:04,536 --> 00:34:07,816
that they have had the
ability since their inception


715
00:34:08,146 --> 00:34:10,966
to represent all of the
information that's necessary


716
00:34:11,226 --> 00:34:13,766
to include multiple
alternative groups


717
00:34:14,016 --> 00:34:17,005
and to identify the purpose
of any member of the group.


718
00:34:17,306 --> 00:34:20,346
You can have multiple video
tracks that are intended


719
00:34:20,346 --> 00:34:23,466
to be chosen mutually
exclusively to each other.


720
00:34:23,815 --> 00:34:25,826
You can have multiple
audio tracks as well.


721
00:34:25,826 --> 00:34:28,275
Multiple captioning
and subtitle tracks.


722
00:34:28,525 --> 00:34:32,735
It's all built into the file
format and has been forever.


723
00:34:33,565 --> 00:34:35,255
Let's talk about
where that stuff shows


724
00:34:35,255 --> 00:34:37,346
up in the binary file
format, and I'm going


725
00:34:37,346 --> 00:34:40,096
to defer the discussion of
how you can create movie files


726
00:34:40,096 --> 00:34:42,676
with these features to a
colleague of mine who's going


727
00:34:42,676 --> 00:34:44,065
to come up and describe the API


728
00:34:44,065 --> 00:34:45,516
that you can use
for that purpose.


729
00:34:45,795 --> 00:34:48,565
But let's just quickly review
what's in the movie file format


730
00:34:48,565 --> 00:34:50,956
that you need to
specify the presence


731
00:34:50,956 --> 00:34:52,226
of accessibility options.


732
00:34:52,886 --> 00:34:54,106
First of all, every track


733
00:34:54,106 --> 00:34:56,246
in a movie file has
a language setting.


734
00:34:56,525 --> 00:34:58,356
It's right there in
the media header atom


735
00:34:58,646 --> 00:35:00,756
of the media that's
associated with that track.


736
00:35:01,126 --> 00:35:03,606
That accommodates
an ISO-639 code.


737
00:35:04,186 --> 00:35:06,916
If you need a larger
declaration of the language,


738
00:35:06,916 --> 00:35:09,056
if you need to declare the
writing system that's used


739
00:35:09,436 --> 00:35:12,336
or the regional variant of the
language that's used in addition


740
00:35:12,336 --> 00:35:15,536
to the language code, there's
also accommodation for storage


741
00:35:15,536 --> 00:35:20,186
of a BCP 47 language tag.


742
00:35:20,186 --> 00:35:23,556
Every track in these file
formats has an alternate track


743
00:35:23,556 --> 00:35:25,906
group setting right there
in the track header atom.


744
00:35:26,106 --> 00:35:29,326
I stole these graphics, by the
way, from the online version


745
00:35:29,536 --> 00:35:31,596
of the QuickTime File
Format documentation.


746
00:35:32,076 --> 00:35:34,036
It was easy to make these
slides, in other words.


747
00:35:34,036 --> 00:35:35,296
All this stuff is
already out there.


748
00:35:35,706 --> 00:35:37,466
But let's talk about what
the alternate track group


749
00:35:37,466 --> 00:35:38,206
setting means.


750
00:35:38,586 --> 00:35:41,156
By default for a
track its value is 0,


751
00:35:41,476 --> 00:35:43,646
meaning that the track is
not a member of a group;


752
00:35:44,046 --> 00:35:45,796
it will be enabled and disabled


753
00:35:45,796 --> 00:35:48,996
by a well-behaved
implementation independently


754
00:35:48,996 --> 00:35:49,836
of all of the tracks.


755
00:35:50,516 --> 00:35:53,146
But, if the alternate track
group setting is something other


756
00:35:53,146 --> 00:35:57,056
than 0, that means it's a
member of a group with all


757
00:35:57,056 --> 00:35:59,816
of the other tracks
that have the same value


758
00:35:59,816 --> 00:36:01,306
for their alternate
track group setting.


759
00:36:01,576 --> 00:36:05,286
So for example I can have
multiple audio tracks all


760
00:36:05,286 --> 00:36:07,916
of which have an alternate
track group setting of 1,


761
00:36:08,346 --> 00:36:11,086
which indicates in a
well-behaved implementation,


762
00:36:11,316 --> 00:36:15,206
those audio tracks will be
selectable mutually exclusively.


763
00:36:15,206 --> 00:36:18,126
When one is selected, the others
will automatically be disabled.


764
00:36:20,536 --> 00:36:23,196
There's also an accommodation
for track references,


765
00:36:23,466 --> 00:36:25,276
if different tracks
have to be associated


766
00:36:25,276 --> 00:36:26,446
with each other in some way.


767
00:36:26,786 --> 00:36:29,166
This is particularly
useful, for example,


768
00:36:29,166 --> 00:36:32,676
if you are carrying forced
subtitles in your movie file


769
00:36:32,676 --> 00:36:34,286
and you want them
to be associated


770
00:36:34,286 --> 00:36:35,506
with a particular audio track.


771
00:36:35,506 --> 00:36:38,416
I'm not going to define what I
mean by "forced subtitles" here


772
00:36:38,676 --> 00:36:40,616
but I'm aware that some
of you may be interested.


773
00:36:40,866 --> 00:36:43,766
If you need more details
about that or other cases


774
00:36:43,766 --> 00:36:45,346
in which track references
are handy,


775
00:36:45,726 --> 00:36:47,936
come to the AV Foundation
lab tomorrow and we'll go


776
00:36:47,936 --> 00:36:49,226
through that with you.


777
00:36:49,936 --> 00:36:53,276
Finally, in order to
describe the specific features


778
00:36:53,616 --> 00:36:57,146
of a track - are these
subtitles for accessibility


779
00:36:57,146 --> 00:36:59,646
or just subtitles for
translation, for example.


780
00:37:00,226 --> 00:37:03,986
It's possible to attach
to a track the information


781
00:37:04,076 --> 00:37:05,276
that makes that distinction.


782
00:37:05,686 --> 00:37:08,596
Every track has what's known
as a user data container,


783
00:37:08,866 --> 00:37:11,926
a place to store additional
descriptive information


784
00:37:11,926 --> 00:37:15,296
about the track, and we've
defined a new user data type


785
00:37:15,826 --> 00:37:18,056
called the "tagged
media characteristic"


786
00:37:18,436 --> 00:37:20,926
that carries exactly the
information that we need


787
00:37:21,236 --> 00:37:23,696
in order to identify
accessibility features


788
00:37:23,696 --> 00:37:24,286
when present.


789
00:37:24,746 --> 00:37:28,196
And the value of these tagged
media characteristics is exactly


790
00:37:28,196 --> 00:37:31,006
the same as the media
characteristics that we declare


791
00:37:31,006 --> 00:37:33,786
in our HTTP Live
Streaming master playlist


792
00:37:34,036 --> 00:37:36,946
when the features are
present, "public.accessibility.


793
00:37:37,136 --> 00:37:40,866
transcribes-spoken-dialog",
"public.accessibility.


794
00:37:40,866 --> 00:37:42,236
describes-music-and-sound".


795
00:37:42,856 --> 00:37:44,296
Adam has more details
in a moment


796
00:37:44,296 --> 00:37:46,026
of how you would
attach those to a track,


797
00:37:46,306 --> 00:37:49,536
but just note it's possible
for you to tag a track


798
00:37:49,766 --> 00:37:51,786
with the features that
the user may be interested


799
00:37:51,786 --> 00:37:55,456
in so the user can recognize the
value of that particular choice.


800
00:37:55,996 --> 00:37:59,376
So in summary, there's
nothing new here at all.


801
00:37:59,926 --> 00:38:01,416
The QuickTime Movie file format


802
00:38:01,416 --> 00:38:05,056
and the MPEG-4 file format
accommodate multiple options


803
00:38:05,146 --> 00:38:07,806
and accommodate accessibility
options natively,


804
00:38:07,976 --> 00:38:09,106
built into the file format.


805
00:38:09,846 --> 00:38:12,866
That's a very convenient way to
package accessibility options


806
00:38:13,086 --> 00:38:15,366
if you want to be
able to transmit a lot


807
00:38:15,366 --> 00:38:17,236
of options together
in a single file.


808
00:38:18,216 --> 00:38:21,536
However, you should be aware
that the implementations


809
00:38:21,606 --> 00:38:26,086
of support for [QuickTime] Movie
files and MPEG-4 files on iOS 7


810
00:38:26,086 --> 00:38:29,196
and OS X Mavericks
support only those files


811
00:38:29,246 --> 00:38:30,526
that are self-contained.


812
00:38:30,896 --> 00:38:34,226
In other words, they include
all of the media they require;


813
00:38:34,396 --> 00:38:36,436
even if there are
multiple options available,


814
00:38:36,606 --> 00:38:38,956
the media for each will be
stored in the same file.


815
00:38:39,386 --> 00:38:42,646
So, you have additional work
that you need to do if you want


816
00:38:42,646 --> 00:38:45,966
to add for example an
accessibility option


817
00:38:45,966 --> 00:38:46,506
with timed text


818
00:38:46,506 --> 00:38:49,006
for accessibility
to an existing file.


819
00:38:49,256 --> 00:38:52,526
The good news is that we have
API in AV Foundation available


820
00:38:52,716 --> 00:38:54,446
that makes that possible,
and we're going


821
00:38:54,446 --> 00:38:56,646
to describe exactly what
it is in just a moment.


822
00:38:57,736 --> 00:39:03,226
One last note about subtitles
in QuickTime Movie files


823
00:39:03,356 --> 00:39:07,486
and in ISO files such as
MPEG-4 files - we're aware of,


824
00:39:07,486 --> 00:39:09,446
in fact we're actively
participating in,


825
00:39:09,826 --> 00:39:12,706
work within MPEG, the Motion
Picture Experts Group,


826
00:39:13,116 --> 00:39:17,596
to define the standard carriage
of WebVTT for timed text


827
00:39:17,996 --> 00:39:20,556
in ISO files such as MPEG-4.


828
00:39:21,376 --> 00:39:23,676
And when that specification
is final


829
00:39:24,046 --> 00:39:27,156
and our implementation is ready,
we expect to announce to you


830
00:39:27,156 --> 00:39:31,186
that we recommend the use
of WebVTT for subtitles


831
00:39:31,496 --> 00:39:36,256
for translation and subtitles
for accessibility in MPEG-4


832
00:39:36,306 --> 00:39:37,496
and QuickTime Movie files.


833
00:39:37,496 --> 00:39:39,726
That's a, we'll have a really
great story when we get there


834
00:39:40,026 --> 00:39:42,956
because the same format will
be supported by all three


835
00:39:42,956 --> 00:39:45,836
of the packaging options that
we've talked about today, HTML5,


836
00:39:45,836 --> 00:39:49,666
HTTP Live Streaming and then
when we get there MPEG-4


837
00:39:49,666 --> 00:39:50,766
and [QuickTime] Movie
files as well.


838
00:39:51,296 --> 00:39:54,436
However in the interim, until
that specification is final,


839
00:39:54,476 --> 00:39:56,766
if you want to add subtitles
to [QuickTime] Movie files


840
00:39:56,766 --> 00:40:01,016
or M4V files, we continue
to recommend the media type,


841
00:40:01,326 --> 00:40:04,556
AVMediaTypeSubtitle, - the
four character code is 'sbtl' -


842
00:40:04,556 --> 00:40:07,536
and the particular
format represented


843
00:40:07,566 --> 00:40:10,266
by the media subtype 'tx3g'.


844
00:40:13,016 --> 00:40:14,896
OK, one last note.


845
00:40:15,366 --> 00:40:18,736
Supposing you really liked
the features of HTML5


846
00:40:18,736 --> 00:40:23,396
for controlling timed text in
JavaScript and applying CSS,


847
00:40:24,246 --> 00:40:26,636
but you also really like
the ability of, say,


848
00:40:26,636 --> 00:40:30,576
HTTP Live Streaming to be able
to conduct those subtitles


849
00:40:30,876 --> 00:40:33,856
to the Apple TV when
played by AirPlay video.


850
00:40:34,226 --> 00:40:37,326
And you're asking, Can I
have the best of both worlds?


851
00:40:37,466 --> 00:40:39,646
When my content is
played in the web browser,


852
00:40:39,876 --> 00:40:42,326
I want to apply the features
of the web browser to it


853
00:40:42,566 --> 00:40:45,566
but when it's played in
another environment I want it


854
00:40:45,566 --> 00:40:46,586
to be just as rich.


855
00:40:47,326 --> 00:40:50,006
And the answer is: yes, you can
have the best of both worlds.


856
00:40:50,466 --> 00:40:54,906
HTML5 defines not only what it
calls "out of band" text tracks,


857
00:40:55,376 --> 00:40:58,806
for which you declare
tracks in your HTML markup,


858
00:40:59,056 --> 00:41:02,226
it also supports what are
known as "in band" text tracks


859
00:41:02,976 --> 00:41:04,876
for cases in which
text is carried


860
00:41:05,006 --> 00:41:08,496
within the main resource
itself, for example,


861
00:41:08,496 --> 00:41:11,606
in an HTTP Live Stream that
has a subtitle rendition


862
00:41:11,606 --> 00:41:14,006
for accessibility or in
a QuickTime Movie file


863
00:41:14,206 --> 00:41:16,166
that has a subtitle
track for accessibility.


864
00:41:16,776 --> 00:41:20,146
We've worked with the WebKit
team to ensure that the versions


865
00:41:20,146 --> 00:41:23,076
of WebKit that will be
made available with iOS 7


866
00:41:23,376 --> 00:41:26,876
and OS X Mavericks support
"in band" text tracks


867
00:41:27,086 --> 00:41:30,656
when these media types are
played via a video element.


868
00:41:31,196 --> 00:41:33,836
Therefore when you play a
movie file with subtitles


869
00:41:33,886 --> 00:41:36,066
or a HTTP Live Stream
with closed-captions,


870
00:41:36,386 --> 00:41:39,356
in those versions of WebKit
you have the full ability


871
00:41:39,356 --> 00:41:43,116
to use JavaScript and CSS
to apply to that text just


872
00:41:43,116 --> 00:41:46,136
as you would if the text tracks
were declared as "out of band".


873
00:41:46,666 --> 00:41:49,266
So that's a good
story for integration.


874
00:41:50,346 --> 00:41:54,386
Finally to review the
choices that we have talked


875
00:41:54,386 --> 00:41:57,416
about here regarding
packaging of media


876
00:41:57,416 --> 00:41:59,666
with accessibility
options, here are some


877
00:41:59,666 --> 00:42:02,386
of the highlight decision
points, not all of them


878
00:42:02,386 --> 00:42:03,446
that may pertain to you.


879
00:42:03,946 --> 00:42:06,016
All three of the things that
I mentioned today, HTML5,


880
00:42:06,016 --> 00:42:08,956
HTTP Live Streaming
and Movie and MPEG-4,


881
00:42:09,196 --> 00:42:11,896
support selectable
captions and subtitles.


882
00:42:13,356 --> 00:42:15,666
HTTP Live Streaming
and QuickTime Movie


883
00:42:15,666 --> 00:42:19,376
and MPEG-4 support
selectable audio options,


884
00:42:19,776 --> 00:42:21,946
not currently possible
in the current version


885
00:42:22,016 --> 00:42:26,206
of HTML5 spec. HTML5 and
HTTP Live Streaming support


886
00:42:26,396 --> 00:42:28,316
references to external media


887
00:42:28,316 --> 00:42:30,946
so that you can add
timed text options


888
00:42:31,056 --> 00:42:33,296
without modifying your
main media resource;


889
00:42:34,446 --> 00:42:36,056
can't do that with
Movie and MPEG-4.


890
00:42:37,676 --> 00:42:41,286
And AirPlay video supports
the timed text options


891
00:42:41,286 --> 00:42:43,486
that are carried within
HTTP Live Streaming


892
00:42:43,746 --> 00:42:44,936
and Movie and MPEG-4.


893
00:42:45,586 --> 00:42:48,466
So, just a summary
to give you an idea


894
00:42:48,536 --> 00:42:51,776
of how you might choose
a particular format.


895
00:42:52,586 --> 00:42:55,786
Well I promised there was more
information available about how


896
00:42:55,786 --> 00:42:58,166
to add subtitles to
Movie and MPEG-4 files


897
00:42:58,646 --> 00:43:01,466
and here comes Adam Sonnanstine
now, a colleague of mine


898
00:43:01,466 --> 00:43:03,186
from the Media Systems Group,


899
00:43:03,186 --> 00:43:04,616
in fact from the
AV Foundation team,


900
00:43:04,926 --> 00:43:05,966
who's going to introduce you


901
00:43:05,966 --> 00:43:07,866
to exactly the API
that you need to use.


902
00:43:08,276 --> 00:43:11,206
Thanks. [Applause]


903
00:43:12,816 --> 00:43:14,476
>> Adam Sonnanstine:
Thank you, Kevin!


904
00:43:15,256 --> 00:43:20,686
So as we've seen, the QuickTime
file format can carry subtitles


905
00:43:20,686 --> 00:43:23,766
as well as all of the
accessibility features


906
00:43:23,766 --> 00:43:24,996
that we've been talking about.


907
00:43:24,996 --> 00:43:26,776
That's the alternate
track groups,


908
00:43:26,776 --> 00:43:30,686
the tagged characteristics
and the track associations.


909
00:43:30,686 --> 00:43:32,766
So I'm going to spend
a few minutes talking


910
00:43:32,766 --> 00:43:36,086
about the specific API's that
you can use in your applications


911
00:43:36,326 --> 00:43:39,126
to create Movie files
that have these features.


912
00:43:39,326 --> 00:43:42,086
So I'm going to start by talking
through some of the basics,


913
00:43:42,266 --> 00:43:44,646
some of the specific
data structures


914
00:43:44,646 --> 00:43:48,066
and classes you're going to
use, and then talk through all


915
00:43:48,066 --> 00:43:51,406
of those specific
accessibility features


916
00:43:51,406 --> 00:43:53,136
and the API's for
each one of them.


917
00:43:53,576 --> 00:43:56,006
And we're going to motivate the
whole thing using a scenario


918
00:43:56,356 --> 00:44:00,686
where we add a new subtitle
track to an existing Movie file.


919
00:44:00,886 --> 00:44:02,656
So to see that scenario
visually,


920
00:44:02,656 --> 00:44:06,566
we start out with a movie that
has a few tracks: a video track,


921
00:44:06,566 --> 00:44:09,696
an audio track, and a
single subtitle track.


922
00:44:09,696 --> 00:44:12,676
In this case we're going to use
a Spanish track, and we're going


923
00:44:12,676 --> 00:44:15,666
to create a new Movie and
pull all of those tracks right


924
00:44:15,666 --> 00:44:16,826
over just as they were.


925
00:44:16,826 --> 00:44:19,316
And then we're going to
create our own subtitles,


926
00:44:19,316 --> 00:44:21,116
our own translation
into English,


927
00:44:21,466 --> 00:44:24,176
and push that into an
additional subtitle track


928
00:44:24,176 --> 00:44:25,086
in the output file.


929
00:44:25,266 --> 00:44:27,996
So to see this in action
I'm inviting Courtney back


930
00:44:27,996 --> 00:44:29,416
up stage for a demo.


931
00:44:34,736 --> 00:44:37,206
Alright, so here you
see the demo app.


932
00:44:37,486 --> 00:44:39,006
We have a Movie loaded up.


933
00:44:39,006 --> 00:44:40,276
It's just as I described.


934
00:44:40,276 --> 00:44:43,766
If we open up the Subtitle
menu here, we see that we have


935
00:44:43,766 --> 00:44:45,226
that Spanish subtitle track.


936
00:44:45,526 --> 00:44:47,856
So we can go ahead and
select that and start playing


937
00:44:47,856 --> 00:44:51,396
until we find a subtitle
that we'd like to translate.


938
00:44:51,906 --> 00:44:55,396
[Movie playing] That
one's kind of tough.


939
00:44:55,826 --> 00:44:56,546
Ah, there we go.


940
00:44:56,776 --> 00:44:57,546
That's an easy one.


941
00:44:58,136 --> 00:44:59,226
So let's do that.


942
00:44:59,226 --> 00:45:01,896
So Courtney will type in the
translation which is "Why"


943
00:45:01,896 --> 00:45:05,686
and then what we're going to
do is hit this button over here


944
00:45:05,686 --> 00:45:08,086
which is going to do this
process I just described,


945
00:45:08,086 --> 00:45:10,576
where we create the new Movie
file, and it's going to open it


946
00:45:10,576 --> 00:45:11,946
up in QuickTime Player.


947
00:45:11,946 --> 00:45:13,536
So here's our new file.


948
00:45:13,906 --> 00:45:16,916
We can examine the subtitles
by opening up that menu again


949
00:45:16,916 --> 00:45:17,636
and you can see that,


950
00:45:17,636 --> 00:45:20,796
in addition to the existing
Spanish subtitle track,


951
00:45:20,796 --> 00:45:23,116
we also have the new
English subtitle track


952
00:45:23,116 --> 00:45:23,916
that we just added.


953
00:45:24,416 --> 00:45:26,756
And QuickTime Player knew
to put them in this menu


954
00:45:26,756 --> 00:45:30,236
because we used an alternate
track group as Kevin described.


955
00:45:30,476 --> 00:45:32,536
I'll talk more about
that in just a moment,


956
00:45:32,816 --> 00:45:34,176
but let's examine our handiwork.


957
00:45:34,296 --> 00:45:38,386
So let's check out the
English subtitle track


958
00:45:38,386 --> 00:45:40,596
and start playing.


959
00:45:40,596 --> 00:45:42,696
[Movie playing] There it is.


960
00:45:42,956 --> 00:45:45,936
Alright so we just typed that
in, it's in the Movie file


961
00:45:45,936 --> 00:45:48,246
and that's a great demonstration
of how easy it can be


962
00:45:48,246 --> 00:45:51,916
to add subtitles to a Movie
file using AV Foundation.


963
00:45:52,246 --> 00:45:52,986
Thank you, Courtney!


964
00:45:57,176 --> 00:46:00,556
Alright, so let's take another
look at that diagram here.


965
00:46:00,966 --> 00:46:02,426
We're going to zoom
in just on the part


966
00:46:02,426 --> 00:46:05,126
where we're adding the
subtitle into a new track,


967
00:46:05,546 --> 00:46:07,486
and the first thing that
we're going to do is wrap


968
00:46:07,536 --> 00:46:10,676
that in an instance
of CMSampleBuffer.


969
00:46:11,136 --> 00:46:12,786
In order to get that
sample buffer


970
00:46:12,786 --> 00:46:15,866
into the output file we're going
to be using a couple classes.


971
00:46:15,916 --> 00:46:17,636
The first is AVAssetWriter


972
00:46:17,946 --> 00:46:20,226
and the second is
AVAssetWriterInput.


973
00:46:20,226 --> 00:46:23,516
They work together and you'll
get one track in the output file


974
00:46:23,516 --> 00:46:25,816
for every asset writer
input that you have.


975
00:46:26,996 --> 00:46:29,926
Now for more detail
on the specific format


976
00:46:29,926 --> 00:46:32,646
that the data should be in when
you put it into a sample buffer,


977
00:46:32,946 --> 00:46:35,286
check out the "QuickTime
File Format Specification,"


978
00:46:35,286 --> 00:46:36,866
which is available at that URL.


979
00:46:37,626 --> 00:46:40,106
For more detail on
CMSampleBuffer itself,


980
00:46:40,386 --> 00:46:41,826
it has its own documentation.


981
00:46:41,826 --> 00:46:45,076
But we also gave it a
short introduction in 2010,


982
00:46:45,166 --> 00:46:48,266
in the session called "Using
the Camera with AV Foundation."


983
00:46:48,846 --> 00:46:51,016
I think that happened
around the 15 minute mark


984
00:46:51,016 --> 00:46:52,366
if you're pressed for time.


985
00:46:52,996 --> 00:46:56,366
And lastly, for more
information about AVAssetWriter,


986
00:46:56,366 --> 00:46:59,146
we gave it a very
detailed overview in 2011,


987
00:46:59,146 --> 00:47:02,466
in the session called "Working
with Media in AV Foundation,"


988
00:47:02,796 --> 00:47:05,696
and this one you can
actually watch directly


989
00:47:05,696 --> 00:47:08,026
from the WWDC app
from this year.


990
00:47:08,026 --> 00:47:10,746
But tying it all together
we do have sample code.


991
00:47:10,946 --> 00:47:13,956
It's called "avsubtitleswriter
for OS X," so go ahead


992
00:47:13,956 --> 00:47:16,726
and download that to see
all the details and all


993
00:47:16,726 --> 00:47:20,096
of these concepts working
together in perfect harmony.


994
00:47:22,136 --> 00:47:23,736
Alright, so now that we've
seen sort of the basics,


995
00:47:23,736 --> 00:47:26,086
let's take a look at those
accessibility features,


996
00:47:26,206 --> 00:47:27,516
starting with track groups.


997
00:47:28,066 --> 00:47:30,366
So I mentioned in the demo
that we want a track group


998
00:47:30,366 --> 00:47:33,086
in the output file so that
QuickTime Player knows how


999
00:47:33,086 --> 00:47:37,246
to put it in the menu to select
between the two subtitle tracks,


1000
00:47:37,406 --> 00:47:40,006
and the way you do this with
AVAssetWriter is very similar.


1001
00:47:40,006 --> 00:47:41,316
You create an input group


1002
00:47:41,546 --> 00:47:43,866
that references the
two Asset Writer Inputs


1003
00:47:43,956 --> 00:47:45,896
that you're going to have.


1004
00:47:46,856 --> 00:47:50,776
To see that in code: You
start out by creating an array


1005
00:47:50,776 --> 00:47:53,586
that wraps the two Asset
Writer Inputs, and then you use


1006
00:47:53,586 --> 00:47:55,326
that array to initialize
an instance


1007
00:47:55,466 --> 00:47:59,986
of AVAssetWriterInputGroup,
and then you add


1008
00:47:59,986 --> 00:48:01,116
that into your Asset Writer.


1009
00:48:01,116 --> 00:48:04,106
And you see here that we
nominated the Spanish input


1010
00:48:04,106 --> 00:48:07,496
to be the default,
but if you do not want


1011
00:48:07,496 --> 00:48:10,216
to specify a default you
can pass in nil here.


1012
00:48:10,776 --> 00:48:12,036
So that's track groups.


1013
00:48:12,356 --> 00:48:16,396
The next is track associations.


1014
00:48:16,486 --> 00:48:20,066
We mentioned that you might
want to use a track association


1015
00:48:20,066 --> 00:48:23,116
if you want your subtitle track
to get selected automatically


1016
00:48:23,316 --> 00:48:25,806
when the audio track of the
same language is selected


1017
00:48:25,806 --> 00:48:28,956
by the user, and in the output
file that looks like this.


1018
00:48:28,996 --> 00:48:31,146
You have this association
between the two tracks.


1019
00:48:31,576 --> 00:48:34,686
In this case it's a "selection
follower" association,


1020
00:48:35,506 --> 00:48:37,046
and you might not be surprised


1021
00:48:37,106 --> 00:48:39,836
that with the Asset
Writer we just create


1022
00:48:39,836 --> 00:48:42,586
that same association between
the Asset Writer Inputs.


1023
00:48:43,276 --> 00:48:45,496
In code this is very
simple: It's just one method,


1024
00:48:45,896 --> 00:48:48,306
-addTrackAssociation
WithTrackOfInput:,


1025
00:48:48,566 --> 00:48:51,566
and you're going to use this
to associate the subtitle input


1026
00:48:51,776 --> 00:48:55,886
with the audio input using
the type "selection follower."


1027
00:48:56,696 --> 00:48:58,026
Alright, that's track
associations.


1028
00:48:58,066 --> 00:49:00,796
The last one I want to talk
about is tagged characteristics.


1029
00:49:01,156 --> 00:49:03,576
We've talked in some
length about SDH subtitles.


1030
00:49:03,886 --> 00:49:06,966
If you're going to be
authoring a subtitle track


1031
00:49:06,966 --> 00:49:09,876
that contains all that extra
information, the way you get it


1032
00:49:09,876 --> 00:49:12,956
to be labeled as SDH is to use
a couple tagged characteristics,


1033
00:49:13,326 --> 00:49:15,406
one of them being
"transcribes spoken dialog


1034
00:49:15,406 --> 00:49:16,466
for accessibility."


1035
00:49:17,426 --> 00:49:19,026
And, as you might have guessed,


1036
00:49:19,466 --> 00:49:22,066
to do that with Asset Writer
Input you just tag your


1037
00:49:22,066 --> 00:49:25,586
corresponding Asset Writer Input
with that same characteristic.


1038
00:49:25,586 --> 00:49:27,836
In code, it's a little
bit more involved.


1039
00:49:27,836 --> 00:49:29,876
We're using the general
purpose metadata API,


1040
00:49:30,686 --> 00:49:33,106
but here you just
create a metadata item,


1041
00:49:33,376 --> 00:49:35,736
you set its key space
to "QuickTime user data"


1042
00:49:36,046 --> 00:49:38,456
and it's key to "tagged
characteristic,"


1043
00:49:38,856 --> 00:49:40,816
and then you set the value


1044
00:49:40,816 --> 00:49:42,766
to be the actual
characteristic we want to use.


1045
00:49:42,766 --> 00:49:44,956
In this case it's
"transcribes spoken dialog


1046
00:49:45,016 --> 00:49:45,956
for accessibility."


1047
00:49:46,616 --> 00:49:49,086
And then you just set that on
the Asset Writer Input using the


1048
00:49:49,086 --> 00:49:50,136
-setMetadata: method.


1049
00:49:50,716 --> 00:49:53,136
Now, we've mentioned that there
are two characteristics for SDH.


1050
00:49:53,186 --> 00:49:57,056
To review, the second
one is "describes music


1051
00:49:57,056 --> 00:49:58,516
and sound for accessibility."


1052
00:49:59,156 --> 00:50:01,626
Alright, so that is all of
our accessibility features


1053
00:50:01,626 --> 00:50:02,706
and how to author them.


1054
00:50:02,946 --> 00:50:04,016
The last thing I want to mention


1055
00:50:04,016 --> 00:50:05,556
in this section is
closed captions.


1056
00:50:06,586 --> 00:50:09,306
QuickTime Movie files can
carry closed captions just


1057
00:50:09,306 --> 00:50:10,326
as well as subtitles.


1058
00:50:10,676 --> 00:50:13,916
Most of the concepts and
the API's you're going


1059
00:50:13,916 --> 00:50:15,716
to use are exactly the same.


1060
00:50:15,916 --> 00:50:17,606
The main difference is how
you're going to format the data.


1061
00:50:17,766 --> 00:50:19,496
So for more details
on that, once again,


1062
00:50:19,586 --> 00:50:22,076
see the "QuickTime File
Format Specification."


1063
00:50:23,136 --> 00:50:24,986
Alright so that's how
you can author subtitles


1064
00:50:24,986 --> 00:50:27,256
and closed captions into
QuickTime movie files.


1065
00:50:27,656 --> 00:50:28,966
Let's move on to our last topic,


1066
00:50:28,966 --> 00:50:31,816
which is "accessing the
subtitle text during playback."


1067
00:50:32,176 --> 00:50:33,266
Now why might you
want to do this?


1068
00:50:33,396 --> 00:50:36,386
Well, we'll take a quick look at
the default experience you get


1069
00:50:36,616 --> 00:50:39,106
if you adopt AVPlayerLayer
or AVPlayerView.


1070
00:50:39,676 --> 00:50:41,236
It's a great experience
for most apps:


1071
00:50:41,366 --> 00:50:44,486
You get the subtitles
drawn on top of the video,


1072
00:50:44,766 --> 00:50:47,496
they're styled appropriately
according to the content


1073
00:50:47,496 --> 00:50:49,866
and the user preferences that
we've been talking about,


1074
00:50:50,956 --> 00:50:53,116
but the one thing you
don't have control over is


1075
00:50:53,116 --> 00:50:54,906
where the subtitles are placed.


1076
00:50:55,146 --> 00:50:58,906
After all if your video isn't
taking up the whole screen,


1077
00:50:58,906 --> 00:51:00,856
you might want to put the
subtitles somewhere else.


1078
00:51:01,666 --> 00:51:04,766
So, if you had access
to the actual text


1079
00:51:04,766 --> 00:51:06,666
of the subtitles while
the movie is playing,


1080
00:51:06,906 --> 00:51:09,146
you could do the drawing
wherever you like, yourself.


1081
00:51:10,156 --> 00:51:12,236
Another thing you might want
to do is to allow your users


1082
00:51:12,236 --> 00:51:13,546
to interact with the text.


1083
00:51:13,996 --> 00:51:15,236
Maybe get a dictionary
definition


1084
00:51:15,236 --> 00:51:18,846
for a really difficult word like
this one, and if you had access


1085
00:51:18,846 --> 00:51:20,376
to the text then of
course you'd be able


1086
00:51:20,376 --> 00:51:22,106
to implement this quite
easily: Just slap it


1087
00:51:22,106 --> 00:51:23,826
into a text view of some sort.


1088
00:51:23,866 --> 00:51:25,816
So the way you're
going to do this is


1089
00:51:25,816 --> 00:51:28,686
with a new class called
AVPlayerItemLegibleOutput.


1090
00:51:29,016 --> 00:51:33,566
This is new in iOS 7 and OS X
Mavericks, and it's a companion


1091
00:51:33,566 --> 00:51:36,386
to the Video Output class
that we introduced last year.


1092
00:51:36,386 --> 00:51:39,066
And just like the Video
Output, it allows you to access


1093
00:51:39,126 --> 00:51:42,816
that media data while the
movie is playing, in real time.


1094
00:51:44,226 --> 00:51:46,156
In this case, instead
of video frames,


1095
00:51:46,156 --> 00:51:49,216
we are getting the
text of each subtitle.


1096
00:51:49,606 --> 00:51:52,286
And this is actually the
technology that WebKit is using


1097
00:51:52,486 --> 00:51:54,486
to do the integration
that Kevin described,


1098
00:51:54,776 --> 00:51:58,866
where the out-of-band
subtitles in HTML5 text tracks


1099
00:51:59,076 --> 00:52:01,956
and the in-band subtitles
carried in HLS Streams


1100
00:52:01,956 --> 00:52:04,946
and QuickTime Movie files
can be integrated together.


1101
00:52:04,946 --> 00:52:07,716
So I'm just going to spend a few
minutes introducing this class


1102
00:52:07,776 --> 00:52:08,036
to you.


1103
00:52:08,536 --> 00:52:10,886
We're going to start with the
basics of how you'd use it,


1104
00:52:10,886 --> 00:52:13,716
and then I'm going to talk in
some depth about some things


1105
00:52:13,716 --> 00:52:15,106
to keep in mind if
you're going to try


1106
00:52:15,106 --> 00:52:16,746
to draw the subtitles yourself,


1107
00:52:17,256 --> 00:52:19,596
and finally a few scenarios
we're going to highlight


1108
00:52:20,056 --> 00:52:22,236
where you might want to
use a different solution


1109
00:52:22,236 --> 00:52:23,416
than Legible Output.


1110
00:52:23,416 --> 00:52:26,036
It's not a "one size
fits all" kind of tool.


1111
00:52:27,356 --> 00:52:31,266
Alright, to see this
as a diagram:


1112
00:52:31,856 --> 00:52:33,426
Just like the Video
Output, you're going


1113
00:52:33,426 --> 00:52:35,676
to attach your Legible Output
right onto your player item


1114
00:52:35,676 --> 00:52:38,006
that you're already using
to play back your content,


1115
00:52:38,146 --> 00:52:40,706
and the Legible Output is going
to interact with a delegate


1116
00:52:40,706 --> 00:52:42,686
that you provide,
sending it the string


1117
00:52:42,686 --> 00:52:44,356
for each subtitle as it goes by.


1118
00:52:44,966 --> 00:52:46,546
The string is going
to be in the form


1119
00:52:46,546 --> 00:52:48,456
of an NSAttributedString object.


1120
00:52:48,836 --> 00:52:50,566
It's going to have
styling information


1121
00:52:50,596 --> 00:52:53,036
and positioning information
attached to it.


1122
00:52:53,426 --> 00:52:55,266
And you might be
wondering: If you have more


1123
00:52:55,266 --> 00:52:59,276
than one subtitle track in your
Movie file, which one is going


1124
00:52:59,276 --> 00:53:00,486
to be delivered to the delegate?


1125
00:53:00,486 --> 00:53:03,276
Well, it's the same story as if
we were drawing it ourselves.


1126
00:53:03,276 --> 00:53:04,616
It's the one that corresponds


1127
00:53:04,616 --> 00:53:07,506
to the currently-selected
media selection option.


1128
00:53:08,436 --> 00:53:09,916
To see a little bit of code:


1129
00:53:10,326 --> 00:53:11,926
You create one using
+alloc and -init.


1130
00:53:12,576 --> 00:53:13,586
Nothing fancy here.


1131
00:53:13,636 --> 00:53:15,776
You're going to attach it


1132
00:53:15,836 --> 00:53:17,776
to your player item
using the -addOutput:


1133
00:53:17,776 --> 00:53:21,456
method and then you're going to
create a delegate that conforms


1134
00:53:21,456 --> 00:53:24,956
to the AVPlayerItemLegible
OutputPushDelegate protocol


1135
00:53:25,496 --> 00:53:27,326
and set that onto
the Legible Output.


1136
00:53:27,666 --> 00:53:29,266
Now you notice that
the -setDelegate:


1137
00:53:29,266 --> 00:53:30,606
call takes a dispatch queue.


1138
00:53:30,956 --> 00:53:32,706
You can specify any
queue you want


1139
00:53:32,706 --> 00:53:35,776
and the Legible Output
will invoke all


1140
00:53:35,776 --> 00:53:37,386
of your delegate
methods on that queue.


1141
00:53:37,706 --> 00:53:40,306
If you're going to be
interacting with AppKit or UIKit


1142
00:53:40,306 --> 00:53:42,736
in response to these delegate
callbacks, you're going to want


1143
00:53:42,736 --> 00:53:45,536
to use the main queue, as I
do on this slide, to make sure


1144
00:53:45,536 --> 00:53:46,956
that that is a safe interaction.


1145
00:53:47,026 --> 00:53:50,146
A little bit more detail on
the delegate protocol itself:


1146
00:53:50,686 --> 00:53:52,586
This is the main method
that you'll be using.


1147
00:53:52,966 --> 00:53:55,926
The second parameter is the one


1148
00:53:55,926 --> 00:53:59,066
that you'll be getting the text
from, those attributed strings.


1149
00:53:59,606 --> 00:54:01,486
The third parameter, the
Native Sample Buffers,


1150
00:54:01,486 --> 00:54:04,536
is a more advanced use; most
people won't need to use it.


1151
00:54:04,536 --> 00:54:07,066
Just know that by default
you'll always get an empty array


1152
00:54:07,066 --> 00:54:07,916
for this parameter.


1153
00:54:09,056 --> 00:54:11,356
And of course tying it all
together we have sample code


1154
00:54:11,356 --> 00:54:12,546
for Legible Output as well.


1155
00:54:12,786 --> 00:54:14,376
It's called "AVLegibleMeanings."


1156
00:54:14,376 --> 00:54:17,046
So go ahead and download this
sample to see Legible Output


1157
00:54:17,336 --> 00:54:19,166
in context and in full detail.


1158
00:54:19,166 --> 00:54:22,776
So that's sort of the basics
of using Legible Output.


1159
00:54:23,206 --> 00:54:25,946
Let's move on now to "things
to think about if you're going


1160
00:54:25,946 --> 00:54:27,656
to be drawing the
subtitles yourself."


1161
00:54:27,706 --> 00:54:29,656
We don't expect that everyone
is going to want to do that,


1162
00:54:29,656 --> 00:54:32,146
in fact probably very
few, but if you do,


1163
00:54:32,466 --> 00:54:34,156
remember that you
have the styling


1164
00:54:34,156 --> 00:54:35,696
and positioning attributes
attached


1165
00:54:35,696 --> 00:54:37,116
to each attributed string.


1166
00:54:37,906 --> 00:54:38,926
They look something like this.


1167
00:54:40,006 --> 00:54:43,816
They're all declared and
defined in CMTextMarkup.h,


1168
00:54:43,816 --> 00:54:46,926
but I'm just going to highlight
a few things: The first is


1169
00:54:46,926 --> 00:54:50,716
that it the attributes
are loosely based


1170
00:54:50,716 --> 00:54:54,076
on the WebVTT model for
styling and positioning,


1171
00:54:54,076 --> 00:54:56,836
so if you're used to that model
already then this should be


1172
00:54:56,836 --> 00:54:57,576
pretty familiar.


1173
00:54:58,026 --> 00:55:01,536
The second thing is that
this is a common format.


1174
00:55:01,536 --> 00:55:03,896
We're going to give you the
same set of attributes no matter


1175
00:55:03,896 --> 00:55:08,896
where the subtitles came from,
whether it was TX3G or WebVTT


1176
00:55:09,036 --> 00:55:11,606
or CEA-608 or any of
those other acronyms.


1177
00:55:12,266 --> 00:55:15,976
So you only have to understand
these attributes and not all


1178
00:55:15,976 --> 00:55:17,186
of those individual formats.


1179
00:55:17,236 --> 00:55:20,666
And the last thing I want to
mention is this whole topic


1180
00:55:20,666 --> 00:55:23,236
of the user preferences
for subtitle styling.


1181
00:55:23,636 --> 00:55:25,016
We've talked about
how important it is


1182
00:55:25,016 --> 00:55:27,056
that these are the
most important sets


1183
00:55:27,056 --> 00:55:28,276
of styling information.


1184
00:55:28,836 --> 00:55:30,816
The great news is that
when we're populating these


1185
00:55:30,816 --> 00:55:32,676
attributes, the Legible
Output takes


1186
00:55:32,676 --> 00:55:34,826
into account those
user preferences.


1187
00:55:34,866 --> 00:55:37,346
So just by following these
values you don't have


1188
00:55:37,346 --> 00:55:39,136
to do any extra work
to make sure


1189
00:55:39,136 --> 00:55:40,726
that you're respecting
the user's preferences.


1190
00:55:41,246 --> 00:55:44,076
Of course we do expect
that some people will want


1191
00:55:44,076 --> 00:55:46,286
to modify the styling a little
bit to suit their needs.


1192
00:55:46,896 --> 00:55:48,376
If you are going to do
that you're going to want


1193
00:55:48,376 --> 00:55:50,586
to make sure that you're not
accidentally overriding the


1194
00:55:50,586 --> 00:55:53,346
user's preferences, and the
way you can do that is to look


1195
00:55:53,346 --> 00:55:55,676
at the MediaAccessibility
framework.


1196
00:55:55,676 --> 00:55:57,266
This is going to
provide two services.


1197
00:55:57,826 --> 00:56:02,316
You can both access the
current set of user preferences


1198
00:56:02,316 --> 00:56:04,596
and it will also give
you a notification


1199
00:56:04,596 --> 00:56:07,176
if the user changes those
preferences while your


1200
00:56:07,176 --> 00:56:08,176
application is running.


1201
00:56:08,336 --> 00:56:11,156
So that's the story on
drawing subtitles yourself.


1202
00:56:11,636 --> 00:56:14,536
The last thing I want to mention
is when you might not want


1203
00:56:14,536 --> 00:56:15,566
to use Legible Output.


1204
00:56:16,346 --> 00:56:18,836
Well, if you're going to do
any sort of indexing operation


1205
00:56:19,066 --> 00:56:22,996
over all the subtitle
text in a Movie file,


1206
00:56:23,286 --> 00:56:25,496
you should take a look
at AVAssetReader instead.


1207
00:56:25,496 --> 00:56:28,456
It's going to be
a better way to do


1208
00:56:28,456 --> 00:56:30,916
that for pretty much any case.


1209
00:56:30,916 --> 00:56:33,676
If you're just going to be
doing some custom styling


1210
00:56:33,676 --> 00:56:37,236
of WebVTT content at a basic
level, maybe to match the look


1211
00:56:37,236 --> 00:56:39,246
and feel of your application,
you're going to want


1212
00:56:39,246 --> 00:56:41,116
to take a look at the
textStyleRules property


1213
00:56:41,116 --> 00:56:43,106
on AVPlayerItem that
we've mentioned before.


1214
00:56:43,106 --> 00:56:45,016
That's going to be
much easier to use.


1215
00:56:45,016 --> 00:56:47,366
You won't have to do
the drawing yourself.


1216
00:56:47,366 --> 00:56:50,066
And finally, if you think
that the Legible Output sounds


1217
00:56:50,066 --> 00:56:52,826
like a great way to get
the subtitles and draw them


1218
00:56:53,006 --> 00:56:55,026
with whatever styling
you want without regard


1219
00:56:55,026 --> 00:56:57,926
to the user preferences: By
now you can probably guess


1220
00:56:57,956 --> 00:56:59,106
that we don't want
you to do that,


1221
00:56:59,166 --> 00:57:01,666
but more importantly your
users don't want you do


1222
00:57:01,666 --> 00:57:02,426
to that either.


1223
00:57:02,786 --> 00:57:06,686
Some of your users might
have very specific needs


1224
00:57:06,746 --> 00:57:09,616
for how the subtitles
should look, so for the sake


1225
00:57:09,616 --> 00:57:12,296
of your users, make sure
that their needs are taken


1226
00:57:12,296 --> 00:57:14,616
into account as the
most important thing.


1227
00:57:15,296 --> 00:57:16,976
Alright, that's Legible Output.


1228
00:57:16,976 --> 00:57:18,436
That was our last topic.


1229
00:57:18,436 --> 00:57:20,356
Let's see what we learned today.


1230
00:57:20,686 --> 00:57:24,576
So, we started out by learning
how we can support accessibility


1231
00:57:24,576 --> 00:57:27,506
during playback either by
doing very little work,


1232
00:57:27,506 --> 00:57:30,316
maybe by adopting AVKit and
letting it handle the details,


1233
00:57:30,626 --> 00:57:34,686
or, in a more advanced case,
using the Media Selection API's


1234
00:57:34,686 --> 00:57:36,186
to manage all the
details yourself.


1235
00:57:36,846 --> 00:57:39,166
We talked about some of your
choices for content delivery


1236
00:57:39,166 --> 00:57:40,316
and their pros and cons.


1237
00:57:40,316 --> 00:57:46,056
That was the HTML5 text
tracks, HTTP Live Streaming


1238
00:57:46,056 --> 00:57:47,496
and QuickTime Movie files.


1239
00:57:47,876 --> 00:57:50,476
And we talked about
how to add subtitles


1240
00:57:50,476 --> 00:57:53,396
to those Movie files
using AVAssetWriter,


1241
00:57:53,966 --> 00:57:55,076
and finally we talked about how


1242
00:57:55,076 --> 00:57:58,116
to access the subtitle
text during playback using


1243
00:57:58,116 --> 00:57:59,656
AVPlayerItemLegibleOutput.


1244
00:58:00,046 --> 00:58:03,606
For more information we have our
documentation, and you can check


1245
00:58:03,606 --> 00:58:06,136
out the Apple Development forums
to get your questions answered.


1246
00:58:06,776 --> 00:58:08,086
There are some related sessions.


1247
00:58:08,376 --> 00:58:11,896
If you stick around in this
room, coming up right up next,


1248
00:58:11,896 --> 00:58:14,436
if they don't kick you out
first, is the "What's New


1249
00:58:14,436 --> 00:58:15,866
in Camera Capture" session.


1250
00:58:16,076 --> 00:58:16,966
It's always a fun one.


1251
00:58:17,266 --> 00:58:18,716
And tomorrow morning
we have a session


1252
00:58:18,716 --> 00:58:20,736
on "Advanced Editing
in AV Foundation."


1253
00:58:22,246 --> 00:58:23,696
Alright, so that's all.


1254
00:58:23,986 --> 00:58:26,546
Thank you very much for coming,
have a great rest of your week,


1255
00:58:26,546 --> 00:58:28,606
and if you do one thing on
the way out of this session:


1256
00:58:28,986 --> 00:58:31,206
Download our sample code and
see how you can make your


1257
00:58:31,206 --> 00:58:33,816
applications and your
content accessible


1258
00:58:33,816 --> 00:58:35,926
to the broadest range of people.


1259
00:58:36,216 --> 00:58:36,566
Thank you!


1260
00:58:37,066 --> 00:58:46,710
[ Silence ]

