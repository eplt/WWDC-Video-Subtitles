1
00:00:19,720 --> 00:00:24,291
音频单元扩展


2
00:00:25,292 --> 00:00:27,794
谢谢 早上好


3
00:00:29,696 --> 00:00:31,698
我是道格·怀亚特
Core Audio的团队


4
00:00:31,865 --> 00:00:34,768
我想向大家展示我们新近研发的产品


5
00:00:35,169 --> 00:00:36,970
叫做音频单元扩展


6
00:00:37,371 --> 00:00:42,409
这是iOS 9和OS X El
Capitan系统的一项新技术


7
00:00:43,944 --> 00:00:46,747
关于音频单元
自OS X和iOS系统诞生伊始


8
00:00:46,813 --> 00:00:51,318
我们就在操作系统中植入了该技术


9
00:00:52,085 --> 00:00:54,521
操作系统包括许多内置单元


10
00:00:54,588 --> 00:00:57,758
从I/O单元到混音器


11
00:00:58,258 --> 00:01:02,396
给软件采样器提供了多种不同的特效


12
00:01:04,096 --> 00:01:06,333
在我们的许多高级API中


13
00:01:06,400 --> 00:01:09,169
我们都使用了这些内置音频单元


14
00:01:09,369 --> 00:01:10,737
比如媒体播放栈


15
00:01:12,072 --> 00:01:15,742
但是音频单元同时也是一款OS X中


16
00:01:15,876 --> 00:01:17,811
广泛使用的第三方插件格式


17
00:01:18,178 --> 00:01:20,948
市面上有着成千上万种


18
00:01:21,014 --> 00:01:21,949
第三方音频单元


19
00:01:24,251 --> 00:01:25,886
现在音频单元扩展


20
00:01:25,953 --> 00:01:28,922
使我们首次在OS X和iOS系统中


21
00:01:29,423 --> 00:01:31,725
拥有了全能插件模型


22
00:01:32,259 --> 00:01:35,262
音频单元扩展是基于
应用扩展技术开发的


23
00:01:35,762 --> 00:01:39,066
这就意味着 如果你在
编写插件你可以将插件


24
00:01:39,132 --> 00:01:42,636
打包进App而App可以在
App Stores中进行销售


25
00:01:49,676 --> 00:01:53,247
作为该技术的一部分我们优化了API


26
00:01:53,747 --> 00:01:56,617
同时维持了兼容性


27
00:01:57,117 --> 00:02:00,454
在这次演讲中
我将详细汇报这一新的API


28
00:02:01,221 --> 00:02:03,924
我们将它称为第三代音频单元API


29
00:02:05,926 --> 00:02:07,895
在音频单元框架基础之上


30
00:02:07,961 --> 00:02:11,965
使用AUAudioUnit的
Objective-C类型建开发而成


31
00:02:12,032 --> 00:02:15,736
既然从属于Objective-C
类别当然能够与Swift完美兼容


32
00:02:15,802 --> 00:02:17,004
我们都将见证这一点


33
00:02:19,940 --> 00:02:21,975
本次演讲我们还会讨论


34
00:02:22,042 --> 00:02:24,511
AVFoundation框架内的
其他许多类别


35
00:02:25,145 --> 00:02:28,982
我们有AV音频单元组件管理器


36
00:02:29,616 --> 00:02:31,451
和AV音频单元组件


37
00:02:32,152 --> 00:02:35,656
用来定位系统中的音频组件


38
00:02:36,390 --> 00:02:38,659
这在iOS 9中还是首次


39
00:02:39,293 --> 00:02:40,928
在Yosemite系统也是如此


40
00:02:41,728 --> 00:02:44,364
在今天我们将要展示的代码样本中


41
00:02:44,932 --> 00:02:47,367
我们也将会用到
AVAudioEngine


42
00:02:48,202 --> 00:02:50,704
尤其是AVAudioUnit


43
00:02:50,771 --> 00:02:52,806
和AVAudioUnitEffect类别


44
00:02:53,207 --> 00:02:56,276
两者都是在去年的OS发布的


45
00:02:58,545 --> 00:03:00,814
那么现在我们谈一谈兼容性


46
00:03:00,881 --> 00:03:02,683
这是OS X中的情况


47
00:03:03,050 --> 00:03:05,652
我们现在拥有二代音频单元主机


48
00:03:06,053 --> 00:03:09,256
以及二代音频单元执行


49
00:03:09,623 --> 00:03:12,659
主机与音频部件实例之间


50
00:03:12,726 --> 00:03:13,861
通过信息通讯


51
00:03:14,528 --> 00:03:16,630
实现执行功能


52
00:03:16,697 --> 00:03:18,999
则基于音频部件出厂功能基础


53
00:03:21,435 --> 00:03:23,670
我们拥有一组新的API


54
00:03:24,037 --> 00:03:27,140
因此就有了使用这些API的新主机


55
00:03:27,741 --> 00:03:31,945
以及植入的使用这些
新的API的音频单元


56
00:03:32,312 --> 00:03:35,582
主机与 AU音频单元类通讯


57
00:03:35,983 --> 00:03:40,053
新的第三代音频单元会
将AU音频单元纳入子类


58
00:03:40,854 --> 00:03:42,823
这就成了两种不同的API


59
00:03:42,890 --> 00:03:45,225
我们怎么才能确保兼容呢


60
00:03:45,826 --> 00:03:48,629
我们需要在这两种API之间使用桥站


61
00:03:49,930 --> 00:03:51,665
正因有了桥站我们会发现


62
00:03:52,065 --> 00:03:57,004
第三代主机与现有的二代音频单元


63
00:03:57,237 --> 00:03:59,540
几乎完全兼容


64
00:04:00,274 --> 00:04:04,578
相反现有的二代主机只需要很小的改动


65
00:04:04,645 --> 00:04:08,482
就可适应新的第三代音频单元


66
00:04:08,815 --> 00:04:11,552
我将详细介绍这些API的改动


67
00:04:15,455 --> 00:04:17,558
现在我将给大家展示


68
00:04:17,624 --> 00:04:19,760
在经过细微改良的
Logic Pro版本中


69
00:04:19,826 --> 00:04:22,896
使用新的音频单元的演示


70
00:04:25,332 --> 00:04:29,536
这里有一小段音乐里面有鼓点循环


71
00:04:31,238 --> 00:04:34,541
我将把一个音频单元放到这条音轨上


72
00:04:35,943 --> 00:04:38,612
这里所有的都是
Apple内置的音频单元


73
00:04:40,147 --> 00:04:45,419
这里还有一个叫做
v3失真的演示音频单元


74
00:04:46,687 --> 00:04:48,555
这样我打开这个音频单元


75
00:04:49,389 --> 00:04:54,695
我可以找到心仪的预置方案
我们可以听到Logic


76
00:04:54,828 --> 00:04:56,363
通过这个音频单元播放出来


77
00:05:01,668 --> 00:05:02,603
声音很干


78
00:05:04,771 --> 00:05:05,806
完全失真了


79
00:05:06,807 --> 00:05:09,309
现在如果我查看活动监视器


80
00:05:10,110 --> 00:05:13,413
我们可以发现


81
00:05:13,480 --> 00:05:17,317
这个失真音频单元在一个
独立进程AU v3 失真中运作


82
00:05:17,484 --> 00:05:19,820
这会消耗一点CPU


83
00:05:20,721 --> 00:05:21,889
会占据一些线程


84
00:05:23,090 --> 00:05:27,794
假设这个音频单元内部
有一个bug它就会崩溃


85
00:05:27,861 --> 00:05:30,430
我可以在活动监视器中进行模拟


86
00:05:30,964 --> 00:05:31,965
我可以强制退出


87
00:05:34,168 --> 00:05:36,470
注意Logic界面一片空白


88
00:05:36,870 --> 00:05:38,205
但音乐还在继续播放


89
00:05:49,183 --> 00:05:51,485
这是我们刚刚探讨问题的一个图


90
00:05:52,052 --> 00:05:54,955
这是经过细微改良的
Logic Pro


91
00:05:55,756 --> 00:05:59,893
但本质上还是使用
现有的二代API进行通讯


92
00:06:00,260 --> 00:06:03,830
与AU音频单元桥接


93
00:06:04,131 --> 00:06:06,533
进而在独立扩展服务进程中


94
00:06:06,900 --> 00:06:10,604
我们看到失真AU音频单元子类


95
00:06:11,305 --> 00:06:13,040
和定制的视图控制器同时运行


96
00:06:13,607 --> 00:06:16,210
Logic进程中也有视图控制器


97
00:06:16,810 --> 00:06:18,612
你可以看到这些是如何


98
00:06:19,213 --> 00:06:21,281
进行跨进程桥接的


99
00:06:24,918 --> 00:06:27,588
现在我们再看托管音频单元


100
00:06:28,255 --> 00:06:31,859
我将向大家展示使用
三代API的一个案例


101
00:06:32,159 --> 00:06:35,295
我们有这一段称为音频单元
v3 Example的样本代码


102
00:06:35,729 --> 00:06:38,232
几小时前我检查过这段代码还没有写好


103
00:06:38,565 --> 00:06:42,603
我希望今天它能够工作正常


104
00:06:42,903 --> 00:06:45,339
在这个样本代码项目中
你可以看到有很多个样靶


105
00:06:45,472 --> 00:06:48,175
其中一个叫做AU主机


106
00:06:49,009 --> 00:06:51,879
这个App相当简洁明了


107
00:06:52,279 --> 00:06:56,250
但它展示了怎样找到
并打开系统中音频单元的过程


108
00:06:56,950 --> 00:06:58,485
怎样连接形成特效链


109
00:06:58,819 --> 00:07:02,322
怎样选择音频单元预置方案


110
00:07:02,756 --> 00:07:05,792
以及怎样打开音频单元自定义界面


111
00:07:07,794 --> 00:07:11,498
因此在AU主机app中
我们有所谓的简单播放引擎


112
00:07:11,899 --> 00:07:15,369
也就是使用
AVAudioEngine的Swift类


113
00:07:16,036 --> 00:07:19,106
它使用一个AV音频播放器结点


114
00:07:19,173 --> 00:07:20,841
并连接到AV音频单元特效


115
00:07:21,241 --> 00:07:23,810
继而AV音频单元特效显示出


116
00:07:23,977 --> 00:07:26,547
内部的AU音频单元


117
00:07:27,147 --> 00:07:31,018
也就是第三代音频
单元API的一个主类


118
00:07:31,752 --> 00:07:33,487
播放器连接到特效器 


119
00:07:33,554 --> 00:07:34,988
混音器和输出上


120
00:07:35,255 --> 00:07:37,424
这就是简单播放引擎的工作原理


121
00:07:38,892 --> 00:07:42,963
我们还将看到如何使用


122
00:07:43,030 --> 00:07:46,400
AV音频单元组件管理
器类别选择系统中的


123
00:07:46,466 --> 00:07:50,103
AV音频单元组件


124
00:07:50,170 --> 00:07:52,606
以及控制AV音频单元选择的特效


125
00:07:54,641 --> 00:07:56,443
让我们来看一段代码


126
00:07:56,510 --> 00:07:59,580
首先在使用音频单元时


127
00:07:59,646 --> 00:08:01,281
我们有一个非常重要的数据结构


128
00:08:01,882 --> 00:08:03,784
我们有音频组件描述


129
00:08:04,284 --> 00:08:06,787
以及三个相关的主要域组件类别


130
00:08:07,254 --> 00:08:10,390
子类别以及制造商


131
00:08:10,824 --> 00:08:14,628
这一元组标记出系统中特定的音频单元


132
00:08:15,229 --> 00:08:16,730
标记也十分重要


133
00:08:16,797 --> 00:08:19,566
由音频组件部分植入


134
00:08:19,933 --> 00:08:23,370
系统也会植入新的音频组件


135
00:08:23,804 --> 00:08:25,772
在解说过程中
我们还会对部分进行细致探讨


136
00:08:26,406 --> 00:08:28,008
很重要的一点是


137
00:08:28,075 --> 00:08:29,943
这是识别插件的关键


138
00:08:32,145 --> 00:08:34,948
因此 为了找到系统中的音频单元组件


139
00:08:35,849 --> 00:08:38,919
首先我们需要创建一个包含通配符的


140
00:08:39,653 --> 00:08:41,321
音频组件描述


141
00:08:41,655 --> 00:08:43,724
这里我们所说的组件类别是特效


142
00:08:43,823 --> 00:08:44,958
那并不是通配符 


143
00:08:45,392 --> 00:08:48,462
这里还有组件子类别和元制造商


144
00:08:48,795 --> 00:08:52,065
那些才是通配符
这样我们有了组件描述


145
00:08:52,266 --> 00:08:54,067
可以识别任何特效了


146
00:08:55,969 --> 00:09:00,574
接下来我们可以选择任意特效组件描述


147
00:09:00,641 --> 00:09:03,510
应用到AV音频单元组件管理器


148
00:09:04,111 --> 00:09:06,914
我们会得到与通配符相适应的系统中的


149
00:09:07,247 --> 00:09:08,749
所有特效的渲染


150
00:09:09,616 --> 00:09:13,353
现在我们有了一系列
AV音频单元组件对象


151
00:09:13,987 --> 00:09:18,392
其中包含了名称 标签


152
00:09:18,859 --> 00:09:23,363
以及该单元的音频组件描述


153
00:09:25,332 --> 00:09:27,401
我们得到了一系列的组件


154
00:09:27,467 --> 00:09:29,102
我们可以将它放回UI中


155
00:09:29,503 --> 00:09:34,141
继而UI可以在简单
播放引擎中使用这种方法


156
00:09:34,541 --> 00:09:37,945
挑选出一种此前已经上市的


157
00:09:38,645 --> 00:09:39,780
特效组件


158
00:09:40,147 --> 00:09:41,715
这样我们得到了一个组件


159
00:09:42,182 --> 00:09:44,985
将它使用到一种内部的方法上


160
00:09:45,586 --> 00:09:50,791
这种内部方法的本质


161
00:09:50,858 --> 00:09:51,792
就是这样


162
00:09:52,292 --> 00:09:56,430
我们将命名一种
新的AV音频单元分类方法


163
00:09:57,297 --> 00:10:00,901
这种方法需要基于这里的


164
00:10:00,968 --> 00:10:03,103
组件描述创造一个实例


165
00:10:04,137 --> 00:10:07,274
这是一种异步功能
也就是说它会进行实例化


166
00:10:07,341 --> 00:10:09,309
但真正将音频单元实例化


167
00:10:09,743 --> 00:10:11,845
并且我们可以使用之后


168
00:10:13,647 --> 00:10:20,554
就会自行关闭


169
00:10:21,488 --> 00:10:23,023
因此这里我们可以得到回馈信号


170
00:10:23,090 --> 00:10:24,791
这是Swift闭合语法


171
00:10:25,392 --> 00:10:27,027
我们有自己的AV音频单元


172
00:10:29,296 --> 00:10:32,999
随后我们可以将它应用到我们的引擎上


173
00:10:33,700 --> 00:10:36,270
我们将它储存到一个成员变量即特效中


174
00:10:39,339 --> 00:10:43,677
我们也就得到了一个可以
察觉特效的AV音频单元


175
00:10:43,744 --> 00:10:45,579
我们对引擎打入补丁


176
00:10:46,146 --> 00:10:48,515
特效和主混音器断开


177
00:10:49,216 --> 00:10:51,585
然后连接播放器和特效


178
00:10:52,886 --> 00:10:55,889
然后特效再连接到主混音器节点


179
00:10:57,658 --> 00:10:59,560
这样我们就在播放
引擎中加入了一种特效


180
00:11:01,428 --> 00:11:05,632
我们可以保存真实的AU音频单元


181
00:11:06,066 --> 00:11:09,203
这是插件利用插件我们可以
做各种各样有趣的事情


182
00:11:09,269 --> 00:11:13,640
比如操控组件的特效预置方案和参数


183
00:11:14,942 --> 00:11:18,946
例如 从这里我们将看到
出厂预置方案的列表


184
00:11:20,581 --> 00:11:23,383
这也将向表格视图而不是UI中


185
00:11:23,450 --> 00:11:25,719
植入一个域


186
00:11:27,221 --> 00:11:29,356
这样 用户可以选择出厂预置


187
00:11:31,225 --> 00:11:33,227
最后我们还想向诸位展示


188
00:11:34,328 --> 00:11:36,129
我们将怎样利用
接下来我要展示的App


189
00:11:36,430 --> 00:11:39,132
得到音频单元的自定义视图


190
00:11:39,199 --> 00:11:40,968
以及怎样将其嵌入主程序视图


191
00:11:41,535 --> 00:11:43,904
现在我们进入了主机的视图控制器


192
00:11:44,404 --> 00:11:47,574
我们要求播放引擎给我们音频单元


193
00:11:47,875 --> 00:11:49,810
然后再从音频单元中


194
00:11:49,910 --> 00:11:50,911
获得视图控制器


195
00:11:51,211 --> 00:11:53,046
当完成了这些步骤之后它将反馈给我们


196
00:11:53,113 --> 00:11:56,483
一个视图控制器
我们就将它嵌入到主视图中


197
00:11:58,252 --> 00:12:00,821
好的 接下来有请我的同事
迈克尔·霍普金斯


198
00:12:01,255 --> 00:12:03,390
为大家演示这个App是如何运作的


199
00:12:12,699 --> 00:12:13,867
非常感谢你 道格


200
00:12:14,168 --> 00:12:16,003
非常荣幸今天有机会


201
00:12:16,069 --> 00:12:20,474
向大家演示这款基于
AVAudioEngine第三代主应用


202
00:12:21,008 --> 00:12:23,343
如何在iPad上使用


203
00:12:24,144 --> 00:12:26,780
正如你所见我点击一下主机的图标


204
00:12:26,847 --> 00:12:28,148
就可以打开它


205
00:12:29,116 --> 00:12:32,653
在屏幕的左手边
我们有一个包含音频单元


206
00:12:33,153 --> 00:12:35,122
在系统呈现的所有特效的列表


207
00:12:35,489 --> 00:12:39,593
既包含了内部
Apple音频组件的特效


208
00:12:40,027 --> 00:12:42,396
也包含了我自己添加的


209
00:12:42,462 --> 00:12:44,565
新扩展的第三代音频单元


210
00:12:45,766 --> 00:12:48,969
在屏幕的顶端有一个播放键 


211
00:12:49,069 --> 00:12:51,672
点击可以触发鼓点循环的播放


212
00:12:52,739 --> 00:12:56,009
现在让我们来看看
怎样应用一些特效结点


213
00:12:56,210 --> 00:12:57,411
以及怎样将它们加到图表中


214
00:12:57,945 --> 00:12:59,746
首先我播放一次无特效音乐


215
00:12:59,813 --> 00:13:01,114
然后我再加几个特效


216
00:13:01,181 --> 00:13:02,683
这样方便大家听出它的作用


217
00:13:09,790 --> 00:13:13,660
利用高通率波器滤除大部分铙钹的声音


218
00:13:13,994 --> 00:13:15,729
以及其他高频声音


219
00:13:17,431 --> 00:13:19,600
声音略有延迟
在这个屋子里不是很听得清楚


220
00:13:22,936 --> 00:13:24,371
这段音乐就播放到这儿我们继续


221
00:13:24,872 --> 00:13:26,106
现在我在向大家展示


222
00:13:26,173 --> 00:13:29,443
在iPad上运行音频扩展单元


223
00:13:29,510 --> 00:13:31,078
这将会是它的处女秀


224
00:13:32,112 --> 00:13:33,881
这是一首失真的演示


225
00:13:34,681 --> 00:13:37,584
当选择之后大家可以看到


226
00:13:37,651 --> 00:13:40,420
音频单元所提供的所有出厂预置的列表


227
00:13:41,255 --> 00:13:44,091
这里面包含了一些鼓点特别明显的方案


228
00:13:44,358 --> 00:13:47,160
也包含了一些非常狂野的设置
比如外星人的叨叨声


229
00:13:48,462 --> 00:13:49,663
刚才道格提到


230
00:13:49,830 --> 00:13:54,067
第三代音频单元
在iOS上有自定义界面


231
00:13:54,568 --> 00:13:56,036
我将向大家演示


232
00:13:56,103 --> 00:13:57,905
我继续演示点击视图按钮


233
00:13:58,405 --> 00:14:02,476
我们所完成的是从音频单元中


234
00:14:02,543 --> 00:14:04,478
加载视图控制器的动作


235
00:14:04,545 --> 00:14:08,382
我将它作为子视图控制器
安装在App中


236
00:14:08,448 --> 00:14:11,852
我们首次在主机中拥有


237
00:14:11,919 --> 00:14:13,921
带有UI的内置音频单元


238
00:14:15,088 --> 00:14:19,459
我们有一个很大的滑动条
对不起 是按钮


239
00:14:19,526 --> 00:14:21,795
可以用来控制失真的量


240
00:14:22,863 --> 00:14:24,464
请允许我继续我将播放这段声音


241
00:14:24,531 --> 00:14:25,933
以便诸位能亲耳判别


242
00:14:43,984 --> 00:14:45,452
这真的很有趣


243
00:14:45,519 --> 00:14:47,788
我们可以在一个主应用中


244
00:14:47,855 --> 00:14:52,326
流畅地使用多点触控的UI


245
00:14:52,392 --> 00:14:54,528
而且省去了很多麻烦


246
00:14:54,795 --> 00:14:57,064
过去我们还得切换到另一个App


247
00:14:57,130 --> 00:14:59,032
捣鼓半天再切回主应用


248
00:14:59,366 --> 00:15:01,268
开始录音后再切换回去


249
00:15:01,335 --> 00:15:03,070
现在你再也不必重复这些步骤了


250
00:15:09,042 --> 00:15:09,877
谢谢


251
00:15:10,744 --> 00:15:12,379
我还想指出


252
00:15:12,446 --> 00:15:15,849
这个音频单元正是刚才道格在
Logic里面播放演示中 


253
00:15:15,916 --> 00:15:17,551
使用的那个音频单元


254
00:15:17,951 --> 00:15:20,954
事实上 音频单元的源代码完全一样


255
00:15:21,021 --> 00:15:22,322
无需再做修改


256
00:15:22,890 --> 00:15:26,560
编码也十分相似因为编写过程中


257
00:15:26,627 --> 00:15:28,495
我使用了
Core Animation


258
00:15:28,562 --> 00:15:30,831
以使API更为便携


259
00:15:31,498 --> 00:15:33,300
要将这个音频单元植入iOS 


260
00:15:33,367 --> 00:15:36,937
唯一需要做的必要改变就是事件模型


261
00:15:37,004 --> 00:15:39,473
我们需要用UIKit里的触摸事件


262
00:15:39,540 --> 00:15:44,978
代替桌面的APPkit鼠标事件


263
00:15:45,512 --> 00:15:47,581
说真的 诸位有机会利用一点点改变


264
00:15:47,648 --> 00:15:50,384
就可以在桌面和iOS上


265
00:15:51,151 --> 00:15:54,221
同时发布一个音频单元


266
00:15:55,189 --> 00:15:56,023
非常感谢


267
00:15:57,224 --> 00:15:58,158
现场交还给道格


268
00:16:01,328 --> 00:16:02,162
感谢迈克尔


269
00:16:05,666 --> 00:16:08,802
我想和大家探讨一下


270
00:16:09,169 --> 00:16:11,605
不使用
AVAudioEngine的情况下


271
00:16:11,672 --> 00:16:13,640
怎样在主操作程序中
使用音频单元的问题


272
00:16:14,441 --> 00:16:18,145
在使用AU音频单元类


273
00:16:18,545 --> 00:16:20,614
异步创建一个组件描述实例时


274
00:16:20,681 --> 00:16:21,882
我们会使用类似的方法


275
00:16:21,949 --> 00:16:22,783
请看那里


276
00:16:23,550 --> 00:16:26,720
对于还在使用二代主机的人来说


277
00:16:27,054 --> 00:16:29,890
我们最简单的翻译途径是


278
00:16:29,957 --> 00:16:32,392
使用音频组件进行实例化


279
00:16:32,793 --> 00:16:34,928
我们将细致探讨该问题


280
00:16:37,631 --> 00:16:39,433
现在 我想和大家探讨一下


281
00:16:40,300 --> 00:16:42,069
用扩展服务进程替代插件


282
00:16:42,135 --> 00:16:45,305
加载到主机进程中的问题


283
00:16:47,074 --> 00:16:50,310
任何接触过音频单元的人都清楚


284
00:16:50,377 --> 00:16:52,312
利用我们现有的插件模型


285
00:16:52,646 --> 00:16:55,449
插件总是加载到主机进程中


286
00:16:55,883 --> 00:16:59,553
对于三代主机来说也是这样


287
00:16:59,786 --> 00:17:02,055
如果是一个二代插件


288
00:17:02,389 --> 00:17:05,526
可能是iOS上使用的苹果插件


289
00:17:05,592 --> 00:17:09,128
也可能是OS X上使用的第三方插件


290
00:17:09,796 --> 00:17:12,799
但不论哪种情形都是二代音频单元


291
00:17:12,866 --> 00:17:15,368
不需要考虑其他因素
始终是加载到主机进程中的


292
00:17:17,003 --> 00:17:19,873
现在三代音频单元讲起来


293
00:17:19,940 --> 00:17:21,008
略微有点复杂


294
00:17:21,675 --> 00:17:25,345
在初始状态下三代音频单元加载到


295
00:17:25,412 --> 00:17:28,080
一个独立的扩展服务进程


296
00:17:28,448 --> 00:17:31,185
这张图表显示的是在Logic
出现之前我们所见情形


297
00:17:32,686 --> 00:17:35,656
对于二代和三代主机来说


298
00:17:35,722 --> 00:17:36,990
这都是正确的


299
00:17:38,091 --> 00:17:43,197
现在OS X上插件只能


300
00:17:43,263 --> 00:17:46,099
直接加载到主机进程中


301
00:17:46,600 --> 00:17:50,103
为了使之成为可能需要同时使用到二者


302
00:17:50,637 --> 00:17:54,007
在实例化音频单元时


303
00:17:54,074 --> 00:17:55,876
主机需要将选项传递给


304
00:17:55,943 --> 00:17:58,812
我们刚才所见到的
任意一种异步创建方法


305
00:17:59,980 --> 00:18:02,182
你可以看到新标记的名称


306
00:18:02,249 --> 00:18:03,517
叫做进程加载音频单元


307
00:18:04,051 --> 00:18:07,554
还需要利用


308
00:18:07,888 --> 00:18:11,625
音频组件包列表条目


309
00:18:11,859 --> 00:18:13,160
进行特殊的打包和授权


310
00:18:13,861 --> 00:18:15,863
如果同时使用


311
00:18:16,230 --> 00:18:19,766
那么框架将把插件


312
00:18:19,833 --> 00:18:21,268
加载到主机进程


313
00:18:21,401 --> 00:18:23,837
主机将会直接与插件的


314
00:18:24,271 --> 00:18:26,773
AU音频单元子类进行通讯


315
00:18:30,010 --> 00:18:33,046
作为一个主机编写人员
你为什么想这样做呢


316
00:18:33,547 --> 00:18:36,216
原因是要在安全性和性能之间


317
00:18:36,316 --> 00:18:37,384
进行权衡


318
00:18:37,885 --> 00:18:41,255
毋庸置疑 向App中添加
第三方代码会有安全风险


319
00:18:41,321 --> 00:18:46,059
如果在App中崩溃


320
00:18:46,393 --> 00:18:48,529
用户埋怨的将会是你


321
00:18:48,595 --> 00:18:50,063
而不是特效不佳的插件


322
00:18:51,532 --> 00:18:54,201
但另一方面 出于性能考虑


323
00:18:54,268 --> 00:18:57,838
如果你在做主机


324
00:18:57,905 --> 00:19:00,641
你想向进程中加载插件


325
00:19:00,774 --> 00:19:03,043
因为与独立的扩展服务程序通讯


326
00:19:03,110 --> 00:19:04,244
会造成一些间接损耗


327
00:19:04,845 --> 00:19:07,181
我们以40微秒


328
00:19:07,281 --> 00:19:09,383
为一个渲染周期进行了计算


329
00:19:09,950 --> 00:19:12,452
你可以自行计算一下


330
00:19:12,519 --> 00:19:14,788
这在你的主机中有多么重大的意义


331
00:19:15,355 --> 00:19:19,526
可能还需要与一些
程序外的插件进行通讯


332
00:19:20,060 --> 00:19:21,662
你还需要把这部分算上


333
00:19:22,229 --> 00:19:23,664
此外你预期渲染多少声频


334
00:19:23,730 --> 00:19:26,867
同样也是需要考虑的因素


335
00:19:27,668 --> 00:19:33,674
比如 如果以32帧这样
在每个渲染循环之间间隔为1毫秒


336
00:19:34,007 --> 00:19:36,543
因此40微秒的损耗将


337
00:19:36,610 --> 00:19:38,512
占据高达5.5%的比例


338
00:19:40,414 --> 00:19:43,217
如果你是主机编写人员
你需要做出这样的权衡


339
00:19:44,985 --> 00:19:46,353
我之前提到过


340
00:19:46,420 --> 00:19:49,489
现有的二代音频单元主机


341
00:19:49,857 --> 00:19:52,125
在与三代音频单元共存时需要几处改变


342
00:19:52,192 --> 00:19:53,994
以下便是需要改变的地方


343
00:19:55,229 --> 00:19:58,565
我提到了音频组件描述标记


344
00:19:59,166 --> 00:20:01,635
这里便是组件标记


345
00:20:01,702 --> 00:20:04,638
这是一种称为异步实例化需求的新标记


346
00:20:05,239 --> 00:20:09,576
它适用于多数
哪怕不是全部的三代音频单元


347
00:20:10,010 --> 00:20:13,146
如果你在组件描述中看到了这个标记


348
00:20:13,213 --> 00:20:16,550
你就必须使用新的音频组件实例化方法


349
00:20:16,950 --> 00:20:19,019
而不是音频组件新实例


350
00:20:21,021 --> 00:20:23,757
类似的在二代主机上


351
00:20:24,391 --> 00:20:27,361
如果你想进入一个
音频单元的视图控制器


352
00:20:28,161 --> 00:20:31,698
你也必须使用一种新的异步方法


353
00:20:32,099 --> 00:20:34,801
有一种新的属性请求视图控制器


354
00:20:35,269 --> 00:20:36,503
也是异步的


355
00:20:36,570 --> 00:20:38,906
你可以在音频单元属性h部分中


356
00:20:39,106 --> 00:20:41,241
详细阅读


357
00:20:43,610 --> 00:20:46,180
关于这些异步方法


358
00:20:46,580 --> 00:20:49,883
你可以利用二代单元使用新的方法


359
00:20:49,983 --> 00:20:54,688
但如果有标记那就必须使用三代单元


360
00:20:56,190 --> 00:20:57,658
我们的思路是


361
00:20:57,991 --> 00:21:01,929
我们这么做的动机是
因为这样能提高响应能力


362
00:21:02,229 --> 00:21:04,932
如果实例化音频单元需要半秒


363
00:21:04,998 --> 00:21:08,569
如果你释放主线程


364
00:21:09,203 --> 00:21:11,638
你的主应用 仪表或者其他动画


365
00:21:11,705 --> 00:21:13,307
将继续流畅运行


366
00:21:14,441 --> 00:21:16,944
尤其是在更新现有代码时


367
00:21:17,010 --> 00:21:21,381
这也正是我在测试内测代码时


368
00:21:21,448 --> 00:21:23,417
做的第一件事


369
00:21:23,483 --> 00:21:24,718
就像坐在那儿


370
00:21:24,785 --> 00:21:27,054
干等主线程完成异步操作


371
00:21:27,721 --> 00:21:28,822
千万别这么干


372
00:21:28,922 --> 00:21:33,727
因为这样不仅会打乱
你正在制作的任何图表


373
00:21:34,194 --> 00:21:36,563
而且会扰乱框架的基础程序


374
00:21:37,130 --> 00:21:40,968
而这些可能是音频单元
实例化中所必要的


375
00:21:41,368 --> 00:21:43,770
如果你干等主线程那么你将会陷入僵局


376
00:21:43,971 --> 00:21:44,805
千万别这么干


377
00:21:47,241 --> 00:21:49,376
现在我们把话题


378
00:21:49,443 --> 00:21:52,980
从主机音频单元转到


379
00:21:53,046 --> 00:21:55,215
使用三代API创建音频单元上来


380
00:21:57,317 --> 00:22:02,055
首先考虑到新的音频单元模型
是基于应用扩展的


381
00:22:02,222 --> 00:22:04,258
我们简单聊一聊应用扩展


382
00:22:05,459 --> 00:22:09,997
应用扩展是appex.文件类型扩展


383
00:22:10,364 --> 00:22:13,600
Xcode将把它们嵌入
App插件条目中


384
00:22:14,034 --> 00:22:18,505
我们可以看到系统是如何


385
00:22:18,906 --> 00:22:21,542
将它们加载到独立的扩展服务进程中的


386
00:22:22,075 --> 00:22:26,313
你可以在应用扩展编写指南中


387
00:22:26,580 --> 00:22:28,482
读到应用扩展的全部细节


388
00:22:31,218 --> 00:22:35,489
我们新的样本代码
项目音频单元v3示例


389
00:22:35,956 --> 00:22:38,825
包含了一段叫做
Filter Demo的


390
00:22:38,892 --> 00:22:39,927
示例音频单元执行


391
00:22:42,663 --> 00:22:43,964
当你研究样本项目时


392
00:22:44,031 --> 00:22:46,800
你会发现
Filter Demo有三个目标


393
00:22:47,301 --> 00:22:49,303
它有我们所说的容器App


394
00:22:50,070 --> 00:22:54,708
里面有有应用扩展


395
00:22:55,142 --> 00:22:58,245
和普通代码的框架


396
00:22:58,612 --> 00:23:01,815
App和扩展都链接到框架中


397
00:23:03,483 --> 00:23:06,753
在框架内 我们有两种主要的类别


398
00:23:07,120 --> 00:23:08,856
一种是
AU v3 Filter Demo


399
00:23:09,289 --> 00:23:11,425
是AU音频单元的子类别


400
00:23:11,692 --> 00:23:13,927
还有一种是
Filter Demo视图控制器


401
00:23:14,761 --> 00:23:18,498
控制着音频单元的自定义界面


402
00:23:20,501 --> 00:23:22,636
这么做最酷的一面就是


403
00:23:23,070 --> 00:23:26,907
我们开发了


404
00:23:27,341 --> 00:23:30,010
属于自己的信号处理和视图代码


405
00:23:30,811 --> 00:23:33,914
我们可以完全在
自己App的环境中完成


406
00:23:33,981 --> 00:23:36,683
因此我们不再是
在独立的SPC服务进程中清除bug


407
00:23:36,750 --> 00:23:38,652
而是在与我们自己的
App交互过程中清除bug


408
00:23:38,719 --> 00:23:39,620
开发属于自己的代码


409
00:23:40,521 --> 00:23:43,190
我们还让用户在打开App时


410
00:23:43,257 --> 00:23:44,525
觉得看起来很不错


411
00:23:44,591 --> 00:23:46,627
这并不仅仅是一种为了
别人而设计的插件


412
00:23:47,127 --> 00:23:49,930
我们也不是通过复制代码


413
00:23:49,997 --> 00:23:51,298
才实现这一目标


414
00:23:52,432 --> 00:23:57,237
这在OS X上还有一个额外的好处


415
00:23:57,771 --> 00:24:00,507
如果我们想的话


416
00:24:00,707 --> 00:24:03,310
我们可以指定这一框架
成为主进程加载束


417
00:24:07,447 --> 00:24:09,049
让我们看看应用扩展


418
00:24:09,116 --> 00:24:11,952
这里有一个包含很多
重要条目的info plist


419
00:24:12,352 --> 00:24:15,489
NSExtensionPointIdentifier
告诉系统


420
00:24:15,556 --> 00:24:18,992
这是什么样的扩展


421
00:24:19,393 --> 00:24:21,161
主故事板告诉系统


422
00:24:21,228 --> 00:24:24,064
当打开我的扩展服务进程时打开故事板


423
00:24:25,199 --> 00:24:28,101
最后 还有一个音频组件序列告诉系统


424
00:24:28,402 --> 00:24:32,139
这是我在注册的


425
00:24:32,673 --> 00:24:33,707
音频组件描述


426
00:24:37,311 --> 00:24:40,614
简单提示一下在你的故事板中


427
00:24:40,681 --> 00:24:44,518
你必须明确你的自定义类


428
00:24:44,651 --> 00:24:47,454
如果你要把它嵌入一个独立框架


429
00:24:47,521 --> 00:24:49,323
你需要明确是哪个模块


430
00:24:50,490 --> 00:24:53,227
就像我们这里的一样


431
00:24:53,293 --> 00:24:54,494
扩展本身其实没有代码


432
00:24:54,561 --> 00:24:56,196
有的只是一小部分确保里面有代码


433
00:24:56,864 --> 00:24:59,066
我们要链接
Filter Demo框架


434
00:24:59,166 --> 00:25:00,367
这里的都是好东西


435
00:25:00,901 --> 00:25:03,704
我们有一个全局变量来指向它


436
00:25:06,373 --> 00:25:07,941
让我们回到框架


437
00:25:09,376 --> 00:25:10,744
框架中的主类别是


438
00:25:10,811 --> 00:25:13,313
Filter Demo视图控制器


439
00:25:13,814 --> 00:25:15,382
在扩展术语中


440
00:25:15,449 --> 00:25:17,317
这是扩展的首要类别


441
00:25:17,751 --> 00:25:20,521
创建或者加载扩展时


442
00:25:20,921 --> 00:25:22,756
系统都会创建一个


443
00:25:22,823 --> 00:25:24,591
属于这个首要类别的实例


444
00:25:25,192 --> 00:25:26,593
它有两个主要任务


445
00:25:26,894 --> 00:25:30,063
它创建AU音频单元的子类别


446
00:25:30,497 --> 00:25:33,500
比如你所预见的视图控制器


447
00:25:33,567 --> 00:25:36,303
它创建并管理插件定制界面


448
00:25:38,438 --> 00:25:41,542
这是Filter Demo
视图控制器类别定义


449
00:25:42,643 --> 00:25:44,878
从AU视图控制器演变而来


450
00:25:45,579 --> 00:25:48,649
本质上是一种NS或者UI视图控制器


451
00:25:49,483 --> 00:25:51,718
还使用了一种叫做


452
00:25:51,919 --> 00:25:53,420
AU音频单元工工厂的协议


453
00:25:53,921 --> 00:25:57,524
那是一个简单的协议
仅仅使用了一种方法 


454
00:25:59,059 --> 00:26:01,228
利用组件描述创建音频单元


455
00:26:02,563 --> 00:26:04,698
这一方法的任务是


456
00:26:04,765 --> 00:26:07,267
创建AU音频单元的子类别


457
00:26:08,702 --> 00:26:10,771
也就是这里的
AU v3 Filter Demo


458
00:26:14,608 --> 00:26:17,578
现在让我们看看AU音频单元的子类别


459
00:26:19,913 --> 00:26:22,482
由于种种原因我们只简单地探讨一下


460
00:26:22,950 --> 00:26:27,554
这些实际上是内嵌的C++类别或对象


461
00:26:28,021 --> 00:26:31,391
所有算法都是在滤波器
DSP kernel中进行的


462
00:26:33,260 --> 00:26:34,328
我们一会儿可以听到


463
00:26:34,394 --> 00:26:36,129
这比单是看它的代码有趣多了


464
00:26:37,965 --> 00:26:42,803
我们有一些处理总线的代码


465
00:26:43,136 --> 00:26:47,541
这是特效它有一个输入一个输出


466
00:26:47,608 --> 00:26:51,011
我们的基本类别需要
我们提供一连串的总线


467
00:26:51,111 --> 00:26:52,746
从而有支持的数字


468
00:26:53,514 --> 00:26:55,449
我们有所谓的参数树


469
00:26:56,450 --> 00:26:57,918
稍后我们会弄清它是指什么


470
00:26:58,485 --> 00:26:59,486
这是初始化器


471
00:27:00,587 --> 00:27:04,324
我们要做的第一件事就是
初始化我们的输入和输出总线


472
00:27:05,058 --> 00:27:07,594
然后将它们汇总到总线序列


473
00:27:09,096 --> 00:27:12,132
这些总线序列都包含一个单独的总线


474
00:27:16,103 --> 00:27:18,338
现在我们看看参数


475
00:27:18,939 --> 00:27:21,575
每个参数都是一个对象


476
00:27:21,975 --> 00:27:26,346
每个对象你都可以把它想成


477
00:27:26,647 --> 00:27:27,848
连接执行和主机之间的桥梁


478
00:27:27,915 --> 00:27:30,517
中间是参数对象


479
00:27:30,884 --> 00:27:32,419
这是一个简单的低通滤波器


480
00:27:32,486 --> 00:27:34,087
只有两个参数


481
00:27:34,354 --> 00:27:36,089
截止频率和停留


482
00:27:36,924 --> 00:27:39,159
每个参数都有标识符


483
00:27:39,426 --> 00:27:41,161
这里我们说截止


484
00:27:41,428 --> 00:27:42,996
它有一个本地化的名字


485
00:27:43,063 --> 00:27:44,798
我们做的不对这里没有进行本地化


486
00:27:46,099 --> 00:27:46,934
它有地址


487
00:27:47,000 --> 00:27:48,335
我们简要探讨一下它


488
00:27:48,936 --> 00:27:50,704
排列这些单元或者标记


489
00:27:51,071 --> 00:27:53,874
在使用二代音频单元时


490
00:27:54,007 --> 00:27:56,610
你会觉得这些标记是一样的


491
00:27:57,377 --> 00:27:59,379
这样我们创建了
我们的第一个参数


492
00:27:59,913 --> 00:28:02,716
我们会以几乎一样的方式
创建第二个参数


493
00:28:03,851 --> 00:28:06,653
最后我们可以创建我们自己的参数树


494
00:28:07,221 --> 00:28:09,723
将这两个参数排成序列


495
00:28:11,124 --> 00:28:14,428
这样我们就有了我们自己的参数树
我们想要将它接通


496
00:28:14,761 --> 00:28:17,264
以便与我们的DSP代码相连


497
00:28:19,132 --> 00:28:21,535
我们的方法是在参数树中


498
00:28:21,802 --> 00:28:25,572
安装一个叫做执行器值观测器的块


499
00:28:26,874 --> 00:28:30,277
只要是主机或界面参数改变


500
00:28:30,344 --> 00:28:33,881
这个块在任何时候都可以被调动


501
00:28:34,548 --> 00:28:37,150
因此 针对这种改变


502
00:28:37,451 --> 00:28:40,454
我们仅仅需要在我们的
DSP kernel中设置新的值


503
00:28:40,988 --> 00:28:43,390
可以立刻获得音响特效


504
00:28:45,592 --> 00:28:47,661
反过来有时这个参数树


505
00:28:47,728 --> 00:28:51,398
需要信号处理过程


506
00:28:51,465 --> 00:28:52,766
更新参数值


507
00:28:53,333 --> 00:28:55,068
它从DSP


508
00:28:56,937 --> 00:28:59,039
获取当前值


509
00:28:59,106 --> 00:29:00,774
将它反馈到参数树上


510
00:29:04,077 --> 00:29:07,080
这是一种重要的替换值方法


511
00:29:07,581 --> 00:29:10,117
如果你熟悉二代音频单元API


512
00:29:10,184 --> 00:29:12,753
这一过程被称为音频单元初始化


513
00:29:13,854 --> 00:29:17,191
这在Objective-C
可不是一个很好的名字


514
00:29:17,691 --> 00:29:19,993
所以我们决定要将它具体化


515
00:29:20,961 --> 00:29:25,132
初始化的时间就是用来


516
00:29:25,465 --> 00:29:28,669
准备渲染和分配有关的渲染资源


517
00:29:29,937 --> 00:29:33,640
比如缓冲 DSP状态 等等


518
00:29:34,541 --> 00:29:37,644
我们首要做的事情被称为基础类别方法


519
00:29:39,112 --> 00:29:42,583
然后我们要求总线分配存储空间给插件


520
00:29:42,783 --> 00:29:44,651
以便声频输入


521
00:29:45,786 --> 00:29:49,456
我们可以初始化我们的信号处理


522
00:29:50,457 --> 00:29:55,629
要根据现在输出总线的通道数和采样率


523
00:29:58,465 --> 00:30:01,268
因此我们有一种完全相反的方法


524
00:30:01,568 --> 00:30:03,504
叫做解除渲染资源分配


525
00:30:03,871 --> 00:30:05,739
我们把这还称为基础类


526
00:30:06,106 --> 00:30:09,510
原则上撤销我们
在分配过程中所做的一切


527
00:30:12,546 --> 00:30:16,116
利用块进行渲染过程


528
00:30:16,884 --> 00:30:21,421
在每个渲染循环中都会用到


529
00:30:21,522 --> 00:30:24,424
但我们需要在渲染开始前就提供块


530
00:30:25,792 --> 00:30:29,129
我们捕获C++代码


531
00:30:29,663 --> 00:30:32,599
改成作为指针局部变量


532
00:30:33,233 --> 00:30:37,871
原因是我们需要在实时环境中操作块


533
00:30:38,205 --> 00:30:41,808
这对于处理任何Objective-C
对象来说都不安全


534
00:30:42,309 --> 00:30:46,146
运行时间会阻塞


535
00:30:46,480 --> 00:30:49,283
造成音频故障


536
00:30:50,083 --> 00:30:54,688
因此我们将再次捕获C++代码变量


537
00:30:57,391 --> 00:30:59,026
然后在放回块


538
00:30:59,927 --> 00:31:02,029
它将反馈AU音频单元状态


539
00:31:03,096 --> 00:31:05,566
如果你熟悉二代API


540
00:31:05,632 --> 00:31:07,467
参数大体一致


541
00:31:07,835 --> 00:31:10,470
有时间标记 许多样本帧


542
00:31:11,004 --> 00:31:12,472
一个输出音频缓冲表


543
00:31:13,040 --> 00:31:15,909
这里是一个新玩意儿叫做实时事件表头


544
00:31:16,877 --> 00:31:19,713
我将详细介绍它


545
00:31:19,780 --> 00:31:22,583
它还与计划参数和MIDI事件相关


546
00:31:25,552 --> 00:31:27,354
最后是推动输入块


547
00:31:27,888 --> 00:31:31,058
主机告诉我们这叫音频单元的执行器


548
00:31:31,124 --> 00:31:33,927
获得输入的来源


549
00:31:35,596 --> 00:31:37,097
因此在输入块的内部


550
00:31:37,431 --> 00:31:40,868
我们要做的第一件事


551
00:31:41,134 --> 00:31:46,106
就是将推动输入块交给输入C++对象


552
00:31:46,340 --> 00:31:49,476
并且要求输入块为
渲染循环抓取音频输入


553
00:31:51,044 --> 00:31:53,280
随后我们清理清理缓冲


554
00:31:53,347 --> 00:31:56,583
我们再把它们交给DSP状态


555
00:31:57,851 --> 00:32:03,323
最后 DSP状态为渲染循环处理音频


556
00:32:04,391 --> 00:32:06,793
缓冲器已经收到信号


557
00:32:06,894 --> 00:32:09,963
只需给它一个时间标记和帧计数


558
00:32:10,163 --> 00:32:12,432
以及实时事件的链接表


559
00:32:13,333 --> 00:32:15,502
这便是这个音频单元的内容


560
00:32:15,569 --> 00:32:17,104
但代码的全部并不止这些


561
00:32:17,171 --> 00:32:18,572
实际信号处理的代码


562
00:32:18,639 --> 00:32:19,773
远比这多得多


563
00:32:20,374 --> 00:32:22,342
但正如我们刚才讲的那样


564
00:32:22,743 --> 00:32:24,044
听远比看来得好


565
00:32:24,111 --> 00:32:25,879
因此我想再次请回
迈克尔·霍普金斯


566
00:32:26,513 --> 00:32:29,316
向我们展示
AU v3 Filter Demo


567
00:32:32,286 --> 00:32:33,120
谢谢道格


568
00:32:40,327 --> 00:32:46,066
我继续讲 从包含扩展的应用容器开始


569
00:32:47,234 --> 00:32:49,570
你将首先看到


570
00:32:49,636 --> 00:32:51,905
屏幕左边是我们的
Filter Demo


571
00:32:52,272 --> 00:32:54,141
我们将它分解成代码样本


572
00:32:54,675 --> 00:32:59,313
右边是我之前给你们
演示的失真演示应用


573
00:33:00,347 --> 00:33:02,015
我将启动Filter Demo


574
00:33:03,150 --> 00:33:04,918
在屏幕的顶部


575
00:33:04,985 --> 00:33:06,320
你会看到


576
00:33:06,386 --> 00:33:07,654
道格谈到的两个参数


577
00:33:08,121 --> 00:33:10,390
在停留参数中有停止点


578
00:33:10,858 --> 00:33:12,726
在UI中永一个滑动块


579
00:33:12,793 --> 00:33:14,828
和一个文本域来表示


580
00:33:15,329 --> 00:33:18,365
实际上 应用包括了这部分UI 


581
00:33:18,432 --> 00:33:23,437
而主屏幕面积较大的图案


582
00:33:23,737 --> 00:33:26,139
实际上是音频单元


583
00:33:26,540 --> 00:33:27,875
嵌入视图


584
00:33:29,076 --> 00:33:32,679
我可以通过拖动滑动条


585
00:33:32,746 --> 00:33:34,181
来改变参数的值


586
00:33:35,249 --> 00:33:39,920
看有什么变化应用改变


587
00:33:40,454 --> 00:33:43,323
该参数的值也改变


588
00:33:43,390 --> 00:33:44,858
视图也随参数而更新


589
00:33:45,592 --> 00:33:47,861
正如您将看到更新是实时的


590
00:33:48,529 --> 00:33:51,899
相反我可以直接


591
00:33:52,099 --> 00:33:53,267
点击和拖动


592
00:33:53,700 --> 00:33:55,736
我们嵌入的音频单元


593
00:33:56,370 --> 00:33:58,705
你会注意到当我用手指拖动它时


594
00:33:58,772 --> 00:34:01,475
应用接收到参数已经改变的通知


595
00:34:01,909 --> 00:34:04,511
然后会依次更新


596
00:34:05,379 --> 00:34:07,247
但这是一种没有音乐的


597
00:34:07,314 --> 00:34:09,283
无聊演示 对吧


598
00:34:09,983 --> 00:34:11,618
让我们来听一听


599
00:34:30,637 --> 00:34:32,005
我能整天做这个


600
00:34:32,072 --> 00:34:32,906
你有时间吗


601
00:34:35,309 --> 00:34:40,080
现在真的很酷 很流畅
谢谢


602
00:34:40,581 --> 00:34:44,685
用你的手指就可以玩多触点UI


603
00:34:44,751 --> 00:34:46,119
非常有趣


604
00:34:46,453 --> 00:34:47,621
很神奇


605
00:34:47,688 --> 00:34:51,958
另一件有趣的事是


606
00:34:52,926 --> 00:34:55,728
因为我们以这种方式设计的用户界面


607
00:34:55,795 --> 00:35:00,000
可以适应任何大小尺寸的设备


608
00:35:00,467 --> 00:35:04,538
我们以这个iPad为例


609
00:35:04,605 --> 00:35:07,608
旋转后看到不同的用户界面


610
00:35:07,941 --> 00:35:12,379
从纵向视图到横向视图 反之亦然


611
00:35:14,581 --> 00:35:17,784
我们能做到这点是因为
我们支持自动布局


612
00:35:17,851 --> 00:35:20,854
我们考虑大小等级 


613
00:35:21,188 --> 00:35:23,757
但当我们把它放到


614
00:35:23,824 --> 00:35:26,226
我们的主应用中


615
00:35:26,293 --> 00:35:29,229
而主应用的屏幕专用插件更小
会发生什么呢


616
00:35:30,063 --> 00:35:32,199
所以我返回


617
00:35:32,699 --> 00:35:34,401
打开主机


618
00:35:35,035 --> 00:35:37,404
我要清除失真样本


619
00:35:37,504 --> 00:35:40,440
嵌入我们的
Filter Demo视图


620
00:35:40,507 --> 00:35:41,775
点击视图加载


621
00:35:42,276 --> 00:35:43,877
现在你可以看到


622
00:35:43,944 --> 00:35:50,083
虽然加载的垂直空间
很有限 水平比较大


623
00:35:50,651 --> 00:35:52,553
但是仍能可以运行


624
00:35:52,619 --> 00:35:55,656
没有标签重叠


625
00:35:57,691 --> 00:35:59,626
它仍然完全按我们所期望的运行


626
00:36:02,162 --> 00:36:04,398
这是一个奇妙的新技术


627
00:36:04,464 --> 00:36:06,934
我们很兴奋 终于能够给你们


628
00:36:07,201 --> 00:36:10,804
我都迫不及待地想看看
在你们的iOS应用上运行的情况了


629
00:36:11,972 --> 00:36:12,806
谢谢


630
00:36:16,743 --> 00:36:17,578
谢谢你 迈克


631
00:36:20,814 --> 00:36:24,117
现在我大概讲一下关于包含应用


632
00:36:24,751 --> 00:36:27,154
这个是插件载体


633
00:36:27,221 --> 00:36:29,022
通过快速迭代和快速开发提供协助


634
00:36:29,656 --> 00:36:33,560
但你可能考虑在包含
应用里放置其他东西


635
00:36:34,061 --> 00:36:36,897
通过Filter Demo
我们知道有简单播放引擎


636
00:36:37,364 --> 00:36:39,900
而且你还可以加载


637
00:36:39,967 --> 00:36:41,134
某些复杂的播放引擎


638
00:36:42,236 --> 00:36:44,404
主体应用能满足你的需求 


639
00:36:44,471 --> 00:36:47,541
你可以在其中放置触摸控制器


640
00:36:47,841 --> 00:36:49,743
在插件视图里可能没有空间


641
00:36:50,043 --> 00:36:51,278
储存全部触摸控制器


642
00:36:51,345 --> 00:36:54,948
就算空间足够 但你可能考虑


643
00:36:55,349 --> 00:36:56,750
在包含应用中


644
00:36:56,817 --> 00:36:57,918
储存其他东西


645
00:36:58,785 --> 00:37:02,189
这个应用还能储存文件资料


646
00:37:02,723 --> 00:37:06,126
还有压缩插件视图的功能


647
00:37:08,262 --> 00:37:11,231
下面是关于创建一个应用扩展的总结


648
00:37:11,865 --> 00:37:15,435
如果你要在OS X系统
进程上加载构架


649
00:37:15,502 --> 00:37:18,939
先抛开Swift语言不讲


650
00:37:19,806 --> 00:37:22,609
我们也不建议你们在
OS X系统上这样做


651
00:37:22,676 --> 00:37:26,146
因为Swift API可能会变化


652
00:37:27,047 --> 00:37:29,917
如果你开发不兼容
Swift版本一的插件


653
00:37:29,983 --> 00:37:32,886
并且加载到使用
Swift其他版本的主机


654
00:37:32,953 --> 00:37:35,689
会出现问题


655
00:37:37,024 --> 00:37:37,858
情况会很糟糕


656
00:37:38,725 --> 00:37:43,096
我们知道你在这儿看到样本代码


657
00:37:43,163 --> 00:37:45,899
你会试着开发自己的插件


658
00:37:45,966 --> 00:37:48,902
你需要知道有三个相关指标需要开发


659
00:37:49,269 --> 00:37:50,404
这有一点儿复杂


660
00:37:50,737 --> 00:37:52,739
我们计划开发X code模板


661
00:37:53,173 --> 00:37:56,043
但是现在你可以从随意复制
Filter Demo


662
00:38:00,214 --> 00:38:03,283
现在我从主机和实现两个方面 


663
00:38:03,817 --> 00:38:07,120
总体讲一下


664
00:38:07,321 --> 00:38:09,556
关于现代化AU音频单元API


665
00:38:12,793 --> 00:38:15,529
针对版本2和版本3的属性


666
00:38:15,596 --> 00:38:17,998
我们来做一下比较


667
00:38:18,632 --> 00:38:21,368
版本2AU音频单元API


668
00:38:21,702 --> 00:38:23,704
属性有作用域和元素


669
00:38:24,204 --> 00:38:26,907
全局范围有大量属性可用


670
00:38:26,974 --> 00:38:29,009
所以可以编写很多代码


671
00:38:29,309 --> 00:38:32,279
K音频单元全局范围和元素0


672
00:38:34,248 --> 00:38:37,150
在Swift语言中非常折磨人


673
00:38:37,784 --> 00:38:41,388
很多的属性值都是无效指针


674
00:38:41,922 --> 00:38:44,858
都出都可以看到无用指标


675
00:38:44,925 --> 00:38:46,560
这着实让我头疼


676
00:38:47,327 --> 00:38:50,731
对这些功能我们争议颇多


677
00:38:52,499 --> 00:38:55,002
相比较之下 在版本3 API里


678
00:38:55,469 --> 00:38:57,104
属性依旧是那些属性


679
00:38:57,938 --> 00:39:01,041
我们在Objective-C和
Swift语言里使用了dot语法


680
00:39:01,408 --> 00:39:04,178
这样你就可以以最大帧的AU进行渲染


681
00:39:05,112 --> 00:39:09,550
我们还对关键值编码
和关键值观测兼容进行分类


682
00:39:09,616 --> 00:39:12,953
这样你就可以对键使用值


683
00:39:13,053 --> 00:39:15,789
对关键路径添加观测器


684
00:39:16,790 --> 00:39:20,294
我们还对总线阵列添加
专门的KVO方法


685
00:39:20,661 --> 00:39:24,264
对所有的总线添加观测器这样你就不必


686
00:39:24,331 --> 00:39:26,233
同时时刻注意总线


687
00:39:26,667 --> 00:39:30,070
还可以在总线上添加KVO观测器


688
00:39:30,571 --> 00:39:34,174
免去了许多麻烦


689
00:39:35,742 --> 00:39:38,579
说到总线 在新的API中


690
00:39:38,645 --> 00:39:40,380
这些都已经进行了完善


691
00:39:40,781 --> 00:39:42,716
我们拥有AU音频单元总线阵列


692
00:39:43,350 --> 00:39:46,119
AU音频单元有一组输入总线


693
00:39:46,186 --> 00:39:47,521
和一组输出总线


694
00:39:48,689 --> 00:39:51,291
并且总线有两个主要属性


695
00:39:51,692 --> 00:39:54,027
他们有一种格式和一个名称


696
00:39:54,528 --> 00:39:56,964
格式由主机处理


697
00:39:58,665 --> 00:40:01,335
我们可以拒绝我们不想要的格式


698
00:40:01,401 --> 00:40:03,704
版本3的音频单元使用的格式


699
00:40:03,770 --> 00:40:04,905
与版本2 相同


700
00:40:08,308 --> 00:40:09,376
让我们看一下参数


701
00:40:09,443 --> 00:40:11,278
在版本2的API和参数中


702
00:40:11,411 --> 00:40:13,981
这里有一些问题


703
00:40:14,047 --> 00:40:15,349
因为我们改变的是属性


704
00:40:15,849 --> 00:40:18,952
这里有些不实用范围元素ID元祖


705
00:40:19,019 --> 00:40:21,321
此外在较为复杂的AU中 


706
00:40:21,855 --> 00:40:23,624
这里的位元不足


707
00:40:24,525 --> 00:40:27,461
再次我们开发了带有长参数列表的功能


708
00:40:27,861 --> 00:40:30,931
我们也开发了更好的
AU事件监听器API


709
00:40:33,567 --> 00:40:36,503
版本3的API中之前曾在


710
00:40:38,071 --> 00:40:40,340
介绍参数树和
Filter Demo的时候提到


711
00:40:40,707 --> 00:40:42,142
当然 这是个完整的参数树


712
00:40:42,242 --> 00:40:45,779
可以对其进行分组 


713
00:40:45,846 --> 00:40:48,582
这是有模拟合成器的简单模拟例子


714
00:40:48,916 --> 00:40:51,451
它有振荡器组 过滤组和放大器组


715
00:40:51,919 --> 00:40:55,556
这个过滤器和放大器组下还有组


716
00:40:55,856 --> 00:40:59,726
在这个颜色最鲜艳盒子下是
参数 波形八度


717
00:41:00,260 --> 00:41:03,197
滤波器截止点和共振


718
00:41:03,263 --> 00:41:06,266
包线区 维持和释放


719
00:41:07,734 --> 00:41:10,637
这些盒子都是节点  


720
00:41:10,704 --> 00:41:12,940
不管是组别还是参数 


721
00:41:13,006 --> 00:41:17,511
在参数树上的节点都有
一个唯一的永久的ID


722
00:41:17,778 --> 00:41:19,813
这个像一个C标识符


723
00:41:21,448 --> 00:41:25,419
所以用这些唯一的ID
我们可以启动KVC


724
00:41:25,485 --> 00:41:27,454
然后找到想要的参数


725
00:41:27,788 --> 00:41:32,192
例如振荡器 波动或者滤波器 包线等


726
00:41:32,593 --> 00:41:34,828
这让那些具有庞大的数据树


727
00:41:34,895 --> 00:41:37,030
更为复杂的音频组件


728
00:41:37,097 --> 00:41:39,499
变得更为灵活


729
00:41:40,534 --> 00:41:41,835
现在  你会注意到


730
00:41:41,902 --> 00:41:44,137
参数有数字地址


731
00:41:44,271 --> 00:41:48,408
且是64个位的地址但是在任何时候


732
00:41:48,475 --> 00:41:52,346
我们必须认为这只是暂时地址


733
00:41:52,813 --> 00:41:54,581
因为这些地址不是我们设定的


734
00:41:56,950 --> 00:41:59,753
也就是说如果我是一个主应用  


735
00:41:59,820 --> 00:42:02,122
我想记录参数自动化  


736
00:42:02,456 --> 00:42:06,560
我应该记录使用关键路径的自动化参数


737
00:42:07,094 --> 00:42:10,664
而不是其地址


738
00:42:13,700 --> 00:42:15,102
我之前提到过


739
00:42:15,802 --> 00:42:20,240
AU参数对象


740
00:42:20,340 --> 00:42:24,111
参数值在主机和视图之间的通讯中心


741
00:42:24,411 --> 00:42:27,181
另一方面 也是音频单元执行器


742
00:42:29,750 --> 00:42:31,852
现在  从主机的角度来看


743
00:42:32,186 --> 00:42:36,256
参数对象属性 包括值


744
00:42:36,323 --> 00:42:38,692
还有最小值和最大值等等


745
00:42:39,459 --> 00:42:42,062
所以我们可进行设置


746
00:42:42,462 --> 00:42:44,932
并获得使用点记法的参数值


747
00:42:45,832 --> 00:42:48,368
现在我们仍然可以按照
防止反馈回路发生的方式


748
00:42:48,435 --> 00:42:50,304
进行数值设置  


749
00:42:51,104 --> 00:42:56,243
这在性能和UI简化方面都有优势


750
00:42:56,410 --> 00:42:59,546
我们不希望看到的情况是
在我们滑动到下一个画面后


751
00:42:59,613 --> 00:43:02,182
看到与前一张不同的通知


752
00:43:02,983 --> 00:43:06,486
所以设置值的方法可以实现这种效果


753
00:43:07,855 --> 00:43:12,659
并且在往参数 参数树
或者参数组添加观测器后


754
00:43:12,726 --> 00:43:15,863
可以看到标志


755
00:43:16,864 --> 00:43:19,032
当我们这样操作时  


756
00:43:19,099 --> 00:43:21,335
我们能返回参数
这就是我们在底部所看到的


757
00:43:21,835 --> 00:43:24,371
这里有个块称为AU参数观测器


758
00:43:24,872 --> 00:43:26,173
通过观测器 我们能看到


759
00:43:26,507 --> 00:43:29,309
参数改变后的地址和新值


760
00:43:32,079 --> 00:43:35,582
至于执行方面 我们在
Filter Demo已经了解到


761
00:43:36,049 --> 00:43:38,185
有执行器 值观测器 


762
00:43:38,418 --> 00:43:40,120
以及值供应块


763
00:43:40,721 --> 00:43:42,523
现在 我们在
Filter Demo中


764
00:43:42,589 --> 00:43:44,358
将这些块安装到参数树上


765
00:43:44,525 --> 00:43:48,061
也可以安装到参数树的任意位置


766
00:43:48,462 --> 00:43:50,297
甚至可以安装到单个参数上


767
00:43:54,168 --> 00:43:56,103
我也想展示下在调度参数方面


768
00:43:56,236 --> 00:43:57,938
我们已经做到的事情


769
00:43:58,005 --> 00:43:59,806
因为我想在版本2的API 中


770
00:44:00,174 --> 00:44:02,476
这是个大的改进


771
00:44:03,710 --> 00:44:06,280
我们有主机和执行器


772
00:44:06,346 --> 00:44:08,215
可以分别处理不同事件


773
00:44:08,782 --> 00:44:13,420
但这里我们还使用了
AU音频单元基础分类


774
00:44:13,487 --> 00:44:15,255
从而帮助我们实现该功能


775
00:44:15,956 --> 00:44:19,993
所以主机能从
AU音频单元获得一个模块


776
00:44:20,060 --> 00:44:21,762
称之为计划参数模块


777
00:44:22,496 --> 00:44:26,700
渲染过程中  调用该模块


778
00:44:27,167 --> 00:44:28,802
精准改变参数


779
00:44:29,870 --> 00:44:32,739
所以第一个要做的计划表
是一个抽样时间


780
00:44:33,440 --> 00:44:35,609
这个计划表值会累增


781
00:44:35,676 --> 00:44:38,745
如果音频单元使用累增方式


782
00:44:39,346 --> 00:44:41,882
例如苹果婚姻器所做的一样


783
00:44:44,251 --> 00:44:46,653
最后的2个参数  


784
00:44:46,854 --> 00:44:49,923
功能参数和参数地址


785
00:44:49,990 --> 00:44:52,659
将被改变成新的参数值


786
00:44:54,228 --> 00:44:55,662
在执行方面


787
00:44:55,729 --> 00:44:57,030
事情略有不同


788
00:44:57,097 --> 00:45:00,100
我们从主机那得到的 
并不仅仅是传递操作


789
00:45:00,934 --> 00:45:03,103
相反基础类将获得


790
00:45:03,170 --> 00:45:06,340
刚我们在
Filter Demo看到的


791
00:45:07,341 --> 00:45:08,509
内部渲染块


792
00:45:08,575 --> 00:45:11,512
它将把只属于渲染循环的实时事件


793
00:45:12,179 --> 00:45:14,781
传递到渲染块上


794
00:45:15,516 --> 00:45:19,086
所以基础类会保证


795
00:45:19,520 --> 00:45:21,855
所有待定预订参量变换计划表的完整


796
00:45:22,222 --> 00:45:25,158
只在渲染时


797
00:45:25,392 --> 00:45:27,494
分配相关块到音频单元中


798
00:45:29,897 --> 00:45:31,365
这就是参数计划策略


799
00:45:31,431 --> 00:45:34,201
在MIDI事件中
我们也做了完全相同的事情


800
00:45:35,102 --> 00:45:36,403
主机在开始渲染前


801
00:45:36,937 --> 00:45:39,173
从音频单元获取了一个块


802
00:45:40,007 --> 00:45:42,509
在渲染时间里调用那个块


803
00:45:43,377 --> 00:45:46,246
现在你可以看到
我们在音频单元API版本2中


804
00:45:46,480 --> 00:45:48,215
增加了一个叫做网线的功能参数


805
00:45:49,983 --> 00:45:55,255
它只有1个MIDI网线 16个通道


806
00:45:55,689 --> 00:45:59,092
现在我们有256虚拟MIDI网线


807
00:45:59,393 --> 00:46:00,894
如果想要有巨大样品库的音频单元


808
00:46:01,395 --> 00:46:03,597
现在可以做到了


809
00:46:03,830 --> 00:46:07,334
所有的这些 都可以
在虚拟MIDI网线中进行处理


810
00:46:09,203 --> 00:46:11,238
在MIDI事件的执行方面


811
00:46:11,305 --> 00:46:14,341
这与计划参数的实现完全相同


812
00:46:15,142 --> 00:46:19,012
基础类AU 音频单元保护内部计划表


813
00:46:19,813 --> 00:46:23,083
并仅在应该起作用的时候


814
00:46:23,617 --> 00:46:28,222
在渲染循环期间 通过实时事件清单


815
00:46:28,288 --> 00:46:30,257
将事件传递到内部渲染块


816
00:46:32,125 --> 00:46:34,761
我们认为这是很大的改善


817
00:46:34,828 --> 00:46:36,597
节省了执行器很多工作


818
00:46:39,099 --> 00:46:43,370
关于渲染 总的来说 
我们仍然使用拉模式


819
00:46:43,437 --> 00:46:46,673
意思就是一个输出装置拉一个混音器


820
00:46:47,074 --> 00:46:49,710
拉一个特效 拉另一个特效 拉播放器


821
00:46:49,776 --> 00:46:51,778
音频流通过链回流


822
00:46:52,746 --> 00:46:55,182
API版本2的不同点是


823
00:46:55,249 --> 00:46:58,218
音频单元需要保持一些状态


824
00:46:58,619 --> 00:47:02,356
这里需要提到一个概念
即它是否是从其他音频单元上游


825
00:47:02,422 --> 00:47:05,993
或一个功能反馈信号获得输入信号


826
00:47:06,593 --> 00:47:08,195
API版本3中 就更简单了


827
00:47:08,996 --> 00:47:12,432
AU并不需要保持该状态


828
00:47:12,900 --> 00:47:15,302
我们在Filter Demo中


829
00:47:15,736 --> 00:47:18,372
看到的反馈信号来自主机


830
00:47:18,705 --> 00:47:20,174
且在每个渲染循环期间进行传递


831
00:47:21,542 --> 00:47:24,845
其他的 API的功能极其相似


832
00:47:24,912 --> 00:47:27,481
这使得我们可以


833
00:47:27,548 --> 00:47:28,782
在它们之间快速连接


834
00:47:32,586 --> 00:47:37,391
现在 若你的主机是
直接调用AU 音频单元进行渲染


835
00:47:37,691 --> 00:47:40,661
而不是使用AU图标
或AVAudioEngine


836
00:47:41,628 --> 00:47:45,832
这是会调用配置渲染源


837
00:47:45,899 --> 00:47:49,069
然后将它们放在渲染块中


838
00:47:50,070 --> 00:47:51,672
你可调用渲染块进行渲染


839
00:47:52,706 --> 00:47:54,875
看起来和内部渲染块非常相似


840
00:47:57,477 --> 00:47:59,646
这些有必要回顾一下


841
00:47:59,713 --> 00:48:03,283
在渲染时间出现的
音频缓冲器的一些规则


842
00:48:03,951 --> 00:48:06,820
现在 主机提供了一个
输出音频缓冲器清单


843
00:48:07,354 --> 00:48:11,291
在输出音频缓冲器清单中 
M数据指针可以是0


844
00:48:12,292 --> 00:48:15,696
音频单元必须用一个内部
自备的缓冲器进行取代


845
00:48:16,496 --> 00:48:19,499
同时AU必须保证


846
00:48:19,566 --> 00:48:22,703
缓冲器持续有效直至下个渲染循环出现


847
00:48:23,270 --> 00:48:25,038
以上是全部内容  顺便说一下


848
00:48:25,105 --> 00:48:27,841
和音频单元版本2完全相同
我一直在重复强调


849
00:48:28,509 --> 00:48:29,409
因为它真的很重要


850
00:48:31,445 --> 00:48:34,882
现在 在渲染块中有一些规则


851
00:48:34,948 --> 00:48:37,718
和输入缓冲器的规则相似但并不一样


852
00:48:38,151 --> 00:48:41,221
主机提供输入块AU调用它输入


853
00:48:41,288 --> 00:48:45,125
当AU调用那个块进行输入时


854
00:48:45,526 --> 00:48:48,462
它必须为那个块提供


855
00:48:48,662 --> 00:48:52,032
非0的M数据指针的
有效音频缓冲器清单


856
00:48:52,833 --> 00:48:55,602
现在 主机允许取代储存器的这些指针


857
00:48:56,503 --> 00:49:00,774
即它拥有并可以确保保持有效


858
00:49:00,841 --> 00:49:04,478
直至下个渲染循环出现或释放渲染资源


859
00:49:05,179 --> 00:49:08,415
所有这些是为了达成一项重要目标


860
00:49:08,482 --> 00:49:11,251
即减少重复操作


861
00:49:15,055 --> 00:49:17,524
好 这里有些幻灯片


862
00:49:18,592 --> 00:49:23,263
让程序员和大家开开眼


863
00:49:23,697 --> 00:49:26,667
音频渲染几乎总是


864
00:49:26,733 --> 00:49:28,669
在实时路径环境里发生的


865
00:49:28,969 --> 00:49:30,971
这是个有限制的环境


866
00:49:31,104 --> 00:49:32,973
因为我们无法分配存储器


867
00:49:33,540 --> 00:49:36,243
意思是说我们甚至不需要


868
00:49:36,310 --> 00:49:38,078
调用调度异步通信


869
00:49:38,846 --> 00:49:42,049
事实上我们不能访问因为可能被限制了


870
00:49:42,649 --> 00:49:47,054
比如获取一个互斥量或等一个信号量


871
00:49:47,421 --> 00:49:51,859
原因是 若我们进行限制
那么我们就限制了所有时间


872
00:49:52,292 --> 00:49:53,861
然后系统中的音频渲染路径


873
00:49:53,927 --> 00:49:55,696
将错过它的截止期限


874
00:49:56,196 --> 00:49:59,333
这时故障就会发生


875
00:50:00,534 --> 00:50:05,038
所以在使用和调用


876
00:50:05,372 --> 00:50:08,542
不好意思 是使用和执行
这些渲染块时需要非常小心


877
00:50:10,277 --> 00:50:14,081
在Filter Demo中你可以
看到我们如何准备一些块长


878
00:50:14,281 --> 00:50:17,251
以致不捕捉到我们自己的目标


879
00:50:17,317 --> 00:50:20,254
或任何其他
Objective-C目标


880
00:50:21,288 --> 00:50:24,324
在块中 我们避免了
Objective-C运行时间


881
00:50:24,391 --> 00:50:27,327
因为Objective-C不安全


882
00:50:27,394 --> 00:50:28,762
它可以获得块


883
00:50:29,429 --> 00:50:31,932
不过Swift运行时间也完全相同


884
00:50:32,399 --> 00:50:37,504
这也是为什么在Filter Demo中
你将看到C++目标


885
00:50:37,571 --> 00:50:41,775
我们为这些C++目标捕获指针


886
00:50:42,242 --> 00:50:44,311
现在如果你讨厌C++


887
00:50:44,578 --> 00:50:46,914
你也可以用单纯功能的C做一样的事情


888
00:50:46,980 --> 00:50:48,615
尽管我不太确定为什么你想要那么做


889
00:50:51,118 --> 00:50:52,286
讨厌的东西已经说太多了


890
00:50:52,352 --> 00:50:54,054
现在有请亚力克·利特尔


891
00:50:54,154 --> 00:50:57,925
为我们展示Apple Music
创建app中的音频单元扩展


892
00:51:04,431 --> 00:51:09,269
谢谢你 道格
我在Apple的音乐创建应用处工作


893
00:51:09,336 --> 00:51:11,205
做的事情有
GarageBand和Logic


894
00:51:11,271 --> 00:51:14,842
我们很激动有新的音频单元扩展


895
00:51:14,908 --> 00:51:17,978
我们认为它将为开发者和用户


896
00:51:18,045 --> 00:51:19,847
提供真正的权利和创造的可能性


897
00:51:19,913 --> 00:51:21,415
我会讲到


898
00:51:21,481 --> 00:51:23,550
我们的一些计划


899
00:51:23,984 --> 00:51:27,454
首先我们计划支持音频单元扩展


900
00:51:27,521 --> 00:51:29,489
当然是在所有主要应用中支持


901
00:51:29,556 --> 00:51:32,759
也就是GarageBand iOS
GarageBand Mac


902
00:51:32,960 --> 00:51:36,129
Logic Pro X
Logic Pro 10和Mainstage


903
00:51:37,631 --> 00:51:42,703
我们今天要做的是看一些例子


904
00:51:42,769 --> 00:51:46,240
一些GarageBand iOS的
非常漂亮的图片


905
00:51:46,306 --> 00:51:48,008
这只是很初级的东西


906
00:51:48,075 --> 00:51:49,877
我们会给你们一些概念


907
00:51:49,943 --> 00:51:51,578
关于作为支持音频单元扩展的主机


908
00:51:52,279 --> 00:51:53,780
我们将计划做什么


909
00:51:55,148 --> 00:51:58,919
首先我们将支持AU工具


910
00:51:59,219 --> 00:52:01,154
接下来我要说的例子是


911
00:52:01,221 --> 00:52:03,624
关于我们将如何执行这些AU工具的


912
00:52:05,292 --> 00:52:07,094
首先用一些图像


913
00:52:07,160 --> 00:52:08,896
来解释我们将要做什么  很简单的


914
00:52:08,962 --> 00:52:11,832
但GarageBand
将向视图控制器进行请求


915
00:52:11,899 --> 00:52:13,400
视图控制器是一个自定义UI


916
00:52:14,301 --> 00:52:15,969
等下我们会讲到这个


917
00:52:16,570 --> 00:52:18,539
将MIDI事件传递到音频单元


918
00:52:18,605 --> 00:52:22,309
当然随后你会收到通过音频总线的音频


919
00:52:24,411 --> 00:52:26,280
回到约定的图片


920
00:52:27,247 --> 00:52:31,151
GarageBand我们主启动屏幕


921
00:52:31,218 --> 00:52:34,588
进入接触工具传送带


922
00:52:34,821 --> 00:52:38,525
这里有我们所有的接触工具


923
00:52:38,592 --> 00:52:40,928
键盘 鼓 小吉他 等等这类东西


924
00:52:41,828 --> 00:52:45,132
看左边  那里有这个容器


925
00:52:45,199 --> 00:52:47,501
若GarageBand看到设备上


926
00:52:47,568 --> 00:52:49,570
已装有音频单元


927
00:52:49,636 --> 00:52:51,605
容器会展示出来


928
00:52:51,672 --> 00:52:53,674
我可以滑动到那个容器


929
00:52:54,274 --> 00:52:55,843
那是我的音频单元存在的地方


930
00:52:56,076 --> 00:52:56,910
假若我轻敲它


931
00:52:59,847 --> 00:53:04,051
可以看到设备上
已经安装了所有的音频单元工具


932
00:53:04,651 --> 00:53:07,054
现在如果我轻敲其中一个工具


933
00:53:08,155 --> 00:53:10,224
我们可以看到一个
大的灰色盒子和一个键盘 


934
00:53:10,691 --> 00:53:13,861
我们将为你展示


935
00:53:14,328 --> 00:53:17,431
GarageBand里面漂亮的
内嵌视图里的自定义UI


936
00:53:17,497 --> 00:53:19,666
我认为整件事情最酷的部分是


937
00:53:20,334 --> 00:53:22,503
我们会在主机里


938
00:53:22,569 --> 00:53:25,606
显示音频单元的真实情况


939
00:53:25,672 --> 00:53:28,742
我们将为你提供标准
GarageBand键盘


940
00:53:28,809 --> 00:53:30,978
以便你可以进行操作


941
00:53:31,411 --> 00:53:35,315
我们将记录MIDI并接收音频


942
00:53:36,617 --> 00:53:38,919
这只是之前说到的亮点而已


943
00:53:39,553 --> 00:53:41,488
当你提供这些自定义UI时


944
00:53:41,555 --> 00:53:44,925
请确保不会在这里


945
00:53:45,092 --> 00:53:47,261
防止任何自定义
MIDI控制器类型的设备


946
00:53:47,327 --> 00:53:49,830
因为我们不会在
GarageBand捕捉你的MIDI


947
00:53:51,231 --> 00:53:54,468
来快速看一下我们在设备上的新改动


948
00:53:55,402 --> 00:53:59,173
再一次 限制屏幕空间括大了


949
00:53:59,239 --> 00:54:01,642
所以在右上角有个按钮


950
00:54:01,742 --> 00:54:03,310
这里可以接入控制视图


951
00:54:04,044 --> 00:54:06,213
这是自定义UI


952
00:54:06,413 --> 00:54:08,582
那里所有的控制另外还有一点点空间


953
00:54:08,649 --> 00:54:10,851
用户可以在按钮底下的键盘上操作


954
00:54:11,518 --> 00:54:14,788
这或许是我今天讲的最重要的幻灯片


955
00:54:14,855 --> 00:54:17,658
这是我们在视图控制器


956
00:54:17,891 --> 00:54:19,993
要注意的要点


957
00:54:20,794 --> 00:54:23,797
想让GarageBand
看起来更美观


958
00:54:24,298 --> 00:54:25,732
那就请多注意这些要点


959
00:54:25,799 --> 00:54:29,736
我们将一起做一些很酷的事情


960
00:54:30,370 --> 00:54:32,973
我们真的很高兴可以看到


961
00:54:33,040 --> 00:54:35,609
现在用户可以通过
GarageBand


962
00:54:35,676 --> 00:54:37,511
真正地操作


963
00:54:37,578 --> 00:54:40,180
音频单元接口


964
00:54:40,514 --> 00:54:42,149
我们也很高兴可以和你们一起工作


965
00:54:42,216 --> 00:54:43,250
想出很酷的东西


966
00:54:52,326 --> 00:54:53,160
谢谢你 亚力克


967
00:54:54,394 --> 00:54:57,531
我想你们应该会有些疑问


968
00:54:57,965 --> 00:54:59,867
我来猜猜都有哪些


969
00:55:01,969 --> 00:55:04,838
iOS上的跨应用音频怎么样


970
00:55:05,672 --> 00:55:07,241
这是个老问题了


971
00:55:08,242 --> 00:55:10,611
有很多支持它的app


972
00:55:11,111 --> 00:55:13,881
根据我们的观点


973
00:55:13,947 --> 00:55:17,284
这个使用了API版本2的部分子集


974
00:55:17,351 --> 00:55:18,719
且不支持某些功能


975
00:55:18,785 --> 00:55:21,455
比如参数支持 预置 等等


976
00:55:22,089 --> 00:55:25,058
我收到这些请求


977
00:55:25,125 --> 00:55:26,960
我想我们应该有一个完整的插件模型


978
00:55:27,394 --> 00:55:28,662
这就是我们现在所有的


979
00:55:29,830 --> 00:55:32,266
我们并不是不赞成跨应用音频


980
00:55:32,332 --> 00:55:35,936
我们只是看得更远一些


981
00:55:36,303 --> 00:55:38,739
通过音频单元扩展
增加这些以前没有的功能


982
00:55:41,441 --> 00:55:43,210
现在在OS X上


983
00:55:43,277 --> 00:55:45,012
若你有主机和音频单元


984
00:55:45,345 --> 00:55:47,548
你或许会考虑兼容性的问题


985
00:55:48,248 --> 00:55:51,051
连接桥将解决很多麻烦


986
00:55:51,118 --> 00:55:54,054
它们是兼容的我们做了大量的工作


987
00:55:54,254 --> 00:55:57,391
尽可能的让这些东西可以起作用


988
00:55:58,091 --> 00:56:01,728
但如果你可以或者需要一些功能时


989
00:56:01,895 --> 00:56:03,830
我建议你升级到版本3


990
00:56:03,897 --> 00:56:06,700
比如说 你可能想要重做


991
00:56:06,767 --> 00:56:08,502
处理MIDI事件的方法或计划参数


992
00:56:09,736 --> 00:56:12,439
关于端口 我们有一个捷径


993
00:56:12,506 --> 00:56:15,008
它叫做AU音频单元v2连接桥


994
00:56:15,075 --> 00:56:18,645
这是一个AU音频单元子类


995
00:56:18,712 --> 00:56:21,815
在AU版本2上执行
所以你可以从那开始


996
00:56:21,882 --> 00:56:25,752
并开发出更加全面执行器


997
00:56:28,522 --> 00:56:30,357
正如迈克尔刚提到的


998
00:56:31,225 --> 00:56:34,094
音频单元版本3


999
00:56:34,161 --> 00:56:36,296
是iOS和OS X之间
主要的交叉平台


1000
00:56:36,730 --> 00:56:41,468
AU音频单元上的信号处理代码
绝对是最方便的途径


1001
00:56:41,535 --> 00:56:43,770
因为无需进行UI实现


1002
00:56:44,204 --> 00:56:45,539
或任何依赖设备


1003
00:56:47,474 --> 00:56:51,111
AU视图控制器来自UI
或NSViewController


1004
00:56:51,178 --> 00:56:53,180
所以会感觉有些异类


1005
00:56:53,680 --> 00:56:56,517
但某些时候可以进入到特定平台UI


1006
00:56:57,851 --> 00:56:59,686
我们快没时间了


1007
00:56:59,853 --> 00:57:03,390
要讲的话估计需要一个小时


1008
00:57:03,457 --> 00:57:06,860
此刻我建议你参考


1009
00:57:07,561 --> 00:57:08,862
音频单元框架上的页眉文件


1010
00:57:08,996 --> 00:57:13,200
由于一些历史原因
你需要连接AudioToolbox


1011
00:57:13,567 --> 00:57:16,803
主要的信头文件是AU音频单元h


1012
00:57:17,738 --> 00:57:20,440
但Core Audio工具箱框架上
有其他的AU视图控制器


1013
00:57:20,908 --> 00:57:24,378
这是带AU音频单元组件的
AVFoundation框架


1014
00:57:24,444 --> 00:57:26,947
所有的这些里面


1015
00:57:27,347 --> 00:57:32,286
都有很棒的信头文件
所以我强烈建议你查看一下


1016
00:57:34,388 --> 00:57:38,225
最后如果你想要用音频单元标志


1017
00:57:38,292 --> 00:57:39,560
我们还有一个白色版本


1018
00:57:40,027 --> 00:57:43,263
你可以查看这个链接获取许可


1019
00:57:44,631 --> 00:57:46,099
以上部分到此结束


1020
00:57:46,466 --> 00:57:48,435
我们已经看到在iOS上的音频里


1021
00:57:48,502 --> 00:57:50,838
第一次有一个完整的插件模式


1022
00:57:51,205 --> 00:57:54,341
在OS X的音频里
也第一次有一个完整的插件模式


1023
00:57:55,042 --> 00:57:58,445
通过打包音频单元成app扩展


1024
00:57:58,679 --> 00:58:01,582
你就可以在iOS
和OS X App Stores上


1025
00:58:01,849 --> 00:58:03,717
销售音频单元了


1026
00:58:04,618 --> 00:58:09,756
我们看了带有
AVAudioEngine的简单主机应用


1027
00:58:10,257 --> 00:58:12,326
并添加到新品


1028
00:58:12,693 --> 00:58:14,127
音频单元v3样本之中


1029
00:58:14,862 --> 00:58:17,297
如果编写样品代码时出现漏洞的话


1030
00:58:17,364 --> 00:58:19,533
我们鼓励大家读一下文件


1031
00:58:20,033 --> 00:58:23,036
然后在AU主机和实现上试试


1032
00:58:23,103 --> 00:58:25,606
我知道你一定会这么做的


1033
00:58:28,942 --> 00:58:34,014
更多信息 这是我们昨天的部分


1034
00:58:34,882 --> 00:58:35,716
谢谢

