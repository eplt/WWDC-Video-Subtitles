1
00:00:00,506 --> 00:00:05,500
[ Music ]


2
00:00:11,516 --> 00:00:14,566
[ Applause ]


3
00:00:15,066 --> 00:00:16,606
>> Welcome to the Metal for Pro


4
00:00:16,606 --> 00:00:17,186
Apps session.


5
00:00:17,506 --> 00:00:19,286
My name is Eugene, and together


6
00:00:19,286 --> 00:00:20,856
with Dileep and Brian, we'll be


7
00:00:20,856 --> 00:00:22,586
talking about utilizing Metal to


8
00:00:22,586 --> 00:00:24,236
enable new workflows and unleash


9
00:00:24,346 --> 00:00:26,416
all the power of Macs and iPads


10
00:00:26,496 --> 00:00:28,076
for your Pro applications.


11
00:00:28,996 --> 00:00:30,636
But what is a Pro App?


12
00:00:31,156 --> 00:00:32,976
We at Apple define it as an


13
00:00:32,976 --> 00:00:35,316
application used by creative


14
00:00:35,396 --> 00:00:36,896
professionals in the content


15
00:00:36,896 --> 00:00:37,666
making business.


16
00:00:37,866 --> 00:00:39,796
That includes animators and live


17
00:00:39,796 --> 00:00:42,616
TV, photography, 3D animation,


18
00:00:43,286 --> 00:00:44,516
print media, and audio


19
00:00:44,516 --> 00:00:45,166
production.


20
00:00:46,146 --> 00:00:48,106
Additionally, it includes both


21
00:00:48,106 --> 00:00:49,496
first party as well as


22
00:00:49,496 --> 00:00:51,106
third-party apps created by


23
00:00:51,386 --> 00:00:52,216
developers like you.


24
00:00:53,026 --> 00:00:56,926
These are apps such as Autodesk


25
00:00:57,736 --> 00:00:59,686
Maya for 3D animation rigging


26
00:00:59,686 --> 00:01:02,456
and visual effects or maybe


27
00:01:02,456 --> 00:01:05,586
Logic Pro for audio and music


28
00:01:05,636 --> 00:01:06,076
production.


29
00:01:06,076 --> 00:01:10,156
Serif Labs Affinity Photo for


30
00:01:10,156 --> 00:01:12,056
professional image editing or


31
00:01:13,106 --> 00:01:14,686
Black Magic's DaVinci Resolve,


32
00:01:15,166 --> 00:01:16,336
professional application for


33
00:01:16,336 --> 00:01:17,636
video editing.


34
00:01:18,636 --> 00:01:20,226
Pro apps have always been an


35
00:01:20,226 --> 00:01:22,266
important of our ecosystem, and


36
00:01:22,266 --> 00:01:23,806
with the recent release of the


37
00:01:23,806 --> 00:01:26,476
new Mac Pro our new Pro Display


38
00:01:26,726 --> 00:01:29,356
XDR robust support for external


39
00:01:29,356 --> 00:01:30,956
GPU's and the new A12X


40
00:01:30,956 --> 00:01:32,856
bionic-powered iPad pro.


41
00:01:33,166 --> 00:01:34,626
We really doubled down on our


42
00:01:34,686 --> 00:01:36,206
focus and commitment in this


43
00:01:36,206 --> 00:01:36,556
space.


44
00:01:37,526 --> 00:01:39,066
So why are pro apps different


45
00:01:39,066 --> 00:01:40,166
from other workloads?


46
00:01:41,316 --> 00:01:43,156
One key thing is that they


47
00:01:43,156 --> 00:01:44,806
operate on really large assets.


48
00:01:45,486 --> 00:01:47,066
This includes up to 8K video,


49
00:01:47,686 --> 00:01:49,296
billions of polygons, thousands


50
00:01:49,296 --> 00:01:50,936
of photos, hundreds of audio


51
00:01:50,936 --> 00:01:51,486
tracks.


52
00:01:52,406 --> 00:01:56,466
They also require a lot of CPU


53
00:01:56,466 --> 00:01:57,966
and GPU horsepower.


54
00:01:58,536 --> 00:02:01,246
Finally, there is always the


55
00:02:01,246 --> 00:02:04,726
challenge of achieving real-time


56
00:02:04,806 --> 00:02:06,096
interaction while maintaining


57
00:02:06,096 --> 00:02:07,496
the full fidelity of the


58
00:02:07,496 --> 00:02:08,175
original content.


59
00:02:08,826 --> 00:02:10,216
So let's go to the agenda of


60
00:02:10,485 --> 00:02:11,045
today's talk.


61
00:02:12,376 --> 00:02:14,146
First, we'll introduce the video


62
00:02:14,146 --> 00:02:15,306
editing pipeline on our


63
00:02:15,306 --> 00:02:17,306
platforms and discuss how to


64
00:02:17,306 --> 00:02:19,016
optimize it for groundbreaking


65
00:02:19,016 --> 00:02:19,476
8K.


66
00:02:20,236 --> 00:02:21,956
Next, we'll talk about how you


67
00:02:21,956 --> 00:02:24,296
can add HDR support to your app.


68
00:02:25,126 --> 00:02:28,126
Then, we show you how to scale


69
00:02:28,126 --> 00:02:30,516
across all CPU ports and GPU


70
00:02:30,516 --> 00:02:30,846
channels.


71
00:02:31,456 --> 00:02:33,406
And finally, we'll discuss how


72
00:02:33,406 --> 00:02:35,216
to achieve most efficient data


73
00:02:35,216 --> 00:02:35,726
transfers.


74
00:02:36,866 --> 00:02:38,866
So let's start by talking about


75
00:02:38,866 --> 00:02:40,646
the video editing pipeline with


76
00:02:40,646 --> 00:02:41,926
8K content in mind.


77
00:02:43,156 --> 00:02:44,816
We at Apple find video editing


78
00:02:44,816 --> 00:02:46,396
as one of the most demanding and


79
00:02:46,606 --> 00:02:47,686
creative workloads.


80
00:02:48,086 --> 00:02:50,186
So we will use video apps as a


81
00:02:50,186 --> 00:02:52,656
use case to show how Metal helps


82
00:02:52,656 --> 00:02:52,726
you.


83
00:02:53,446 --> 00:02:55,356
But before we start, I'd like to


84
00:02:55,356 --> 00:02:56,336
give a huge thanks to our


85
00:02:56,336 --> 00:02:57,616
friends at Black Magic Design.


86
00:02:58,136 --> 00:02:58,956
We've been working with them


87
00:02:58,956 --> 00:03:00,976
really closely optimizing both


88
00:03:01,026 --> 00:03:02,546
DaVinci Resolve and our platform


89
00:03:02,546 --> 00:03:05,006
to unleash new 8K workflows, and


90
00:03:05,006 --> 00:03:06,436
we're really proud of what we


91
00:03:06,436 --> 00:03:07,646
have achieved together.


92
00:03:08,526 --> 00:03:10,736
But let's see how it all worked


93
00:03:10,736 --> 00:03:13,416
before when we first tried 8K


94
00:03:13,416 --> 00:03:14,106
[inaudible] content.


95
00:03:14,866 --> 00:03:16,756
You see the result is not real


96
00:03:16,786 --> 00:03:17,016
time.


97
00:03:17,666 --> 00:03:19,666
We have heavy stuttering, and


98
00:03:19,666 --> 00:03:20,726
the experience is not great.


99
00:03:22,026 --> 00:03:23,296
So that doesn't work.


100
00:03:24,176 --> 00:03:25,576
Let's see how professionals


101
00:03:25,756 --> 00:03:27,496
worked around this problem.


102
00:03:28,036 --> 00:03:30,296
So they have huge raw footage in


103
00:03:30,296 --> 00:03:30,706
8K.


104
00:03:31,216 --> 00:03:34,386
First, they transcoded to get


105
00:03:34,386 --> 00:03:36,296
all the [inaudible].


106
00:03:36,526 --> 00:03:38,336
Then they sub-sampled and


107
00:03:38,336 --> 00:03:39,696
downscaled it to 4K proxy.


108
00:03:40,046 --> 00:03:41,996
So they can apply edits and


109
00:03:41,996 --> 00:03:43,686
affects in real time, but there


110
00:03:43,686 --> 00:03:45,376
is one really important catch.


111
00:03:46,256 --> 00:03:48,226
You cannot color grade proxy


112
00:03:48,226 --> 00:03:49,596
data simply because it's not


113
00:03:49,596 --> 00:03:50,046
accurate.


114
00:03:50,626 --> 00:03:52,426
So now you have to go back and


115
00:03:52,426 --> 00:03:54,406
apply all of your edits to the


116
00:03:54,406 --> 00:03:56,386
original content, run an offline


117
00:03:56,386 --> 00:03:58,106
render job which may take hours.


118
00:03:58,736 --> 00:04:00,636
Review it with your director and


119
00:04:00,636 --> 00:04:01,656
then rinse and repeat.


120
00:04:02,616 --> 00:04:04,076
We at Apple want to make it


121
00:04:04,076 --> 00:04:05,666
faster for our users.


122
00:04:06,586 --> 00:04:08,076
We really want all the


123
00:04:08,076 --> 00:04:09,486
professionals to work straight


124
00:04:09,486 --> 00:04:11,356
in 8K content out of the box.


125
00:04:11,866 --> 00:04:12,966
So let me tell you the story of


126
00:04:13,006 --> 00:04:14,796
how we enabled real time video


127
00:04:14,796 --> 00:04:16,226
editing in 8K.


128
00:04:17,476 --> 00:04:19,206
So it starts with building an


129
00:04:19,206 --> 00:04:20,245
efficient video editing


130
00:04:20,245 --> 00:04:20,875
pipeline.


131
00:04:21,526 --> 00:04:23,166
We'll cover the general design


132
00:04:23,166 --> 00:04:24,916
of an efficient pipeline, what


133
00:04:24,916 --> 00:04:26,516
frameworks to use, and how to


134
00:04:26,516 --> 00:04:28,246
maximize all the available


135
00:04:28,246 --> 00:04:28,646
hardware.


136
00:04:29,726 --> 00:04:31,626
Then, we'll discuss how to


137
00:04:31,626 --> 00:04:33,476
manage real large assets.


138
00:04:33,996 --> 00:04:35,746
And finally, we'll tell you


139
00:04:36,446 --> 00:04:37,796
about some challenges you might


140
00:04:37,796 --> 00:04:39,166
face trying to maintain a


141
00:04:39,456 --> 00:04:41,056
predictable frame rate and how


142
00:04:41,056 --> 00:04:41,836
to overcome them.


143
00:04:42,986 --> 00:04:45,026
So let's dive into the video


144
00:04:45,026 --> 00:04:45,756
editing pipeline.


145
00:04:47,476 --> 00:04:49,366
Here are typical building blocks


146
00:04:49,366 --> 00:04:52,366
most video editing apps need to


147
00:04:52,366 --> 00:04:52,666
have.


148
00:04:53,366 --> 00:04:54,546
So we start by reading the


149
00:04:54,546 --> 00:04:56,376
content, then we need to decode


150
00:04:56,376 --> 00:04:57,746
it so we can process it.


151
00:04:57,886 --> 00:04:59,936
And finally, present or encode.


152
00:05:00,696 --> 00:05:02,846
In today's session, I'll be


153
00:05:02,846 --> 00:05:05,906
focusing on the decode process,


154
00:05:05,906 --> 00:05:07,226
encode and display blocks.


155
00:05:07,696 --> 00:05:08,926
We will be covering the import


156
00:05:08,926 --> 00:05:10,356
and export blocks which


157
00:05:10,356 --> 00:05:11,726
typically use AVFoundation


158
00:05:11,786 --> 00:05:12,106
framework.


159
00:05:12,696 --> 00:05:14,506
I encourage you to check out our


160
00:05:14,506 --> 00:05:16,446
samples on AVAssetReader and


161
00:05:16,446 --> 00:05:17,206
AVAssetWriter.


162
00:05:17,806 --> 00:05:21,226
Let's dive in how to make


163
00:05:21,226 --> 00:05:23,256
decoding part closer to Metal.


164
00:05:24,696 --> 00:05:26,316
Apple provides a flexible


165
00:05:26,316 --> 00:05:27,906
low-level framework called Video


166
00:05:27,906 --> 00:05:29,446
Toolbox to achieve efficient,


167
00:05:29,806 --> 00:05:31,056
high-performance video


168
00:05:31,296 --> 00:05:31,776
processing.


169
00:05:32,346 --> 00:05:34,266
It can be used on iOS, macOS,


170
00:05:34,266 --> 00:05:36,626
and tvOS, supports a huge number


171
00:05:36,626 --> 00:05:38,476
of formats and leverages any


172
00:05:38,476 --> 00:05:40,066
available hardware on our


173
00:05:40,066 --> 00:05:40,506
devices.


174
00:05:41,526 --> 00:05:42,766
The building block for the


175
00:05:42,766 --> 00:05:44,016
decode is a decompression


176
00:05:44,016 --> 00:05:45,696
session, and I can quickly show


177
00:05:45,696 --> 00:05:47,006
you how to set it up.


178
00:05:47,826 --> 00:05:50,506
First, we specify that we want


179
00:05:50,506 --> 00:05:51,526
to use [inaudible] video


180
00:05:51,526 --> 00:05:52,006
decoding.


181
00:05:53,146 --> 00:05:55,296
Then we create a session for


182
00:05:55,296 --> 00:05:56,596
each video stream.


183
00:05:57,296 --> 00:05:58,736
We set it up with a completion


184
00:05:58,736 --> 00:05:59,366
handler here.


185
00:06:01,216 --> 00:06:04,466
While we go through our video


186
00:06:04,466 --> 00:06:07,176
stream we call decode frame with


187
00:06:07,176 --> 00:06:08,196
an [inaudible] flag.


188
00:06:08,196 --> 00:06:09,746
This is really important to make


189
00:06:09,746 --> 00:06:10,976
the code [inaudible].


190
00:06:11,776 --> 00:06:13,156
Apple frame decode completion,


191
00:06:13,526 --> 00:06:15,076
our callback is going to be


192
00:06:15,076 --> 00:06:15,246
called.


193
00:06:15,246 --> 00:06:18,016
And finally please don't forget


194
00:06:18,066 --> 00:06:20,126
to clean up after you are done.


195
00:06:20,606 --> 00:06:23,126
So now we know how to decompress


196
00:06:23,126 --> 00:06:23,666
our frames.


197
00:06:24,196 --> 00:06:25,776
Now let's talk about how to make


198
00:06:25,776 --> 00:06:27,106
sure that we are doing it in a


199
00:06:27,106 --> 00:06:28,216
most optimal way.


200
00:06:30,066 --> 00:06:32,416
Your Mac might have set several


201
00:06:32,416 --> 00:06:34,236
hardware decoding blocks


202
00:06:34,236 --> 00:06:34,776
available.


203
00:06:35,186 --> 00:06:36,766
To make sure we are using the


204
00:06:36,766 --> 00:06:38,816
same physical memory with zero


205
00:06:38,816 --> 00:06:39,846
copies we'll leverage an


206
00:06:39,846 --> 00:06:41,086
internal object called an


207
00:06:41,086 --> 00:06:41,826
IOSurface.


208
00:06:42,846 --> 00:06:45,276
IOSurface is a hardware


209
00:06:45,276 --> 00:06:47,516
accelerated image buffer with


210
00:06:47,516 --> 00:06:48,916
GPU [inaudible] tracking.


211
00:06:49,616 --> 00:06:51,416
It also gives you interprocess


212
00:06:51,496 --> 00:06:53,376
and interframework access to the


213
00:06:53,376 --> 00:06:55,206
same GPU memory so it's perfect


214
00:06:55,206 --> 00:06:56,666
for this scenario.


215
00:06:57,696 --> 00:06:59,546
Core Video and Metal provides


216
00:07:00,046 --> 00:07:02,426
you an easy way to leverage the


217
00:07:02,426 --> 00:07:04,136
benefits of IOSurface using an


218
00:07:04,186 --> 00:07:05,006
object called


219
00:07:05,356 --> 00:07:06,716
CVMetalTextureCache.


220
00:07:07,196 --> 00:07:08,706
Let's see how to set it up.


221
00:07:09,936 --> 00:07:12,976
So here we create our


222
00:07:12,976 --> 00:07:15,286
CVMetalTextureCache, and we want


223
00:07:15,286 --> 00:07:16,686
to make sure we use the Metal


224
00:07:16,686 --> 00:07:18,196
device we're going to be using


225
00:07:18,196 --> 00:07:19,346
for pixel processing.


226
00:07:19,786 --> 00:07:22,446
So next whenever we get a new CV


227
00:07:22,446 --> 00:07:23,936
pixel buffer, we need to turn it


228
00:07:23,936 --> 00:07:24,886
into a Metal texture.


229
00:07:25,306 --> 00:07:26,996
It happens automatically at zero


230
00:07:26,996 --> 00:07:28,716
cost if our pixel buffer is


231
00:07:28,836 --> 00:07:30,186
backed by an IOSurface.


232
00:07:30,986 --> 00:07:33,206
Finally, don't forget to clean


233
00:07:33,206 --> 00:07:34,446
up your textures and pixel


234
00:07:34,446 --> 00:07:36,336
buffers to ensure proper reuse


235
00:07:36,436 --> 00:07:39,506
in the texture cache.


236
00:07:39,836 --> 00:07:41,556
So now we have our frame as an


237
00:07:41,556 --> 00:07:43,986
MTL texture, and we are ready to


238
00:07:43,986 --> 00:07:45,066
do some pixel processing.


239
00:07:45,366 --> 00:07:47,196
Here we have several options.


240
00:07:48,706 --> 00:07:50,406
Of course, we can write our own


241
00:07:50,406 --> 00:07:51,896
processing and grading kernels


242
00:07:52,206 --> 00:07:53,346
and it's really easy since


243
00:07:53,346 --> 00:07:54,576
Metal's [inaudible] language is


244
00:07:54,796 --> 00:07:55,676
C++ based.


245
00:07:55,676 --> 00:07:58,196
At the same time, we highly


246
00:07:58,196 --> 00:07:59,646
encourage you to use Metal


247
00:07:59,816 --> 00:08:01,186
performance shaders to do your


248
00:08:01,186 --> 00:08:01,946
pixel processing.


249
00:08:02,416 --> 00:08:03,446
You can even build your own


250
00:08:03,446 --> 00:08:04,976
neural network as part of your


251
00:08:04,976 --> 00:08:05,446
pipeline.


252
00:08:06,826 --> 00:08:08,666
Now let's see how to use MPS to


253
00:08:08,666 --> 00:08:10,726
run a typical blur filter.


254
00:08:12,076 --> 00:08:13,766
So we start with the Metal queue


255
00:08:14,276 --> 00:08:15,716
and the common buffer.


256
00:08:17,516 --> 00:08:20,356
We create a Gaussian blur


257
00:08:20,536 --> 00:08:23,246
kernel, one of many built into


258
00:08:23,996 --> 00:08:24,346
MPS.


259
00:08:24,346 --> 00:08:26,066
And now, we can attempt to


260
00:08:26,066 --> 00:08:27,926
encode the work in place and we


261
00:08:28,106 --> 00:08:29,666
provide a fallback allocator in


262
00:08:29,666 --> 00:08:31,996
the case it fails.


263
00:08:31,996 --> 00:08:33,515
And, finally, we commit our


264
00:08:33,716 --> 00:08:34,246
common buffer.


265
00:08:34,666 --> 00:08:36,616
MPS is a really powerful


266
00:08:36,616 --> 00:08:38,916
framework tuned for every device


267
00:08:38,916 --> 00:08:40,256
on our platform.


268
00:08:40,326 --> 00:08:41,666
We encourage you to read more


269
00:08:41,666 --> 00:08:43,206
and start using it.


270
00:08:44,166 --> 00:08:45,576
So we are done with the pixel


271
00:08:45,576 --> 00:08:47,016
processing and we are ready to


272
00:08:47,116 --> 00:08:49,046
encode our MTL texture to the


273
00:08:49,046 --> 00:08:49,766
output format.


274
00:08:50,566 --> 00:08:52,986
Of course, we will again use


275
00:08:52,986 --> 00:08:54,936
Video Toolbox here and let me


276
00:08:54,936 --> 00:08:56,456
show you how to do that in the


277
00:08:56,456 --> 00:08:58,326
most efficient way.


278
00:08:58,956 --> 00:09:00,316
Your new Mac Pro might have


279
00:09:00,316 --> 00:09:02,336
several GPU's and each of them


280
00:09:02,456 --> 00:09:03,426
might have more than one


281
00:09:03,426 --> 00:09:04,196
encoding engine.


282
00:09:08,936 --> 00:09:10,446
Of course, we can let Video


283
00:09:10,446 --> 00:09:12,166
Toolbox be the best available


284
00:09:12,166 --> 00:09:13,996
device, but in many cases you'll


285
00:09:13,996 --> 00:09:15,206
want to specify a device


286
00:09:15,276 --> 00:09:17,596
explicitly to minimize copy


287
00:09:17,596 --> 00:09:18,076
overhead.


288
00:09:18,326 --> 00:09:20,546
So let's see how we do this and


289
00:09:20,546 --> 00:09:22,246
how to use CVPixelBufferPool to


290
00:09:22,246 --> 00:09:23,506
keep memory recycled.


291
00:09:28,106 --> 00:09:29,826
So here is how we get a list of


292
00:09:30,056 --> 00:09:31,456
all available encoders.


293
00:09:32,566 --> 00:09:34,506
First, we use the enable


294
00:09:34,876 --> 00:09:35,896
[inaudible] to ensure we are


295
00:09:35,896 --> 00:09:37,766
leveraging hardware encoding.


296
00:09:38,276 --> 00:09:39,996
Then, we tell Video Toolbox


297
00:09:40,136 --> 00:09:41,366
which device we want to use.


298
00:09:41,456 --> 00:09:43,386
This is a critical step to


299
00:09:43,386 --> 00:09:44,566
ensure we're encoding on the


300
00:09:44,566 --> 00:09:46,436
same device we did our pixel


301
00:09:46,436 --> 00:09:46,946
processing.


302
00:09:48,386 --> 00:09:49,896
Another great thing here is we


303
00:09:49,896 --> 00:09:51,646
can use CVPixelBufferPool to get


304
00:09:51,646 --> 00:09:53,426
the surfaces in the exact format


305
00:09:53,726 --> 00:09:55,546
used by the hardware encoder.


306
00:09:57,366 --> 00:09:58,836
So this is how we get a buffer


307
00:09:59,146 --> 00:10:00,836
from the pool and then we use


308
00:10:01,166 --> 00:10:02,666
MetalTextureCache again.


309
00:10:03,306 --> 00:10:05,506
Now we can convert our


310
00:10:05,836 --> 00:10:07,546
[inaudible] process data to


311
00:10:07,546 --> 00:10:08,896
[inaudible] format which is what


312
00:10:08,896 --> 00:10:09,976
Video Toolbox needs.


313
00:10:10,846 --> 00:10:12,696
And, as usual, we clean up


314
00:10:12,696 --> 00:10:14,246
everything to keep buffers


315
00:10:15,786 --> 00:10:17,016
recycled.


316
00:10:17,016 --> 00:10:18,976
So we can now build the most


317
00:10:18,976 --> 00:10:21,256
efficient pipeline possible and


318
00:10:21,256 --> 00:10:22,076
that's really great.


319
00:10:22,846 --> 00:10:24,106
We'll cover display section


320
00:10:24,106 --> 00:10:25,546
separately and now let's talk


321
00:10:25,546 --> 00:10:26,826
about 8K for a bit.


322
00:10:28,256 --> 00:10:30,716
8K means really large assets.


323
00:10:31,076 --> 00:10:32,676
So let's see how to deal with


324
00:10:32,676 --> 00:10:32,776
them.


325
00:10:33,786 --> 00:10:35,116
First, let's do the math.


326
00:10:35,636 --> 00:10:37,466
An 8K frame is just huge.


327
00:10:38,286 --> 00:10:40,456
It is 16 times larger than an HD


328
00:10:40,456 --> 00:10:42,566
frame totaling up to 270


329
00:10:42,566 --> 00:10:44,256
megabytes uncompressed.


330
00:10:44,786 --> 00:10:49,256
And we have to send almost 300


331
00:10:49,256 --> 00:10:50,336
megabytes every frame.


332
00:10:50,666 --> 00:10:52,296
So for 30 frames per second we


333
00:10:52,296 --> 00:10:54,316
have nine gigabytes per second


334
00:10:54,316 --> 00:10:55,016
of bandwidth.


335
00:10:55,386 --> 00:10:56,796
It's really close to the PCI


336
00:10:56,796 --> 00:10:57,456
Express limit.


337
00:10:58,236 --> 00:10:59,826
Moreover, even with [inaudible]


338
00:10:59,826 --> 00:11:01,916
4 by 4 compression, a 10-minute


339
00:11:02,246 --> 00:11:04,496
clip can easily take massive one


340
00:11:04,726 --> 00:11:05,256
terabyte.


341
00:11:05,796 --> 00:11:07,636
This creates a real challenge


342
00:11:08,006 --> 00:11:09,216
for real-time playback.


343
00:11:09,556 --> 00:11:11,596
So let's see what it looks like


344
00:11:11,596 --> 00:11:12,986
when we trace it using


345
00:11:12,986 --> 00:11:14,996
instruments in [inaudible].


346
00:11:15,206 --> 00:11:17,456
So here is a system trace for


347
00:11:17,456 --> 00:11:18,936
the video playback session we


348
00:11:18,936 --> 00:11:19,546
showed earlier.


349
00:11:20,666 --> 00:11:22,116
If we zoom into the Virtual


350
00:11:22,116 --> 00:11:23,666
Memory Track, we see a huge


351
00:11:23,666 --> 00:11:24,756
amount of page folds.


352
00:11:26,056 --> 00:11:27,346
And the associated [inaudible]


353
00:11:27,426 --> 00:11:28,676
cost is really high.


354
00:11:29,066 --> 00:11:30,226
We can see it below.


355
00:11:31,226 --> 00:11:32,746
So that naturally explains why


356
00:11:32,746 --> 00:11:33,986
all the decoding threads are


357
00:11:33,986 --> 00:11:35,746
stuck and cannot proceed.


358
00:11:37,066 --> 00:11:38,366
We need to manage our memory


359
00:11:38,576 --> 00:11:39,536
more carefully.


360
00:11:40,086 --> 00:11:43,816
[Inaudible] an operating system


361
00:11:43,816 --> 00:11:44,916
don't actually physically


362
00:11:44,916 --> 00:11:46,346
allocate memory pages until they


363
00:11:46,346 --> 00:11:46,706
are used.


364
00:11:47,096 --> 00:11:48,756
So once we start accessing all


365
00:11:48,756 --> 00:11:50,056
of these new pages from many


366
00:11:50,056 --> 00:11:51,306
decoding [inaudible] we have to


367
00:11:51,306 --> 00:11:53,136
wait for the system to map all


368
00:11:53,136 --> 00:11:54,116
those pages for us.


369
00:11:55,166 --> 00:11:56,006
The way to figure that is


370
00:11:56,006 --> 00:11:56,516
simple.


371
00:11:56,816 --> 00:11:59,506
Pre-warm your CPU buffers before


372
00:11:59,506 --> 00:12:01,596
use to make sure all the pages


373
00:12:01,596 --> 00:12:03,536
are resident before playback


374
00:12:04,376 --> 00:12:05,386
starts.


375
00:12:06,086 --> 00:12:07,746
Now let me give you a few more


376
00:12:07,806 --> 00:12:10,946
memory management tips.


377
00:12:11,076 --> 00:12:12,606
Every allocation has a system


378
00:12:12,606 --> 00:12:12,956
call.


379
00:12:13,306 --> 00:12:15,246
One simple rule is to allocate


380
00:12:15,246 --> 00:12:16,586
early enough and avoid


381
00:12:16,816 --> 00:12:18,246
mid-workflow allocations.


382
00:12:18,966 --> 00:12:21,036
Another good advice is to always


383
00:12:21,036 --> 00:12:22,146
reuse your buffers.


384
00:12:22,556 --> 00:12:24,326
This is why it's so important to


385
00:12:24,326 --> 00:12:25,666
use objects such as


386
00:12:25,666 --> 00:12:27,116
CVPixelBufferPool and


387
00:12:27,346 --> 00:12:28,716
CVMetalTextureCache.


388
00:12:30,016 --> 00:12:31,746
So now we have improved the way


389
00:12:31,746 --> 00:12:34,076
we manage our frames but there


390
00:12:34,076 --> 00:12:35,796
are always many, many smaller


391
00:12:35,796 --> 00:12:37,636
allocations needed along the


392
00:12:37,636 --> 00:12:38,926
lifetime of your app.


393
00:12:39,226 --> 00:12:40,426
Let me give you some tips on how


394
00:12:40,426 --> 00:12:41,056
to manage those.


395
00:12:41,706 --> 00:12:44,236
With MTLheap's we can


396
00:12:44,236 --> 00:12:45,836
efficiently manage all of our


397
00:12:46,086 --> 00:12:47,216
transit allocations.


398
00:12:47,906 --> 00:12:49,106
Allocating from a MTLheap


399
00:12:49,286 --> 00:12:51,266
doesn't require a kernel call


400
00:12:51,386 --> 00:12:52,336
since the entire heap is


401
00:12:52,336 --> 00:12:54,286
allocated at creation time.


402
00:12:54,756 --> 00:12:56,436
The heap is a monolithic


403
00:12:56,436 --> 00:12:58,266
resource from the system's point


404
00:12:58,266 --> 00:12:58,526
of view.


405
00:12:58,946 --> 00:13:00,306
So it's made resident as a


406
00:13:00,306 --> 00:13:00,826
whole.


407
00:13:01,936 --> 00:13:03,366
Also, allocating from heap


408
00:13:03,806 --> 00:13:05,496
allows for tighter memory


409
00:13:05,946 --> 00:13:06,096
packing,


410
00:13:06,716 --> 00:13:08,266
and with heaps you can alias


411
00:13:08,266 --> 00:13:10,096
resource memory within the


412
00:13:10,096 --> 00:13:10,756
common buffer.


413
00:13:11,036 --> 00:13:12,346
Something we trust impossible


414
00:13:12,346 --> 00:13:13,486
with the regular buffers.


415
00:13:13,976 --> 00:13:15,626
Let me show you how to do this.


416
00:13:16,976 --> 00:13:18,446
In this sample, we will be


417
00:13:18,446 --> 00:13:20,326
aliasing transit allocations.


418
00:13:20,746 --> 00:13:23,066
First, we created the heap using


419
00:13:23,066 --> 00:13:23,816
our device.


420
00:13:24,296 --> 00:13:26,926
Along the filter stages, we


421
00:13:27,136 --> 00:13:28,736
created the uniforms for our


422
00:13:28,736 --> 00:13:31,006
blur kernel from that heap.


423
00:13:32,046 --> 00:13:34,006
Next, we allocate another buffer


424
00:13:34,006 --> 00:13:35,886
for color grade uniforms from


425
00:13:35,886 --> 00:13:37,146
that same heap.


426
00:13:37,736 --> 00:13:39,216
So after the color grading


427
00:13:39,216 --> 00:13:40,326
stage, we don't need those


428
00:13:40,326 --> 00:13:41,916
anymore and we mark them as


429
00:13:41,916 --> 00:13:43,966
aliasable, and the heap can


430
00:13:43,966 --> 00:13:45,486
actually recycle that memory for


431
00:13:45,696 --> 00:13:46,846
future allocations.


432
00:13:47,736 --> 00:13:49,596
So when we allocate a new


433
00:13:49,626 --> 00:13:51,436
intermediate buffer, the heap is


434
00:13:51,556 --> 00:13:53,566
free to reuse any memory marked


435
00:13:53,566 --> 00:13:55,946
as aliasable so this is really


436
00:13:55,946 --> 00:13:56,346
efficient.


437
00:13:57,746 --> 00:13:59,236
So that was a quick overview of


438
00:13:59,236 --> 00:14:01,046
how to manage our resource


439
00:14:01,046 --> 00:14:01,696
allocations.


440
00:14:02,306 --> 00:14:04,276
Now let's talk about how to


441
00:14:04,486 --> 00:14:06,246
present our friends with a


442
00:14:06,646 --> 00:14:08,306
predictable frame rate.


443
00:14:09,146 --> 00:14:11,216
So here is a timing sample for


444
00:14:11,416 --> 00:14:13,026
triple buffer Metal application.


445
00:14:14,016 --> 00:14:15,476
In this example, we're playing a


446
00:14:15,476 --> 00:14:17,986
30-hertz video on a 60-hertz


447
00:14:18,056 --> 00:14:18,396
display.


448
00:14:19,106 --> 00:14:20,546
Notice how the frames are


449
00:14:20,546 --> 00:14:21,776
showing up on the display at a


450
00:14:21,776 --> 00:14:23,856
non-uniform cadence.


451
00:14:24,566 --> 00:14:26,036
Users feel it as stutters.


452
00:14:27,386 --> 00:14:29,276
So why is this happening?


453
00:14:29,806 --> 00:14:32,436
Note how the CPU is incurring


454
00:14:32,436 --> 00:14:34,516
GPU work without regard for


455
00:14:34,566 --> 00:14:34,896
timing.


456
00:14:36,516 --> 00:14:38,056
Once the third frame is


457
00:14:38,426 --> 00:14:39,376
[inaudible], the CPU is blocked


458
00:14:39,736 --> 00:14:41,086
waiting for a [inaudible] to


459
00:14:41,176 --> 00:14:42,606
become available which is not


460
00:14:42,726 --> 00:14:44,496
going to happen until frame one


461
00:14:44,496 --> 00:14:45,236
leaves the glass.


462
00:14:46,756 --> 00:14:48,716
So this approach maximizes GPU


463
00:14:48,956 --> 00:14:51,836
utilization but produces visible


464
00:14:51,836 --> 00:14:52,366
stutters.


465
00:14:53,626 --> 00:14:55,696
We generally want each frame to


466
00:14:55,696 --> 00:14:57,276
remain on the glass an equal


467
00:14:57,306 --> 00:14:59,266
amount of time.


468
00:14:59,456 --> 00:15:01,296
As a solution, Core Video offers


469
00:15:01,296 --> 00:15:02,166
an interface called


470
00:15:02,316 --> 00:15:03,336
CVDisplayLink.


471
00:15:03,646 --> 00:15:05,326
This is a high-precision


472
00:15:05,446 --> 00:15:07,406
low-level timer which notifies


473
00:15:07,406 --> 00:15:09,616
you before every VBLANK at a


474
00:15:09,616 --> 00:15:10,896
displaced refresh rate.


475
00:15:11,646 --> 00:15:13,736
Rather than let the CPU


476
00:15:13,736 --> 00:15:14,976
[inaudible] as many frames as


477
00:15:14,976 --> 00:15:17,266
possible, We use display link to


478
00:15:17,496 --> 00:15:18,986
determine the right time to


479
00:15:18,986 --> 00:15:20,906
submit each frame to the GPU.


480
00:15:21,696 --> 00:15:23,886
This significantly reduces video


481
00:15:23,886 --> 00:15:24,506
playback jitter.


482
00:15:25,326 --> 00:15:26,386
So let me show you the code


483
00:15:26,386 --> 00:15:28,766
snippet how to do this.


484
00:15:28,966 --> 00:15:30,556
We started by making a link with


485
00:15:30,556 --> 00:15:31,646
the display we will be using.


486
00:15:32,206 --> 00:15:35,866
Then, we set up our callback


487
00:15:35,866 --> 00:15:37,896
handler and for every call we


488
00:15:37,966 --> 00:15:40,086
will get the current time and


489
00:15:40,086 --> 00:15:41,396
the next VBLANK time.


490
00:15:41,996 --> 00:15:43,436
And we can use these values to


491
00:15:43,686 --> 00:15:44,996
determine when to issue a


492
00:15:45,276 --> 00:15:46,716
present call assuming we have


493
00:15:46,956 --> 00:15:47,876
processed frames ready.


494
00:15:48,486 --> 00:15:50,616
And we can adjust the desired


495
00:15:50,866 --> 00:15:52,246
frequency to our needs.


496
00:15:53,206 --> 00:15:54,566
So this will significantly


497
00:15:54,606 --> 00:15:56,286
reduce stutters but we can take


498
00:15:56,286 --> 00:15:57,266
it a step further.


499
00:15:58,086 --> 00:16:00,336
For example, playing 24-hertz


500
00:16:00,396 --> 00:16:02,296
content on a 60-hertz display,


501
00:16:02,666 --> 00:16:04,206
we need three-two pull down.


502
00:16:04,596 --> 00:16:06,946
It means we will present even


503
00:16:06,946 --> 00:16:08,916
frames for three VBLANKS and odd


504
00:16:08,916 --> 00:16:11,066
frames over two VBLANKS.


505
00:16:11,786 --> 00:16:13,486
This is the best we can do given


506
00:16:13,486 --> 00:16:15,076
the mismatch, and the code


507
00:16:15,076 --> 00:16:16,206
snippet I just showed you will


508
00:16:16,206 --> 00:16:18,286
handle this just fine, but the


509
00:16:18,286 --> 00:16:19,796
good news is we can do even


510
00:16:19,796 --> 00:16:20,086
better.


511
00:16:20,836 --> 00:16:23,386
Our new Pro Display XDR supports


512
00:16:23,386 --> 00:16:25,546
multiple refresh rates including


513
00:16:25,656 --> 00:16:26,446
48-hertz.


514
00:16:26,966 --> 00:16:29,286
So your 24-hertz content will


515
00:16:29,286 --> 00:16:31,286
play extremely smoothly jitter


516
00:16:31,286 --> 00:16:31,546
free.


517
00:16:32,906 --> 00:16:34,696
So we have made quite a few


518
00:16:34,696 --> 00:16:36,036
important optimizations.


519
00:16:37,036 --> 00:16:38,056
Now I'd like to show you the


520
00:16:38,056 --> 00:16:38,726
final result.


521
00:16:39,246 --> 00:16:40,586
This is DaVinci Resolve now


522
00:16:41,126 --> 00:16:42,916
playing that same 8k stream.


523
00:16:43,636 --> 00:16:44,866
As you can see, playback is


524
00:16:44,866 --> 00:16:46,826
smooth with no stutters.


525
00:16:47,366 --> 00:16:49,876
This has been a great


526
00:16:50,046 --> 00:16:51,326
collaboration for us with Black


527
00:16:51,326 --> 00:16:51,596
Magic.


528
00:16:52,156 --> 00:16:53,576
We achieved outstanding results


529
00:16:53,816 --> 00:16:55,296
together, and we encourage you


530
00:16:55,546 --> 00:16:56,716
to start leveraging our


531
00:16:56,956 --> 00:16:58,786
high-performance frameworks and


532
00:16:58,786 --> 00:17:00,286
start building new and exciting


533
00:17:00,496 --> 00:17:02,366
pro apps for our platform.


534
00:17:02,856 --> 00:17:05,406
We have tackled that 8k


535
00:17:05,406 --> 00:17:05,856
challenge.


536
00:17:06,606 --> 00:17:08,786
Now I'd like to invite Dileep to


537
00:17:08,786 --> 00:17:10,896
talk about our support for HDR


538
00:17:11,616 --> 00:17:13,056
and how you can enable it in


539
00:17:13,056 --> 00:17:13,406
your app.


540
00:17:13,925 --> 00:17:14,195
Dileep?


541
00:17:15,516 --> 00:17:20,046
[ Applause ]


542
00:17:20,546 --> 00:17:21,705
>> Thanks, Eugene.


543
00:17:22,396 --> 00:17:24,566
In recent years high-dynamic


544
00:17:24,566 --> 00:17:26,346
range rendering and displays


545
00:17:26,346 --> 00:17:27,756
have greatly enhanced the


546
00:17:27,826 --> 00:17:29,576
quality of images that we see on


547
00:17:29,576 --> 00:17:29,966
screen.


548
00:17:30,936 --> 00:17:32,876
At Apple we have been constantly


549
00:17:33,156 --> 00:17:34,246
[inaudible] support to improve


550
00:17:34,246 --> 00:17:36,116
the image technology.


551
00:17:36,626 --> 00:17:38,466
As you know, we have added many


552
00:17:38,466 --> 00:17:40,416
technologies such as retina


553
00:17:40,416 --> 00:17:43,176
display, 4K and 5K resolution,


554
00:17:43,466 --> 00:17:45,866
wide gamut color space and many


555
00:17:46,256 --> 00:17:47,796
and have enabled you, the


556
00:17:47,796 --> 00:17:50,166
developers, to create amazing


557
00:17:50,166 --> 00:17:51,826
and high-quality images.


558
00:17:52,556 --> 00:17:54,326
Continuing in that part, this


559
00:17:54,326 --> 00:17:56,576
year we are adding great support


560
00:17:56,576 --> 00:17:58,656
for HDR on macOS.


561
00:17:59,336 --> 00:18:00,726
I'm excited to give you an


562
00:18:00,726 --> 00:18:02,806
overview of the support for HDR


563
00:18:02,856 --> 00:18:04,406
rendering and display.


564
00:18:05,376 --> 00:18:07,826
To do that, I'll cover four


565
00:18:07,826 --> 00:18:08,676
topics with you.


566
00:18:09,376 --> 00:18:11,996
One, I'll briefly talk about


567
00:18:11,996 --> 00:18:13,696
some common traits of HDR


568
00:18:13,696 --> 00:18:14,186
images.


569
00:18:15,106 --> 00:18:17,386
Then I'll describe our approach


570
00:18:17,386 --> 00:18:19,666
to HDR, our rendering model of


571
00:18:20,726 --> 00:18:20,816
HDR.


572
00:18:21,066 --> 00:18:23,456
Then I'll go into detail on how


573
00:18:23,456 --> 00:18:26,116
to use Metal for HDR rendering.


574
00:18:26,656 --> 00:18:28,496
And finally, wrap it up with


575
00:18:28,496 --> 00:18:30,416
some recommendations on best


576
00:18:30,416 --> 00:18:31,036
practices.


577
00:18:32,346 --> 00:18:34,696
So let's begin with describing


578
00:18:34,696 --> 00:18:36,536
some common traits of HDR


579
00:18:36,536 --> 00:18:37,216
images.


580
00:18:37,636 --> 00:18:38,866
What makes them special?


581
00:18:39,956 --> 00:18:41,506
Compared to standard dynamic


582
00:18:41,506 --> 00:18:44,456
range or SDR images, HDR images


583
00:18:44,856 --> 00:18:46,656
have better contrast levels.


584
00:18:47,336 --> 00:18:48,826
They have great details in the


585
00:18:48,826 --> 00:18:50,436
dark and the bright areas of the


586
00:18:50,436 --> 00:18:50,826
image.


587
00:18:52,126 --> 00:18:54,476
Usually SDR images, these


588
00:18:54,476 --> 00:18:56,126
details are not discernible.


589
00:18:56,386 --> 00:18:58,276
They're either crushed or washed


590
00:18:58,276 --> 00:18:58,426
out.


591
00:19:00,036 --> 00:19:03,206
HDR images have more colors with


592
00:19:03,206 --> 00:19:04,976
wide range of colors in them.


593
00:19:05,486 --> 00:19:07,146
They look very realistic.


594
00:19:08,376 --> 00:19:10,336
Also, they are really bright.


595
00:19:10,826 --> 00:19:12,266
The brightness information is


596
00:19:12,356 --> 00:19:15,566
encoded in the image itself with


597
00:19:15,566 --> 00:19:17,696
such a high brightness and great


598
00:19:17,696 --> 00:19:19,816
contrast ratios, they make it


599
00:19:19,916 --> 00:19:21,976
possible to add lighting effects


600
00:19:21,976 --> 00:19:24,216
in the scene that look closer to


601
00:19:24,216 --> 00:19:24,856
real life.


602
00:19:25,596 --> 00:19:28,176
And finally, they need to be


603
00:19:28,176 --> 00:19:29,886
viewed on a capable display.


604
00:19:30,816 --> 00:19:32,636
The display that can preserve


605
00:19:32,786 --> 00:19:34,496
all the details of the image.


606
00:19:35,026 --> 00:19:36,356
The display in itself should


607
00:19:36,356 --> 00:19:38,316
have underlying technologies to


608
00:19:38,316 --> 00:19:39,666
be able to produce high


609
00:19:39,666 --> 00:19:41,926
brightness, high color fidelity,


610
00:19:41,926 --> 00:19:43,436
and great contrast ratios.


611
00:19:44,656 --> 00:19:47,026
Our new Pro Display XDR is a


612
00:19:47,176 --> 00:19:49,826
great example of that.


613
00:19:50,046 --> 00:19:53,136
Now, how do we render and


614
00:19:53,136 --> 00:19:54,866
display these amazing HDR


615
00:19:54,866 --> 00:19:56,856
contents on our devices?


616
00:19:58,036 --> 00:19:59,676
At Apple, we have a unique


617
00:19:59,676 --> 00:20:00,456
approach for this.


618
00:20:01,076 --> 00:20:03,256
We call this EDR, extended


619
00:20:03,256 --> 00:20:04,146
dynamic range.


620
00:20:05,636 --> 00:20:07,606
In this approach, we use the


621
00:20:07,606 --> 00:20:09,226
brightness headroom available on


622
00:20:09,226 --> 00:20:10,376
the display to show the


623
00:20:10,376 --> 00:20:12,376
highlights and shadows of HDR


624
00:20:12,376 --> 00:20:12,976
images.


625
00:20:13,656 --> 00:20:15,976
Let me explain the concept in


626
00:20:16,686 --> 00:20:16,856
detail.


627
00:20:17,276 --> 00:20:19,096
As you know, the brightness set


628
00:20:19,096 --> 00:20:20,716
on a display is dependent on the


629
00:20:20,716 --> 00:20:22,006
viewing conditions or the


630
00:20:22,006 --> 00:20:22,956
ambient conditions.


631
00:20:23,986 --> 00:20:25,606
For example, if you're in a


632
00:20:25,606 --> 00:20:27,446
dimmed room the brightness set


633
00:20:27,446 --> 00:20:29,186
on your display could be 200


634
00:20:29,186 --> 00:20:31,626
nits, maybe low, and the


635
00:20:31,626 --> 00:20:34,366
brightness set is ideal to view


636
00:20:34,406 --> 00:20:37,716
SDR contents such as UI or


637
00:20:37,716 --> 00:20:39,456
Safari or YouTube video.


638
00:20:40,656 --> 00:20:42,736
But if your display is capable


639
00:20:42,736 --> 00:20:45,736
of producing up to thousand nits


640
00:20:45,736 --> 00:20:47,396
then you have a huge brightness


641
00:20:47,396 --> 00:20:48,516
headroom available on the


642
00:20:48,516 --> 00:20:48,926
display.


643
00:20:49,566 --> 00:20:52,126
Similarly, if you're in well-lit


644
00:20:52,126 --> 00:20:54,066
conditions such as office space,


645
00:20:54,626 --> 00:20:55,696
the brightness set on the


646
00:20:55,696 --> 00:20:58,026
display could be higher, say 500


647
00:20:58,026 --> 00:20:58,316
nits.


648
00:20:58,966 --> 00:21:00,586
And again, the brightness set is


649
00:21:00,636 --> 00:21:03,306
ideal to view SDR contents but


650
00:21:03,306 --> 00:21:04,806
still you have brightness


651
00:21:04,856 --> 00:21:06,756
headroom left on the display in


652
00:21:06,756 --> 00:21:07,696
this condition too.


653
00:21:08,216 --> 00:21:11,016
In an approach to HDR, we take


654
00:21:11,016 --> 00:21:11,956
advantage of this.


655
00:21:12,476 --> 00:21:14,596
When we render the pixels, we


656
00:21:14,596 --> 00:21:16,726
map the SDR pixels to the


657
00:21:16,726 --> 00:21:18,336
brightness set on the display


658
00:21:18,766 --> 00:21:20,756
and use the headroom to map the


659
00:21:20,796 --> 00:21:21,826
HDR pixels.


660
00:21:22,396 --> 00:21:25,146
The extent to which we map these


661
00:21:25,146 --> 00:21:27,266
two categories really depends on


662
00:21:27,266 --> 00:21:28,646
the viewing conditions as you


663
00:21:28,646 --> 00:21:30,086
can clearly see in the two


664
00:21:30,086 --> 00:21:31,586
examples here.


665
00:21:33,216 --> 00:21:35,236
However, too, rendering this


666
00:21:35,286 --> 00:21:37,356
model, the pixels needs to be


667
00:21:37,476 --> 00:21:40,076
structured in a certain way and


668
00:21:40,256 --> 00:21:43,236
we do that by scaling the HDR


669
00:21:43,236 --> 00:21:45,176
pixels relative to the SDR


670
00:21:45,366 --> 00:21:46,466
brightness of the display.


671
00:21:47,966 --> 00:21:49,786
Let's use our previous example


672
00:21:49,786 --> 00:21:51,316
of a dimmed room and see how the


673
00:21:51,316 --> 00:21:53,026
pixel values are structured


674
00:21:53,026 --> 00:21:54,246
relative to the brightness of


675
00:21:54,246 --> 00:21:54,756
the display.


676
00:21:56,266 --> 00:21:58,106
In here, we represent the


677
00:21:58,156 --> 00:22:01,026
brightness in X axis and the


678
00:22:01,026 --> 00:22:02,976
normalized pixel values in Y


679
00:22:02,976 --> 00:22:03,466
axis.


680
00:22:04,126 --> 00:22:06,216
In this example, the brightness


681
00:22:06,216 --> 00:22:09,746
of the display set to 200 nits.


682
00:22:10,566 --> 00:22:12,956
In our rendering model we always


683
00:22:12,956 --> 00:22:14,646
reserve the pixel values, the


684
00:22:14,646 --> 00:22:16,396
normalized pixel values in the


685
00:22:16,396 --> 00:22:19,606
range 0 to 14 SDR contents and


686
00:22:19,606 --> 00:22:21,576
we map it to the brightness set


687
00:22:21,576 --> 00:22:22,176
on the display.


688
00:22:23,196 --> 00:22:25,406
So a pixel value of one here


689
00:22:25,776 --> 00:22:28,256
corresponds to 200 nits.


690
00:22:29,116 --> 00:22:30,736
But as you can see, there is a


691
00:22:30,736 --> 00:22:32,276
huge headroom available on the


692
00:22:32,336 --> 00:22:32,746
display.


693
00:22:33,186 --> 00:22:35,316
So you have pixel values from


694
00:22:35,316 --> 00:22:37,366
one through five available to


695
00:22:37,366 --> 00:22:39,166
represent HDR contents.


696
00:22:40,126 --> 00:22:42,886
A scale factor of 5x relative to


697
00:22:42,886 --> 00:22:44,906
the SDR range to take full


698
00:22:44,906 --> 00:22:46,016
advantage of the display


699
00:22:46,016 --> 00:22:46,596
brightness.


700
00:22:47,886 --> 00:22:49,686
We call this scale factor as


701
00:22:50,136 --> 00:22:52,366
maximum EDR.


702
00:22:53,036 --> 00:22:54,806
If the viewing conditions change


703
00:22:54,906 --> 00:22:57,146
or you're in a well-lit room and


704
00:22:57,146 --> 00:22:58,926
the brightness is increased to


705
00:22:58,926 --> 00:23:01,806
500 nits, then the maximum EDR


706
00:23:01,806 --> 00:23:05,346
drops down but note the pixel


707
00:23:05,346 --> 00:23:07,036
values in the range zero to one


708
00:23:07,396 --> 00:23:09,416
are still dedicated for SDR


709
00:23:09,566 --> 00:23:10,196
contents.


710
00:23:10,876 --> 00:23:12,396
But they're mapped differently


711
00:23:12,396 --> 00:23:15,246
now, so now a pixel value of one


712
00:23:15,386 --> 00:23:17,846
corresponds to 500 nits instead


713
00:23:17,846 --> 00:23:19,646
of 200 in the previous example.


714
00:23:20,906 --> 00:23:22,506
And since you have a smaller


715
00:23:22,506 --> 00:23:24,156
headroom available here, in this


716
00:23:24,156 --> 00:23:26,046
case, you have a smaller range


717
00:23:26,046 --> 00:23:27,786
of pixel calls available to


718
00:23:27,786 --> 00:23:29,396
represent HDR contents.


719
00:23:30,236 --> 00:23:32,316
So merely 2x here in this


720
00:23:32,316 --> 00:23:34,266
example, relative to the SDR


721
00:23:34,386 --> 00:23:36,406
range to represent HDR pixels.


722
00:23:37,626 --> 00:23:39,666
As you can see, we structured


723
00:23:39,666 --> 00:23:41,766
our pixels in such a way that


724
00:23:41,876 --> 00:23:43,816
the HDR pixels are relative to


725
00:23:43,816 --> 00:23:46,076
the SDR range and they scale


726
00:23:46,166 --> 00:23:47,686
relative to the SDR range.


727
00:23:48,576 --> 00:23:50,646
We also use negative pixels for


728
00:23:50,646 --> 00:23:52,176
representing the darker side of


729
00:23:52,436 --> 00:23:53,656
the HDR image.


730
00:23:54,646 --> 00:23:58,116
So in summary, EDR or external


731
00:23:58,116 --> 00:23:59,816
dynamic range is a display


732
00:23:59,816 --> 00:24:01,766
referred rendering model in


733
00:24:01,766 --> 00:24:03,296
which we use the brightness


734
00:24:03,296 --> 00:24:04,686
headroom available on the


735
00:24:04,686 --> 00:24:07,386
display for HDR pixels, and we


736
00:24:07,626 --> 00:24:10,186
scale the HDR pixels relative to


737
00:24:10,186 --> 00:24:11,656
the SDR brightness of the


738
00:24:11,656 --> 00:24:12,066
display.


739
00:24:13,426 --> 00:24:16,066
The advantage of this model is


740
00:24:16,066 --> 00:24:18,196
that you can do HDR rendering on


741
00:24:18,386 --> 00:24:20,196
pretty much any display on which


742
00:24:20,196 --> 00:24:23,116
we can set brightness, but if


743
00:24:23,116 --> 00:24:24,946
you have more capable display


744
00:24:25,126 --> 00:24:27,196
such as of a new Pro Display XDR


745
00:24:27,646 --> 00:24:28,926
with its huge headroom


746
00:24:28,926 --> 00:24:31,196
availability then the contents


747
00:24:31,196 --> 00:24:35,246
are going to look just better.


748
00:24:35,436 --> 00:24:37,036
Now that we have looked into our


749
00:24:37,036 --> 00:24:38,676
rendering model of our approach


750
00:24:38,676 --> 00:24:41,416
to HDR, let's look into what


751
00:24:41,416 --> 00:24:43,726
API's do we have and how you can


752
00:24:43,726 --> 00:24:45,266
use those API's in your


753
00:24:45,266 --> 00:24:45,866
application.


754
00:24:48,566 --> 00:24:51,166
On both macOS and iOS, you have


755
00:24:51,166 --> 00:24:52,016
a couple of options.


756
00:24:52,886 --> 00:24:55,526
One, you can use AVFoundation


757
00:24:56,506 --> 00:24:56,786
API's.


758
00:24:56,786 --> 00:24:58,816
These API's are ideal for media


759
00:24:58,816 --> 00:24:59,886
playback applications.


760
00:25:00,586 --> 00:25:02,646
They handle all aspects of tone


761
00:25:02,646 --> 00:25:04,186
mapping and color management for


762
00:25:04,186 --> 00:25:04,336
you.


763
00:25:05,216 --> 00:25:07,376
Two, you can directly use Metal.


764
00:25:08,026 --> 00:25:09,426
Metal provides with a lot of


765
00:25:09,426 --> 00:25:11,356
options and great flexibility.


766
00:25:12,386 --> 00:25:15,196
Using the CAMetalLayer and EDR


767
00:25:15,196 --> 00:25:17,806
API's, you can take full control


768
00:25:17,806 --> 00:25:19,226
of HDR rendering in your


769
00:25:19,226 --> 00:25:21,146
application including tone


770
00:25:21,146 --> 00:25:23,066
mapping and color management.


771
00:25:24,316 --> 00:25:26,186
These API's are ideal for


772
00:25:26,426 --> 00:25:27,316
content creation.


773
00:25:28,626 --> 00:25:30,696
Now using a code snippet, let's


774
00:25:30,696 --> 00:25:32,286
look at how the metal layer and


775
00:25:32,286 --> 00:25:34,336
the EDR API's all come together


776
00:25:34,336 --> 00:25:35,876
in an application, shall we?


777
00:25:36,686 --> 00:25:39,086
So the first and the foremost


778
00:25:39,086 --> 00:25:40,906
that you do in your code base is


779
00:25:40,906 --> 00:25:43,026
to check for the EDR support on


780
00:25:43,026 --> 00:25:45,076
the display, and this screen


781
00:25:45,076 --> 00:25:46,276
provides you with the property


782
00:25:46,276 --> 00:25:47,276
for that.


783
00:25:47,856 --> 00:25:50,106
Then as usual, you create and


784
00:25:50,146 --> 00:25:51,306
set up your metal layer.


785
00:25:52,426 --> 00:25:53,856
When you set up the metal layer,


786
00:25:54,016 --> 00:25:55,906
you need to choose a wide gamut


787
00:25:55,986 --> 00:25:57,816
color space that suits your


788
00:25:57,816 --> 00:25:58,436
application.


789
00:25:59,466 --> 00:26:01,236
Metal supports rendering into


790
00:26:01,236 --> 00:26:02,996
wide gamut color spaces such as


791
00:26:03,106 --> 00:26:05,656
BT2020 or B3.


792
00:26:06,756 --> 00:26:08,436
Next, you need to choose the


793
00:26:08,436 --> 00:26:10,116
transfer function that matches


794
00:26:10,116 --> 00:26:10,756
your content.


795
00:26:11,516 --> 00:26:13,386
Again, the API's have support


796
00:26:13,386 --> 00:26:15,206
for all industry standard


797
00:26:15,246 --> 00:26:18,116
transfer functions such as PQ,


798
00:26:18,116 --> 00:26:19,416
HLG, or Gamma.


799
00:26:20,876 --> 00:26:23,406
Then you need to choose pixel


800
00:26:23,406 --> 00:26:25,166
format for your HDR rendering.


801
00:26:25,926 --> 00:26:28,606
We recommend that you use float


802
00:26:28,606 --> 00:26:30,766
16 as a preferred pixel format


803
00:26:30,816 --> 00:26:32,636
for most of your HDR rendering


804
00:26:32,636 --> 00:26:35,486
needs because float 16 has


805
00:26:35,596 --> 00:26:37,116
enough precision to carry the


806
00:26:37,216 --> 00:26:38,376
color and the brightness


807
00:26:38,376 --> 00:26:40,096
information for HDR contents.


808
00:26:40,646 --> 00:26:43,076
And finally, in the layers set


809
00:26:43,076 --> 00:26:44,646
up you need to indicate to Metal


810
00:26:44,966 --> 00:26:46,866
that you have opted in to EDR


811
00:26:46,866 --> 00:26:47,626
rendering model.


812
00:26:48,576 --> 00:26:50,066
So this is a typical layer set


813
00:26:50,066 --> 00:26:52,046
up that you would do.


814
00:26:52,446 --> 00:26:54,156
Next, moving on to main render


815
00:26:54,226 --> 00:26:54,446
loop.


816
00:26:54,946 --> 00:26:56,566
In the main render loop you need


817
00:26:56,566 --> 00:26:58,016
to get the brightness headroom


818
00:26:58,016 --> 00:26:59,166
that we talked about or the


819
00:26:59,166 --> 00:27:01,466
maximum EDR information, right?


820
00:27:01,796 --> 00:27:03,806
So NSScreen provides you with


821
00:27:03,806 --> 00:27:05,346
the property for that.


822
00:27:05,856 --> 00:27:07,416
But note, this property is


823
00:27:07,416 --> 00:27:07,996
dynamic.


824
00:27:08,506 --> 00:27:09,676
It keeps changing with the


825
00:27:09,676 --> 00:27:11,486
viewing conditions or when the


826
00:27:11,486 --> 00:27:12,646
brightness of the display


827
00:27:12,646 --> 00:27:13,106
changes.


828
00:27:13,616 --> 00:27:15,756
So you need to register for a


829
00:27:15,756 --> 00:27:17,686
notification for any changes on


830
00:27:17,686 --> 00:27:20,506
this property and as maximum EDR


831
00:27:20,686 --> 00:27:22,976
changes, you need to redraw your


832
00:27:23,066 --> 00:27:23,726
contents.


833
00:27:25,516 --> 00:27:27,936
Now, if you are handling tone


834
00:27:27,936 --> 00:27:29,486
mapping and color management


835
00:27:29,486 --> 00:27:30,996
yourselves in the application,


836
00:27:31,446 --> 00:27:32,946
you need to do some additional


837
00:27:32,946 --> 00:27:34,686
pixel processing in the shaders.


838
00:27:35,206 --> 00:27:36,856
Let's review some common steps


839
00:27:36,916 --> 00:27:39,686
that you would do.


840
00:27:39,936 --> 00:27:43,236
Typically the video come in


841
00:27:43,236 --> 00:27:44,636
[inaudible] color format.


842
00:27:45,056 --> 00:27:46,306
So the first step in your


843
00:27:46,306 --> 00:27:48,046
application or in your shaders


844
00:27:48,116 --> 00:27:49,786
is to convert it to RGB.


845
00:27:50,876 --> 00:27:53,206
Also, the video contents come


846
00:27:53,316 --> 00:27:54,796
encoded with some kind of


847
00:27:54,796 --> 00:27:56,566
non-linear transfer functions


848
00:27:56,796 --> 00:27:57,766
such as PQ.


849
00:27:58,646 --> 00:28:00,296
So the next step in the shader


850
00:28:00,296 --> 00:28:02,576
is to apply inverse transfer


851
00:28:02,576 --> 00:28:04,376
function and linearize your


852
00:28:04,376 --> 00:28:06,726
pixels, and then normalize it in


853
00:28:06,726 --> 00:28:08,626
the range zero to one.


854
00:28:10,066 --> 00:28:12,806
And then use the maximum EDR


855
00:28:12,886 --> 00:28:14,746
that you got from NSScreen and


856
00:28:14,916 --> 00:28:16,806
scale the pixels as we discussed


857
00:28:16,806 --> 00:28:17,946
in the EDR section.


858
00:28:18,426 --> 00:28:21,136
And then perform editing,


859
00:28:21,136 --> 00:28:23,116
grading, or any processing that


860
00:28:23,256 --> 00:28:25,286
suits your application, and


861
00:28:25,286 --> 00:28:27,646
finally, perform tone mapping.


862
00:28:28,986 --> 00:28:30,406
If the brightness changes then


863
00:28:30,406 --> 00:28:32,066
you need to do the tone mapping


864
00:28:32,066 --> 00:28:32,976
with different set of


865
00:28:32,976 --> 00:28:33,686
parameters.


866
00:28:34,556 --> 00:28:37,996
If your contents are in a color


867
00:28:37,996 --> 00:28:39,526
space that is different from the


868
00:28:39,526 --> 00:28:41,866
one on the display then you also


869
00:28:41,866 --> 00:28:43,406
need to apply proper color


870
00:28:43,466 --> 00:28:44,006
conversions.


871
00:28:45,406 --> 00:28:47,116
However, if you don't want to


872
00:28:47,236 --> 00:28:48,616
handle tone mapping or


873
00:28:48,616 --> 00:28:49,876
teleprocessing, and you want


874
00:28:49,876 --> 00:28:51,686
Metal to handle it for you, you


875
00:28:51,686 --> 00:28:52,836
can easily do that.


876
00:28:53,926 --> 00:28:55,616
When you create a Metal layer,


877
00:28:56,296 --> 00:28:58,596
attach an EDR metadata object


878
00:28:58,596 --> 00:28:58,936
with it.


879
00:28:59,986 --> 00:29:01,606
Typically the EDR metadata


880
00:29:01,606 --> 00:29:03,276
object provides the information


881
00:29:03,566 --> 00:29:05,286
on the mastering display and it


882
00:29:05,286 --> 00:29:06,916
also tells Metal how you want to


883
00:29:06,916 --> 00:29:07,916
map your pixels.


884
00:29:08,836 --> 00:29:10,296
You also need to use one of the


885
00:29:10,296 --> 00:29:12,176
linear color spaces available


886
00:29:12,176 --> 00:29:12,636
with Metal.


887
00:29:13,176 --> 00:29:16,356
So once all your pixel


888
00:29:16,356 --> 00:29:18,406
processing is done, your frame


889
00:29:18,406 --> 00:29:19,086
is ready.


890
00:29:19,306 --> 00:29:21,476
Use the existing Metal API's to


891
00:29:21,606 --> 00:29:23,226
present your frame on the


892
00:29:23,226 --> 00:29:23,626
screen.


893
00:29:24,206 --> 00:29:27,316
As we noted earlier, you need a


894
00:29:27,316 --> 00:29:29,496
capable display such as of a Pro


895
00:29:29,496 --> 00:29:31,126
Display XDR to view these


896
00:29:31,126 --> 00:29:31,676
contents.


897
00:29:32,736 --> 00:29:35,416
We also support HDR 10 and Dolby


898
00:29:35,416 --> 00:29:37,026
Vision TV's available in the


899
00:29:37,026 --> 00:29:37,526
market.


900
00:29:38,636 --> 00:29:40,856
So this is a simple illustration


901
00:29:40,856 --> 00:29:43,626
of how you can use Metal layer


902
00:29:43,836 --> 00:29:46,746
and EDR API's for HDR rendering


903
00:29:46,876 --> 00:29:47,746
in your application.


904
00:29:48,656 --> 00:29:50,716
So before we end this section,


905
00:29:51,336 --> 00:29:53,406
let's review some key takeaways


906
00:29:53,586 --> 00:29:55,196
and some recommendations on best


907
00:29:55,196 --> 00:29:55,826
practices.


908
00:29:58,656 --> 00:30:00,936
Remember to redraw and update


909
00:30:00,936 --> 00:30:02,536
your content as the brightness


910
00:30:02,536 --> 00:30:02,946
changes.


911
00:30:04,506 --> 00:30:06,366
Use float 16 as a preferred


912
00:30:06,366 --> 00:30:09,066
pixel format for most of your


913
00:30:09,066 --> 00:30:09,896
HDR rendering needs.


914
00:30:11,346 --> 00:30:13,196
When you set up the Metal layer,


915
00:30:13,196 --> 00:30:14,566
select the color space and


916
00:30:14,796 --> 00:30:16,426
transfer function that matches


917
00:30:16,426 --> 00:30:18,396
your content and then perform


918
00:30:18,396 --> 00:30:19,936
any additional processing in the


919
00:30:19,936 --> 00:30:21,446
shaders as necessary.


920
00:30:22,226 --> 00:30:24,596
Last, but not the least, HDR


921
00:30:24,886 --> 00:30:27,686
processing adds to computational


922
00:30:27,686 --> 00:30:29,226
overhead and adds [inaudible].


923
00:30:30,006 --> 00:30:32,766
So bypass tone mapping if your


924
00:30:32,836 --> 00:30:34,656
contents are already tone mapped


925
00:30:35,066 --> 00:30:37,006
or if performance is more


926
00:30:37,006 --> 00:30:39,136
important for you than color


927
00:30:39,136 --> 00:30:39,736
accuracy.


928
00:30:40,936 --> 00:30:43,686
So, in summary, we have provided


929
00:30:43,686 --> 00:30:45,876
you with powerful API's, a


930
00:30:45,876 --> 00:30:47,896
display for EDR rendering model


931
00:30:47,896 --> 00:30:50,356
support on both iOS and macOS,


932
00:30:50,356 --> 00:30:52,986
and a great support for our Pro


933
00:30:52,986 --> 00:30:53,796
Display XDR.


934
00:30:54,796 --> 00:30:56,816
I'm sure you can use these tools


935
00:30:56,816 --> 00:30:59,330
to create amazing HDR contents.


936
00:31:02,546 --> 00:31:03,936
In the next section, we are


937
00:31:03,936 --> 00:31:05,856
going to talk about how you can


938
00:31:05,856 --> 00:31:07,616
leverage the computational


939
00:31:07,616 --> 00:31:09,026
resources available on the


940
00:31:09,066 --> 00:31:10,786
platform to get the best


941
00:31:10,786 --> 00:31:12,756
possible performance and to tell


942
00:31:12,756 --> 00:31:15,386
you all about it, I invite Brian


943
00:31:15,386 --> 00:31:16,146
Ross on stage.


944
00:31:17,516 --> 00:31:20,500
[ Applause ]


945
00:31:25,366 --> 00:31:26,016
>> Thanks, Dileep.


946
00:31:27,316 --> 00:31:28,926
Scaling your performance to


947
00:31:28,926 --> 00:31:30,896
harness both CPU and GPU


948
00:31:30,896 --> 00:31:32,386
parallelism is the most


949
00:31:32,386 --> 00:31:34,286
important and sometimes the


950
00:31:34,286 --> 00:31:35,936
easiest optimization you can do.


951
00:31:36,886 --> 00:31:38,206
In this section, I'm going to


952
00:31:38,206 --> 00:31:40,176
talk about several ways to scale


953
00:31:40,176 --> 00:31:41,276
your performance based on the


954
00:31:41,276 --> 00:31:42,566
architecture of your hardware.


955
00:31:43,366 --> 00:31:44,636
So first, I'll talk about how


956
00:31:44,636 --> 00:31:46,316
Metal can help you to scale


957
00:31:46,316 --> 00:31:48,346
across any number of CPU cores.


958
00:31:49,556 --> 00:31:50,936
Next, I'll talk about how to


959
00:31:50,936 --> 00:31:54,226
leverage, utilize asynchronous


960
00:31:54,286 --> 00:31:55,326
GPU channels.


961
00:31:56,156 --> 00:31:57,476
And finally, I'll close this


962
00:31:57,476 --> 00:31:59,826
section by going over a few ways


963
00:32:00,276 --> 00:32:01,776
to use multiple GPU's.


964
00:32:02,366 --> 00:32:05,276
So today's props are adding more


965
00:32:05,276 --> 00:32:06,146
and more complexity.


966
00:32:07,276 --> 00:32:09,266
They demand more CPU cycles to


967
00:32:09,616 --> 00:32:11,486
decode frames, build render


968
00:32:11,486 --> 00:32:13,736
graphs, and encode metal render


969
00:32:13,736 --> 00:32:14,136
passes.


970
00:32:15,446 --> 00:32:17,406
Doing all this on a single CPU


971
00:32:17,406 --> 00:32:18,706
thread is not sufficient for


972
00:32:18,706 --> 00:32:19,466
today's devices.


973
00:32:20,736 --> 00:32:22,616
The latest iPhone has six cores


974
00:32:23,166 --> 00:32:25,196
and a Mac Pro can have up to 28.


975
00:32:26,556 --> 00:32:28,756
Therefore scalable multithread


976
00:32:28,756 --> 00:32:30,516
architecture is key to great


977
00:32:30,516 --> 00:32:31,566
performance on all of our


978
00:32:31,566 --> 00:32:32,006
devices.


979
00:32:32,896 --> 00:32:34,106
Metal is designed for


980
00:32:34,106 --> 00:32:34,696
multithreading.


981
00:32:35,576 --> 00:32:37,256
In this section, let's look at


982
00:32:37,256 --> 00:32:38,746
two ways how you can parallelize


983
00:32:38,746 --> 00:32:40,306
your encoding on the CPU.


984
00:32:40,536 --> 00:32:42,896
So I'm going to set up an


985
00:32:42,896 --> 00:32:45,166
example of a typical video


986
00:32:45,166 --> 00:32:45,466
frame.


987
00:32:46,216 --> 00:32:48,056
With a classic single threaded


988
00:32:48,056 --> 00:32:49,736
rendering, you could serially


989
00:32:49,736 --> 00:32:51,956
decode frames and build commands


990
00:32:51,956 --> 00:32:53,576
into a single command buffer in


991
00:32:53,576 --> 00:32:55,006
GPU execution order.


992
00:32:55,786 --> 00:32:56,846
And you typically have to fit


993
00:32:56,936 --> 00:32:58,746
this into some tiny fraction of


994
00:32:58,746 --> 00:32:59,426
your frame time.


995
00:33:00,386 --> 00:33:02,276
And of course, you're going to


996
00:33:02,276 --> 00:33:03,536
have maximum latency because you


997
00:33:03,536 --> 00:33:04,856
have to encode the entire


998
00:33:04,856 --> 00:33:06,936
command buffer before the GPU


999
00:33:06,936 --> 00:33:07,636
can consume it.


1000
00:33:08,176 --> 00:33:09,446
Obviously, there's a better way


1001
00:33:09,446 --> 00:33:09,916
to do this.


1002
00:33:10,106 --> 00:33:11,506
So what we're going to do is


1003
00:33:11,506 --> 00:33:13,326
start by building in parallelism


1004
00:33:13,436 --> 00:33:16,656
with the CPU.


1005
00:33:16,846 --> 00:33:18,546
Render blit and compute passes


1006
00:33:18,546 --> 00:33:20,016
are the basic granularity of


1007
00:33:20,016 --> 00:33:21,056
multithreading on Metal.


1008
00:33:21,866 --> 00:33:23,266
All you need to do is create


1009
00:33:23,266 --> 00:33:25,286
multiple command buffers and


1010
00:33:25,286 --> 00:33:27,096
start encoding passes into each


1011
00:33:27,156 --> 00:33:27,976
on a separate thread.


1012
00:33:28,816 --> 00:33:30,126
You can encode in any order you


1013
00:33:30,126 --> 00:33:30,566
wish.


1014
00:33:30,986 --> 00:33:32,956
The final order of execution is


1015
00:33:32,956 --> 00:33:34,356
determined by the order that you


1016
00:33:34,356 --> 00:33:35,486
added to the command queue.


1017
00:33:36,106 --> 00:33:37,906
So now let's look at how you can


1018
00:33:37,906 --> 00:33:39,000
do this in your code.


1019
00:33:42,336 --> 00:33:43,726
Encoding multiple command


1020
00:33:43,726 --> 00:33:44,686
buffers is actually quite


1021
00:33:44,726 --> 00:33:45,096
simple.


1022
00:33:45,556 --> 00:33:47,256
The first thing we do is we


1023
00:33:47,256 --> 00:33:48,956
create any number of Metal


1024
00:33:48,956 --> 00:33:50,366
command buffer objects from the


1025
00:33:50,906 --> 00:33:51,000
queue.


1026
00:33:52,436 --> 00:33:54,686
Next, we define the GPU


1027
00:33:54,686 --> 00:33:56,166
execution order up front by


1028
00:33:56,166 --> 00:33:57,426
using the enqueue interface.


1029
00:33:57,496 --> 00:33:58,416
This is great because you could


1030
00:33:58,416 --> 00:33:59,686
do it early and you don't have


1031
00:33:59,726 --> 00:34:00,956
to wait for encoding to complete


1032
00:34:01,046 --> 00:34:01,666
first.


1033
00:34:02,116 --> 00:34:05,576
And finally, for each command


1034
00:34:05,576 --> 00:34:06,826
buffer we create a separate


1035
00:34:06,826 --> 00:34:08,426
thread using the asynchronous


1036
00:34:08,426 --> 00:34:10,806
dispatch queue and encode passes


1037
00:34:10,806 --> 00:34:12,216
for the frame and that's it.


1038
00:34:12,326 --> 00:34:13,786
It's really fast and it's really


1039
00:34:13,786 --> 00:34:14,235
simple.


1040
00:34:15,716 --> 00:34:17,065
So as you could see in our


1041
00:34:17,065 --> 00:34:18,286
example, we've done a good job


1042
00:34:18,286 --> 00:34:19,866
parallelizing with multiple


1043
00:34:19,866 --> 00:34:21,076
Metal command buffer objects,


1044
00:34:21,076 --> 00:34:23,226
but what if you have one really


1045
00:34:23,226 --> 00:34:25,255
large effects and blending pass?


1046
00:34:26,036 --> 00:34:28,396
In this case, Metal offers a


1047
00:34:28,396 --> 00:34:30,286
dedicated parallel encoder that


1048
00:34:30,286 --> 00:34:32,606
allows you to encode on multiple


1049
00:34:32,606 --> 00:34:34,146
threads without explicitly


1050
00:34:34,146 --> 00:34:36,585
dividing up the render pass or


1051
00:34:36,585 --> 00:34:37,346
the command buffer.


1052
00:34:38,096 --> 00:34:39,216
Let's take a look at how easy


1053
00:34:39,216 --> 00:34:39,996
this is to doing your


1054
00:34:39,996 --> 00:34:41,000
application.


1055
00:34:43,346 --> 00:34:44,646
So here, the first thing we do


1056
00:34:44,646 --> 00:34:46,126
is create a parallel encoder


1057
00:34:46,126 --> 00:34:47,076
from the command buffer.


1058
00:34:48,196 --> 00:34:49,416
Then we create any number of


1059
00:34:49,416 --> 00:34:51,376
subordinate coders and this is


1060
00:34:51,376 --> 00:34:53,065
actually where we define the GPU


1061
00:34:53,065 --> 00:34:54,786
execution order by the order


1062
00:34:54,786 --> 00:34:56,255
that we create the subordinates.


1063
00:34:57,716 --> 00:34:58,846
Next, we create a separate


1064
00:34:58,846 --> 00:35:00,406
thread and call our encoding


1065
00:35:00,406 --> 00:35:01,406
function for each.


1066
00:35:01,636 --> 00:35:02,666
This is where the effects and


1067
00:35:02,666 --> 00:35:03,866
blending will be processed.


1068
00:35:05,326 --> 00:35:06,236
And finally we set up a


1069
00:35:06,236 --> 00:35:07,456
notification when the threads


1070
00:35:07,456 --> 00:35:09,616
are complete and we end


1071
00:35:09,616 --> 00:35:10,716
parallelizing encoding, and


1072
00:35:10,716 --> 00:35:11,296
that's it.


1073
00:35:11,376 --> 00:35:12,406
That's all you have to do.


1074
00:35:12,406 --> 00:35:13,786
It's very simple and very


1075
00:35:13,786 --> 00:35:14,266
efficient.


1076
00:35:14,936 --> 00:35:16,206
So I've shown you two ways on


1077
00:35:16,206 --> 00:35:17,836
how to parallelize on the CPU.


1078
00:35:18,246 --> 00:35:19,776
Now let's see how Metal can help


1079
00:35:19,776 --> 00:35:22,226
you to leverage asynchronous GPU


1080
00:35:22,226 --> 00:35:22,916
channels.


1081
00:35:25,056 --> 00:35:26,916
Modern GPU's today have a common


1082
00:35:26,916 --> 00:35:27,626
capability.


1083
00:35:28,366 --> 00:35:29,836
They each contain a number of


1084
00:35:29,836 --> 00:35:30,906
channels that allow you to


1085
00:35:31,276 --> 00:35:33,416
execute asynchronously so this


1086
00:35:33,416 --> 00:35:35,316
means that you can potentially


1087
00:35:35,316 --> 00:35:36,476
decode video on one channel


1088
00:35:36,476 --> 00:35:39,296
while also executing 3D effects


1089
00:35:39,296 --> 00:35:39,866
on another.


1090
00:35:41,226 --> 00:35:42,706
Metal could extract this type of


1091
00:35:42,706 --> 00:35:44,196
parallelism in two ways.


1092
00:35:44,786 --> 00:35:46,176
The first comes naturally just


1093
00:35:46,176 --> 00:35:47,856
by using the render, blit, and


1094
00:35:47,856 --> 00:35:49,316
compute encoders for the


1095
00:35:49,316 --> 00:35:50,386
appropriate workloads.


1096
00:35:51,216 --> 00:35:52,346
The other way Metal extracts


1097
00:35:52,346 --> 00:35:54,196
parallelism is by analyzing your


1098
00:35:54,196 --> 00:35:55,106
data dependencies.


1099
00:35:55,836 --> 00:35:57,176
But the most compelling detail


1100
00:35:57,176 --> 00:35:58,356
of all here is you get most of


1101
00:35:58,356 --> 00:35:58,946
this for free.


1102
00:35:59,476 --> 00:36:00,796
Metal does a lot of this for you


1103
00:36:00,796 --> 00:36:01,366
under the hood.


1104
00:36:02,736 --> 00:36:03,336
Let's see how.


1105
00:36:04,006 --> 00:36:06,806
So let's look at how the GPU


1106
00:36:06,806 --> 00:36:08,026
executes a series of these


1107
00:36:08,026 --> 00:36:08,596
frames.


1108
00:36:09,066 --> 00:36:10,696
Here I have another video frame


1109
00:36:10,696 --> 00:36:11,186
example.


1110
00:36:11,186 --> 00:36:12,866
In your application we're going


1111
00:36:12,866 --> 00:36:13,926
to be decoding with Video


1112
00:36:13,926 --> 00:36:16,146
Toolbox followed by using the


1113
00:36:16,146 --> 00:36:17,776
blit encoder to upload those


1114
00:36:17,856 --> 00:36:19,666
frames from system to VRAM.


1115
00:36:20,016 --> 00:36:21,886
Then we'll apply filtering with


1116
00:36:21,886 --> 00:36:23,896
compute and effects and blending


1117
00:36:23,896 --> 00:36:24,526
with render.


1118
00:36:26,656 --> 00:36:27,666
This work will happen


1119
00:36:27,666 --> 00:36:28,906
repetitively for each frame.


1120
00:36:29,596 --> 00:36:30,866
So now let's see how this gets


1121
00:36:30,866 --> 00:36:33,326
executed on both the CPU and the


1122
00:36:33,326 --> 00:36:34,926
GPU in a timeline diagram.


1123
00:36:35,276 --> 00:36:36,506
Let's also see if we can apply


1124
00:36:36,506 --> 00:36:38,016
some optimizations to improve


1125
00:36:38,016 --> 00:36:38,766
concurrency.


1126
00:36:39,296 --> 00:36:41,556
The first thing we're going to


1127
00:36:41,556 --> 00:36:43,746
do is encode frame one commands


1128
00:36:43,746 --> 00:36:45,106
using the various encoders on


1129
00:36:45,106 --> 00:36:45,796
separate threads.


1130
00:36:45,796 --> 00:36:48,166
This work is going to get


1131
00:36:48,196 --> 00:36:49,636
scheduled and eventually


1132
00:36:49,636 --> 00:36:50,786
executed across all the


1133
00:36:50,786 --> 00:36:51,446
channels.


1134
00:36:52,266 --> 00:36:53,826
And then we continue on with


1135
00:36:53,826 --> 00:36:56,526
frames two, three, and four.


1136
00:36:57,056 --> 00:37:00,186
Thanks to Metal, you can see


1137
00:37:00,186 --> 00:37:01,196
that we're already achieving


1138
00:37:01,196 --> 00:37:02,616
some parallelism for free.


1139
00:37:03,816 --> 00:37:04,916
But we can also see there's a


1140
00:37:04,916 --> 00:37:05,896
lot of gaps.


1141
00:37:06,586 --> 00:37:07,596
This means that some of the


1142
00:37:07,596 --> 00:37:08,856
threads and channels are sitting


1143
00:37:08,856 --> 00:37:10,256
idle during our valuable frame


1144
00:37:10,256 --> 00:37:10,506
time.


1145
00:37:11,006 --> 00:37:12,996
To maintain efficiency, we want


1146
00:37:12,996 --> 00:37:14,396
to saturate our channels as much


1147
00:37:14,396 --> 00:37:15,006
as possible.


1148
00:37:16,316 --> 00:37:17,616
Metal can't always do all this


1149
00:37:17,616 --> 00:37:17,976
for us.


1150
00:37:17,976 --> 00:37:19,546
So in this case it's time to


1151
00:37:19,546 --> 00:37:20,926
apply some optimizations.


1152
00:37:21,846 --> 00:37:23,116
You'll notice on the CPU there


1153
00:37:23,116 --> 00:37:24,916
is extremely large gaps.


1154
00:37:25,206 --> 00:37:27,516
This can happen for many reasons


1155
00:37:27,516 --> 00:37:29,166
but for simplicity I'll focus on


1156
00:37:29,166 --> 00:37:30,076
a common mistake.


1157
00:37:30,786 --> 00:37:31,856
Sometimes applications


1158
00:37:31,856 --> 00:37:33,436
gratuitously call or wait until


1159
00:37:33,436 --> 00:37:35,426
completed after encoding and


1160
00:37:35,426 --> 00:37:36,486
committing a command buffer.


1161
00:37:37,496 --> 00:37:38,986
In this scenario it's creating


1162
00:37:38,986 --> 00:37:41,106
large gaps or bubbles for the


1163
00:37:41,106 --> 00:37:42,806
duration of our decode workload.


1164
00:37:43,496 --> 00:37:45,076
It's also causing small gaps in


1165
00:37:45,076 --> 00:37:46,486
the decode channel in the GPU.


1166
00:37:47,306 --> 00:37:49,266
To fix that, we can try to


1167
00:37:49,266 --> 00:37:50,286
replace the weight with a


1168
00:37:50,286 --> 00:37:51,236
completion handler.


1169
00:37:52,086 --> 00:37:53,456
This will avoid blocking on the


1170
00:37:53,456 --> 00:37:55,656
CPU and schedule any post


1171
00:37:55,656 --> 00:37:56,966
processing after the GPU is


1172
00:37:56,966 --> 00:37:57,456
completed.


1173
00:37:58,076 --> 00:37:59,306
Let's try that and see where it


1174
00:37:59,306 --> 00:38:00,426
gets us.


1175
00:38:03,116 --> 00:38:04,426
So you can see that's much


1176
00:38:04,426 --> 00:38:04,976
better.


1177
00:38:05,296 --> 00:38:06,436
We're now keeping our CPU


1178
00:38:06,436 --> 00:38:07,006
threads busy.


1179
00:38:07,006 --> 00:38:08,596
You will also notice that the


1180
00:38:08,596 --> 00:38:10,286
decoding channel is saturated


1181
00:38:10,286 --> 00:38:11,006
really nicely.


1182
00:38:11,296 --> 00:38:13,776
We could still see quite a few


1183
00:38:13,896 --> 00:38:16,146
gaps in the blit, compute, and


1184
00:38:16,146 --> 00:38:17,156
render channels.


1185
00:38:18,236 --> 00:38:19,406
Looking closely, you can see


1186
00:38:19,406 --> 00:38:20,596
that there is a rewrite


1187
00:38:20,596 --> 00:38:22,506
dependency where the upload


1188
00:38:22,506 --> 00:38:24,746
can't begin until the decode is


1189
00:38:24,746 --> 00:38:25,186
finished.


1190
00:38:26,266 --> 00:38:28,006
One solution to fix this problem


1191
00:38:28,006 --> 00:38:30,096
is to decode say 10 frames


1192
00:38:30,096 --> 00:38:30,406
ahead.


1193
00:38:30,916 --> 00:38:31,806
This will remove that


1194
00:38:31,806 --> 00:38:32,396
dependency.


1195
00:38:32,586 --> 00:38:33,576
Let's try it and see what


1196
00:38:33,576 --> 00:38:34,000
happens.


1197
00:38:37,356 --> 00:38:38,726
So now our resource updates look


1198
00:38:38,726 --> 00:38:39,046
great.


1199
00:38:39,386 --> 00:38:41,016
We're saturating both the video


1200
00:38:41,016 --> 00:38:43,056
and the blit channels, but


1201
00:38:43,056 --> 00:38:43,836
you'll notice that there is


1202
00:38:43,836 --> 00:38:45,676
still a few gaps in the compute


1203
00:38:45,676 --> 00:38:46,596
and render channels.


1204
00:38:47,566 --> 00:38:49,206
Similar to last time if you look


1205
00:38:49,206 --> 00:38:50,676
closely, you could see that


1206
00:38:50,676 --> 00:38:51,756
there's another dependency but


1207
00:38:51,756 --> 00:38:53,696
the filtering cannot begin until


1208
00:38:53,696 --> 00:38:55,916
the blit channel has uploaded


1209
00:38:56,126 --> 00:38:56,666
all the data.


1210
00:38:58,076 --> 00:38:59,686
Similar to before, we can fix


1211
00:38:59,766 --> 00:39:01,806
this by preloading our bit maps


1212
00:39:01,806 --> 00:39:02,466
ahead of time.


1213
00:39:03,146 --> 00:39:04,156
This will remove that


1214
00:39:04,156 --> 00:39:05,000
dependency.


1215
00:39:08,206 --> 00:39:10,826
And with this, we've now closed


1216
00:39:10,826 --> 00:39:11,846
most of the gaps and we have a


1217
00:39:11,846 --> 00:39:13,176
really efficient pipeline.


1218
00:39:13,656 --> 00:39:14,966
So now that I've reviewed the


1219
00:39:14,966 --> 00:39:16,656
GPU channels and some example


1220
00:39:16,656 --> 00:39:19,456
optimizations, let's see how to


1221
00:39:19,456 --> 00:39:22,286
continue scaling performance on


1222
00:39:22,286 --> 00:39:23,256
more GPU's.


1223
00:39:25,216 --> 00:39:27,016
GPU's are quickly becoming a


1224
00:39:27,066 --> 00:39:28,156
performance multiplier.


1225
00:39:29,106 --> 00:39:30,436
Supporting more GPU's can


1226
00:39:30,436 --> 00:39:32,116
accelerate image processing,


1227
00:39:32,596 --> 00:39:34,536
video editing, and improve your


1228
00:39:34,536 --> 00:39:35,486
overall frame rate.


1229
00:39:36,016 --> 00:39:38,316
In this section, I'm first going


1230
00:39:38,316 --> 00:39:41,236
to go over how Metal can be used


1231
00:39:41,316 --> 00:39:42,606
to leverage multi GPU


1232
00:39:42,606 --> 00:39:43,616
configurations.


1233
00:39:44,576 --> 00:39:45,766
Then I'll show you a few load


1234
00:39:45,766 --> 00:39:47,056
balancing strategies proven


1235
00:39:47,056 --> 00:39:49,006
effective by Pro App developers


1236
00:39:49,006 --> 00:39:49,336
today.


1237
00:39:49,996 --> 00:39:51,286
And finally, I'll discuss how to


1238
00:39:51,286 --> 00:39:52,976
synchronize operations between


1239
00:39:52,976 --> 00:39:53,656
your GPU's.


1240
00:39:55,036 --> 00:39:57,046
So what can Metal do for your


1241
00:39:57,046 --> 00:39:57,866
Pro App?


1242
00:39:58,146 --> 00:39:59,626
To start, Metal gives you all


1243
00:39:59,626 --> 00:40:01,516
the tools you need to detect all


1244
00:40:01,516 --> 00:40:02,796
the connected GPU's and their


1245
00:40:02,796 --> 00:40:03,776
capabilities.


1246
00:40:04,666 --> 00:40:06,076
With Metal it's easy to manage


1247
00:40:06,076 --> 00:40:07,286
multiple GPU's because they're


1248
00:40:07,286 --> 00:40:08,796
essentially just separate Metal


1249
00:40:08,796 --> 00:40:09,776
device objects.


1250
00:40:10,166 --> 00:40:11,866
So program them as the same as


1251
00:40:11,866 --> 00:40:13,226
you do today for a single GPU.


1252
00:40:14,306 --> 00:40:15,906
Metal also supports a brand-new


1253
00:40:16,246 --> 00:40:17,516
peer group transferring PI.


1254
00:40:18,286 --> 00:40:19,746
This incorporates the concept of


1255
00:40:19,866 --> 00:40:21,796
remote texture views which allow


1256
00:40:21,796 --> 00:40:23,926
you to copy data between GPU's.


1257
00:40:24,866 --> 00:40:26,086
And finally, Metal offers


1258
00:40:26,136 --> 00:40:27,816
powerful shared events that


1259
00:40:27,816 --> 00:40:29,026
allow you to synchronize your


1260
00:40:29,026 --> 00:40:30,426
workloads between GPU's.


1261
00:40:30,666 --> 00:40:32,106
Now let's take a quick look at


1262
00:40:32,106 --> 00:40:33,836
how to detect multi GPU


1263
00:40:33,836 --> 00:40:34,786
configurations.


1264
00:40:36,676 --> 00:40:38,406
Metal exposes device properties


1265
00:40:38,406 --> 00:40:39,706
to identify the location,


1266
00:40:40,096 --> 00:40:41,866
location number, and max


1267
00:40:41,866 --> 00:40:43,336
transfer rate for each device.


1268
00:40:44,116 --> 00:40:45,306
This information could be used


1269
00:40:45,736 --> 00:40:47,466
to say determine the fastest


1270
00:40:47,466 --> 00:40:49,496
possible hosted device transfer


1271
00:40:49,496 --> 00:40:49,966
device.


1272
00:40:50,696 --> 00:40:52,246
It can also be used to determine


1273
00:40:52,286 --> 00:40:53,706
if a device is integrated,


1274
00:40:54,056 --> 00:40:56,296
discreet, or external or even


1275
00:40:56,296 --> 00:40:57,326
low power or headless.


1276
00:40:58,316 --> 00:40:59,716
So once we're able to detect


1277
00:40:59,716 --> 00:41:01,756
multiple GPU's with this, it's


1278
00:41:01,756 --> 00:41:03,796
time to think about how to


1279
00:41:03,796 --> 00:41:05,066
balance your workloads.


1280
00:41:06,636 --> 00:41:08,426
There is many, many ways to load


1281
00:41:08,426 --> 00:41:10,416
balance between GPU's, and


1282
00:41:10,416 --> 00:41:11,226
there's a lot of design


1283
00:41:11,226 --> 00:41:12,136
decisions that you have to


1284
00:41:12,136 --> 00:41:13,076
consider when you select


1285
00:41:13,076 --> 00:41:13,756
strategy.


1286
00:41:14,526 --> 00:41:15,626
At the end of the day what we


1287
00:41:15,726 --> 00:41:17,806
seek is a really simple load


1288
00:41:17,806 --> 00:41:19,626
balancing strategy with higher


1289
00:41:19,676 --> 00:41:20,596
scale and efficiency.


1290
00:41:21,306 --> 00:41:22,726
Let's go over a few proven


1291
00:41:22,726 --> 00:41:24,036
strategies that some Pro App


1292
00:41:24,036 --> 00:41:25,956
developers are using today.


1293
00:41:26,736 --> 00:41:27,856
The first and most


1294
00:41:27,856 --> 00:41:29,916
straightforward is supporting


1295
00:41:29,916 --> 00:41:31,036
alternating frames.


1296
00:41:31,226 --> 00:41:32,916
So the concept is to ping pong


1297
00:41:32,916 --> 00:41:34,526
odd and even frames between the


1298
00:41:34,526 --> 00:41:35,346
two GPU's.


1299
00:41:35,976 --> 00:41:37,496
This easily fits into existing


1300
00:41:37,496 --> 00:41:39,236
architectures and can


1301
00:41:39,236 --> 00:41:40,506
potentially double the rate that


1302
00:41:40,506 --> 00:41:41,666
you process frames.


1303
00:41:42,316 --> 00:41:43,886
However, sometimes apps have


1304
00:41:44,566 --> 00:41:46,376
variable workloads like UI


1305
00:41:46,376 --> 00:41:48,106
updates or graph building, and


1306
00:41:48,106 --> 00:41:50,516
this might result in unbalanced


1307
00:41:50,866 --> 00:41:51,586
load balancing.


1308
00:41:52,136 --> 00:41:53,636
So let's take a look at another


1309
00:41:53,636 --> 00:41:54,156
strategy.


1310
00:41:54,766 --> 00:41:58,286
This one uses small 32 by


1311
00:41:58,336 --> 00:42:00,746
32-pixel tiles to distribute


1312
00:42:00,826 --> 00:42:01,826
[inaudible] evenly among the


1313
00:42:01,826 --> 00:42:02,546
GPU's.


1314
00:42:03,266 --> 00:42:05,196
So if you have four GPU's, you


1315
00:42:05,196 --> 00:42:06,596
can preselect separate tile


1316
00:42:06,596 --> 00:42:07,436
groups for each.


1317
00:42:08,076 --> 00:42:09,626
Here we use a random assignment


1318
00:42:09,626 --> 00:42:10,946
to avoid too much correlation


1319
00:42:10,946 --> 00:42:11,516
with the scene.


1320
00:42:11,976 --> 00:42:13,986
This means that mapping of tiles


1321
00:42:13,986 --> 00:42:15,546
to GPU's is constant from frame


1322
00:42:15,546 --> 00:42:15,916
to frame.


1323
00:42:16,406 --> 00:42:18,376
This is a really good solution


1324
00:42:18,486 --> 00:42:20,386
for compute heavy workloads but


1325
00:42:20,386 --> 00:42:21,806
might not be the best choice for


1326
00:42:21,806 --> 00:42:22,926
bandwidth intensive ones.


1327
00:42:23,676 --> 00:42:24,916
To see this in more detail,


1328
00:42:24,916 --> 00:42:26,016
check out the rate tracing


1329
00:42:26,016 --> 00:42:26,446
section.


1330
00:42:26,586 --> 00:42:29,886
So here's a similar approach


1331
00:42:29,936 --> 00:42:31,146
that uses a tile queue.


1332
00:42:31,836 --> 00:42:32,796
In this case, the host


1333
00:42:32,796 --> 00:42:34,136
application can populate the


1334
00:42:34,136 --> 00:42:35,676
queue with all the tiles.


1335
00:42:36,426 --> 00:42:37,866
They can then be dequeued on


1336
00:42:37,866 --> 00:42:40,026
demand by each GPU based on an


1337
00:42:40,026 --> 00:42:41,606
algorithm that keeps the GPU's


1338
00:42:41,606 --> 00:42:41,996
busy.


1339
00:42:42,866 --> 00:42:44,446
This approach may provide really


1340
00:42:44,446 --> 00:42:45,996
good load balancing but it is


1341
00:42:45,996 --> 00:42:46,996
adding more complexity.


1342
00:42:48,306 --> 00:42:50,166
So once we've decided on our


1343
00:42:50,166 --> 00:42:51,916
load balancing scheme, we need


1344
00:42:51,916 --> 00:42:52,926
to think about how to


1345
00:42:53,016 --> 00:42:54,146
synchronize our workloads


1346
00:42:54,146 --> 00:42:55,526
between the GPU's.


1347
00:42:56,106 --> 00:42:58,626
To accomplish this, Metal


1348
00:42:58,626 --> 00:43:00,116
provides a powerful construct


1349
00:43:00,116 --> 00:43:01,176
called shared events.


1350
00:43:01,846 --> 00:43:03,506
They allow you to specify


1351
00:43:03,736 --> 00:43:04,966
synchronization points in your


1352
00:43:04,966 --> 00:43:07,306
app where you can wait and


1353
00:43:07,366 --> 00:43:08,856
signal for specific command


1354
00:43:08,856 --> 00:43:09,286
completion.


1355
00:43:10,436 --> 00:43:12,116
This can be done across GPU's,


1356
00:43:12,556 --> 00:43:14,606
between a CPU and the GPU, and


1357
00:43:14,606 --> 00:43:15,526
across processes.


1358
00:43:16,136 --> 00:43:17,536
Let's put this into practice.


1359
00:43:18,566 --> 00:43:21,016
So here's an example of a single


1360
00:43:21,016 --> 00:43:22,416
GPU workload that performs a


1361
00:43:22,416 --> 00:43:23,926
motion analysis on pairs of


1362
00:43:23,926 --> 00:43:24,526
frames.


1363
00:43:25,136 --> 00:43:26,496
Notice that these are all render


1364
00:43:26,496 --> 00:43:27,746
workloads so we can't take


1365
00:43:27,746 --> 00:43:29,006
advantage of the parallel


1366
00:43:29,386 --> 00:43:30,566
asynchronous channels that we


1367
00:43:30,566 --> 00:43:33,556
talked about earlier, but if we


1368
00:43:33,556 --> 00:43:35,916
have two GPU's, we can divide


1369
00:43:35,916 --> 00:43:36,966
this work between them to


1370
00:43:36,966 --> 00:43:38,076
improve performance.


1371
00:43:38,436 --> 00:43:40,326
So the strategy here is to move


1372
00:43:40,326 --> 00:43:41,486
the motion analysis to the


1373
00:43:41,486 --> 00:43:42,336
second GPU.


1374
00:43:42,906 --> 00:43:45,166
Keep in mind that each motion


1375
00:43:45,166 --> 00:43:47,726
pass has to analyze the previous


1376
00:43:47,776 --> 00:43:48,676
pair of frames.


1377
00:43:49,316 --> 00:43:50,866
This means that we have to wait


1378
00:43:50,866 --> 00:43:51,956
for the previous frames to be


1379
00:43:51,956 --> 00:43:54,086
written before we read them from


1380
00:43:54,086 --> 00:43:56,076
the motion pass and this repeats


1381
00:43:56,146 --> 00:43:57,096
for each frame pair.


1382
00:43:57,746 --> 00:44:00,676
So we can accomplish this by


1383
00:44:00,676 --> 00:44:02,156
using Metal shared events.


1384
00:44:02,666 --> 00:44:03,886
First, we need to signal


1385
00:44:03,886 --> 00:44:05,246
completion when the frames are


1386
00:44:05,246 --> 00:44:07,276
done rendering, and then we wait


1387
00:44:07,276 --> 00:44:08,956
for that signal before reading


1388
00:44:08,956 --> 00:44:10,826
them with motion pass.


1389
00:44:11,566 --> 00:44:13,346
And with this, we can safely


1390
00:44:13,346 --> 00:44:14,886
offload the motion analysis to a


1391
00:44:14,886 --> 00:44:16,836
second GPU and everything runs


1392
00:44:16,836 --> 00:44:17,336
in parallel.


1393
00:44:18,056 --> 00:44:19,676
And because the signal


1394
00:44:19,766 --> 00:44:21,026
[inaudible] encoded on the GPU,


1395
00:44:21,346 --> 00:44:22,776
you don't block any CPU


1396
00:44:22,776 --> 00:44:23,326
execution.


1397
00:44:24,426 --> 00:44:25,896
So now let's take a look at how


1398
00:44:25,896 --> 00:44:26,876
we can do this in our code.


1399
00:44:27,526 --> 00:44:29,806
So the first thing we're going


1400
00:44:29,806 --> 00:44:31,266
to do is create a shared event


1401
00:44:31,736 --> 00:44:33,076
from the device that renders our


1402
00:44:33,076 --> 00:44:33,786
frames.


1403
00:44:34,576 --> 00:44:36,416
We also create two command


1404
00:44:36,446 --> 00:44:37,916
queues, one for each device.


1405
00:44:39,116 --> 00:44:40,796
Now to render the frames, we


1406
00:44:40,796 --> 00:44:42,006
create a command buffer and


1407
00:44:42,236 --> 00:44:44,676
encode, then immediately encode


1408
00:44:44,676 --> 00:44:46,286
a signal event to notify the


1409
00:44:46,286 --> 00:44:47,566
other GPU's that we're complete.


1410
00:44:48,606 --> 00:44:50,356
And finally, to encode the


1411
00:44:50,356 --> 00:44:54,426
motion, we start by creating a


1412
00:44:54,426 --> 00:44:55,576
command buffer from the queue.


1413
00:44:56,096 --> 00:44:57,496
Then immediately encode a wait


1414
00:44:57,496 --> 00:44:59,296
event to avoid reading the


1415
00:44:59,296 --> 00:45:00,416
frames before they're done.


1416
00:45:01,466 --> 00:45:02,666
And then we encode the motion


1417
00:45:02,666 --> 00:45:04,786
analysis and commit, and as you


1418
00:45:04,786 --> 00:45:05,876
can see it's a fairly


1419
00:45:05,986 --> 00:45:07,306
straightforward process and it's


1420
00:45:07,306 --> 00:45:08,186
very powerful.


1421
00:45:08,576 --> 00:45:10,576
And before I move on, let's take


1422
00:45:10,576 --> 00:45:12,196
a look at how we can look at


1423
00:45:12,516 --> 00:45:14,316
multi GPU's and channels in our


1424
00:45:14,316 --> 00:45:14,916
tools.


1425
00:45:15,486 --> 00:45:18,726
So Metal System Trace shows the


1426
00:45:18,726 --> 00:45:20,616
work for each of your test


1427
00:45:20,616 --> 00:45:21,146
GPU's.


1428
00:45:21,616 --> 00:45:22,896
In this example we're using four


1429
00:45:22,966 --> 00:45:23,446
GPU's.


1430
00:45:23,446 --> 00:45:25,896
One internal, and three external


1431
00:45:25,896 --> 00:45:26,536
GPU's.


1432
00:45:26,876 --> 00:45:30,156
It exposes detailed visibility


1433
00:45:30,436 --> 00:45:32,166
into each GPU by showing all the


1434
00:45:32,166 --> 00:45:34,116
asynchronous workloads across


1435
00:45:34,116 --> 00:45:35,936
all the channels, and it maps


1436
00:45:35,996 --> 00:45:38,266
those workloads with relevant


1437
00:45:38,316 --> 00:45:39,116
symbol names.


1438
00:45:39,706 --> 00:45:42,416
In the activity summary, you


1439
00:45:42,416 --> 00:45:43,616
could actually see all the


1440
00:45:43,616 --> 00:45:45,246
execution statistics for all the


1441
00:45:45,246 --> 00:45:46,286
connected GPU's.


1442
00:45:47,566 --> 00:45:48,956
You could even dive deeper to


1443
00:45:49,016 --> 00:45:50,246
see more detailed channel


1444
00:45:50,246 --> 00:45:52,776
information for any GPU on a per


1445
00:45:52,776 --> 00:45:53,536
frame basis.


1446
00:45:54,296 --> 00:45:55,676
This includes details for page


1447
00:45:55,676 --> 00:45:56,926
on and page off in the blit


1448
00:45:56,926 --> 00:45:58,996
channel or compute and render


1449
00:45:58,996 --> 00:45:59,716
workloads.


1450
00:46:00,686 --> 00:46:02,266
You can even drill down to see


1451
00:46:02,266 --> 00:46:03,666
IOSurface access.


1452
00:46:04,336 --> 00:46:05,476
As Eugene mentioned, this is


1453
00:46:05,476 --> 00:46:06,536
something that's very useful


1454
00:46:06,536 --> 00:46:07,896
because a lot of Pro Apps need


1455
00:46:07,896 --> 00:46:10,976
to utilize IOSurfaces, which is


1456
00:46:11,406 --> 00:46:12,946
really necessary for framework


1457
00:46:13,006 --> 00:46:13,886
interoperability.


1458
00:46:14,446 --> 00:46:17,546
And finally, our tools give you


1459
00:46:17,546 --> 00:46:19,146
visibility into Metal events and


1460
00:46:19,146 --> 00:46:19,896
shared events.


1461
00:46:19,896 --> 00:46:22,096
So you can actually see where


1462
00:46:22,096 --> 00:46:23,206
the signal and wait events


1463
00:46:23,206 --> 00:46:23,646
occur.


1464
00:46:24,466 --> 00:46:25,406
It also shows how many


1465
00:46:25,406 --> 00:46:26,896
milliseconds are spent waiting


1466
00:46:27,386 --> 00:46:28,756
and draws dependency lines for


1467
00:46:28,756 --> 00:46:29,366
you to follow.


1468
00:46:30,596 --> 00:46:31,606
And finally at the bottom,


1469
00:46:31,746 --> 00:46:32,736
there's even detailed lists


1470
00:46:32,736 --> 00:46:33,996
about your events in the


1471
00:46:33,996 --> 00:46:34,786
activity summary.


1472
00:46:35,446 --> 00:46:37,096
So Metal system trace is a great


1473
00:46:37,146 --> 00:46:38,796
tool for all your Pro App needs.


1474
00:46:39,626 --> 00:46:40,626
So now that we understand how to


1475
00:46:40,626 --> 00:46:42,846
utilize multiple GPU's, let's


1476
00:46:42,846 --> 00:46:44,306
look at how to transfer data


1477
00:46:44,306 --> 00:46:45,476
between them.


1478
00:46:46,976 --> 00:46:48,646
Scaling performance across CPU's


1479
00:46:48,646 --> 00:46:49,936
and GPU's is extremely


1480
00:46:49,936 --> 00:46:51,676
important, but at the end of the


1481
00:46:51,676 --> 00:46:53,666
day your Pro App is only as fast


1482
00:46:53,666 --> 00:46:55,016
as its slowest bottleneck.


1483
00:46:55,856 --> 00:46:57,236
When you're transferring massive


1484
00:46:57,236 --> 00:46:59,776
8K frames, your data transfers


1485
00:46:59,776 --> 00:47:00,786
can quickly become that


1486
00:47:00,786 --> 00:47:01,286
bottleneck.


1487
00:47:01,896 --> 00:47:04,396
In this section, I'm going to


1488
00:47:04,396 --> 00:47:05,276
talk about bandwidth


1489
00:47:05,276 --> 00:47:07,186
considerations and how they


1490
00:47:07,186 --> 00:47:08,436
relate to the new Mac Pro.


1491
00:47:09,476 --> 00:47:11,806
Then I'll review a few Metal


1492
00:47:11,806 --> 00:47:13,746
peer groups transfer strategies,


1493
00:47:14,126 --> 00:47:15,156
and some of these are already in


1494
00:47:15,156 --> 00:47:16,796
use today by Pro App developers.


1495
00:47:17,276 --> 00:47:18,316
And finally I'll walk you


1496
00:47:18,356 --> 00:47:20,186
through an example use case to


1497
00:47:20,186 --> 00:47:21,676
show how Infinity Fabric Link


1498
00:47:21,676 --> 00:47:22,926
can help unlock challenging


1499
00:47:22,926 --> 00:47:23,656
workflows.


1500
00:47:24,286 --> 00:47:27,496
So let's start by looking at the


1501
00:47:27,496 --> 00:47:28,686
transfer rates for our key


1502
00:47:28,726 --> 00:47:29,636
connection points.


1503
00:47:29,986 --> 00:47:31,866
Our baseline here is PCI Express


1504
00:47:31,906 --> 00:47:33,696
gen 3 with 16 links.


1505
00:47:34,846 --> 00:47:36,206
So first we have Thunderbolt 3.


1506
00:47:36,206 --> 00:47:38,586
In the real world this maxes out


1507
00:47:38,586 --> 00:47:39,956
around one-quarter of the rate


1508
00:47:39,956 --> 00:47:41,076
of PCI Express.


1509
00:47:41,486 --> 00:47:42,846
It's a really great scalable


1510
00:47:42,846 --> 00:47:44,456
solution for compute heavy


1511
00:47:44,456 --> 00:47:45,996
workloads but maybe not the best


1512
00:47:46,076 --> 00:47:47,386
for bandwidth intensive ones.


1513
00:47:48,146 --> 00:47:51,096
Next we have two GPU's each with


1514
00:47:51,096 --> 00:47:52,256
their one PCI lanes.


1515
00:47:52,576 --> 00:47:53,936
This can double your bandwidth.


1516
00:47:55,026 --> 00:47:57,096
And this week we introduced the


1517
00:47:57,096 --> 00:47:58,706
new Infinity Fabric Link with


1518
00:47:58,826 --> 00:48:00,006
the peer group transfer API


1519
00:48:00,596 --> 00:48:02,036
which can transfer data between


1520
00:48:02,036 --> 00:48:04,046
GPU's at speeds up to five times


1521
00:48:04,046 --> 00:48:07,166
that of PCI Express.


1522
00:48:07,606 --> 00:48:09,526
So now let's look at some common


1523
00:48:09,616 --> 00:48:10,786
Mac Pro configurations.


1524
00:48:11,596 --> 00:48:13,156
This diagram illustrates a great


1525
00:48:13,156 --> 00:48:14,426
configuration for bandwidth


1526
00:48:14,426 --> 00:48:15,196
intensive ones.


1527
00:48:16,146 --> 00:48:17,556
Here we have a new Apple


1528
00:48:17,556 --> 00:48:19,056
Afterburner which has its own


1529
00:48:19,056 --> 00:48:20,346
dedicated PCI lanes.


1530
00:48:21,226 --> 00:48:22,876
We also have two internal GPU's


1531
00:48:22,876 --> 00:48:24,386
with their own dedicated PCI


1532
00:48:24,386 --> 00:48:24,616
lanes.


1533
00:48:25,496 --> 00:48:26,716
And finally, you can connect


1534
00:48:26,816 --> 00:48:28,456
those GPU's with Infinity Fabric


1535
00:48:28,526 --> 00:48:30,346
Link to quickly copy data


1536
00:48:30,346 --> 00:48:31,566
between them.


1537
00:48:32,976 --> 00:48:34,476
The Mac Pro also allows you to


1538
00:48:34,476 --> 00:48:36,356
have up to four internal GPU's


1539
00:48:36,356 --> 00:48:38,096
that share two sets of PCI


1540
00:48:38,096 --> 00:48:38,336
lanes.


1541
00:48:39,226 --> 00:48:40,456
Because the lanes are shared, it


1542
00:48:40,456 --> 00:48:41,726
lends itself maybe to a more


1543
00:48:41,726 --> 00:48:43,156
compute heavy pro application.


1544
00:48:43,766 --> 00:48:45,516
And in this case, it can also be


1545
00:48:45,516 --> 00:48:46,556
connected with the Infinity


1546
00:48:46,596 --> 00:48:47,126
Fabric Link.


1547
00:48:47,706 --> 00:48:51,506
So there is many, many ways to


1548
00:48:51,506 --> 00:48:52,646
manage these transfer


1549
00:48:52,646 --> 00:48:53,466
strategies.


1550
00:48:53,886 --> 00:48:55,026
I'm going to go over a few


1551
00:48:55,026 --> 00:48:56,676
proven strategies that some Pro


1552
00:48:56,676 --> 00:48:57,926
App developers are using today.


1553
00:48:59,186 --> 00:49:00,866
The most straightforward


1554
00:49:00,866 --> 00:49:02,446
approach is to transfer entire


1555
00:49:02,506 --> 00:49:03,496
frames for display.


1556
00:49:04,196 --> 00:49:05,396
The premise is to process


1557
00:49:05,396 --> 00:49:06,646
alternating frames.


1558
00:49:06,986 --> 00:49:08,206
Any frame processed on the


1559
00:49:08,206 --> 00:49:09,846
auxiliary device can be


1560
00:49:09,846 --> 00:49:10,876
transferred quickly to the


1561
00:49:10,876 --> 00:49:12,926
display attached GPU and then


1562
00:49:13,236 --> 00:49:16,516
sent to the display.


1563
00:49:16,516 --> 00:49:17,926
Another transfer strategy is to


1564
00:49:17,926 --> 00:49:20,566
send tiles to each GPU that are


1565
00:49:20,566 --> 00:49:22,156
essentially pieces of the entire


1566
00:49:22,156 --> 00:49:22,546
frame.


1567
00:49:23,376 --> 00:49:24,736
All the tiles processed on the


1568
00:49:24,736 --> 00:49:26,146
auxiliary device can be sent to


1569
00:49:26,146 --> 00:49:27,956
the display GPU and then


1570
00:49:27,956 --> 00:49:29,276
reconstructed as part of the


1571
00:49:29,276 --> 00:49:30,526
final output image.


1572
00:49:31,566 --> 00:49:32,826
This result has really good load


1573
00:49:32,826 --> 00:49:33,246
balancing.


1574
00:49:34,186 --> 00:49:35,826
So we've looked at two


1575
00:49:35,826 --> 00:49:36,956
strategies quickly.


1576
00:49:37,336 --> 00:49:39,066
Now let's see a great example of


1577
00:49:39,066 --> 00:49:40,806
a Pro App actually leveraging


1578
00:49:40,806 --> 00:49:42,646
the Infinity Fabric Link.


1579
00:49:43,556 --> 00:49:45,316
So over the last six months,


1580
00:49:45,316 --> 00:49:46,976
I've had the opportunity to


1581
00:49:46,976 --> 00:49:48,326
collaborate with the Final Cut


1582
00:49:48,326 --> 00:49:48,716
Pro team.


1583
00:49:49,426 --> 00:49:51,056
They've done an outstanding job


1584
00:49:51,056 --> 00:49:52,746
optimizing for the new Mac Pro.


1585
00:49:53,536 --> 00:49:55,496
They're scaling across 28 CPU


1586
00:49:55,496 --> 00:49:58,066
cores and all internal GPU's.


1587
00:49:58,916 --> 00:50:00,376
They've also fully utilized the


1588
00:50:00,376 --> 00:50:01,436
Infinity Fabric Link.


1589
00:50:02,026 --> 00:50:03,416
This is helping them to enable


1590
00:50:03,526 --> 00:50:06,286
real time editing of multiple 8K


1591
00:50:06,286 --> 00:50:06,976
ProRes video streams.


1592
00:50:08,406 --> 00:50:09,836
Now let's take a closer look at


1593
00:50:09,836 --> 00:50:10,886
how this works.


1594
00:50:12,306 --> 00:50:13,516
So here we have a simple


1595
00:50:13,516 --> 00:50:14,956
timeline diagram that shows how


1596
00:50:14,956 --> 00:50:16,886
video streams move from the CPU


1597
00:50:16,996 --> 00:50:17,716
to the display.


1598
00:50:17,716 --> 00:50:19,816
In this case we're focusing on


1599
00:50:19,876 --> 00:50:22,136
playback of three 8k ProRes raw


1600
00:50:22,136 --> 00:50:23,796
video streams with some effects.


1601
00:50:24,816 --> 00:50:25,706
This is how it might look on a


1602
00:50:25,766 --> 00:50:26,536
single GPU.


1603
00:50:28,116 --> 00:50:29,536
So first, we encode frame one


1604
00:50:29,536 --> 00:50:30,636
commands on the CPU.


1605
00:50:31,706 --> 00:50:33,536
Then upload all three streams


1606
00:50:33,536 --> 00:50:34,946
over PCI to VRAM.


1607
00:50:36,166 --> 00:50:38,206
Finally we process those streams


1608
00:50:38,206 --> 00:50:39,976
with effects on the GPU and


1609
00:50:39,976 --> 00:50:40,486
display.


1610
00:50:41,016 --> 00:50:43,276
We continue this process for


1611
00:50:43,276 --> 00:50:44,736
each of the additional frames.


1612
00:50:45,876 --> 00:50:47,186
And as much as we want this to


1613
00:50:47,186 --> 00:50:48,696
fit within our 30 frames per


1614
00:50:48,696 --> 00:50:50,466
second, it won't.


1615
00:50:50,846 --> 00:50:52,316
It's just too much work to pack


1616
00:50:52,316 --> 00:50:53,286
into that space.


1617
00:50:53,626 --> 00:50:55,926
A Pro App will drop at least 30%


1618
00:50:55,926 --> 00:50:56,696
of their frames in this


1619
00:50:56,696 --> 00:50:57,296
scenario.


1620
00:50:57,936 --> 00:50:58,916
Now let's see how this might


1621
00:50:58,916 --> 00:51:00,826
work on a dual GPU system.


1622
00:51:02,046 --> 00:51:04,456
So first, we encode frame one as


1623
00:51:04,456 --> 00:51:05,466
in the previous example.


1624
00:51:06,546 --> 00:51:07,816
For frame two, we follow a


1625
00:51:07,816 --> 00:51:08,846
similar process.


1626
00:51:09,386 --> 00:51:10,606
Now this is looking really good.


1627
00:51:10,606 --> 00:51:12,286
We've got things going in


1628
00:51:12,286 --> 00:51:12,976
parallel here.


1629
00:51:13,306 --> 00:51:14,696
But do we double our frame rate?


1630
00:51:15,406 --> 00:51:16,796
Unfortunately, we don't.


1631
00:51:17,456 --> 00:51:20,356
The problem comes when any frame


1632
00:51:20,356 --> 00:51:21,516
that we've processed on the


1633
00:51:21,516 --> 00:51:23,136
auxiliary device has to somehow


1634
00:51:23,136 --> 00:51:24,996
be copied back to the display


1635
00:51:24,996 --> 00:51:26,206
attach device, and this is where


1636
00:51:26,266 --> 00:51:27,096
things get tricky.


1637
00:51:27,766 --> 00:51:30,256
To get the display GPU, we have


1638
00:51:30,256 --> 00:51:33,106
to copy a 265-megabyte output


1639
00:51:33,106 --> 00:51:35,936
buffer over PCI to the host, and


1640
00:51:35,936 --> 00:51:37,566
then we copy a second time from


1641
00:51:37,566 --> 00:51:38,866
there to the display attached


1642
00:51:38,866 --> 00:51:39,246
GPU.


1643
00:51:40,606 --> 00:51:42,026
This can take up to 48


1644
00:51:42,026 --> 00:51:43,206
milliseconds on a good day.


1645
00:51:43,626 --> 00:51:45,136
So now, let's continue with


1646
00:51:45,136 --> 00:51:46,516
frames three and four to give


1647
00:51:46,516 --> 00:51:48,000
you a better picture.


1648
00:51:50,436 --> 00:51:51,746
And you can quickly see that


1649
00:51:51,746 --> 00:51:52,866
we're using a considerable


1650
00:51:52,866 --> 00:51:54,936
amount of PCI bandwidth but also


1651
00:51:54,936 --> 00:51:56,106
we see a lot of gaps and


1652
00:51:56,106 --> 00:51:56,856
dependencies.


1653
00:51:57,296 --> 00:51:58,406
We're still doing better than


1654
00:51:58,406 --> 00:52:00,076
the single GPU case, but it's


1655
00:52:00,076 --> 00:52:01,326
not going to double our frame


1656
00:52:01,326 --> 00:52:01,496
rate.


1657
00:52:02,386 --> 00:52:04,306
All this PCI traffic will result


1658
00:52:04,306 --> 00:52:05,586
in dropping some frames.


1659
00:52:06,146 --> 00:52:09,076
But to improve on this problem,


1660
00:52:09,376 --> 00:52:11,186
the Mac Pro introduces the new


1661
00:52:11,186 --> 00:52:12,456
Infinity Fabric Link feature


1662
00:52:12,456 --> 00:52:13,586
with the peer group API.


1663
00:52:14,056 --> 00:52:16,006
This completely blows away the


1664
00:52:16,006 --> 00:52:16,776
GPU copy.


1665
00:52:18,436 --> 00:52:20,046
You could see here with Infinity


1666
00:52:20,046 --> 00:52:21,656
Fabric Link the transfer is much


1667
00:52:21,656 --> 00:52:22,316
faster.


1668
00:52:23,046 --> 00:52:24,666
It also frees up a considerable


1669
00:52:24,666 --> 00:52:27,576
amount of PCI bandwidth and with


1670
00:52:27,576 --> 00:52:29,186
that bandwidth we can upload our


1671
00:52:29,246 --> 00:52:30,226
frames earlier.


1672
00:52:32,256 --> 00:52:33,786
Infinity Fabric Link also


1673
00:52:33,786 --> 00:52:35,556
operates on its own parallel GPU


1674
00:52:35,556 --> 00:52:35,956
channel.


1675
00:52:36,526 --> 00:52:37,576
This means you could transfer


1676
00:52:37,576 --> 00:52:39,216
data while using the render and


1677
00:52:39,216 --> 00:52:40,306
compute channels at the same


1678
00:52:40,306 --> 00:52:40,596
time.


1679
00:52:41,916 --> 00:52:42,846
This helps us to improve


1680
00:52:42,846 --> 00:52:44,486
concurrency and hide latency.


1681
00:52:44,856 --> 00:52:46,316
At the end of the day, this can


1682
00:52:46,316 --> 00:52:48,006
enable your Pro App to unlock


1683
00:52:48,316 --> 00:52:49,776
challenging workloads and enable


1684
00:52:49,776 --> 00:52:50,646
new use cases.


1685
00:52:51,346 --> 00:52:52,406
So this is what it looks like on


1686
00:52:52,406 --> 00:52:53,786
a boring timeline diagram.


1687
00:52:54,376 --> 00:52:55,566
But now let's see what it looks


1688
00:52:55,566 --> 00:52:56,076
in action.


1689
00:52:56,666 --> 00:52:59,336
This is the Final Cut Pro demo


1690
00:52:59,336 --> 00:53:00,296
you saw in the keynote.


1691
00:53:00,886 --> 00:53:01,856
You can see it plays back


1692
00:53:01,856 --> 00:53:03,776
multiple streams of 8K video


1693
00:53:03,776 --> 00:53:05,336
with effects and transitions.


1694
00:53:05,336 --> 00:53:08,316
This is also done in real time


1695
00:53:08,316 --> 00:53:09,806
using multiple GPU's and the


1696
00:53:09,806 --> 00:53:10,776
Infinity Fabric Link.


1697
00:53:11,776 --> 00:53:13,556
Final Cut Pro is an outstanding


1698
00:53:13,556 --> 00:53:15,356
example of a Pro App utilizing


1699
00:53:15,586 --> 00:53:17,066
efficient data transfers.


1700
00:53:17,376 --> 00:53:19,136
So now before we close this


1701
00:53:19,136 --> 00:53:21,156
section, let's look at how to


1702
00:53:21,156 --> 00:53:22,846
use Infinity Fabric Link and the


1703
00:53:22,966 --> 00:53:25,336
peer grant transfer group API in


1704
00:53:25,336 --> 00:53:25,796
your code.


1705
00:53:26,466 --> 00:53:29,456
So the first thing you need to


1706
00:53:29,976 --> 00:53:31,756
do is detect these connections.


1707
00:53:32,176 --> 00:53:33,666
To facilitate this, Metal


1708
00:53:33,666 --> 00:53:35,376
defines a brand-new peer group


1709
00:53:35,376 --> 00:53:37,626
API, defines properties on the


1710
00:53:37,626 --> 00:53:39,516
Metal device for peer group ID,


1711
00:53:39,596 --> 00:53:40,546
index, and count.


1712
00:53:41,866 --> 00:53:43,146
With this you can detect if you


1713
00:53:43,146 --> 00:53:44,836
have linked GPU's and if they


1714
00:53:44,836 --> 00:53:46,726
have shared PCI lanes or dual


1715
00:53:46,726 --> 00:53:47,546
PCI lanes.


1716
00:53:47,916 --> 00:53:49,206
More importantly, you can use


1717
00:53:49,206 --> 00:53:52,046
this to determine the best


1718
00:53:52,046 --> 00:53:53,756
configuration for you and scale


1719
00:53:53,756 --> 00:53:54,886
your performance based on the


1720
00:53:54,886 --> 00:53:56,016
bandwidth limitations.


1721
00:53:58,226 --> 00:53:59,296
And this is how you transfer


1722
00:53:59,296 --> 00:54:00,746
data between GPU's.


1723
00:54:01,226 --> 00:54:02,766
The first thing you need to do


1724
00:54:02,766 --> 00:54:04,366
is create your shared event from


1725
00:54:04,366 --> 00:54:05,476
the auxiliary device.


1726
00:54:06,396 --> 00:54:08,466
We also create a render texture


1727
00:54:08,466 --> 00:54:10,006
and a remote texture view.


1728
00:54:10,436 --> 00:54:11,616
The remote view will give our


1729
00:54:11,616 --> 00:54:13,926
display attached GPU access to


1730
00:54:14,036 --> 00:54:15,396
the auxiliary texture.


1731
00:54:17,016 --> 00:54:18,436
Next we create an encoder and


1732
00:54:18,436 --> 00:54:18,846
render.


1733
00:54:20,136 --> 00:54:20,976
This should immediately be


1734
00:54:21,056 --> 00:54:22,486
followed by the encoded signal


1735
00:54:23,366 --> 00:54:23,526
event.


1736
00:54:24,416 --> 00:54:26,066
Now on the display device we


1737
00:54:26,066 --> 00:54:27,446
create a blit command buffer.


1738
00:54:28,036 --> 00:54:29,426
We immediately encode a wait


1739
00:54:29,426 --> 00:54:29,756
event.


1740
00:54:29,826 --> 00:54:31,046
So we wait for the rendering to


1741
00:54:31,046 --> 00:54:32,476
complete before transferring the


1742
00:54:32,476 --> 00:54:32,826
data.


1743
00:54:33,446 --> 00:54:36,406
And finally we do a copy using


1744
00:54:36,406 --> 00:54:37,736
the textured view, and that's


1745
00:54:37,736 --> 00:54:38,006
it.


1746
00:54:38,406 --> 00:54:39,026
Very simple.


1747
00:54:41,596 --> 00:54:43,446
Utilizing Metal peer group API


1748
00:54:43,596 --> 00:54:45,436
to leverage Infinity Fabric Link


1749
00:54:45,676 --> 00:54:47,336
can unlock challenging workloads


1750
00:54:47,336 --> 00:54:49,196
by reducing your PCI bandwidth.


1751
00:54:49,726 --> 00:54:51,516
It also can enhance concurrency


1752
00:54:51,846 --> 00:54:53,086
by using a parallel channel.


1753
00:54:53,846 --> 00:54:55,026
So before I conclude this


1754
00:54:55,026 --> 00:54:57,306
session, let's look at one more


1755
00:54:57,376 --> 00:54:58,846
really great Pro App in action.


1756
00:55:00,366 --> 00:55:01,616
So now I'm excited to share a


1757
00:55:01,616 --> 00:55:03,266
demo of Affinity Photo from


1758
00:55:03,266 --> 00:55:04,176
Serif Labs.


1759
00:55:04,746 --> 00:55:05,916
The engineers at Serif have done


1760
00:55:05,916 --> 00:55:07,886
an outstanding job of adopting


1761
00:55:07,886 --> 00:55:08,266
Metal.


1762
00:55:08,626 --> 00:55:10,836
They're also a really, really


1763
00:55:10,836 --> 00:55:12,676
good example of how to


1764
00:55:12,676 --> 00:55:13,996
officially leverage platform


1765
00:55:13,996 --> 00:55:14,686
resources.


1766
00:55:15,266 --> 00:55:16,836
On a typical document, their


1767
00:55:16,836 --> 00:55:18,256
performance can be around 10


1768
00:55:18,256 --> 00:55:20,126
times faster on a single GPU


1769
00:55:20,396 --> 00:55:21,876
when compared to an eight course


1770
00:55:21,876 --> 00:55:22,296
CPU.


1771
00:55:23,186 --> 00:55:23,936
Let's take a look.


1772
00:55:25,566 --> 00:55:26,876
So in this example, Affinity is


1773
00:55:26,876 --> 00:55:29,126
going to be live compositing a


1774
00:55:29,126 --> 00:55:30,296
massive document called the


1775
00:55:30,336 --> 00:55:30,936
rabbit trick.


1776
00:55:31,726 --> 00:55:32,996
As the video demonstrates, it


1777
00:55:32,996 --> 00:55:34,796
has hundreds of massive layers,


1778
00:55:35,026 --> 00:55:36,616
and they'll be compositing at 4K


1779
00:55:36,616 --> 00:55:37,196
resolution.


1780
00:55:38,156 --> 00:55:39,456
Some layers have pixel data


1781
00:55:39,456 --> 00:55:40,656
while others have procedural


1782
00:55:40,656 --> 00:55:41,466
adjustments.


1783
00:55:42,446 --> 00:55:43,476
This will be hierarchically


1784
00:55:43,476 --> 00:55:46,056
composited in real time, and


1785
00:55:46,056 --> 00:55:47,406
this will also put a tremendous


1786
00:55:47,406 --> 00:55:49,456
load on both the CPU and the


1787
00:55:49,886 --> 00:55:50,000
GPU.


1788
00:55:52,006 --> 00:55:53,556
Now let's run this massive


1789
00:55:53,596 --> 00:55:54,606
document on the CPU.


1790
00:55:55,396 --> 00:55:57,256
This is using an 18-core system.


1791
00:55:57,736 --> 00:55:58,636
You could see that we're able to


1792
00:55:58,636 --> 00:56:00,516
composite in real time; however,


1793
00:56:00,516 --> 00:56:02,736
the document is so complex it


1794
00:56:02,736 --> 00:56:03,896
gets a little bit choppy in the


1795
00:56:03,896 --> 00:56:04,966
user interface.


1796
00:56:08,946 --> 00:56:10,286
Now let's switch and run that on


1797
00:56:10,286 --> 00:56:11,276
a single GPU.


1798
00:56:12,266 --> 00:56:13,346
Here, you can see the UI


1799
00:56:13,346 --> 00:56:15,076
responds really well and


1800
00:56:15,076 --> 00:56:16,256
everything runs smoothly.


1801
00:56:16,476 --> 00:56:18,366
The frame rate runs about 18 to


1802
00:56:18,366 --> 00:56:19,500
20 frames per second.


1803
00:56:22,616 --> 00:56:23,776
And now for the best part.


1804
00:56:23,776 --> 00:56:25,456
We're going to enable a total of


1805
00:56:25,646 --> 00:56:27,856
four external GPU's and as you


1806
00:56:27,856 --> 00:56:29,076
can see it runs incredibly


1807
00:56:29,166 --> 00:56:30,746
smooth and it maintains greater


1808
00:56:30,746 --> 00:56:31,996
than 60 frames per second the


1809
00:56:31,996 --> 00:56:32,786
entire time.


1810
00:56:33,436 --> 00:56:34,566
This is due in part to


1811
00:56:34,566 --> 00:56:36,906
Affinity's advanced tile-based


1812
00:56:36,906 --> 00:56:37,896
load balancing scheme.


1813
00:56:38,586 --> 00:56:39,716
They can distribute their work


1814
00:56:39,716 --> 00:56:41,466
efficiently among any number of


1815
00:56:41,466 --> 00:56:43,326
GPU's, and with this they can


1816
00:56:43,326 --> 00:56:44,556
achieve linear performance


1817
00:56:44,556 --> 00:56:45,046
scaling.


1818
00:56:45,656 --> 00:56:48,236
Here is one last example that I


1819
00:56:48,236 --> 00:56:48,686
want to share.


1820
00:56:49,696 --> 00:56:50,826
This is one of Affinity Photo's


1821
00:56:50,826 --> 00:56:52,546
most memory bandwidth intensive


1822
00:56:52,546 --> 00:56:54,236
filters known as depth of field.


1823
00:56:55,426 --> 00:56:56,566
Here we're previewing in real


1824
00:56:56,566 --> 00:56:57,896
time on the CPU.


1825
00:56:58,556 --> 00:57:00,096
You can visually see the time it


1826
00:57:00,096 --> 00:57:01,226
takes between applying the


1827
00:57:01,226 --> 00:57:02,286
effect and it actually


1828
00:57:02,286 --> 00:57:02,706
rendering.


1829
00:57:03,626 --> 00:57:04,956
This is still impressive, and


1830
00:57:04,956 --> 00:57:06,996
it's fast, but the GPU can make


1831
00:57:06,996 --> 00:57:08,000
this even better.


1832
00:57:09,336 --> 00:57:10,066
So now we're going to run the


1833
00:57:10,066 --> 00:57:11,866
same effect with four external


1834
00:57:11,866 --> 00:57:12,146
GPU's.


1835
00:57:12,146 --> 00:57:14,466
You could see here it runs


1836
00:57:14,466 --> 00:57:16,536
amazingly smooth and easily


1837
00:57:16,536 --> 00:57:18,086
maintains a frame rate greater


1838
00:57:18,086 --> 00:57:19,346
than 60 frames per second.


1839
00:57:20,196 --> 00:57:21,836
This particular filter is memory


1840
00:57:21,836 --> 00:57:22,896
bandwidth intensive.


1841
00:57:23,276 --> 00:57:25,076
So we get great improvement here


1842
00:57:25,396 --> 00:57:27,736
because of the massive memory


1843
00:57:27,736 --> 00:57:29,696
bandwidth available on modern


1844
00:57:29,696 --> 00:57:30,536
GPU's today.


1845
00:57:31,356 --> 00:57:32,766
And this is an outstanding


1846
00:57:32,766 --> 00:57:34,476
example of how to officially


1847
00:57:34,476 --> 00:57:36,186
scale performance across


1848
00:57:36,186 --> 00:57:37,376
multiple GPU's.


1849
00:57:37,946 --> 00:57:40,686
So before we close this session,


1850
00:57:41,026 --> 00:57:42,346
let's review some of the key


1851
00:57:42,346 --> 00:57:43,116
takeaways.


1852
00:57:44,506 --> 00:57:45,856
Apple provides a wealth of


1853
00:57:45,856 --> 00:57:47,716
frameworks to solve all your Pro


1854
00:57:47,716 --> 00:57:48,006
App needs.


1855
00:57:48,856 --> 00:57:50,526
You can leverage this ecosystem


1856
00:57:50,526 --> 00:57:52,126
to achieve real-time editing


1857
00:57:52,126 --> 00:57:54,576
performance on 8k content with a


1858
00:57:54,576 --> 00:57:55,586
predictable frame rate.


1859
00:57:57,086 --> 00:57:59,456
Apple's AV Foundation and Core


1860
00:57:59,456 --> 00:58:01,516
Animation Metal Layer provide


1861
00:58:01,516 --> 00:58:03,406
API's to seamlessly support high


1862
00:58:03,406 --> 00:58:04,426
dynamic range.


1863
00:58:04,826 --> 00:58:06,196
You can couple this with HDR


1864
00:58:06,256 --> 00:58:08,686
TV's and Apple's new Pro Display


1865
00:58:08,686 --> 00:58:11,256
XDR to generate amazing videos


1866
00:58:11,256 --> 00:58:11,916
and images.


1867
00:58:12,516 --> 00:58:15,436
The Mac Pro can have up to 28


1868
00:58:15,526 --> 00:58:17,266
CPU cores and four internal


1869
00:58:17,266 --> 00:58:18,116
GPU's.


1870
00:58:18,666 --> 00:58:20,096
Metal provides all the API for


1871
00:58:20,206 --> 00:58:21,426
you to scale your performance


1872
00:58:21,426 --> 00:58:22,796
across all these devices.


1873
00:58:24,366 --> 00:58:26,186
And finally, we introduced a new


1874
00:58:26,186 --> 00:58:27,746
hardware feature Affinity Fabric


1875
00:58:27,746 --> 00:58:29,296
Link with a Metal peer group


1876
00:58:29,296 --> 00:58:29,656
API.


1877
00:58:30,516 --> 00:58:32,186
This empowers you to leverage


1878
00:58:32,186 --> 00:58:34,926
this connection to unlock new


1879
00:58:34,926 --> 00:58:36,146
and exciting use cases.


1880
00:58:37,626 --> 00:58:39,386
For more information, please


1881
00:58:39,386 --> 00:58:41,146
visit our website and please


1882
00:58:41,146 --> 00:58:42,626
visit us in tomorrow's lab.


1883
00:58:42,956 --> 00:58:44,456
Also check out additional Metal


1884
00:58:44,456 --> 00:58:45,366
labs on Friday.


1885
00:58:45,596 --> 00:58:46,456
Thank you very much.


1886
00:58:47,516 --> 00:58:51,500
[ Applause ]

