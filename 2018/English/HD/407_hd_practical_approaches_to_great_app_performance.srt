1
00:00:07,516 --> 00:00:18,516
[ Music ]


2
00:00:19,516 --> 00:00:25,416
[ Applause ]


3
00:00:25,916 --> 00:00:26,946
>> Good afternoon everyone.


4
00:00:27,406 --> 00:00:28,456
My name is John Hess.


5
00:00:28,456 --> 00:00:29,466
Today I'm going to be joined by


6
00:00:29,466 --> 00:00:30,586
Matthew Lucas, and we are going


7
00:00:30,586 --> 00:00:31,606
to be talking to all of you


8
00:00:31,606 --> 00:00:33,166
about practical approaches to


9
00:00:33,166 --> 00:00:34,506
great app performance.


10
00:00:35,406 --> 00:00:36,906
Now, I'm an engineer on the


11
00:00:36,906 --> 00:00:38,286
Xcode team, and I've had the


12
00:00:38,346 --> 00:00:39,796
luxury of spending the last


13
00:00:39,796 --> 00:00:41,546
several years focused on


14
00:00:41,546 --> 00:00:42,236
performance work.


15
00:00:42,736 --> 00:00:44,226
First, with Project Find, and


16
00:00:44,226 --> 00:00:47,186
Open Quickly, two areas of Xcode


17
00:00:47,826 --> 00:00:49,126
that treat performance as the


18
00:00:49,126 --> 00:00:49,896
primary feature.


19
00:00:50,766 --> 00:00:52,056
Most recently, I've had the


20
00:00:52,056 --> 00:00:54,136
opportunity to do a survey of


21
00:00:54,136 --> 00:00:55,846
Xcode GY responsiveness, and I


22
00:00:55,846 --> 00:00:57,126
want to share with you the


23
00:00:57,126 --> 00:00:58,326
approaches that I take to


24
00:00:58,326 --> 00:01:00,296
performance work, both in code


25
00:01:00,296 --> 00:01:01,376
that I'm intimately familiar


26
00:01:01,376 --> 00:01:03,136
with, and in code that I'm just


27
00:01:03,136 --> 00:01:04,596
experiencing for the first time.


28
00:01:05,936 --> 00:01:07,716
Now, if I could get everyone in


29
00:01:07,716 --> 00:01:09,496
today's presentation to just


30
00:01:09,496 --> 00:01:11,886
take one lesson away, it is that


31
00:01:11,946 --> 00:01:13,276
all of your performance work


32
00:01:13,276 --> 00:01:14,716
should be based on measurement.


33
00:01:15,696 --> 00:01:17,096
Before you start solving a


34
00:01:17,096 --> 00:01:18,816
performance problem, you should


35
00:01:18,816 --> 00:01:21,126
measure, to establish a baseline


36
00:01:21,366 --> 00:01:22,536
so you know where you stand.


37
00:01:23,666 --> 00:01:25,196
As you iterate on solving a


38
00:01:25,196 --> 00:01:26,716
performance problem, you should


39
00:01:26,716 --> 00:01:28,146
measure it each step of the way


40
00:01:28,576 --> 00:01:29,826
to ensure that your performance


41
00:01:29,826 --> 00:01:31,376
changes are having the impact


42
00:01:31,466 --> 00:01:32,026
that you expect.


43
00:01:33,336 --> 00:01:34,346
When you're done solving a


44
00:01:34,346 --> 00:01:35,916
performance problem, you should


45
00:01:35,916 --> 00:01:37,656
measure again, so that you can


46
00:01:37,656 --> 00:01:38,846
compare to your original


47
00:01:38,846 --> 00:01:41,046
baseline, and make a quantified


48
00:01:41,046 --> 00:01:43,166
claim about just how much you've


49
00:01:43,166 --> 00:01:44,226
improved the performance of your


50
00:01:44,226 --> 00:01:44,746
application.


51
00:01:45,196 --> 00:01:46,766
You want to share this with your


52
00:01:46,766 --> 00:01:48,896
boss, your colleagues, and your


53
00:01:48,896 --> 00:01:49,506
users.


54
00:01:50,566 --> 00:01:51,416
Now, when you think about


55
00:01:51,416 --> 00:01:52,966
improving performance for your


56
00:01:52,966 --> 00:01:55,166
users, you need to think about


57
00:01:55,166 --> 00:01:56,826
what I like to call the total


58
00:01:56,826 --> 00:01:57,786
performance impact.


59
00:01:58,656 --> 00:02:01,246
If you improve the functionality


60
00:02:01,246 --> 00:02:03,216
and performance of one area of


61
00:02:03,216 --> 00:02:06,706
your application, by 50%, but


62
00:02:06,706 --> 00:02:08,136
it's something that just 1% of


63
00:02:08,136 --> 00:02:10,006
your users encounter, that does


64
00:02:10,006 --> 00:02:11,456
not have nearly the breadth of


65
00:02:11,456 --> 00:02:13,286
impact as improving some other


66
00:02:13,286 --> 00:02:15,526
feature by just 10% that all of


67
00:02:15,526 --> 00:02:16,806
your users use all the time.


68
00:02:17,336 --> 00:02:18,096
So make sure you're not


69
00:02:18,096 --> 00:02:19,676
optimizing edge cases, and make


70
00:02:19,676 --> 00:02:20,816
sure that your changes are


71
00:02:20,816 --> 00:02:22,596
impacting all of your users.


72
00:02:24,536 --> 00:02:27,736
Now how do we fix performance


73
00:02:27,736 --> 00:02:28,086
bugs?


74
00:02:28,086 --> 00:02:29,106
Well, how do we fix regular


75
00:02:29,106 --> 00:02:29,526
bugs?


76
00:02:29,966 --> 00:02:31,586
Normally it starts with some


77
00:02:31,586 --> 00:02:33,036
sort of defect report from


78
00:02:33,036 --> 00:02:35,026
users, and we take this report


79
00:02:35,026 --> 00:02:36,466
of the application not behaving


80
00:02:36,466 --> 00:02:38,216
the way that people expect, and


81
00:02:38,216 --> 00:02:39,946
we find some way to synthesize


82
00:02:40,066 --> 00:02:41,696
steps to reproduce so that we


83
00:02:41,696 --> 00:02:42,866
can cause the failure at will.


84
00:02:43,646 --> 00:02:45,346
Once we've done this, we attach


85
00:02:45,346 --> 00:02:46,526
a debugger to our program, so


86
00:02:46,526 --> 00:02:47,846
that we can see just what our


87
00:02:47,846 --> 00:02:48,826
program is doing while it is


88
00:02:48,826 --> 00:02:49,376
misbehaving.


89
00:02:50,866 --> 00:02:51,706
We combine that with our


90
00:02:51,706 --> 00:02:52,656
knowledge of how the code is


91
00:02:52,656 --> 00:02:54,576
supposed to work, to modify it


92
00:02:54,576 --> 00:02:56,176
as necessary and eliminate the


93
00:02:56,176 --> 00:02:57,156
undesired behavior.


94
00:02:57,936 --> 00:02:58,966
We verify that we haven't


95
00:02:58,966 --> 00:03:00,516
introduced any unwanted side


96
00:03:00,516 --> 00:03:02,046
effects, and we repeat as


97
00:03:02,046 --> 00:03:03,546
necessary until we've completely


98
00:03:03,546 --> 00:03:04,186
solved the bug.


99
00:03:05,736 --> 00:03:07,686
I've fixed performance bugs in


100
00:03:07,686 --> 00:03:08,996
just the same way.


101
00:03:10,086 --> 00:03:11,136
Except instead of using a


102
00:03:11,136 --> 00:03:13,766
debugger, I use a profiler, and


103
00:03:13,826 --> 00:03:15,666
a profiler is just a fancy tool


104
00:03:15,666 --> 00:03:16,246
for measuring.


105
00:03:16,996 --> 00:03:18,666
I find some set of steps to


106
00:03:18,666 --> 00:03:20,806
reproduce the program being


107
00:03:20,806 --> 00:03:21,216
slow.


108
00:03:21,966 --> 00:03:23,386
And I run those steps with a


109
00:03:23,386 --> 00:03:25,106
profiler attached, so that I can


110
00:03:25,106 --> 00:03:26,606
get an insight into what my code


111
00:03:26,606 --> 00:03:27,656
is doing while it's running


112
00:03:27,656 --> 00:03:28,106
slowly.


113
00:03:29,226 --> 00:03:31,016
I combine that knowledge with


114
00:03:31,016 --> 00:03:32,556
what my program has to do to


115
00:03:32,556 --> 00:03:34,206
accomplish the task at hand, and


116
00:03:34,266 --> 00:03:36,056
I find steps that are happening


117
00:03:36,236 --> 00:03:37,606
and remove them, because the


118
00:03:37,606 --> 00:03:39,926
primary way you make your code


119
00:03:39,926 --> 00:03:42,286
faster is you remove redundant


120
00:03:42,286 --> 00:03:43,756
steps from whatever is that is


121
00:03:43,756 --> 00:03:44,326
calculating.


122
00:03:45,736 --> 00:03:47,456
Now, I make the modifications to


123
00:03:47,456 --> 00:03:49,136
the source code, and I repeat


124
00:03:49,136 --> 00:03:50,486
and measure as necessary until


125
00:03:50,486 --> 00:03:52,886
I'm happy with the total result.


126
00:03:54,936 --> 00:03:56,186
When I'm doing this type of


127
00:03:56,186 --> 00:03:57,666
performance work, I often find


128
00:03:57,666 --> 00:03:59,486
myself in one of a handful of


129
00:03:59,486 --> 00:04:00,176
scenarios.


130
00:04:00,736 --> 00:04:02,026
And these different scenarios


131
00:04:02,056 --> 00:04:03,406
change the way that I go about


132
00:04:03,496 --> 00:04:05,166
testing the code in question to


133
00:04:05,196 --> 00:04:06,126
reproduce the bugs.


134
00:04:06,776 --> 00:04:09,046
Sometimes I'm up against a big


135
00:04:09,096 --> 00:04:10,926
performance regression, right?


136
00:04:11,006 --> 00:04:12,086
Everything was moving along


137
00:04:12,086 --> 00:04:14,116
smoothly, then someone checked


138
00:04:14,116 --> 00:04:15,396
something in on our team, maybe


139
00:04:15,446 --> 00:04:17,086
it was me, and performance has


140
00:04:17,086 --> 00:04:18,226
fallen through the floor, and


141
00:04:18,226 --> 00:04:19,495
now we have to go back and find


142
00:04:19,495 --> 00:04:21,296
out what caused this regression.


143
00:04:22,065 --> 00:04:23,246
If this regression is very


144
00:04:23,246 --> 00:04:25,986
pronounced, or it's in an area


145
00:04:25,986 --> 00:04:27,186
that I don't think it's likely


146
00:04:27,186 --> 00:04:28,086
to regress again in the


147
00:04:28,086 --> 00:04:29,576
immediate future, I may just


148
00:04:29,676 --> 00:04:31,966
test it with my hands, manually,


149
00:04:32,086 --> 00:04:33,216
with the profiler attached.


150
00:04:34,386 --> 00:04:36,116
However, your performance


151
00:04:36,116 --> 00:04:37,376
victories are going to be


152
00:04:37,376 --> 00:04:40,056
hard-won battles, and they can


153
00:04:40,056 --> 00:04:42,126
easily be lost through a slow


154
00:04:42,126 --> 00:04:43,196
stream of regressions.


155
00:04:43,986 --> 00:04:45,806
I would encourage all of you to


156
00:04:45,806 --> 00:04:46,926
write automated performance


157
00:04:46,926 --> 00:04:48,986
tests to capture your app's


158
00:04:48,986 --> 00:04:50,356
performance, so that you can


159
00:04:50,356 --> 00:04:51,836
ensure that it's not regressing


160
00:04:51,836 --> 00:04:52,316
over time.


161
00:04:55,256 --> 00:04:56,596
Another scenario I often find


162
00:04:56,596 --> 00:04:58,726
myself in, is, are applications


163
00:04:58,726 --> 00:05:00,326
performing the same as it has


164
00:05:00,326 --> 00:05:01,246
been for a long time?


165
00:05:01,656 --> 00:05:03,356
Maybe it is running at 45 frames


166
00:05:03,356 --> 00:05:04,666
a second in some drawing test,


167
00:05:05,156 --> 00:05:06,826
but we expect it to run at 60.


168
00:05:06,826 --> 00:05:07,886
It needs to be improved


169
00:05:07,886 --> 00:05:09,426
marginally, and we have reason


170
00:05:09,426 --> 00:05:10,986
to believe through our previous


171
00:05:10,986 --> 00:05:12,736
performance work that we can get


172
00:05:12,736 --> 00:05:14,126
there through spot fixes and


173
00:05:14,126 --> 00:05:15,546
incremental changes.


174
00:05:16,326 --> 00:05:17,726
Now, in this type of scenario, I


175
00:05:17,726 --> 00:05:19,186
probably also have automated


176
00:05:19,186 --> 00:05:20,876
tests already in play, because I


177
00:05:20,876 --> 00:05:22,216
understand my performance over


178
00:05:24,796 --> 00:05:24,896
time.


179
00:05:25,106 --> 00:05:26,856
And a third scenario, our


180
00:05:26,856 --> 00:05:28,176
application is just suffering


181
00:05:28,176 --> 00:05:29,336
from a poor design and


182
00:05:29,446 --> 00:05:30,666
performance is orders of


183
00:05:30,666 --> 00:05:32,036
magnitude worse than it should


184
00:05:32,036 --> 00:05:32,226
be.


185
00:05:33,516 --> 00:05:34,726
We know that we can't improve it


186
00:05:34,726 --> 00:05:36,626
with simple spot fixes, because


187
00:05:36,626 --> 00:05:37,666
we've tried them in the past,


188
00:05:37,906 --> 00:05:39,356
and we are still stuck here with


189
00:05:39,606 --> 00:05:41,416
a very sub-par performance.


190
00:05:42,006 --> 00:05:43,856
In a situation like this, you'd


191
00:05:43,856 --> 00:05:45,096
want to do a total performance


192
00:05:45,096 --> 00:05:45,986
overhaul, where you are


193
00:05:45,986 --> 00:05:47,446
redesigning some core part of


194
00:05:47,446 --> 00:05:48,716
the feature, or the algorithms


195
00:05:48,716 --> 00:05:50,516
in question, so that performance


196
00:05:50,786 --> 00:05:51,916
is a primary constraint.


197
00:05:52,456 --> 00:05:53,746
And definitely in these cases,


198
00:05:53,906 --> 00:05:55,216
you would have performance tests


199
00:05:55,536 --> 00:05:56,686
to measure that you're actually


200
00:05:56,686 --> 00:05:57,626
hitting your performance


201
00:05:57,626 --> 00:05:58,136
targets.


202
00:05:59,246 --> 00:06:00,856
Now, it is important that you


203
00:06:00,856 --> 00:06:01,936
know just what to test.


204
00:06:02,346 --> 00:06:03,686
I want to caution you that I


205
00:06:03,686 --> 00:06:05,096
don't ever immediately jump to


206
00:06:05,096 --> 00:06:06,086
these sort of performance


207
00:06:06,086 --> 00:06:08,106
overhauls as a way of fixing a


208
00:06:08,106 --> 00:06:08,896
performance problem.


209
00:06:09,296 --> 00:06:10,816
I love to do that.


210
00:06:10,816 --> 00:06:12,046
It's sort of Greenfield


211
00:06:12,046 --> 00:06:13,106
engineering, where you get to


212
00:06:13,106 --> 00:06:14,326
design things from the ground


213
00:06:14,326 --> 00:06:16,126
up, but it's very risky.


214
00:06:16,556 --> 00:06:17,346
You're going to end up with a


215
00:06:17,346 --> 00:06:18,666
better product at the end, but


216
00:06:18,666 --> 00:06:19,686
it's going to be a turbulent


217
00:06:19,686 --> 00:06:21,376
path getting there as you rework


218
00:06:21,376 --> 00:06:23,976
an entire feature.


219
00:06:24,116 --> 00:06:25,186
When you're doing this style of


220
00:06:25,186 --> 00:06:26,666
work, it is imperative you


221
00:06:26,666 --> 00:06:28,156
understand not only the


222
00:06:28,286 --> 00:06:29,436
functional constraints of the


223
00:06:29,436 --> 00:06:31,336
code in question, but also the


224
00:06:31,336 --> 00:06:32,986
performance constraints, and the


225
00:06:32,986 --> 00:06:34,356
typical use patterns that your


226
00:06:34,356 --> 00:06:35,616
users are most frequently


227
00:06:35,616 --> 00:06:37,386
applying to this feature, and


228
00:06:37,386 --> 00:06:39,106
you only get that by having done


229
00:06:39,256 --> 00:06:40,276
performance work in the area in


230
00:06:40,276 --> 00:06:40,736
the past.


231
00:06:41,636 --> 00:06:43,326
I'd like to share an anecdote


232
00:06:43,326 --> 00:06:45,046
about our work on a situation


233
00:06:45,046 --> 00:06:46,216
like this, within Xcode.


234
00:06:47,216 --> 00:06:49,406
In Xcode 9, we reworked Project


235
00:06:49,406 --> 00:06:50,606
Find, with performance as a


236
00:06:50,606 --> 00:06:51,406
primary goal.


237
00:06:52,366 --> 00:06:53,716
It was our goal to deliver


238
00:06:53,716 --> 00:06:55,376
search results in just tens of


239
00:06:55,376 --> 00:06:56,076
milliseconds.


240
00:06:56,926 --> 00:06:59,156
When we were going to discuss


241
00:06:59,156 --> 00:07:00,006
this feature with our


242
00:07:00,006 --> 00:07:01,366
colleagues, we were often


243
00:07:01,366 --> 00:07:03,536
challenged to perform searches


244
00:07:03,536 --> 00:07:05,286
across large projects for things


245
00:07:05,286 --> 00:07:07,106
like string, or even the letter


246
00:07:07,106 --> 00:07:07,336
E.


247
00:07:07,446 --> 00:07:08,976
Things that produce millions of


248
00:07:08,976 --> 00:07:10,446
results, right?


249
00:07:10,446 --> 00:07:12,106
And certainly if our application


250
00:07:12,216 --> 00:07:13,426
could produce millions of


251
00:07:13,426 --> 00:07:14,866
results quickly, it would be


252
00:07:14,866 --> 00:07:15,776
fast on anything.


253
00:07:16,476 --> 00:07:17,896
But if you consider what typical


254
00:07:17,896 --> 00:07:20,516
patterns are, we search for APIs


255
00:07:20,516 --> 00:07:22,046
we use, the names of our own


256
00:07:22,046 --> 00:07:24,336
classes, the names of, you know,


257
00:07:24,496 --> 00:07:25,616
images that we're referencing.


258
00:07:25,616 --> 00:07:26,286
Things like that.


259
00:07:26,346 --> 00:07:27,546
They produce dozens, maybe


260
00:07:27,546 --> 00:07:28,606
hundreds of results.


261
00:07:28,936 --> 00:07:30,276
Certainly, it is essential that


262
00:07:30,276 --> 00:07:32,076
the application works decently


263
00:07:32,076 --> 00:07:33,236
when you get a million results,


264
00:07:33,496 --> 00:07:35,086
but the normal use case is


265
00:07:35,156 --> 00:07:36,026
hundreds of results.


266
00:07:36,806 --> 00:07:38,486
Now, some of your work in doing


267
00:07:38,486 --> 00:07:40,186
a task like search is going to


268
00:07:40,186 --> 00:07:41,396
be proportional on things like


269
00:07:41,746 --> 00:07:43,816
generating the raw results, and


270
00:07:43,816 --> 00:07:45,326
other work is going to be based


271
00:07:45,326 --> 00:07:46,916
on how efficiently you can index


272
00:07:46,916 --> 00:07:48,296
the text in the project, and


273
00:07:48,296 --> 00:07:49,666
avoid work in the first place.


274
00:07:50,156 --> 00:07:51,996
In these two scenarios, you're


275
00:07:51,996 --> 00:07:53,976
likely to have completely


276
00:07:53,976 --> 00:07:55,286
different targets for what you


277
00:07:55,286 --> 00:07:56,826
would optimize to make one of


278
00:07:56,826 --> 00:07:57,916
these searches faster than the


279
00:07:57,916 --> 00:07:59,046
other, right?


280
00:07:59,046 --> 00:08:00,156
So it's essential that you


281
00:08:00,156 --> 00:08:02,426
understand how your users are


282
00:08:02,426 --> 00:08:03,316
going to use the product, so


283
00:08:03,506 --> 00:08:04,696
that you can optimize for the


284
00:08:04,726 --> 00:08:05,536
right cases.


285
00:08:07,956 --> 00:08:09,696
Now, in all of these cases, I


286
00:08:09,696 --> 00:08:11,206
need to do some form of testing,


287
00:08:11,686 --> 00:08:13,066
whether it's manual, or


288
00:08:13,066 --> 00:08:13,556
automated.


289
00:08:16,246 --> 00:08:17,556
I want to share with you two


290
00:08:17,556 --> 00:08:18,886
types of performance tests that


291
00:08:18,886 --> 00:08:20,196
I will typically write to


292
00:08:20,196 --> 00:08:21,516
measure the performance of


293
00:08:22,026 --> 00:08:22,186
Xcode.


294
00:08:23,436 --> 00:08:25,436
We will either do unit tests, or


295
00:08:25,436 --> 00:08:26,376
integration tests.


296
00:08:26,956 --> 00:08:28,176
Let's compare and contrast them.


297
00:08:29,376 --> 00:08:31,306
In a performance unit test, it's


298
00:08:31,306 --> 00:08:33,616
your goal to isolate some


299
00:08:33,616 --> 00:08:35,096
feature of your application and


300
00:08:35,096 --> 00:08:36,356
measure it all by itself.


301
00:08:36,966 --> 00:08:37,726
You might mock out its


302
00:08:37,756 --> 00:08:39,236
dependencies, and you might


303
00:08:39,236 --> 00:08:41,126
launch it in a context where it


304
00:08:41,126 --> 00:08:42,736
has been isolated.


305
00:08:43,496 --> 00:08:45,666
If I were to write performance


306
00:08:45,666 --> 00:08:47,266
unit tests for Xcode's code


307
00:08:47,266 --> 00:08:48,676
completion, I might write a


308
00:08:48,676 --> 00:08:50,406
series of three small tests.


309
00:08:51,076 --> 00:08:52,896
One of these tests would measure


310
00:08:53,256 --> 00:08:54,616
talking to the compiler and


311
00:08:54,616 --> 00:08:56,426
getting the raw results, the raw


312
00:08:56,426 --> 00:08:57,266
set of code completion


313
00:08:57,266 --> 00:08:57,876
candidates back.


314
00:08:58,946 --> 00:09:01,056
Another performance test would


315
00:09:01,056 --> 00:09:02,906
measure correlating, ranking and


316
00:09:02,906 --> 00:09:04,386
scoring those results, so we


317
00:09:04,386 --> 00:09:05,406
knew which ones to display to


318
00:09:05,406 --> 00:09:05,806
the user.


319
00:09:06,926 --> 00:09:08,896
A third test might take those


320
00:09:08,926 --> 00:09:10,636
already prepared results, and


321
00:09:10,636 --> 00:09:11,636
measure putting them into UI


322
00:09:11,636 --> 00:09:13,156
elements for final display.


323
00:09:13,156 --> 00:09:15,016
And in covering all three of


324
00:09:15,016 --> 00:09:16,846
these areas, I would have pretty


325
00:09:16,846 --> 00:09:17,986
good coverage over the major


326
00:09:17,986 --> 00:09:20,056
components of code completion in


327
00:09:20,056 --> 00:09:20,546
the IDE.


328
00:09:23,136 --> 00:09:24,796
Now, there are some great


329
00:09:24,886 --> 00:09:26,276
aspects to these performance


330
00:09:26,276 --> 00:09:26,976
unit tests.


331
00:09:27,596 --> 00:09:28,326
They're going to be highly


332
00:09:28,326 --> 00:09:30,026
focused, which means if they


333
00:09:30,026 --> 00:09:31,276
regress in the future, I'm going


334
00:09:31,276 --> 00:09:32,706
to have a very good idea on


335
00:09:32,706 --> 00:09:33,986
where the regression is, because


336
00:09:34,026 --> 00:09:35,066
the code that is running has


337
00:09:35,066 --> 00:09:36,086
been scoped so well.


338
00:09:36,706 --> 00:09:38,976
They are also going to produce


339
00:09:39,286 --> 00:09:40,626
much more repeatable results


340
00:09:40,626 --> 00:09:41,336
from run to run.


341
00:09:41,466 --> 00:09:42,436
They're not going to have a big


342
00:09:42,436 --> 00:09:44,556
variance in the times that they


343
00:09:44,556 --> 00:09:45,036
produce.


344
00:09:45,426 --> 00:09:46,676
Again, because the code is so


345
00:09:46,676 --> 00:09:47,156
focused.


346
00:09:48,176 --> 00:09:49,186
Now, let's contrast that to an


347
00:09:49,186 --> 00:09:50,056
integration test.


348
00:09:51,076 --> 00:09:52,936
In an integration test, your job


349
00:09:52,936 --> 00:09:54,796
is to measure the performance of


350
00:09:54,796 --> 00:09:56,616
your application as your users


351
00:09:56,616 --> 00:09:57,336
experience it.


352
00:09:58,326 --> 00:09:59,016
Holistically.


353
00:09:59,866 --> 00:10:01,506
So, if I was writing code


354
00:10:01,506 --> 00:10:03,106
completion unit tests for Xcode,


355
00:10:03,756 --> 00:10:05,996
I'm sorry, integration tests, I


356
00:10:05,996 --> 00:10:08,466
would launch the full Xcode app.


357
00:10:08,466 --> 00:10:09,566
I would open a source file.


358
00:10:09,566 --> 00:10:11,136
I would navigate to the source


359
00:10:11,136 --> 00:10:13,366
file, and I would type, and I


360
00:10:13,366 --> 00:10:14,396
would bring up code completion


361
00:10:14,486 --> 00:10:15,306
over and over again.


362
00:10:16,076 --> 00:10:17,636
When I profile this, to see what


363
00:10:17,636 --> 00:10:18,686
Xcode is doing, and how much


364
00:10:18,686 --> 00:10:20,316
time it is taking, I am going to


365
00:10:20,316 --> 00:10:21,886
find that this test is anything


366
00:10:21,886 --> 00:10:22,956
but focused and quiet.


367
00:10:24,006 --> 00:10:25,476
Xcode is going to be doing


368
00:10:25,476 --> 00:10:26,986
drawing and layout as I type.


369
00:10:26,986 --> 00:10:28,996
It is going to be doing syntax


370
00:10:29,066 --> 00:10:29,906
coloring as I type.


371
00:10:30,556 --> 00:10:31,536
In the background, it might be


372
00:10:31,536 --> 00:10:33,636
indexing, fetching get status,


373
00:10:34,086 --> 00:10:35,506
deciding to show new files in


374
00:10:35,506 --> 00:10:35,976
the Assistant Editor,


375
00:10:36,056 --> 00:10:36,866
and all of these things are


376
00:10:37,166 --> 00:10:40,056
going to be competing for CPU


377
00:10:40,116 --> 00:10:41,806
resources, along with code


378
00:10:41,806 --> 00:10:42,246
completion.


379
00:10:43,086 --> 00:10:44,046
Maybe when I look in the


380
00:10:44,046 --> 00:10:45,786
Profiler, I'll see that we spend


381
00:10:45,786 --> 00:10:47,636
80% of our time syntax coloring,


382
00:10:47,916 --> 00:10:50,136
and 20% of our time in code


383
00:10:50,136 --> 00:10:50,626
completion.


384
00:10:51,086 --> 00:10:52,636
And with this data, I would know


385
00:10:52,636 --> 00:10:54,776
that the best way to improve


386
00:10:54,816 --> 00:10:55,976
code completion performance


387
00:10:56,256 --> 00:10:57,696
would be to defer syntax


388
00:10:57,746 --> 00:10:58,076
coloring.


389
00:10:58,686 --> 00:11:00,256
I will never gain that type of


390
00:11:00,256 --> 00:11:01,946
knowledge with a highly focused


391
00:11:01,946 --> 00:11:02,546
unit test.


392
00:11:02,546 --> 00:11:04,366
So if I can get everyone here to


393
00:11:04,366 --> 00:11:05,606
take two things away from this


394
00:11:05,606 --> 00:11:07,476
presentation, the second one


395
00:11:07,746 --> 00:11:08,866
should be that your performance


396
00:11:08,866 --> 00:11:10,936
investigations should absolutely


397
00:11:10,936 --> 00:11:12,506
start with these wide


398
00:11:12,506 --> 00:11:14,226
integration tests that measure


399
00:11:14,226 --> 00:11:15,846
how the users experience your


400
00:11:15,846 --> 00:11:16,406
application.


401
00:11:18,026 --> 00:11:19,296
So I'm talking about testing,


402
00:11:19,626 --> 00:11:21,026
measuring and profiling.


403
00:11:21,456 --> 00:11:22,346
And right now, I'd like to


404
00:11:22,346 --> 00:11:24,166
introduce you to profiling in


405
00:11:24,216 --> 00:11:25,546
Xcode with instruments.


406
00:11:25,786 --> 00:11:26,646
Let's head over to the demo


407
00:11:26,646 --> 00:11:27,166
machine.


408
00:11:35,056 --> 00:11:35,926
Today we are going to be looking


409
00:11:35,926 --> 00:11:37,146
at a performance problem that we


410
00:11:37,146 --> 00:11:39,186
fixed between Xcode 9 and Xcode


411
00:11:39,186 --> 00:11:39,516
10.


412
00:11:39,516 --> 00:11:41,216
I want to show it to you.


413
00:11:41,696 --> 00:11:44,436
I'm going to launch Xcode 9, and


414
00:11:44,436 --> 00:11:45,286
open our solar system


415
00:11:45,286 --> 00:11:45,856
application.


416
00:11:47,056 --> 00:11:47,766
Now the problem that we are


417
00:11:47,766 --> 00:11:48,836
going to be looking at is


418
00:11:48,836 --> 00:11:49,796
creating tabs.


419
00:11:50,456 --> 00:11:51,486
I'm going to just press


420
00:11:51,486 --> 00:11:52,956
Command-T quickly a couple of


421
00:11:52,956 --> 00:11:54,996
times, and as you can see, the


422
00:11:54,996 --> 00:11:56,896
whole screen flashes black, and


423
00:11:56,896 --> 00:11:58,166
it takes several seconds to


424
00:11:58,166 --> 00:11:58,996
create those tabs.


425
00:11:59,626 --> 00:12:01,116
That definitely doesn't meet my


426
00:12:01,116 --> 00:12:02,216
expectations as far as


427
00:12:02,216 --> 00:12:04,036
performance goes, and we need to


428
00:12:04,036 --> 00:12:04,596
fix this.


429
00:12:04,956 --> 00:12:06,376
So let's take a look at how you


430
00:12:06,376 --> 00:12:06,826
would do that.


431
00:12:08,266 --> 00:12:09,106
First, I'm going to launch


432
00:12:09,106 --> 00:12:09,566
Instruments.


433
00:12:09,606 --> 00:12:10,716
That is our profiling tool.


434
00:12:11,436 --> 00:12:12,686
You can do that from the Xcode


435
00:12:12,686 --> 00:12:14,586
menu, under Open Developer Tool,


436
00:12:14,886 --> 00:12:15,506
Instruments.


437
00:12:15,976 --> 00:12:17,766
Now, I'm currently in Xcode 9,


438
00:12:18,106 --> 00:12:19,146
so if I choose this, it's going


439
00:12:19,146 --> 00:12:20,036
to launch the Instruments from


440
00:12:20,036 --> 00:12:21,476
Xcode 9, and of course, I want


441
00:12:21,476 --> 00:12:22,606
the Instruments from Xcode 10,


442
00:12:22,706 --> 00:12:23,766
which I've put here in my doc.


443
00:12:24,066 --> 00:12:26,066
So I'm going to hide Xcode, and


444
00:12:26,066 --> 00:12:28,956
bring up Instruments.


445
00:12:29,146 --> 00:12:30,366
Now, when Instruments launches,


446
00:12:31,796 --> 00:12:33,026
we're presented with a list of


447
00:12:33,026 --> 00:12:34,226
profiling tools that we could


448
00:12:34,226 --> 00:12:35,546
use to measure our application.


449
00:12:36,356 --> 00:12:37,426
There's all kinds of tools here.


450
00:12:37,786 --> 00:12:38,736
They can measure graphics


451
00:12:38,736 --> 00:12:41,186
utilization, memory consumption,


452
00:12:41,836 --> 00:12:44,006
IO, and time in general.


453
00:12:45,726 --> 00:12:47,096
It can be intimidating to know


454
00:12:47,096 --> 00:12:48,406
which one of these profilers to


455
00:12:48,406 --> 00:12:49,676
start with.


456
00:12:51,236 --> 00:12:53,936
I would encourage all of you, if


457
00:12:53,936 --> 00:12:55,596
you just learn one of these


458
00:12:55,596 --> 00:12:56,976
tools, it should be the Time


459
00:12:56,976 --> 00:12:57,516
Profiler.


460
00:12:58,296 --> 00:13:00,426
I use it for 95% or more of my


461
00:13:00,426 --> 00:13:01,166
performance work.


462
00:13:01,736 --> 00:13:03,246
When your users complain about


463
00:13:03,246 --> 00:13:04,546
your app being slow, they're


464
00:13:04,546 --> 00:13:05,726
complaining about it taking too


465
00:13:05,726 --> 00:13:07,796
long, and long is time.


466
00:13:08,746 --> 00:13:10,116
If it turns out that you're slow


467
00:13:10,116 --> 00:13:10,926
because you're doing too much


468
00:13:10,926 --> 00:13:12,636
IO, that is going to correlate


469
00:13:12,636 --> 00:13:13,706
with time, and you will be able


470
00:13:13,706 --> 00:13:14,696
to see this with the Time


471
00:13:14,696 --> 00:13:15,036
Profiler.


472
00:13:15,036 --> 00:13:17,146
So if you learn just one


473
00:13:17,146 --> 00:13:18,376
instrument, it should be the


474
00:13:18,376 --> 00:13:19,126
Time Profiler.


475
00:13:20,276 --> 00:13:21,756
Let's take a look at how that


476
00:13:22,506 --> 00:13:22,636
works.


477
00:13:25,346 --> 00:13:26,646
I'm going to launch the Time


478
00:13:26,646 --> 00:13:28,496
Profiler by just double clicking


479
00:13:28,496 --> 00:13:31,246
on it here, and make Instruments


480
00:13:31,336 --> 00:13:32,226
take the full best op.


481
00:13:33,646 --> 00:13:35,396
Now, we'd like to record Xcode.


482
00:13:36,416 --> 00:13:38,086
In the upper left-hand corner of


483
00:13:38,256 --> 00:13:39,836
the Instruments window, you can


484
00:13:39,836 --> 00:13:41,126
control which process you're


485
00:13:41,126 --> 00:13:42,466
going to attach to and record.


486
00:13:43,096 --> 00:13:45,236
By default, hitting this record


487
00:13:45,236 --> 00:13:46,726
button would record all


488
00:13:46,726 --> 00:13:47,636
processes on my Mac.


489
00:13:48,286 --> 00:13:50,926
I just want to focus on Xcode.


490
00:13:54,856 --> 00:13:56,866
I'll switch this popover to


491
00:13:56,956 --> 00:13:59,046
Xcode and hit record.


492
00:13:59,536 --> 00:14:00,786
Now, I like to keep an eye on


493
00:14:00,786 --> 00:14:02,256
this area of the window to track


494
00:14:02,256 --> 00:14:03,396
view while I'm recording.


495
00:14:03,786 --> 00:14:05,216
So I'm going to resize the Xcode


496
00:14:05,216 --> 00:14:06,866
window to be a little shorter,


497
00:14:06,866 --> 00:14:08,026
so I can still see that, and


498
00:14:08,256 --> 00:14:09,336
then I'm going to do the thing


499
00:14:09,336 --> 00:14:09,896
that was slow.


500
00:14:09,896 --> 00:14:10,736
I'm going to create a couple


501
00:14:10,736 --> 00:14:11,316
more tabs.


502
00:14:12,726 --> 00:14:15,006
And you can see the graph


503
00:14:15,246 --> 00:14:15,826
changed here.


504
00:14:15,826 --> 00:14:17,016
Now, I'm going to go ahead and


505
00:14:17,086 --> 00:14:19,636
quit, and return to Instruments.


506
00:14:21,316 --> 00:14:23,056
So what just happened?


507
00:14:23,936 --> 00:14:25,266
While the Profiler was running,


508
00:14:26,126 --> 00:14:27,476
it was attached to our process


509
00:14:27,476 --> 00:14:28,076
like a debugger.


510
00:14:28,076 --> 00:14:30,586
And it stopped it, thousands of


511
00:14:30,586 --> 00:14:32,816
times per second, and as it was


512
00:14:32,816 --> 00:14:34,336
stopping it, it gathered back


513
00:14:34,366 --> 00:14:34,936
traces.


514
00:14:35,236 --> 00:14:37,026
Now, just a reminder, a back


515
00:14:37,026 --> 00:14:38,546
trace is a description of how


516
00:14:38,546 --> 00:14:39,706
your program got to where it


517
00:14:39,706 --> 00:14:40,386
currently is.


518
00:14:40,876 --> 00:14:42,006
So if you're on line 6 of


519
00:14:42,006 --> 00:14:43,716
function C and you got there


520
00:14:43,716 --> 00:14:45,286
because main called A, called B,


521
00:14:45,326 --> 00:14:46,926
called C, then your back trace


522
00:14:47,016 --> 00:14:48,256
is Main, A, B, C.


523
00:14:49,006 --> 00:14:50,346
When Instruments captures one of


524
00:14:50,346 --> 00:14:51,946
these back traces, it notes,


525
00:14:52,226 --> 00:14:53,356
hey, we just spent one


526
00:14:53,356 --> 00:14:54,686
millisecond in function C.


527
00:14:54,686 --> 00:14:56,916
It says one millisecond, because


528
00:14:56,916 --> 00:14:58,056
that is our sampling interval


529
00:14:58,056 --> 00:14:59,016
for recording once every


530
00:14:59,016 --> 00:14:59,546
millisecond.


531
00:15:01,016 --> 00:15:02,696
Now, on the main thread, all


532
00:15:02,696 --> 00:15:03,626
these back traces are going to


533
00:15:03,626 --> 00:15:04,556
start with the Main function,


534
00:15:04,556 --> 00:15:05,596
and they're probably going to


535
00:15:05,596 --> 00:15:06,666
call Application Main, and


536
00:15:06,796 --> 00:15:08,356
they're going to branch out, all


537
00:15:08,356 --> 00:15:09,256
through your source code after


538
00:15:09,256 --> 00:15:09,536
that.


539
00:15:10,206 --> 00:15:11,896
We can collapse these back


540
00:15:11,956 --> 00:15:13,266
traces together, and overlay


541
00:15:13,266 --> 00:15:15,316
them into a prefix tree, so they


542
00:15:15,316 --> 00:15:16,916
start at Main and work their way


543
00:15:16,916 --> 00:15:16,983
out.


544
00:15:17,156 --> 00:15:18,646
And we can bubble up those


545
00:15:18,646 --> 00:15:19,836
millisecond counters that we


546
00:15:19,836 --> 00:15:21,386
captured at the top, so that we


547
00:15:21,386 --> 00:15:23,416
can hierarchically see how much


548
00:15:23,486 --> 00:15:24,716
time was spent in all the


549
00:15:24,716 --> 00:15:25,896
different areas of our source


550
00:15:25,896 --> 00:15:26,126
code.


551
00:15:26,686 --> 00:15:27,636
And we are going to look at this


552
00:15:27,636 --> 00:15:29,416
data to try and find redundant


553
00:15:29,416 --> 00:15:31,066
and unnecessary operations that


554
00:15:31,066 --> 00:15:32,696
we can make faster, and that is


555
00:15:32,696 --> 00:15:33,836
our primary method that we are


556
00:15:33,836 --> 00:15:34,916
going to use to improve the


557
00:15:34,916 --> 00:15:36,076
performance of our application.


558
00:15:37,026 --> 00:15:39,316
Now, as you can imagine, we're


559
00:15:39,316 --> 00:15:40,606
capturing thousands of back


560
00:15:40,606 --> 00:15:41,456
traces per second.


561
00:15:41,456 --> 00:15:43,326
There is an overwhelming amount


562
00:15:43,326 --> 00:15:44,666
of data for you to wade through


563
00:15:44,666 --> 00:15:45,246
in instruments.


564
00:15:46,146 --> 00:15:48,356
My primary advice to you is that


565
00:15:48,356 --> 00:15:49,946
you want to filter this data as


566
00:15:49,946 --> 00:15:51,596
much as possible so that you can


567
00:15:51,596 --> 00:15:53,166
see the course grain performance


568
00:15:53,166 --> 00:15:55,616
leads, and not focus on minutia.


569
00:15:55,616 --> 00:15:56,376
All right?


570
00:15:56,376 --> 00:15:57,786
So I want to show you how to


571
00:15:57,786 --> 00:15:59,046
apply a bunch of powerful


572
00:15:59,046 --> 00:16:00,086
filters and instruments.


573
00:16:04,276 --> 00:16:06,196
So as I did the recording, you


574
00:16:06,196 --> 00:16:07,436
remember, I had the track view


575
00:16:07,436 --> 00:16:07,806
visible.


576
00:16:09,356 --> 00:16:10,476
I did that because I wanted to


577
00:16:10,476 --> 00:16:12,296
see how the CPU utilization


578
00:16:12,296 --> 00:16:13,766
changed and where it was


579
00:16:13,766 --> 00:16:15,836
changing, while I was creating


580
00:16:15,836 --> 00:16:18,156
new tabs, and I noted to myself


581
00:16:18,156 --> 00:16:19,416
that it was right here.


582
00:16:20,186 --> 00:16:21,786
I simply dragged and selected


583
00:16:21,856 --> 00:16:26,076
over that area of the trace, and


584
00:16:26,076 --> 00:16:27,786
I've caused instruments to only


585
00:16:27,786 --> 00:16:31,666
focus its back trace data on


586
00:16:31,666 --> 00:16:32,706
just that time interval.


587
00:16:33,126 --> 00:16:34,356
Everything over here, this is


588
00:16:34,356 --> 00:16:35,556
before I was creating tabs.


589
00:16:36,026 --> 00:16:37,516
Everything over here, this is


590
00:16:37,626 --> 00:16:38,666
after I was creating tabs, when


591
00:16:38,666 --> 00:16:39,786
I was quitting the application.


592
00:16:40,056 --> 00:16:40,976
That's not what I'm trying to


593
00:16:40,976 --> 00:16:42,576
optimize right now, so I don't


594
00:16:42,676 --> 00:16:45,016
need to see that data.


595
00:16:45,196 --> 00:16:48,376
Now, in the bottom area of the


596
00:16:48,376 --> 00:16:49,836
Instruments window, Instruments


597
00:16:49,836 --> 00:16:50,926
is showing me all the traces it


598
00:16:50,926 --> 00:16:51,366
collected.


599
00:16:51,786 --> 00:16:55,376
By default, there is one row per


600
00:16:55,446 --> 00:16:56,206
thread that was running.


601
00:16:56,646 --> 00:16:57,756
And in this example it looks


602
00:16:57,756 --> 00:16:58,856
like there was only four threads


603
00:16:58,856 --> 00:16:59,126
running.


604
00:16:59,386 --> 00:17:00,556
Sometimes you'll have much more.


605
00:17:00,626 --> 00:17:01,716
Depends on how concurrent your


606
00:17:01,716 --> 00:17:02,436
application is.


607
00:17:03,306 --> 00:17:04,796
I often like to collapse these


608
00:17:04,796 --> 00:17:06,276
in the name of focusing, and I


609
00:17:06,276 --> 00:17:07,756
also like to collapse them so


610
00:17:07,756 --> 00:17:10,356
they're based on the top level


611
00:17:10,356 --> 00:17:11,976
functions executing in each of


612
00:17:11,976 --> 00:17:13,346
the threads, rather than the


613
00:17:13,346 --> 00:17:14,636
thread IDs, because that


614
00:17:14,636 --> 00:17:16,165
corresponds better with how I


615
00:17:16,165 --> 00:17:17,406
use Grand Central Dispatch.


616
00:17:18,616 --> 00:17:19,715
Down in the bottom of the


617
00:17:19,715 --> 00:17:21,076
Instruments window, I'm going to


618
00:17:21,076 --> 00:17:22,236
click on this button that says


619
00:17:22,266 --> 00:17:24,576
Call Tree, and I'm going to zoom


620
00:17:24,576 --> 00:17:25,536
in on it, so you can see what


621
00:17:25,536 --> 00:17:26,076
I'm about to do.


622
00:17:26,806 --> 00:17:27,935
There are several filters


623
00:17:27,935 --> 00:17:28,556
available here.


624
00:17:28,906 --> 00:17:30,136
One of them is separate by


625
00:17:30,136 --> 00:17:30,516
thread.


626
00:17:30,516 --> 00:17:31,756
It is on by default.


627
00:17:31,886 --> 00:17:33,176
I am going to go ahead and


628
00:17:33,176 --> 00:17:35,466
disable that, and instead, all


629
00:17:35,466 --> 00:17:36,326
of the threads are going to be


630
00:17:36,326 --> 00:17:37,586
grouped by their top level entry


631
00:17:37,586 --> 00:17:38,926
point, rather than their thread


632
00:17:39,596 --> 00:17:39,666
ID.


633
00:17:42,356 --> 00:17:45,646
Now, looking at this trace, I


634
00:17:45,646 --> 00:17:46,946
can see that of all these


635
00:17:46,946 --> 00:17:49,336
threads running, which by the


636
00:17:49,336 --> 00:17:50,816
way, below the main trace, which


637
00:17:50,816 --> 00:17:53,126
is the aggregate CPU usage, the


638
00:17:53,126 --> 00:17:54,416
CPU usage is broken down per


639
00:17:54,416 --> 00:17:56,086
thread, I can see that almost


640
00:17:56,086 --> 00:17:57,046
all the other threads were


641
00:17:57,176 --> 00:17:58,456
largely inactive during this


642
00:17:58,456 --> 00:17:58,826
trace.


643
00:17:59,416 --> 00:18:00,836
I can focus on just the main


644
00:18:00,836 --> 00:18:03,036
thread by selecting it here, and


645
00:18:03,036 --> 00:18:04,626
now I'm only looking at traces


646
00:18:04,776 --> 00:18:06,476
from the main thread during this


647
00:18:06,526 --> 00:18:07,046
time period.


648
00:18:08,086 --> 00:18:09,606
I'm ready to start digging into


649
00:18:09,606 --> 00:18:11,336
this call hierarchy, so I can


650
00:18:11,336 --> 00:18:12,376
see what my application was


651
00:18:12,416 --> 00:18:12,676
doing.


652
00:18:13,606 --> 00:18:15,106
Often, I'll walk this with the


653
00:18:15,106 --> 00:18:17,116
keyboard, by just pressing right


654
00:18:17,116 --> 00:18:18,356
arrow and down, over and over


655
00:18:18,356 --> 00:18:18,666
again.


656
00:18:19,366 --> 00:18:21,026
But I'd like to show you the


657
00:18:21,026 --> 00:18:22,526
heaviest back trace inspector


658
00:18:22,526 --> 00:18:24,136
that Instruments offers.


659
00:18:24,496 --> 00:18:25,416
If your Inspector is not


660
00:18:25,416 --> 00:18:26,886
visible, you can toggle it with


661
00:18:26,886 --> 00:18:28,756
this button, and the heaviest


662
00:18:28,756 --> 00:18:29,746
back trace will be available


663
00:18:29,836 --> 00:18:31,706
here, in this tab, Extended


664
00:18:31,706 --> 00:18:32,046
Detail.


665
00:18:32,866 --> 00:18:34,296
Now, the heaviest back trace is


666
00:18:34,296 --> 00:18:35,496
just the trace that occurred


667
00:18:35,496 --> 00:18:36,566
most frequently.


668
00:18:36,566 --> 00:18:37,486
It's the back trace that


669
00:18:37,486 --> 00:18:39,196
happened most frequently while


670
00:18:39,196 --> 00:18:40,706
we were recording under the


671
00:18:40,706 --> 00:18:41,476
current selection.


672
00:18:42,116 --> 00:18:43,516
And you can use this to quickly


673
00:18:43,516 --> 00:18:45,176
navigate many frames deep at a


674
00:18:45,176 --> 00:18:45,556
time.


675
00:18:46,496 --> 00:18:47,846
I typically look through here,


676
00:18:48,096 --> 00:18:49,366
looking for my own APIs, and


677
00:18:49,656 --> 00:18:50,816
things that would surprise me


678
00:18:50,816 --> 00:18:51,856
for taking up this amount of


679
00:18:51,856 --> 00:18:54,336
time, or for areas where we make


680
00:18:54,336 --> 00:18:56,036
a significant branching point in


681
00:18:56,036 --> 00:18:57,306
the number of samples.


682
00:18:58,356 --> 00:18:59,996
Now, looking through here, I see


683
00:18:59,996 --> 00:19:02,036
this call, which is to IDE


684
00:19:02,036 --> 00:19:04,636
Navigator, replacement view, did


685
00:19:04,636 --> 00:19:05,576
install view controller.


686
00:19:05,936 --> 00:19:07,106
Now, I'm familiar with this API,


687
00:19:07,106 --> 00:19:08,746
because it's an internal API of


688
00:19:08,746 --> 00:19:09,176
Xcode.


689
00:19:10,156 --> 00:19:12,686
And in the trace, I can see over


690
00:19:12,686 --> 00:19:13,636
here on the left-hand side of


691
00:19:13,636 --> 00:19:14,686
the window that it is


692
00:19:14,686 --> 00:19:18,656
responsible for 1.19 seconds of


693
00:19:18,656 --> 00:19:19,846
the total time we're recording,


694
00:19:20,116 --> 00:19:21,596
or 45% of the time.


695
00:19:22,176 --> 00:19:24,196
That is far and away above my


696
00:19:24,196 --> 00:19:25,356
expectations for how much this


697
00:19:25,356 --> 00:19:27,756
method should cost.


698
00:19:27,936 --> 00:19:29,526
However, it's hard to focus on


699
00:19:29,526 --> 00:19:30,386
what is happening here.


700
00:19:30,586 --> 00:19:32,336
Right? I'm, there is all this


701
00:19:32,336 --> 00:19:33,346
other stuff at the bottom of the


702
00:19:33,346 --> 00:19:35,926
trace, and it looks like I'm,


703
00:19:35,926 --> 00:19:37,596
you know, 30 or 40 stack ranges


704
00:19:37,596 --> 00:19:37,736
deep.


705
00:19:38,056 --> 00:19:39,096
That can be intimidating.


706
00:19:39,456 --> 00:19:40,726
I want to show you how to focus.


707
00:19:41,276 --> 00:19:43,006
The first technique is back here


708
00:19:43,006 --> 00:19:46,976
in that call tree popover again.


709
00:19:47,176 --> 00:19:49,126
I'm going to use this popover to


710
00:19:49,126 --> 00:19:50,516
choose the flattened recursion.


711
00:19:51,756 --> 00:19:55,126
Let's go ahead and do that.


712
00:19:55,196 --> 00:19:56,326
And now you can see that, that


713
00:19:56,326 --> 00:19:57,526
repeated set of method calls


714
00:19:57,526 --> 00:20:00,466
that was right here, oops, has


715
00:20:00,466 --> 00:20:01,086
been collapsed.


716
00:20:02,396 --> 00:20:04,536
I'm sorry, let me scroll down.


717
00:20:05,586 --> 00:20:06,466
That has been collapsed.


718
00:20:06,816 --> 00:20:08,436
In fact, I'm confident that I


719
00:20:08,436 --> 00:20:09,586
want to continue my performance


720
00:20:09,586 --> 00:20:11,556
investigation inside of this IDE


721
00:20:11,556 --> 00:20:14,506
Navigator area, API call, and I


722
00:20:14,506 --> 00:20:16,336
can refocus the entire call tree


723
00:20:17,216 --> 00:20:19,376
by context, clicking here, and


724
00:20:19,376 --> 00:20:20,746
choosing Focus on Subtree.


725
00:20:21,516 --> 00:20:22,446
And Instruments is going to take


726
00:20:22,446 --> 00:20:23,896
that symbol up to the top of the


727
00:20:23,896 --> 00:20:25,386
call graph, it's going to remove


728
00:20:25,386 --> 00:20:26,556
everything else, and it is going


729
00:20:26,556 --> 00:20:28,456
to reset the percentages at 100%


730
00:20:28,726 --> 00:20:30,166
so I can focus on just this.


731
00:20:30,796 --> 00:20:33,096
Now, I can continue to walk this


732
00:20:33,096 --> 00:20:35,686
sample with the arrow keys to


733
00:20:35,686 --> 00:20:36,486
see what we're doing.


734
00:20:36,686 --> 00:20:38,496
And I'm familiar with these


735
00:20:38,496 --> 00:20:38,906
APIs.


736
00:20:38,906 --> 00:20:40,046
And it looks like we're doing


737
00:20:40,206 --> 00:20:41,196
state restoration.


738
00:20:41,766 --> 00:20:43,136
And as I continue to expand


739
00:20:43,136 --> 00:20:45,936
this, I can see that we are sort


740
00:20:45,936 --> 00:20:47,176
of deep inside the table view,


741
00:20:47,466 --> 00:20:49,696
and in addition to there being


742
00:20:49,696 --> 00:20:51,476
this sort of hot call path, you


743
00:20:51,476 --> 00:20:52,986
know, that is taking large


744
00:20:52,986 --> 00:20:54,116
number of the total percentage,


745
00:20:54,436 --> 00:20:55,246
there's all these other


746
00:20:55,246 --> 00:20:56,566
incidental samples as well.


747
00:20:58,266 --> 00:20:59,896
It's easy to get distracted by


748
00:20:59,896 --> 00:21:00,236
these.


749
00:21:01,286 --> 00:21:03,766
One of them here is OPC Message


750
00:21:03,766 --> 00:21:04,076
Send.


751
00:21:04,646 --> 00:21:06,926
This can occur all over your


752
00:21:06,926 --> 00:21:07,676
tracers if you're writing


753
00:21:07,676 --> 00:21:08,296
objective C.


754
00:21:08,606 --> 00:21:09,916
Even if you're writing Swift


755
00:21:09,916 --> 00:21:10,936
code, as you work your way into


756
00:21:10,936 --> 00:21:11,966
the system libraries, you'll see


757
00:21:11,966 --> 00:21:12,296
this.


758
00:21:12,636 --> 00:21:13,856
You'll often see its counterpart


759
00:21:13,856 --> 00:21:15,916
functions, OPC, Load Strong,


760
00:21:15,916 --> 00:21:18,726
Load Weak, etc., Retain, you can


761
00:21:18,726 --> 00:21:20,936
remove all that content from the


762
00:21:20,936 --> 00:21:23,826
call tree by context clicking on


763
00:21:23,866 --> 00:21:28,096
it, and choosing Charge OPC to


764
00:21:28,096 --> 00:21:28,706
Callers.


765
00:21:29,406 --> 00:21:30,436
That's going to tell Instruments


766
00:21:30,466 --> 00:21:31,886
to take all the samples that


767
00:21:31,886 --> 00:21:33,686
came from lib OPC and remove


768
00:21:33,686 --> 00:21:35,176
them from the call data, but


769
00:21:35,176 --> 00:21:36,456
keep the time as attributed to


770
00:21:36,456 --> 00:21:37,636
the parent frames that called


771
00:21:37,636 --> 00:21:37,846
them.


772
00:21:38,176 --> 00:21:39,776
I tend to treat those objective


773
00:21:39,776 --> 00:21:41,126
C runtime functions as just the


774
00:21:41,126 --> 00:21:42,266
cost of doing business when


775
00:21:42,266 --> 00:21:43,306
writing objective C code.


776
00:21:43,706 --> 00:21:45,196
It's rarely the case that I'm


777
00:21:45,196 --> 00:21:46,136
going to attempt to optimize


778
00:21:46,136 --> 00:21:48,396
them out, so I just prefer to


779
00:21:48,456 --> 00:21:49,596
remove them from the data, so I


780
00:21:49,596 --> 00:21:50,886
can focus on the things that I'm


781
00:21:50,886 --> 00:21:51,916
likely to take action on.


782
00:21:53,176 --> 00:21:55,466
Another very powerful filter


783
00:21:55,466 --> 00:21:56,866
that you can apply, and one that


784
00:21:56,866 --> 00:21:59,076
I'm going to use to remove all


785
00:21:59,076 --> 00:22:00,356
these small samples that


786
00:22:00,356 --> 00:22:02,186
occurred during this set of


787
00:22:02,226 --> 00:22:04,676
frames, is here in the call tree


788
00:22:04,676 --> 00:22:05,596
constraint section.


789
00:22:06,126 --> 00:22:07,646
Let me show you.


790
00:22:11,146 --> 00:22:12,716
I'm going to tell Instruments


791
00:22:12,716 --> 00:22:14,006
that I would only like to see


792
00:22:14,486 --> 00:22:16,236
areas of the trace that


793
00:22:16,236 --> 00:22:18,256
accounted for let's say 20 or


794
00:22:18,256 --> 00:22:18,966
more samples.


795
00:22:19,256 --> 00:22:20,566
I'm picking 20 because I know


796
00:22:20,566 --> 00:22:21,606
that I've selected about a two


797
00:22:21,606 --> 00:22:23,066
second interval and 20


798
00:22:23,066 --> 00:22:24,376
milliseconds is going to


799
00:22:24,376 --> 00:22:26,076
represent about 1% of the total


800
00:22:26,076 --> 00:22:27,036
work, and that is about the


801
00:22:27,036 --> 00:22:28,376
granularity that I like to work


802
00:22:28,376 --> 00:22:29,846
at by default.


803
00:22:31,336 --> 00:22:32,926
So with call tree constraints


804
00:22:33,986 --> 00:22:37,206
set to a minimum of 20, I now


805
00:22:37,206 --> 00:22:38,846
focus this down much more


806
00:22:38,846 --> 00:22:39,516
significantly.


807
00:22:40,456 --> 00:22:41,346
Now, I mentioned here that we


808
00:22:41,346 --> 00:22:42,856
were expanding out my view


809
00:22:42,856 --> 00:22:43,296
items.


810
00:22:43,336 --> 00:22:45,026
I see that in the fact that


811
00:22:45,026 --> 00:22:46,446
we're calling NS outline view,


812
00:22:46,446 --> 00:22:47,836
expand item, expand children.


813
00:22:48,436 --> 00:22:50,476
Now, a lot of people would stop


814
00:22:50,946 --> 00:22:51,816
with the call graph at this


815
00:22:51,876 --> 00:22:52,146
point.


816
00:22:52,556 --> 00:22:54,136
They'd see I'm calling into a


817
00:22:54,136 --> 00:22:55,226
system framework, and I'm


818
00:22:55,226 --> 00:22:56,346
spending a lot of time there.


819
00:22:56,706 --> 00:22:58,086
This isn't my fault, right?


820
00:22:58,086 --> 00:22:58,926
What can I do about this?


821
00:22:58,926 --> 00:23:00,486
I can't optimize NS Outline


822
00:23:00,486 --> 00:23:01,976
View, Expand Items.


823
00:23:03,126 --> 00:23:04,606
You absolutely have the power to


824
00:23:04,606 --> 00:23:05,806
influence these situations.


825
00:23:06,336 --> 00:23:07,706
For example, the system


826
00:23:07,706 --> 00:23:08,936
framework could be spending all


827
00:23:08,936 --> 00:23:10,976
of this time because it's


828
00:23:10,976 --> 00:23:11,966
operating on data that you


829
00:23:11,966 --> 00:23:12,526
provided it.


830
00:23:13,366 --> 00:23:14,546
It could be taking a lot of time


831
00:23:14,616 --> 00:23:15,496
because you are calling this


832
00:23:15,496 --> 00:23:16,996
method thousands or millions of


833
00:23:16,996 --> 00:23:17,476
times.


834
00:23:18,366 --> 00:23:19,526
It could be taking a lot of time


835
00:23:19,526 --> 00:23:20,666
because it's calling back into


836
00:23:20,666 --> 00:23:22,376
your code through delegation.


837
00:23:22,376 --> 00:23:24,566
And most importantly, you can


838
00:23:24,566 --> 00:23:25,906
get an insight into what the


839
00:23:25,906 --> 00:23:27,836
system framework is doing by


840
00:23:27,836 --> 00:23:28,886
expanding down through the


841
00:23:28,886 --> 00:23:30,186
Instruments tree, and looking at


842
00:23:30,186 --> 00:23:31,256
the names of functions that are


843
00:23:31,256 --> 00:23:31,816
being called.


844
00:23:32,216 --> 00:23:33,766
In fact, that's exactly how I


845
00:23:33,766 --> 00:23:36,966
learned to fix this bug.


846
00:23:37,166 --> 00:23:39,166
As I expand the trace into the


847
00:23:39,166 --> 00:23:41,406
outline view, I can see that it


848
00:23:41,406 --> 00:23:42,726
is calling these two methods


849
00:23:42,726 --> 00:23:42,966
here.


850
00:23:44,716 --> 00:23:47,106
Batch Expand Items with item


851
00:23:47,106 --> 00:23:49,266
entries, expand children, and do


852
00:23:49,266 --> 00:23:50,686
work after end updates.


853
00:23:51,756 --> 00:23:53,356
Now, those are big clues to me


854
00:23:53,356 --> 00:23:54,366
that there is probably some


855
00:23:54,366 --> 00:23:55,686
opportunity for efficiency


856
00:23:55,686 --> 00:23:56,226
through batching.


857
00:23:56,226 --> 00:23:58,326
As you could imagine, the


858
00:23:58,326 --> 00:24:00,886
outline view starts with a small


859
00:24:00,886 --> 00:24:02,386
set of items, and then we are


860
00:24:02,386 --> 00:24:03,906
trying to restore expansion


861
00:24:03,906 --> 00:24:05,676
state in this area of our code,


862
00:24:05,676 --> 00:24:06,666
and so we are telling it to


863
00:24:06,666 --> 00:24:08,256
open, for example, the top item.


864
00:24:08,506 --> 00:24:09,436
And when we tell it to open the


865
00:24:09,436 --> 00:24:11,406
top item, internally you might


866
00:24:11,406 --> 00:24:12,576
imagine that it moves all the


867
00:24:12,576 --> 00:24:13,296
other items down.


868
00:24:14,056 --> 00:24:15,096
Then you ask me to expand the


869
00:24:15,096 --> 00:24:15,716
second item.


870
00:24:16,106 --> 00:24:17,196
It moves all the items down


871
00:24:17,196 --> 00:24:17,516
again.


872
00:24:17,906 --> 00:24:19,386
And the third item, and so on.


873
00:24:19,386 --> 00:24:20,666
And by the time you're done,


874
00:24:20,966 --> 00:24:22,546
you've moved those bottom items


875
00:24:22,586 --> 00:24:24,246
down thousands of times.


876
00:24:25,166 --> 00:24:26,396
That is all redundant work, and


877
00:24:26,396 --> 00:24:27,626
that is exactly the sort of


878
00:24:27,656 --> 00:24:28,976
thing I'm looking to eliminate


879
00:24:29,206 --> 00:24:30,126
when I'm trying to improve


880
00:24:30,126 --> 00:24:30,736
performance.


881
00:24:31,406 --> 00:24:32,596
Now the fact of these method


882
00:24:32,596 --> 00:24:35,376
calls talk about batching leads


883
00:24:35,376 --> 00:24:36,666
me to believe that there is


884
00:24:36,666 --> 00:24:38,006
probably some API where I can


885
00:24:38,006 --> 00:24:39,416
ask the outline view to do the


886
00:24:39,416 --> 00:24:41,436
work in bulk so it computes all


887
00:24:41,436 --> 00:24:43,336
the positions just once, instead


888
00:24:43,336 --> 00:24:44,386
of over and over again as I make


889
00:24:44,426 --> 00:24:44,986
the calls.


890
00:24:46,236 --> 00:24:48,256
I also see a call that says to


891
00:24:48,256 --> 00:24:50,056
do the work after end updates.


892
00:24:50,406 --> 00:24:52,616
Now, sometimes an API will offer


893
00:24:52,726 --> 00:24:53,956
sort of bulk method that


894
00:24:53,956 --> 00:24:55,696
operates on an array, and other


895
00:24:55,696 --> 00:24:57,416
times, it will offer a sort of


896
00:24:57,416 --> 00:24:59,456
transactional API that says I'm


897
00:24:59,456 --> 00:25:00,806
going to begin making changes,


898
00:25:01,046 --> 00:25:01,716
then you make a bunch of


899
00:25:01,716 --> 00:25:02,996
changes, and then you say you're


900
00:25:02,996 --> 00:25:05,046
done, and it computes something


901
00:25:05,046 --> 00:25:05,856
that happened for the whole


902
00:25:05,856 --> 00:25:07,356
range of your changes, more


903
00:25:07,356 --> 00:25:08,656
efficiently than if it had done


904
00:25:08,656 --> 00:25:10,116
them all individually.


905
00:25:11,126 --> 00:25:12,306
So at this point, I would head


906
00:25:12,306 --> 00:25:14,336
over to the NS Outline View, or


907
00:25:14,336 --> 00:25:15,996
NS Table View API, and I would


908
00:25:15,996 --> 00:25:17,296
look for some such method.


909
00:25:17,686 --> 00:25:19,646
And there is exactly one there.


910
00:25:19,646 --> 00:25:20,936
In NS Table View, there is


911
00:25:20,936 --> 00:25:22,176
methods for beginning and end


912
00:25:22,176 --> 00:25:23,546
updating, that allow the table


913
00:25:23,546 --> 00:25:25,096
view to coalesce, and make all


914
00:25:25,096 --> 00:25:26,296
this work significantly more


915
00:25:26,296 --> 00:25:26,666
efficient.


916
00:25:27,426 --> 00:25:28,856
Of course, we adopted that in


917
00:25:28,896 --> 00:25:29,606
Xcode 10.


918
00:25:30,246 --> 00:25:32,966
Let me show you.


919
00:25:33,046 --> 00:25:34,376
I'm going to launch Xcode 10.


920
00:25:38,056 --> 00:25:39,136
I'm going to open the source as


921
00:25:39,136 --> 00:25:43,086
an application, and I'm going to


922
00:25:43,086 --> 00:25:44,056
create a couple of tabs.


923
00:25:44,586 --> 00:25:46,116
And you can see, there is no


924
00:25:46,116 --> 00:25:47,666
awful flashing, and the tabs


925
00:25:47,666 --> 00:25:48,626
open much more quickly.


926
00:25:49,506 --> 00:25:52,686
Now, I'd like the tabs to open


927
00:25:52,876 --> 00:25:54,846
even quicker than that, right?


928
00:25:54,846 --> 00:25:55,916
So what am I going to do next?


929
00:25:56,596 --> 00:25:57,586
I got lucky here.


930
00:25:58,536 --> 00:25:59,496
It's not every day that you're


931
00:25:59,496 --> 00:26:00,956
going to go into the trace, and


932
00:26:00,956 --> 00:26:02,406
find something so obvious and


933
00:26:02,406 --> 00:26:03,996
easy to fix, that is responsible


934
00:26:03,996 --> 00:26:05,156
for 50% of the sample.


935
00:26:05,916 --> 00:26:08,456
Right? In fact, there is not


936
00:26:08,456 --> 00:26:09,896
going to be any other huge lead


937
00:26:09,896 --> 00:26:10,806
sitting there waiting for me.


938
00:26:11,686 --> 00:26:12,746
Instead, what I'm going to need


939
00:26:12,746 --> 00:26:14,626
to do is go through that whole


940
00:26:14,626 --> 00:26:15,656
sample, with those course


941
00:26:15,656 --> 00:26:17,616
filters applied, so I'm only


942
00:26:17,616 --> 00:26:18,696
looking at operations that take


943
00:26:18,696 --> 00:26:20,286
about 1% of the time or more,


944
00:26:20,286 --> 00:26:21,816
and I'm going to look for every


945
00:26:21,816 --> 00:26:23,436
single thing that I see that I


946
00:26:23,436 --> 00:26:24,836
think I can come up with some


947
00:26:24,836 --> 00:26:25,986
mechanism for making a little


948
00:26:25,986 --> 00:26:26,536
bit faster.


949
00:26:28,056 --> 00:26:29,016
I'm going to note them all down


950
00:26:29,016 --> 00:26:30,496
on a piece of paper or in a text


951
00:26:30,496 --> 00:26:32,216
document or something, and then


952
00:26:32,216 --> 00:26:33,436
I'm going to start solving them.


953
00:26:33,746 --> 00:26:34,736
Now, I need to pick an order to


954
00:26:34,736 --> 00:26:35,656
solve them in, right?


955
00:26:35,656 --> 00:26:37,326
Because sometimes the fifth


956
00:26:37,326 --> 00:26:38,716
thing on the list, fixing it


957
00:26:38,716 --> 00:26:40,016
with an obsolete, whatever fix


958
00:26:40,016 --> 00:26:40,816
you would do for the second


959
00:26:40,816 --> 00:26:42,516
thing on the list, and it feels


960
00:26:42,516 --> 00:26:43,646
bad to do them in the wrong


961
00:26:43,646 --> 00:26:44,516
order, such that you did


962
00:26:44,516 --> 00:26:45,536
redundant work, because that's


963
00:26:45,586 --> 00:26:46,456
the whole thing we're trying to


964
00:26:46,456 --> 00:26:47,506
remove in the first place, is


965
00:26:47,506 --> 00:26:48,116
redundant work.


966
00:26:48,746 --> 00:26:50,476
But it's very hard to predict


967
00:26:50,476 --> 00:26:51,376
how these things are all going


968
00:26:51,376 --> 00:26:51,826
to play out.


969
00:26:52,066 --> 00:26:53,316
And you often can't know until


970
00:26:53,316 --> 00:26:54,316
you've already done the work.


971
00:26:54,746 --> 00:26:57,746
So do not let this stop you from


972
00:26:57,746 --> 00:26:59,446
getting started, because you're


973
00:26:59,446 --> 00:27:00,956
going to get your second 30%


974
00:27:00,956 --> 00:27:03,536
improvement by stacking 10 3%


975
00:27:03,536 --> 00:27:04,186
improvements.


976
00:27:05,706 --> 00:27:05,976
Okay?


977
00:27:07,316 --> 00:27:10,756
Now, I want to go back to the


978
00:27:10,756 --> 00:27:13,516
slides, and show you some of the


979
00:27:13,516 --> 00:27:14,766
techniques we typically use to


980
00:27:14,766 --> 00:27:15,606
make those continued


981
00:27:15,606 --> 00:27:16,126
improvements.


982
00:27:21,346 --> 00:27:22,326
Far and away, the thing that


983
00:27:22,326 --> 00:27:23,896
comes up the most frequently is


984
00:27:23,896 --> 00:27:25,246
using those same techniques the


985
00:27:25,246 --> 00:27:26,236
outline view was using.


986
00:27:26,396 --> 00:27:28,276
Batching and deferring, right?


987
00:27:28,276 --> 00:27:29,736
You have an API, and when the


988
00:27:29,736 --> 00:27:31,526
API is called, it has some side


989
00:27:31,526 --> 00:27:31,836
effect.


990
00:27:32,196 --> 00:27:33,226
And then you have some code


991
00:27:33,226 --> 00:27:34,426
calling your API in the loop.


992
00:27:34,426 --> 00:27:35,396
That's what you're doing-- the


993
00:27:35,586 --> 00:27:36,536
primary piece of work that is


994
00:27:36,536 --> 00:27:37,996
being requested, and having a


995
00:27:37,996 --> 00:27:38,566
side effect.


996
00:27:39,206 --> 00:27:40,986
Well, if no one was reading the


997
00:27:40,986 --> 00:27:42,516
result of the side effect, then


998
00:27:42,516 --> 00:27:43,416
you're doing that work


999
00:27:43,416 --> 00:27:44,536
redundantly, over and over


1000
00:27:44,536 --> 00:27:44,916
again.


1001
00:27:45,736 --> 00:27:47,016
You can often get a much more


1002
00:27:47,016 --> 00:27:48,696
efficient interface by using a


1003
00:27:48,696 --> 00:27:50,366
batch interface, where a client


1004
00:27:50,366 --> 00:27:52,376
gives you an array or some sort


1005
00:27:52,376 --> 00:27:53,476
of collection of all the work to


1006
00:27:53,476 --> 00:27:54,796
be done, so that you can compute


1007
00:27:54,796 --> 00:27:56,056
that side effect just once.


1008
00:27:57,156 --> 00:27:58,176
Now, sometimes you have many


1009
00:27:58,176 --> 00:27:59,526
clients, right?


1010
00:27:59,526 --> 00:28:00,766
And they can't batch across each


1011
00:28:00,766 --> 00:28:02,186
other, and you can get even--


1012
00:28:02,596 --> 00:28:03,606
you can still get that same


1013
00:28:03,606 --> 00:28:04,946
style of performance through


1014
00:28:04,946 --> 00:28:06,346
deferring the work and doing it


1015
00:28:06,346 --> 00:28:06,796
lazily.


1016
00:28:09,196 --> 00:28:10,996
A third easy way to improve


1017
00:28:10,996 --> 00:28:11,966
performance is you look through


1018
00:28:11,966 --> 00:28:14,026
that instrument's trace, is to


1019
00:28:14,026 --> 00:28:15,156
find areas where you see the


1020
00:28:15,156 --> 00:28:17,016
same thing being computed over


1021
00:28:17,016 --> 00:28:17,656
and over again.


1022
00:28:18,236 --> 00:28:19,556
For example, you have a method


1023
00:28:19,676 --> 00:28:20,856
in its computing, the size of


1024
00:28:20,856 --> 00:28:22,526
some text, then you see the same


1025
00:28:22,526 --> 00:28:24,156
thing happening several frames


1026
00:28:24,156 --> 00:28:25,946
later, for the same text, and


1027
00:28:25,946 --> 00:28:27,006
again, and again.


1028
00:28:27,436 --> 00:28:28,426
Now, in this situation, of


1029
00:28:28,496 --> 00:28:29,536
course, you want to try to just


1030
00:28:29,536 --> 00:28:31,076
compute that value one time.


1031
00:28:32,076 --> 00:28:33,226
Compute it at the top, and pass


1032
00:28:33,226 --> 00:28:35,406
it down or maybe cache it.


1033
00:28:36,476 --> 00:28:37,846
Another technique you have


1034
00:28:37,846 --> 00:28:38,876
available in your UI


1035
00:28:38,876 --> 00:28:41,166
applications is considering how


1036
00:28:41,166 --> 00:28:42,296
many views you are using to


1037
00:28:42,296 --> 00:28:43,146
render your UI.


1038
00:28:43,146 --> 00:28:46,466
It can be very great for your


1039
00:28:46,466 --> 00:28:48,106
source code organization to use


1040
00:28:48,106 --> 00:28:50,216
very small views, with small


1041
00:28:50,216 --> 00:28:51,306
sets of functionality, and to


1042
00:28:51,306 --> 00:28:52,286
compose them together into


1043
00:28:52,286 --> 00:28:53,066
larger pieces.


1044
00:28:53,516 --> 00:28:55,216
But the more views you use, the


1045
00:28:55,216 --> 00:28:57,516
harder you tax the rendering and


1046
00:28:57,516 --> 00:28:58,276
layout systems.


1047
00:28:59,306 --> 00:29:01,066
Now, this is a two-way street,


1048
00:29:01,336 --> 00:29:02,776
because smaller views often led


1049
00:29:02,776 --> 00:29:04,086
you to have more fine-grain


1050
00:29:04,086 --> 00:29:05,376
caching, which can be good for


1051
00:29:05,376 --> 00:29:06,156
performance as well.


1052
00:29:07,266 --> 00:29:08,896
But generally, you can tweak the


1053
00:29:08,896 --> 00:29:10,446
number of views that you have in


1054
00:29:10,446 --> 00:29:11,606
order to have a significant


1055
00:29:11,606 --> 00:29:12,666
impact on performance.


1056
00:29:12,786 --> 00:29:14,596
It is not always best to have


1057
00:29:14,596 --> 00:29:16,556
fewer views, otherwise all of


1058
00:29:16,556 --> 00:29:17,606
our applications would just have


1059
00:29:17,686 --> 00:29:18,866
one giant view for the whole


1060
00:29:18,866 --> 00:29:19,116
thing.


1061
00:29:21,266 --> 00:29:22,396
Another technique that comes up


1062
00:29:22,396 --> 00:29:23,816
pretty frequently is using


1063
00:29:23,816 --> 00:29:24,806
direct observation.


1064
00:29:25,356 --> 00:29:26,916
We often have two areas of our


1065
00:29:26,916 --> 00:29:29,716
source code that are loosely


1066
00:29:29,716 --> 00:29:30,136
coupled.


1067
00:29:30,286 --> 00:29:31,466
Maybe one area knows about the


1068
00:29:31,466 --> 00:29:33,296
other, and they're communicating


1069
00:29:33,296 --> 00:29:34,996
with each other through some


1070
00:29:34,996 --> 00:29:36,016
indirect mechanism.


1071
00:29:36,456 --> 00:29:37,796
Maybe they're using NS


1072
00:29:37,796 --> 00:29:39,916
Notification Center, some


1073
00:29:39,966 --> 00:29:41,316
block-based call backs,


1074
00:29:41,516 --> 00:29:43,146
delegation, or key value


1075
00:29:43,146 --> 00:29:43,606
observing.


1076
00:29:45,006 --> 00:29:46,156
Now something that I see very


1077
00:29:46,216 --> 00:29:47,326
frequently is we'll have some


1078
00:29:47,326 --> 00:29:49,076
model code, and it's going in a


1079
00:29:49,076 --> 00:29:50,946
loop, being changed, and every


1080
00:29:50,946 --> 00:29:51,856
time it is going to that loop,


1081
00:29:52,206 --> 00:29:54,146
it is firing lots of KVO


1082
00:29:54,326 --> 00:29:55,136
notifications.


1083
00:29:55,386 --> 00:29:56,286
You can't actually see that in


1084
00:29:56,286 --> 00:29:57,876
the model code, of course, but


1085
00:29:57,956 --> 00:29:59,236
over in some other controller,


1086
00:29:59,526 --> 00:30:00,946
it's madly responding and trying


1087
00:30:00,946 --> 00:30:01,966
to keep up with whatever is


1088
00:30:01,966 --> 00:30:03,126
changing in the model, and


1089
00:30:03,126 --> 00:30:04,786
you're burning lots of CPU time


1090
00:30:04,786 --> 00:30:06,636
doing this, that ends up being


1091
00:30:06,636 --> 00:30:07,656
redundant when you consider the


1092
00:30:07,656 --> 00:30:08,806
whole scope of changes.


1093
00:30:09,496 --> 00:30:12,306
Now, if this was direct callouts


1094
00:30:12,776 --> 00:30:13,826
from the model code, either


1095
00:30:13,826 --> 00:30:14,866
through notifications,


1096
00:30:15,416 --> 00:30:17,106
delegation or manual block-based


1097
00:30:17,106 --> 00:30:18,426
call backs, it would be much


1098
00:30:18,426 --> 00:30:19,506
more obvious that this was


1099
00:30:19,506 --> 00:30:20,516
happening as you edited that


1100
00:30:20,516 --> 00:30:20,936
model code.


1101
00:30:21,396 --> 00:30:22,556
And you might decide that it is


1102
00:30:22,556 --> 00:30:24,366
totally appropriate to pull some


1103
00:30:24,366 --> 00:30:26,126
of those notifications out from


1104
00:30:26,126 --> 00:30:27,916
inside the loop to outside the


1105
00:30:27,916 --> 00:30:29,276
loop, to have a big impact on


1106
00:30:29,276 --> 00:30:29,906
performance.


1107
00:30:30,556 --> 00:30:31,856
Now, alternatively, on the


1108
00:30:31,856 --> 00:30:33,476
controller side, you could use


1109
00:30:33,476 --> 00:30:35,206
one of these deferring and


1110
00:30:35,206 --> 00:30:36,946
batching techniques to avoid the


1111
00:30:36,946 --> 00:30:38,336
redundant work and just not


1112
00:30:38,336 --> 00:30:39,246
respond synchronously.


1113
00:30:41,136 --> 00:30:42,216
Last, this is an easy one.


1114
00:30:42,836 --> 00:30:44,716
Once your code is already on the


1115
00:30:45,046 --> 00:30:46,386
[inaudible] happy path, you


1116
00:30:46,386 --> 00:30:47,586
know, it's already linear, and


1117
00:30:47,586 --> 00:30:48,736
it's not going to get any better


1118
00:30:48,736 --> 00:30:49,366
than linear.


1119
00:30:49,366 --> 00:30:50,346
That's sort of the minimum


1120
00:30:51,796 --> 00:30:52,766
performance that you're going to


1121
00:30:52,766 --> 00:30:52,966
get.


1122
00:30:53,626 --> 00:30:54,876
You're after all the constant


1123
00:30:54,876 --> 00:30:57,186
time improvements that you can.


1124
00:30:57,246 --> 00:30:58,676
Now, an easy one is that if


1125
00:30:58,676 --> 00:31:00,096
you're using dictionaries like


1126
00:31:00,096 --> 00:31:01,366
they were objects, then you


1127
00:31:01,366 --> 00:31:02,636
probably know you're doing this,


1128
00:31:02,926 --> 00:31:04,216
if you have a bunch of string


1129
00:31:04,216 --> 00:31:06,166
constants for all the keys, then


1130
00:31:06,166 --> 00:31:07,466
you can get a big improvement to


1131
00:31:07,466 --> 00:31:09,186
code clarity, to code


1132
00:31:09,186 --> 00:31:11,396
completion, to re-factoring, to


1133
00:31:11,396 --> 00:31:12,396
making the validating your


1134
00:31:12,396 --> 00:31:14,046
source code, by using specific


1135
00:31:14,526 --> 00:31:14,966
types.


1136
00:31:15,076 --> 00:31:16,136
It couldn't be easier with


1137
00:31:16,136 --> 00:31:18,066
strucks and swift with their


1138
00:31:18,066 --> 00:31:19,196
implicit initializers and


1139
00:31:19,196 --> 00:31:20,816
conformance to equitable hash.


1140
00:31:21,336 --> 00:31:23,646
And this can just be hands-down


1141
00:31:23,646 --> 00:31:24,586
an improvement to your source


1142
00:31:24,586 --> 00:31:26,206
code, and you'd be surprised at


1143
00:31:26,206 --> 00:31:27,916
how much time you're spending in


1144
00:31:27,916 --> 00:31:29,546
string hashing and string


1145
00:31:29,546 --> 00:31:31,126
equation if you were doing this


1146
00:31:31,126 --> 00:31:32,546
millions of times on lots of


1147
00:31:32,546 --> 00:31:33,316
small objects.


1148
00:31:34,516 --> 00:31:35,736
So with that, I'd like to turn


1149
00:31:35,736 --> 00:31:37,386
it over to Matthew to talk to


1150
00:31:37,386 --> 00:31:38,966
you about how we've applied


1151
00:31:39,056 --> 00:31:40,226
these techniques inside of


1152
00:31:40,226 --> 00:31:40,686
photos.


1153
00:31:42,516 --> 00:31:47,866
[ Applause ]


1154
00:31:48,366 --> 00:31:48,806
>> Thanks Jim.


1155
00:31:49,966 --> 00:31:50,656
Hi everyone.


1156
00:31:50,826 --> 00:31:52,746
I'm Matthew Lucas, an engineer


1157
00:31:52,806 --> 00:31:56,076
in the photos team, and today I


1158
00:31:56,076 --> 00:31:57,536
want to give you some practical


1159
00:31:57,536 --> 00:31:59,316
examples on performance from


1160
00:31:59,316 --> 00:32:00,296
directly from photos.


1161
00:32:01,306 --> 00:32:02,556
So first, let's talk about


1162
00:32:02,556 --> 00:32:03,536
photos for a second.


1163
00:32:04,076 --> 00:32:05,276
We are all familiar with this


1164
00:32:05,276 --> 00:32:05,466
app.


1165
00:32:06,026 --> 00:32:07,766
It lets you store, browse, and


1166
00:32:07,846 --> 00:32:09,296
experience your favorite


1167
00:32:09,296 --> 00:32:09,696
moments.


1168
00:32:10,236 --> 00:32:11,686
So you can browse your favorite


1169
00:32:11,716 --> 00:32:13,526
moments from the moments view,


1170
00:32:13,646 --> 00:32:14,596
that you can see here.


1171
00:32:14,596 --> 00:32:15,496
It's is the default view.


1172
00:32:15,926 --> 00:32:17,526
But you can also get another


1173
00:32:17,526 --> 00:32:19,456
view from the collection, or the


1174
00:32:19,456 --> 00:32:19,926
years.


1175
00:32:20,566 --> 00:32:22,166
And I'll talk more about this


1176
00:32:22,166 --> 00:32:22,736
view later.


1177
00:32:23,446 --> 00:32:25,306
Now, libraries today can go from


1178
00:32:25,306 --> 00:32:28,346
1,000 to 100,000 assets previous


1179
00:32:29,126 --> 00:32:30,066
depending on your love for


1180
00:32:30,066 --> 00:32:30,636
photography.


1181
00:32:31,196 --> 00:32:33,036
And we all love capturing those


1182
00:32:33,036 --> 00:32:34,696
fun and precious moments we live


1183
00:32:34,696 --> 00:32:34,976
every day.


1184
00:32:36,336 --> 00:32:37,366
So we are patient enough to


1185
00:32:37,366 --> 00:32:38,846
capture them, but we are less


1186
00:32:38,846 --> 00:32:40,156
patient when something like this


1187
00:32:40,156 --> 00:32:40,576
appears.


1188
00:32:41,286 --> 00:32:42,346
How would you feel if something


1189
00:32:42,346 --> 00:32:44,226
moments like this would be


1190
00:32:44,226 --> 00:32:45,296
displayed in Photos the first


1191
00:32:45,296 --> 00:32:46,926
time you launch the app?


1192
00:32:47,386 --> 00:32:48,636
Now, you may also experience


1193
00:32:48,636 --> 00:32:50,596
something like this, where we


1194
00:32:50,596 --> 00:32:51,716
are showing a lot of


1195
00:32:51,716 --> 00:32:53,106
placeholders, and that's really


1196
00:32:53,106 --> 00:32:53,586
not great.


1197
00:32:54,266 --> 00:32:55,356
Maybe you're soft scrolling,


1198
00:32:55,856 --> 00:32:57,216
you'll be lost in this gray


1199
00:32:57,216 --> 00:32:58,936
area, the [inaudible] would


1200
00:32:58,936 --> 00:33:00,736
start to load, but then you'll


1201
00:33:00,736 --> 00:33:01,766
keep scrolling and then you'll


1202
00:33:01,766 --> 00:33:02,886
experience some frame drops


1203
00:33:02,886 --> 00:33:03,876
because the views are being


1204
00:33:03,876 --> 00:33:04,326
updated.


1205
00:33:05,556 --> 00:33:06,836
Well, our goal is to not show


1206
00:33:06,836 --> 00:33:07,626
views like this.


1207
00:33:08,666 --> 00:33:09,876
We think this is not providing a


1208
00:33:09,926 --> 00:33:12,066
great user experience, but we


1209
00:33:12,066 --> 00:33:13,366
understand that sometimes it's


1210
00:33:13,366 --> 00:33:14,156
unavoidable.


1211
00:33:14,556 --> 00:33:15,706
But when it's too frequent, this


1212
00:33:15,706 --> 00:33:16,666
isn't really great.


1213
00:33:18,546 --> 00:33:19,666
Now, when you work on an app,


1214
00:33:19,666 --> 00:33:20,756
you want to make sure that it's


1215
00:33:20,756 --> 00:33:22,456
responsive, and usable at once.


1216
00:33:23,576 --> 00:33:25,296
You also want to make sure that


1217
00:33:25,296 --> 00:33:26,516
the animations are smooth.


1218
00:33:27,226 --> 00:33:30,516
And these two attributes are


1219
00:33:30,516 --> 00:33:31,796
really crucial to providing a


1220
00:33:31,796 --> 00:33:32,786
great user experience.


1221
00:33:33,446 --> 00:33:35,766
If the users don't find your app


1222
00:33:35,766 --> 00:33:37,256
relatable or pertinent, they


1223
00:33:37,256 --> 00:33:38,146
might stop using it.


1224
00:33:39,526 --> 00:33:40,706
Now, to illustrate these two


1225
00:33:40,706 --> 00:33:42,626
points, I would like to give you


1226
00:33:42,626 --> 00:33:43,426
two examples.


1227
00:33:43,716 --> 00:33:45,726
And the first one is going to be


1228
00:33:45,726 --> 00:33:47,406
how we optimize launching to


1229
00:33:47,406 --> 00:33:48,166
this moment view.


1230
00:33:48,886 --> 00:33:50,506
The second one is how we build


1231
00:33:50,506 --> 00:33:52,576
the collections and years view


1232
00:33:52,576 --> 00:33:53,866
for good scrolling preference.


1233
00:33:56,696 --> 00:33:59,876
First, let's do launching


1234
00:34:00,296 --> 00:34:02,296
[inaudible].


1235
00:34:02,716 --> 00:34:03,876
So what is launch?


1236
00:34:04,046 --> 00:34:04,986
There are three kinds of


1237
00:34:04,986 --> 00:34:05,386
launches.


1238
00:34:06,696 --> 00:34:08,176
The first and more expensive one


1239
00:34:08,176 --> 00:34:09,476
is the find referred as called,


1240
00:34:09,476 --> 00:34:11,406
and it depends the first time


1241
00:34:11,406 --> 00:34:12,335
you are going to relaunch your


1242
00:34:12,335 --> 00:34:13,186
app after it reboots.


1243
00:34:14,346 --> 00:34:15,606
So basically, nothing has been


1244
00:34:15,606 --> 00:34:17,446
cached yet, and it might require


1245
00:34:17,446 --> 00:34:19,096
some bug run processes or some


1246
00:34:19,096 --> 00:34:19,946
libraries to load.


1247
00:34:21,136 --> 00:34:23,116
Now, it also happens when the


1248
00:34:23,206 --> 00:34:24,916
system goes under memory


1249
00:34:24,916 --> 00:34:27,136
pressure and starts reclaiming


1250
00:34:27,735 --> 00:34:29,686
some memory.


1251
00:34:30,045 --> 00:34:31,485
Now, if you kill an app, it


1252
00:34:31,485 --> 00:34:32,906
might not trigger a code launch,


1253
00:34:32,906 --> 00:34:34,606
because the system decides when


1254
00:34:34,606 --> 00:34:38,766
the resources should be paged


1255
00:34:38,766 --> 00:34:38,976
out.


1256
00:34:39,065 --> 00:34:40,466
And when you kill an app, and


1257
00:34:40,466 --> 00:34:41,646
you relaunch it a few second


1258
00:34:41,726 --> 00:34:43,835
later, it's almost guaranteed


1259
00:34:43,835 --> 00:34:45,565
that you'll hit a warm launch.


1260
00:34:46,036 --> 00:34:47,706
And we call it warm, because the


1261
00:34:47,706 --> 00:34:50,386
resources or the dependents are


1262
00:34:50,386 --> 00:34:52,116
still in the cache, so it's


1263
00:34:52,116 --> 00:34:52,996
faster to launch.


1264
00:34:54,525 --> 00:34:56,636
Now, the last type is-- we call


1265
00:34:56,636 --> 00:34:59,026
it hot, and it's basically a


1266
00:34:59,026 --> 00:35:00,926
resume, because it's when your


1267
00:35:00,926 --> 00:35:02,526
app is already running and is


1268
00:35:02,526 --> 00:35:03,666
being brought back to the


1269
00:35:03,666 --> 00:35:04,206
foreground.


1270
00:35:05,046 --> 00:35:06,136
So when you start measuring


1271
00:35:06,136 --> 00:35:07,656
launch, you should start by


1272
00:35:07,656 --> 00:35:08,786
measuring the warm launch.


1273
00:35:09,456 --> 00:35:12,636
And the time it takes to launch


1274
00:35:12,636 --> 00:35:14,036
during this warm is less


1275
00:35:14,036 --> 00:35:17,326
variable than the cold launch,


1276
00:35:17,326 --> 00:35:18,656
and the test iteration is much


1277
00:35:18,656 --> 00:35:19,656
faster as you don't need to


1278
00:35:19,656 --> 00:35:20,536
reboot your device.


1279
00:35:21,846 --> 00:35:23,226
Now, the way we measure launch


1280
00:35:23,226 --> 00:35:25,156
is by evaluating the time it


1281
00:35:25,156 --> 00:35:26,566
takes from the moment you hit


1282
00:35:26,676 --> 00:35:28,236
the application icon, and until


1283
00:35:28,236 --> 00:35:29,706
you can start interacting with


1284
00:35:29,706 --> 00:35:30,696
the app.


1285
00:35:30,986 --> 00:35:32,316
And what I mean by interacting


1286
00:35:32,316 --> 00:35:34,386
is that it's really using and


1287
00:35:34,386 --> 00:35:35,726
not interacting with a spinner.


1288
00:35:37,436 --> 00:35:38,826
A common pattern is to dispatch


1289
00:35:38,856 --> 00:35:40,536
some work and display a spinner


1290
00:35:40,536 --> 00:35:41,956
in the meantime, well that


1291
00:35:41,956 --> 00:35:43,126
doesn't make the app usable


1292
00:35:43,126 --> 00:35:44,526
sooner, so we are trying to


1293
00:35:44,526 --> 00:35:47,086
avoid that here.


1294
00:35:47,386 --> 00:35:48,656
Now there are three goals that


1295
00:35:48,656 --> 00:35:49,886
we are shooting for at Photos,


1296
00:35:50,576 --> 00:35:52,056
and the first one is that we


1297
00:35:52,056 --> 00:35:54,486
want to instant, we don't want


1298
00:35:54,486 --> 00:35:57,666
to display any spinner, and we


1299
00:35:57,666 --> 00:35:59,266
don't want to display any


1300
00:36:00,996 --> 00:36:02,256
placeholder or [inaudible].


1301
00:36:03,286 --> 00:36:04,346
And I Have to be honest with


1302
00:36:04,346 --> 00:36:06,686
you, we-- you might see some


1303
00:36:06,686 --> 00:36:07,886
placeholders the first time you


1304
00:36:07,886 --> 00:36:09,536
synchronize with iClub, but when


1305
00:36:09,536 --> 00:36:11,196
the data is local, we really try


1306
00:36:11,266 --> 00:36:13,746
our best to not display any.


1307
00:36:13,996 --> 00:36:15,446
Now, what do we mean by instant?


1308
00:36:16,356 --> 00:36:17,606
Well, the time it takes to


1309
00:36:17,606 --> 00:36:18,836
launch should be the same time


1310
00:36:18,836 --> 00:36:20,106
as the zoom animation from the


1311
00:36:20,106 --> 00:36:20,646
home screen.


1312
00:36:21,086 --> 00:36:22,506
That is usually between 500 and


1313
00:36:22,506 --> 00:36:24,796
600 milliseconds, and that way,


1314
00:36:25,176 --> 00:36:26,386
the transition from the home


1315
00:36:26,386 --> 00:36:27,726
screen to the application is


1316
00:36:27,836 --> 00:36:29,426
seamless for the user, and the


1317
00:36:29,426 --> 00:36:31,036
user can start interacting with


1318
00:36:31,036 --> 00:36:32,576
it, as soon as the animation is


1319
00:36:32,626 --> 00:36:32,876
done.


1320
00:36:33,446 --> 00:36:34,666
And by the way, this is the


1321
00:36:34,666 --> 00:36:35,986
lowest recommendation, not


1322
00:36:35,986 --> 00:36:37,546
something just for photos, so


1323
00:36:37,546 --> 00:36:40,186
it's valid for any apps.


1324
00:36:40,346 --> 00:36:41,666
Now, let's look at how photos


1325
00:36:41,666 --> 00:36:42,266
launches today.


1326
00:36:43,436 --> 00:36:44,956
If we look more closely at what


1327
00:36:44,956 --> 00:36:46,576
is happening exactly, you can


1328
00:36:46,576 --> 00:36:48,656
see that photos is all set up


1329
00:36:48,656 --> 00:36:50,146
and ready before the animation


1330
00:36:50,146 --> 00:36:50,576
is done.


1331
00:36:53,466 --> 00:36:55,216
And if we dive into the launch


1332
00:36:55,216 --> 00:36:57,356
anatomy, you will see there is


1333
00:36:57,356 --> 00:36:58,326
mainly two parts.


1334
00:36:58,746 --> 00:37:00,256
The first part is being spent in


1335
00:37:00,256 --> 00:37:02,156
DYD, this is the loader that is


1336
00:37:02,156 --> 00:37:03,466
going to load and link all of


1337
00:37:03,466 --> 00:37:05,416
your dependent libraries, but


1338
00:37:05,416 --> 00:37:06,436
it's also going to run your


1339
00:37:06,436 --> 00:37:07,576
static initializers.


1340
00:37:08,766 --> 00:37:10,316
And your control over that part


1341
00:37:10,426 --> 00:37:11,476
is limited, but it's not


1342
00:37:11,476 --> 00:37:11,886
impossible.


1343
00:37:12,576 --> 00:37:14,886
I would encourage you to watch


1344
00:37:14,886 --> 00:37:17,166
the DYD session from last year


1345
00:37:18,196 --> 00:37:21,496
in order to get more details on


1346
00:37:21,496 --> 00:37:21,896
that part.


1347
00:37:23,566 --> 00:37:25,686
Now DYD is also calling Main in


1348
00:37:25,686 --> 00:37:27,486
your object table, which leads


1349
00:37:27,486 --> 00:37:28,716
us to the second part here,


1350
00:37:29,106 --> 00:37:30,356
where you have lots of control


1351
00:37:30,356 --> 00:37:32,236
over, and this part, you need to


1352
00:37:32,236 --> 00:37:34,016
make sure that it stays under


1353
00:37:34,016 --> 00:37:35,056
500 milliseconds.


1354
00:37:35,976 --> 00:37:37,376
Now, the first [inaudible] pass


1355
00:37:37,376 --> 00:37:38,386
that is being scheduled right


1356
00:37:38,386 --> 00:37:39,786
after the Did Finish launching


1357
00:37:40,276 --> 00:37:41,286
will mark the end of your


1358
00:37:41,286 --> 00:37:42,796
launch, and this is basically


1359
00:37:42,796 --> 00:37:43,946
when your app should be usable.


1360
00:37:46,016 --> 00:37:47,556
There are a few principles that


1361
00:37:47,606 --> 00:37:49,116
we will be referring to during


1362
00:37:49,116 --> 00:37:51,056
this session, and these are


1363
00:37:51,056 --> 00:37:52,316
really the common pillars of the


1364
00:37:52,316 --> 00:37:53,456
performance work that we


1365
00:37:53,456 --> 00:37:53,846
achieved.


1366
00:37:55,116 --> 00:37:56,976
The first one is that we want to


1367
00:37:56,976 --> 00:37:59,566
be lazy and defer the work that


1368
00:37:59,616 --> 00:38:00,876
we don't need.


1369
00:38:01,396 --> 00:38:02,546
The second one is that we want


1370
00:38:02,546 --> 00:38:04,506
to be proactive, and it's valid


1371
00:38:04,506 --> 00:38:05,256
for two things.


1372
00:38:05,256 --> 00:38:07,866
It's valid for being proactive


1373
00:38:08,006 --> 00:38:09,716
in order to anticipate the work


1374
00:38:09,716 --> 00:38:12,296
that we are making it later, we


1375
00:38:12,296 --> 00:38:13,526
also want to be proactive and


1376
00:38:13,526 --> 00:38:15,176
catch regressions quickly, so


1377
00:38:15,176 --> 00:38:16,116
you should make sure that you


1378
00:38:16,116 --> 00:38:17,586
have continuous integration


1379
00:38:17,916 --> 00:38:18,716
testing in place.


1380
00:38:21,536 --> 00:38:23,116
And the last point is we want to


1381
00:38:23,116 --> 00:38:24,726
be constant, regardless of the


1382
00:38:24,806 --> 00:38:26,046
total amount of data that we


1383
00:38:26,046 --> 00:38:26,566
need to load.


1384
00:38:29,496 --> 00:38:31,646
Now, if we were taking a nave


1385
00:38:31,646 --> 00:38:32,986
approach, and we were loading


1386
00:38:32,986 --> 00:38:34,186
everything we needed during


1387
00:38:34,186 --> 00:38:35,366
launch, this is how long it


1388
00:38:35,366 --> 00:38:37,806
would take roughly for a 30,000


1389
00:38:37,806 --> 00:38:38,556
item library.


1390
00:38:39,696 --> 00:38:41,106
First you need to initialize the


1391
00:38:41,106 --> 00:38:42,696
database, then you need to


1392
00:38:42,696 --> 00:38:43,986
prepare some view controllers.


1393
00:38:44,356 --> 00:38:45,516
You need to configure the data


1394
00:38:45,516 --> 00:38:47,236
sources, load some library


1395
00:38:47,236 --> 00:38:48,586
images, and fetch the cloud


1396
00:38:48,586 --> 00:38:49,066
status.


1397
00:38:49,986 --> 00:38:52,236
And keep in mind that this might


1398
00:38:52,306 --> 00:38:54,496
vary as the data grow, and in


1399
00:38:54,496 --> 00:38:56,666
fact, the data will grow forever


1400
00:38:56,666 --> 00:38:58,606
as people takes pictures every


1401
00:38:59,526 --> 00:38:59,593
day.


1402
00:39:00,046 --> 00:39:01,666
So at Photos, really keep in


1403
00:39:01,666 --> 00:39:02,646
mind that we are dealing with a


1404
00:39:02,646 --> 00:39:05,526
non-bonded data sets.


1405
00:39:05,766 --> 00:39:07,016
Now, let's see how we optimize


1406
00:39:07,016 --> 00:39:09,166
each of these steps for Photos,


1407
00:39:09,166 --> 00:39:09,836
and let's start with


1408
00:39:09,836 --> 00:39:11,846
initializing the database.


1409
00:39:13,236 --> 00:39:15,146
So first, usually, the database


1410
00:39:15,146 --> 00:39:16,606
is initialized and loaded when


1411
00:39:16,606 --> 00:39:18,056
the first query is being fired.


1412
00:39:18,656 --> 00:39:19,886
One optimization that we have


1413
00:39:19,886 --> 00:39:21,806
found was to do it as early as


1414
00:39:21,806 --> 00:39:22,796
possible in the background


1415
00:39:22,796 --> 00:39:24,586
thread, so that it doesn't have


1416
00:39:24,586 --> 00:39:26,346
to do the initialization when


1417
00:39:26,346 --> 00:39:27,636
the first query has been fired.


1418
00:39:28,996 --> 00:39:30,736
And this is an issue, especially


1419
00:39:30,946 --> 00:39:32,256
if the first query is being done


1420
00:39:32,256 --> 00:39:33,006
from the main thread.


1421
00:39:34,756 --> 00:39:39,696
Now, we spend a lot of time and


1422
00:39:39,696 --> 00:39:40,646
we are still spending a lot of


1423
00:39:40,706 --> 00:39:41,956
time reviewing all the queries


1424
00:39:41,956 --> 00:39:43,116
that we're doing during launch,


1425
00:39:43,626 --> 00:39:44,766
and we want to make sure that


1426
00:39:44,846 --> 00:39:46,396
the work that we are doing is


1427
00:39:46,396 --> 00:39:47,786
only the necessary one, and we


1428
00:39:47,786 --> 00:39:49,276
are not doing more.


1429
00:39:53,246 --> 00:39:56,106
Now, lastly, we want to ensure


1430
00:39:56,106 --> 00:39:57,586
that all the queries that we are


1431
00:39:57,586 --> 00:39:59,576
doing are efficient as possible,


1432
00:39:59,576 --> 00:40:01,086
and we want to avoid the complex


1433
00:40:01,086 --> 00:40:04,006
query as much as possible as


1434
00:40:04,636 --> 00:40:04,876
well.


1435
00:40:05,276 --> 00:40:06,986
And we sometimes we understand


1436
00:40:06,986 --> 00:40:08,646
that we need this, and for these


1437
00:40:08,686 --> 00:40:10,676
cases, we are setting up some


1438
00:40:10,676 --> 00:40:12,016
indexes, so that we can speed


1439
00:40:12,016 --> 00:40:12,276
them up.


1440
00:40:15,676 --> 00:40:17,396
Now we are aiming for, at most,


1441
00:40:17,396 --> 00:40:19,546
30 milliseconds spent in that


1442
00:40:19,546 --> 00:40:20,406
initialization.


1443
00:40:21,286 --> 00:40:22,526
So next, let's look at how we


1444
00:40:22,526 --> 00:40:23,246
are preparing our view


1445
00:40:23,246 --> 00:40:23,826
controllers.


1446
00:40:25,106 --> 00:40:25,986
So we have four tabs


1447
00:40:25,986 --> 00:40:27,796
representing the main features


1448
00:40:27,906 --> 00:40:29,486
of the app.


1449
00:40:29,656 --> 00:40:30,966
And so the first thing that we


1450
00:40:30,966 --> 00:40:32,826
need to be careful of is we want


1451
00:40:32,826 --> 00:40:33,926
to minimize the work that is


1452
00:40:33,926 --> 00:40:35,756
being done in the initialization


1453
00:40:35,756 --> 00:40:37,306
of these three non-visible ones,


1454
00:40:37,746 --> 00:40:39,896
and the rule that we are trying


1455
00:40:39,896 --> 00:40:41,516
to follow here is to do as


1456
00:40:41,566 --> 00:40:42,906
little work as possible in the


1457
00:40:42,906 --> 00:40:43,666
initializers.


1458
00:40:44,396 --> 00:40:45,436
We really want to do the bare


1459
00:40:45,436 --> 00:40:47,246
minimum, and note all the data


1460
00:40:47,246 --> 00:40:47,946
in the view that loads.


1461
00:40:50,486 --> 00:40:52,716
This also allows us to


1462
00:40:52,786 --> 00:40:54,646
initialize our controllers in


1463
00:40:54,706 --> 00:40:56,446
constant time.


1464
00:40:58,206 --> 00:40:59,936
Now, lastly, we also want to


1465
00:40:59,936 --> 00:41:01,756
ensure that only the visible


1466
00:41:01,756 --> 00:41:02,376
views are loaded.


1467
00:41:02,896 --> 00:41:06,116
It's easy, and we often regress


1468
00:41:06,116 --> 00:41:07,806
on that part, so you should


1469
00:41:07,806 --> 00:41:11,376
really be careful about that.


1470
00:41:12,016 --> 00:41:12,706
So preparing the view


1471
00:41:12,706 --> 00:41:14,106
controllers, we are now aiming


1472
00:41:14,106 --> 00:41:15,696
for 120 milliseconds.


1473
00:41:16,626 --> 00:41:18,376
But preparing view controllers


1474
00:41:18,376 --> 00:41:19,646
implies configuring the data


1475
00:41:19,646 --> 00:41:21,586
sources, and let's look at that


1476
00:41:21,586 --> 00:41:22,216
chunk next.


1477
00:41:25,056 --> 00:41:26,716
So the Moments view is a


1478
00:41:26,716 --> 00:41:27,996
representation of these things,


1479
00:41:27,996 --> 00:41:30,086
events in your life, and the UI


1480
00:41:30,086 --> 00:41:31,376
represents that by having this


1481
00:41:31,426 --> 00:41:32,796
group of photos, and these


1482
00:41:32,866 --> 00:41:33,266
headers.


1483
00:41:34,206 --> 00:41:35,866
In this library, for example, we


1484
00:41:35,866 --> 00:41:38,596
might have 500 moments, and in


1485
00:41:38,596 --> 00:41:40,026
order to build a view, we need


1486
00:41:40,026 --> 00:41:40,766
to load all the moments up


1487
00:41:40,766 --> 00:41:40,976
front.


1488
00:41:43,236 --> 00:41:44,706
But the only thing we need


1489
00:41:44,956 --> 00:41:46,846
really for these moments is only


1490
00:41:46,846 --> 00:41:48,666
the meta data so we can build


1491
00:41:48,666 --> 00:41:48,986
the view.


1492
00:41:49,706 --> 00:41:50,676
We don't need your content.


1493
00:41:51,226 --> 00:41:54,846
So the first thing we do is we


1494
00:41:54,846 --> 00:41:56,366
fire that query, which is super


1495
00:41:56,366 --> 00:41:56,726
fast.


1496
00:41:56,926 --> 00:41:59,356
And then we are only loading the


1497
00:41:59,396 --> 00:42:01,086
content that we need here.


1498
00:42:02,286 --> 00:42:04,046
In that case here, we are only


1499
00:42:04,046 --> 00:42:05,016
going to load the visible


1500
00:42:05,016 --> 00:42:07,466
content, which in our case is


1501
00:42:07,466 --> 00:42:09,096
going to be between 7 to 10


1502
00:42:09,096 --> 00:42:09,616
Moments.


1503
00:42:10,956 --> 00:42:12,536
Since our deficit is limited,


1504
00:42:12,876 --> 00:42:14,616
and finite, we can allow


1505
00:42:14,616 --> 00:42:16,066
ourselves to do it synchronously


1506
00:42:16,066 --> 00:42:18,376
on the main thread.


1507
00:42:18,696 --> 00:42:20,896
Now, we also want to anticipate


1508
00:42:20,896 --> 00:42:23,526
and schedule the work so that we


1509
00:42:23,526 --> 00:42:25,546
can start loading the remaining


1510
00:42:25,546 --> 00:42:26,596
data as synchronously.


1511
00:42:27,156 --> 00:42:28,406
And we do that on the bug run


1512
00:42:28,406 --> 00:42:30,236
thread, with the right quality


1513
00:42:30,316 --> 00:42:31,356
of service to make sure that it


1514
00:42:31,356 --> 00:42:32,556
doesn't preempt the main thread


1515
00:42:32,556 --> 00:42:33,886
from running.


1516
00:42:38,416 --> 00:42:40,516
Now we are aiming at 100


1517
00:42:40,516 --> 00:42:41,416
milliseconds here.


1518
00:42:44,706 --> 00:42:48,266
So lastly, our data sources are


1519
00:42:48,266 --> 00:42:50,226
also providing some images and


1520
00:42:50,226 --> 00:42:51,456
let's see how we optimize that


1521
00:42:51,506 --> 00:42:51,736
part.


1522
00:42:53,666 --> 00:42:54,916
So this was by far the biggest


1523
00:42:54,916 --> 00:42:55,936
chunk here that we are all


1524
00:42:55,936 --> 00:42:57,986
attacking, and when we realized


1525
00:42:57,986 --> 00:42:59,066
that we were spending multiple


1526
00:42:59,066 --> 00:43:00,376
seconds loading this image


1527
00:43:00,376 --> 00:43:02,536
during launch, we realized that


1528
00:43:02,586 --> 00:43:04,686
we were doing too much work.


1529
00:43:05,086 --> 00:43:06,296
So the first thing that we did


1530
00:43:06,296 --> 00:43:08,686
is that we evaluated the number


1531
00:43:08,686 --> 00:43:10,246
of images that we needed during


1532
00:43:10,246 --> 00:43:12,556
launch, and we are only loading


1533
00:43:12,556 --> 00:43:13,536
that during that first


1534
00:43:13,536 --> 00:43:14,566
transaction.


1535
00:43:15,286 --> 00:43:17,216
In that case, that can be up to


1536
00:43:17,216 --> 00:43:19,436
60 including some piling above


1537
00:43:19,436 --> 00:43:19,876
and below.


1538
00:43:20,576 --> 00:43:23,386
And next, in order to load those


1539
00:43:23,386 --> 00:43:25,036
images firstly, we need to make


1540
00:43:25,036 --> 00:43:26,676
sure that we are all loading


1541
00:43:26,676 --> 00:43:28,046
only low-resolutions one.


1542
00:43:28,806 --> 00:43:29,956
That way we are loading fewer


1543
00:43:29,956 --> 00:43:32,026
pixels in memory, and it is much


1544
00:43:32,026 --> 00:43:32,546
more efficient.


1545
00:43:35,316 --> 00:43:36,566
That chunk is now representing


1546
00:43:36,566 --> 00:43:37,486
200 milliseconds.


1547
00:43:39,316 --> 00:43:40,846
And this is, by far, the biggest


1548
00:43:40,846 --> 00:43:41,566
gain that we had.


1549
00:43:42,296 --> 00:43:43,466
Which I need to be a constant


1550
00:43:43,466 --> 00:43:46,966
time, and that's really great.


1551
00:43:47,786 --> 00:43:49,346
Now, sometimes you have to ask


1552
00:43:49,346 --> 00:43:50,806
yourself the question, is this


1553
00:43:50,806 --> 00:43:52,056
really needed during launch?


1554
00:43:52,286 --> 00:43:54,116
And one of our examples here is


1555
00:43:54,116 --> 00:43:54,896
this footer view.


1556
00:43:55,486 --> 00:43:57,256
That pulls information via the


1557
00:43:57,256 --> 00:44:00,316
network or the database, and


1558
00:44:00,316 --> 00:44:01,666
literally first our design was


1559
00:44:01,666 --> 00:44:03,616
to not show it during launch.


1560
00:44:04,086 --> 00:44:05,806
To prioritize all the images


1561
00:44:05,806 --> 00:44:06,636
that we are seeing here.


1562
00:44:06,906 --> 00:44:08,366
We wanted to show as much images


1563
00:44:08,366 --> 00:44:08,946
as possible.


1564
00:44:09,366 --> 00:44:10,356
So that may be simpler.


1565
00:44:11,456 --> 00:44:12,936
We are now only scheduling that


1566
00:44:12,996 --> 00:44:14,596
work post-launch, and we cache


1567
00:44:14,596 --> 00:44:16,216
to process information for


1568
00:44:16,216 --> 00:44:18,756
raising later.


1569
00:44:20,686 --> 00:44:21,716
Now, if we would have had the


1570
00:44:21,716 --> 00:44:22,936
requirement of displaying this


1571
00:44:22,936 --> 00:44:24,606
information, one approach could


1572
00:44:24,606 --> 00:44:25,786
have been to leverage the


1573
00:44:25,786 --> 00:44:27,176
register background at refresh


1574
00:44:27,176 --> 00:44:29,506
API from UA kit, that will


1575
00:44:29,506 --> 00:44:31,036
proactively clear your app so


1576
00:44:31,086 --> 00:44:32,376
that you can start preparing


1577
00:44:32,376 --> 00:44:33,856
some content when the user is


1578
00:44:33,856 --> 00:44:35,446
going to launch your app.


1579
00:44:37,156 --> 00:44:38,836
So now, that part has gone from


1580
00:44:38,836 --> 00:44:40,726
launch, and that saves us 400


1581
00:44:40,726 --> 00:44:42,066
milliseconds of CPU time.


1582
00:44:43,486 --> 00:44:45,276
If we look at the updated


1583
00:44:45,276 --> 00:44:47,046
breakdown here, we can see that


1584
00:44:47,046 --> 00:44:48,866
we now have only 450


1585
00:44:48,866 --> 00:44:50,216
milliseconds worth of work.


1586
00:44:50,896 --> 00:44:53,776
We are now fitting into that 500


1587
00:44:53,836 --> 00:44:55,866
millisecond time window, and


1588
00:44:55,866 --> 00:44:58,006
regardless of how things can be


1589
00:44:58,006 --> 00:44:59,486
represented concurrently here,


1590
00:44:59,486 --> 00:45:00,816
the most important part of that


1591
00:45:01,246 --> 00:45:02,626
is to really make sure that you


1592
00:45:02,626 --> 00:45:03,596
think about the cost of


1593
00:45:03,636 --> 00:45:04,656
preparing your content.


1594
00:45:05,296 --> 00:45:07,466
And what I mean by think is


1595
00:45:07,466 --> 00:45:09,086
really measure it.


1596
00:45:10,606 --> 00:45:12,806
Now, you should strive for doing


1597
00:45:12,806 --> 00:45:13,746
work in constant time,


1598
00:45:13,746 --> 00:45:14,926
regardless of the total amount


1599
00:45:14,926 --> 00:45:15,896
of data you are loading.


1600
00:45:16,676 --> 00:45:17,796
In our case, really have


1601
00:45:17,796 --> 00:45:19,526
unbonded data assets, and we


1602
00:45:19,746 --> 00:45:21,976
need to stay constant.


1603
00:45:24,756 --> 00:45:25,846
Now that we have launched the


1604
00:45:25,846 --> 00:45:27,746
app, we need to start using it.


1605
00:45:27,746 --> 00:45:28,866
And let's see how we did


1606
00:45:29,096 --> 00:45:30,256
collections and [inaudible] for


1607
00:45:30,256 --> 00:45:31,146
good [inaudible] performance.


1608
00:45:31,226 --> 00:45:34,416
So as I mentioned earlier, our


1609
00:45:34,416 --> 00:45:37,236
users can seamlessly transition


1610
00:45:37,236 --> 00:45:39,136
with animation from the Moments,


1611
00:45:39,436 --> 00:45:40,966
through the collections, to the


1612
00:45:40,966 --> 00:45:41,496
years view.


1613
00:45:44,316 --> 00:45:46,206
And this is a complex hierarchy.


1614
00:45:46,886 --> 00:45:48,306
We have thousands of pictures to


1615
00:45:48,306 --> 00:45:48,746
display.


1616
00:45:49,606 --> 00:45:51,116
We need to support live updates,


1617
00:45:51,686 --> 00:45:53,436
we need to also support


1618
00:45:53,436 --> 00:45:55,186
animation between these layers,


1619
00:45:55,816 --> 00:45:57,276
and we also have some gestures.


1620
00:46:00,436 --> 00:46:01,886
Now, we also have some goals


1621
00:46:01,886 --> 00:46:02,076
here.


1622
00:46:02,956 --> 00:46:04,096
For the experience we want to


1623
00:46:04,096 --> 00:46:05,356
provide to our users.


1624
00:46:06,426 --> 00:46:07,726
The first one is the same as


1625
00:46:07,726 --> 00:46:08,706
before, we don't want to have


1626
00:46:08,706 --> 00:46:09,436
any spinner.


1627
00:46:09,436 --> 00:46:10,156
We don't want to have


1628
00:46:10,256 --> 00:46:12,586
placeholders, but we also want


1629
00:46:12,586 --> 00:46:13,806
to have smooth animations.


1630
00:46:13,996 --> 00:46:15,576
And by smooth animations, I mean


1631
00:46:15,846 --> 00:46:19,396
60 or 120 frames per second,


1632
00:46:19,446 --> 00:46:20,586
depending on the screen you're


1633
00:46:20,586 --> 00:46:21,686
running on.


1634
00:46:23,266 --> 00:46:24,416
Now, remember the principles


1635
00:46:24,416 --> 00:46:25,356
that we've seen before.


1636
00:46:25,876 --> 00:46:26,966
Well, they are all applicable


1637
00:46:26,966 --> 00:46:27,236
here.


1638
00:46:27,586 --> 00:46:28,926
We want to be lazy and defer the


1639
00:46:28,926 --> 00:46:30,036
work we donate up front.


1640
00:46:30,786 --> 00:46:31,876
We want to be proactive, and


1641
00:46:31,876 --> 00:46:34,316
catch regressions quickly, but


1642
00:46:34,316 --> 00:46:35,956
we also want to be constant in


1643
00:46:35,956 --> 00:46:37,476
our layout passes, and


1644
00:46:37,476 --> 00:46:39,096
regardless of a lot of data that


1645
00:46:39,166 --> 00:46:39,686
we are loading.


1646
00:46:41,566 --> 00:46:42,886
Now, this time, we also want to


1647
00:46:42,886 --> 00:46:44,396
be timely, and we want to


1648
00:46:44,396 --> 00:46:45,526
remember the rendering loop


1649
00:46:45,526 --> 00:46:46,046
cycle.


1650
00:46:47,076 --> 00:46:48,426
And what I mean by that is that


1651
00:46:48,426 --> 00:46:49,676
I want you to remember that we


1652
00:46:49,676 --> 00:46:52,096
only have 8 or 16 milliseconds


1653
00:46:52,096 --> 00:46:53,426
to render that frame, so we need


1654
00:46:53,426 --> 00:46:54,206
to make sure that we are not


1655
00:46:54,256 --> 00:46:55,876
going over that time, otherwise


1656
00:46:55,916 --> 00:46:57,156
we would start dropping frames.


1657
00:46:59,356 --> 00:47:01,486
Now, let's take a step back, and


1658
00:47:01,486 --> 00:47:02,636
look at what we are trying to


1659
00:47:02,636 --> 00:47:03,176
achieve here.


1660
00:47:03,866 --> 00:47:05,076
We wanted to have this portable


1661
00:47:05,076 --> 00:47:06,896
view, with sections and mini


1662
00:47:06,896 --> 00:47:07,466
cells in it.


1663
00:47:09,846 --> 00:47:11,226
And that is basically what your


1664
00:47:11,226 --> 00:47:12,836
Collection view is providing,


1665
00:47:12,836 --> 00:47:13,076
right?


1666
00:47:13,636 --> 00:47:15,036
Except that in this extreme


1667
00:47:15,036 --> 00:47:16,246
case, we are restricting the


1668
00:47:16,246 --> 00:47:17,506
limit of what we could achieve


1669
00:47:17,506 --> 00:47:18,576
with a basic approach.


1670
00:47:18,746 --> 00:47:20,546
And that resulted in too many


1671
00:47:20,546 --> 00:47:21,616
views, too many layers.


1672
00:47:23,796 --> 00:47:26,256
But also in an increased layered


1673
00:47:26,256 --> 00:47:28,396
complexity, and that also had an


1674
00:47:28,396 --> 00:47:30,086
increased memory cost.


1675
00:47:31,706 --> 00:47:33,086
So we needed to innovate here,


1676
00:47:33,846 --> 00:47:35,126
and we did that by restricting


1677
00:47:35,126 --> 00:47:36,436
the number of views drastically


1678
00:47:36,436 --> 00:47:37,826
while still using a collection


1679
00:47:37,826 --> 00:47:37,966
view.


1680
00:47:40,176 --> 00:47:42,066
We used a technique more


1681
00:47:42,066 --> 00:47:43,466
commonly used in video games,


1682
00:47:43,466 --> 00:47:44,606
that is called atlasing.


1683
00:47:45,146 --> 00:47:47,106
And it basically consists of


1684
00:47:47,106 --> 00:47:48,766
combining a set of images into a


1685
00:47:48,766 --> 00:47:49,406
single one.


1686
00:47:50,536 --> 00:47:52,186
We do that efficiently by using


1687
00:47:52,186 --> 00:47:53,806
only very small thumbnails


1688
00:47:53,806 --> 00:47:56,736
first, then we stamp all the raw


1689
00:47:56,736 --> 00:47:58,856
image data on the canvas we are


1690
00:47:58,856 --> 00:47:59,716
using as a strip.


1691
00:48:01,156 --> 00:48:03,336
Now, we use image raw data so


1692
00:48:03,336 --> 00:48:04,866
that we can avoid decoding each


1693
00:48:04,866 --> 00:48:07,766
thumbnail as we send.


1694
00:48:08,376 --> 00:48:09,576
So basically we are displaying a


1695
00:48:09,576 --> 00:48:10,726
random strip of images.


1696
00:48:12,406 --> 00:48:14,286
Now, we generate and cache them


1697
00:48:14,286 --> 00:48:15,566
on the fly so that we can be


1698
00:48:15,566 --> 00:48:16,206
more flexible.


1699
00:48:18,436 --> 00:48:20,086
And as we render multiple images


1700
00:48:20,086 --> 00:48:22,026
into a single one, we are


1701
00:48:22,026 --> 00:48:23,316
registering the number of cells,


1702
00:48:23,316 --> 00:48:24,716
layers, objects drastically,


1703
00:48:24,716 --> 00:48:26,006
which simplifies the layout and


1704
00:48:26,006 --> 00:48:29,066
the time spent building it.


1705
00:48:29,686 --> 00:48:31,266
Now, the separate works well,


1706
00:48:31,266 --> 00:48:32,356
but it has trade offs to


1707
00:48:32,356 --> 00:48:34,386
consider as well, and this is


1708
00:48:34,386 --> 00:48:34,966
one of them.


1709
00:48:36,806 --> 00:48:38,606
So if someone tries to long


1710
00:48:38,606 --> 00:48:40,996
press or force search an item


1711
00:48:40,996 --> 00:48:42,866
here, we will need to figure its


1712
00:48:42,916 --> 00:48:44,536
position so that we can achieve


1713
00:48:44,536 --> 00:48:45,426
the preview correctly.


1714
00:48:45,996 --> 00:48:48,136
And as we display a single


1715
00:48:48,136 --> 00:48:50,776
image, we need to maintain the


1716
00:48:50,776 --> 00:48:53,156
mapping of each individual


1717
00:48:53,156 --> 00:48:54,736
image, and its render strip.


1718
00:48:56,086 --> 00:48:57,226
Now, you might be thinking, why


1719
00:48:57,226 --> 00:48:58,216
are we generating them on the


1720
00:48:58,216 --> 00:48:58,536
fly?


1721
00:49:00,016 --> 00:49:01,736
Well, we need to support live


1722
00:49:01,736 --> 00:49:03,626
updates, that's the reason.


1723
00:49:04,416 --> 00:49:05,526
We need also to support


1724
00:49:05,526 --> 00:49:06,536
different view sizes.


1725
00:49:07,426 --> 00:49:08,656
For example, we have landscape


1726
00:49:08,656 --> 00:49:09,016
here.


1727
00:49:09,516 --> 00:49:11,476
But we also have portraits.


1728
00:49:12,976 --> 00:49:16,276
And also we can do that because


1729
00:49:16,276 --> 00:49:17,096
we can [inaudible] because our


1730
00:49:17,096 --> 00:49:18,786
user's labor typically grows


1731
00:49:18,786 --> 00:49:20,606
organically over a long period


1732
00:49:20,606 --> 00:49:22,766
of time, and the cases where we


1733
00:49:22,766 --> 00:49:24,076
might need to generate thousands


1734
00:49:24,076 --> 00:49:25,016
of them are pretty rare.


1735
00:49:27,716 --> 00:49:29,086
Now, you may be wondering also


1736
00:49:29,086 --> 00:49:30,236
why are we not generating the


1737
00:49:30,236 --> 00:49:31,016
whole section then?


1738
00:49:32,616 --> 00:49:33,776
Well the answer is that our


1739
00:49:33,776 --> 00:49:35,306
design record is to do this cool


1740
00:49:35,306 --> 00:49:36,966
animation, where you can see


1741
00:49:36,966 --> 00:49:37,926
that the collections are


1742
00:49:37,926 --> 00:49:39,036
expanding into their own


1743
00:49:39,036 --> 00:49:40,436
sections or collapsing into


1744
00:49:40,436 --> 00:49:42,196
group ones, and the other way


1745
00:49:42,846 --> 00:49:42,986
around.


1746
00:49:45,616 --> 00:49:47,206
So if there is one thing that


1747
00:49:47,206 --> 00:49:48,376
you should also remember from


1748
00:49:48,376 --> 00:49:49,776
that second part is you should


1749
00:49:49,776 --> 00:49:50,916
really think about the layout


1750
00:49:50,916 --> 00:49:53,036
course of your hierarchy and


1751
00:49:53,036 --> 00:49:54,506
measure it.


1752
00:49:56,356 --> 00:49:58,326
Lastly, you should always think


1753
00:49:58,326 --> 00:49:59,106
about performance.


1754
00:49:59,566 --> 00:50:01,066
At Photos, we care deeply about


1755
00:50:01,066 --> 00:50:02,266
it, and this is really part of


1756
00:50:02,266 --> 00:50:02,916
our daily job.


1757
00:50:04,906 --> 00:50:06,796
For more information, you can


1758
00:50:06,796 --> 00:50:09,026
come and see us in these three


1759
00:50:09,026 --> 00:50:10,146
labs that are mentioned here,


1760
00:50:10,246 --> 00:50:12,486
and I hope that you have a great


1761
00:50:12,486 --> 00:50:13,026
conference.


1762
00:50:13,526 --> 00:50:13,806
Thank you.


1763
00:50:14,516 --> 00:50:20,450
[ Applause ]

