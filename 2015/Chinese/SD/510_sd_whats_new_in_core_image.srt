1
00:00:19,786 --> 00:00:22,122
核心图像的新方面


2
00:00:25,759 --> 00:00:27,561
大家早上好
我的名字是大卫·海沃德


3
00:00:27,628 --> 00:00:29,363
今天我很荣幸能给大家讲讲


4
00:00:29,429 --> 00:00:32,432
iOS 9和Mac OS X El
Capitan “核心图像” 上


5
00:00:32,566 --> 00:00:34,501
有什么新料


6
00:00:35,202 --> 00:00:38,172
首先说一下我们今天
要讲哪几件事


7
00:00:38,272 --> 00:00:40,574
首先 我会给那些刚刚
接触主题的人


8
00:00:40,674 --> 00:00:42,743
简单介绍下 “核心图像”


9
00:00:42,876 --> 00:00:44,278
我建议你们回去后


10
00:00:44,344 --> 00:00:46,246
看看我们去年以来的
演示


11
00:00:46,313 --> 00:00:48,849
尤其是其中那个关于如何
在 “核心图像” 中编写内核的


12
00:00:48,916 --> 00:00:49,950
讨论 非常棒


13
00:00:50,684 --> 00:00:52,853
接下来我们会讲一讲
今年在 “核心图像” 上


14
00:00:52,920 --> 00:00:53,854
有什么新料


15
00:00:53,921 --> 00:00:55,455
我们在这里要讲的东西
很多


16
00:00:55,889 --> 00:00:58,659
我们今天会议剩下的三分之一
时间会用来谈谈如何使用


17
00:00:58,725 --> 00:01:00,727
“核心图像”
如何把它与我们的平台上的


18
00:01:00,794 --> 00:01:02,896
其它图形框架
桥接起来


19
00:01:04,131 --> 00:01:05,132
首先


20
00:01:05,933 --> 00:01:07,835
来简单介绍下
“核心图像”


21
00:01:09,469 --> 00:01:10,971
在概念上


22
00:01:11,038 --> 00:01:13,907
“核心图像” 的
理念是指你可以在图像上使用滤镜


23
00:01:14,441 --> 00:01:17,010
举个简单的例子
你有一张输入图像


24
00:01:17,077 --> 00:01:19,980
然后你通过一个滤镜增加了
一种色彩效果 如棕黑色调


25
00:01:20,714 --> 00:01:22,216
但是如果你不喜欢这个


26
00:01:22,282 --> 00:01:24,651
棕黑色调 那么你就可以再
改变一次色彩效果 把色调


27
00:01:24,751 --> 00:01:27,254
改成
偏蓝色调


28
00:01:27,821 --> 00:01:30,591
你也可以使用 “核心图像”
来增加类似几何扭曲这样的


29
00:01:30,657 --> 00:01:32,159
事件
效果


30
00:01:32,426 --> 00:01:36,363
在这个例子中 我们使用的
就是一种简单的转换


31
00:01:36,430 --> 00:01:37,564
放大了图像的某一部分


32
00:01:38,465 --> 00:01:40,701
你可以把这些想象成
各个滤镜上都有一张


33
00:01:40,801 --> 00:01:41,802
中间图像


34
00:01:42,402 --> 00:01:45,339
但是
我们实现滤镜的方法


35
00:01:45,405 --> 00:01:46,974
它们实际上是非常简便的
对象


36
00:01:47,040 --> 00:01:48,876
生成时耗时
极少


37
00:01:49,343 --> 00:01:51,311
在它们之间并无
中间缓冲区


38
00:01:51,378 --> 00:01:52,713
存在的必要


39
00:01:52,779 --> 00:01:54,882
还有一个概念也很重要
和每个滤镜联系在一起的


40
00:01:54,948 --> 00:01:57,217
是一个或者多个
内核


41
00:01:57,651 --> 00:02:01,255
CI内核是小的子例程
这些子例程施加的效果


42
00:02:01,321 --> 00:02:03,323
就是内核想要实现的
效果


43
00:02:04,591 --> 00:02:06,527
“核心图像” 的另一项特性是


44
00:02:06,593 --> 00:02:09,496
我们把这些内核


45
00:02:09,562 --> 00:02:12,132
连接到了一个
程序


46
00:02:12,466 --> 00:02:15,502
尽可能减少中间缓冲区的
使用


47
00:02:15,569 --> 00:02:16,703
以此来提高性能


48
00:02:19,773 --> 00:02:22,643
“核心图像” 还有一项关键特性
我们称之为


49
00:02:22,709 --> 00:02:23,577
“兴趣域支持”


50
00:02:24,144 --> 00:02:26,747
这个理念指的是如果你仅仅
对某个图像的某一部分进行


51
00:02:27,314 --> 00:02:29,650
渲染 这可能是因为你在某张
较大的图象上进行了放大


52
00:02:29,716 --> 00:02:31,451
或者是因为这些渲染是在
图块上进行的


53
00:02:32,553 --> 00:02:35,589
我们就可以问一下每个滤镜
正在渲染的图块需要多大的


54
00:02:35,656 --> 00:02:38,825
图像输入 这样我们就可以
向源图像计算回


55
00:02:38,892 --> 00:02:41,328
要生成想要的输出
需要用到的图像的


56
00:02:41,562 --> 00:02:45,132
精确
区域


57
00:02:45,299 --> 00:02:48,802
“核心图像” 还有一项很棒的
特性 允许我们获得良好的


58
00:02:48,869 --> 00:02:50,270
性能
尤其是当我们处理


59
00:02:50,337 --> 00:02:51,672
大图像时


60
00:02:53,140 --> 00:02:55,976
当你使用 “核心图像” 时
你需要注意其中的


61
00:02:56,043 --> 00:02:57,311
四个
主要类


62
00:02:57,711 --> 00:02:59,012
第一个是CI内核


63
00:02:59,079 --> 00:03:00,647iddle
我之前已经提到了


64
00:02:59,079 --> 00:03:00,647
我之前已经提到了


65
00:03:01,048 --> 00:03:03,283
它代表的是写在 “核心图像”
内核语言的


66
00:03:03,350 --> 00:03:05,485
程序或者例程


67
00:03:05,986 --> 00:03:09,456
第二个关键的类是滤镜
即CI滤镜


68
00:03:09,823 --> 00:03:13,293
这是一个可变对象
可以有多个输入


69
00:03:13,360 --> 00:03:16,530
这些输入参数可以是数字、
向量


70
00:03:16,597 --> 00:03:18,031
或者其他图像


71
00:03:19,399 --> 00:03:23,036
根据输入参数的当前状态
滤镜会使用一个或者多个


72
00:03:23,103 --> 00:03:26,073
内核
来生成


73
00:03:26,139 --> 00:03:27,241
一幅输出图像


74
00:03:27,908 --> 00:03:30,344
一个CI图像就是一个
不可变对象


75
00:03:30,744 --> 00:03:33,614
表示根据已经使用的
上一个内核


76
00:03:33,680 --> 00:03:35,949
生成图像的
“食谱”


77
00:03:37,451 --> 00:03:40,120
最后是
CIContext对象


78
00:03:40,354 --> 00:03:41,755
这是一个非常
重量级的对象


79
00:03:41,822 --> 00:03:44,424
“核心图像” 就是通过这个对象
来进行渲染的


80
00:03:44,925 --> 00:03:47,895
建议你不要太过频繁地在你的
应用程序中创建


81
00:03:47,961 --> 00:03:50,464
这个CIContext对象 如果
你处理的是快速动画


82
00:03:50,531 --> 00:03:51,765
那么创建一次就够了


83
00:03:51,832 --> 00:03:53,567
关于CIContext还有一点很棒


84
00:03:53,634 --> 00:03:57,738
它们可以实现到我们的系统中
各种不同的后端渲染器上


85
00:04:01,141 --> 00:04:04,444
现在我想讲的下一件事
就是我们后面的这个介绍讲的是


86
00:04:04,511 --> 00:04:06,446
今年 “核心图像” 上
有什么新料


87
00:04:07,714 --> 00:04:09,550
我们今天要讲这么几件
事情


88
00:04:10,150 --> 00:04:13,787
我们会讲一下Metal
讲一下新的滤镜


89
00:04:14,288 --> 00:04:18,325
新的检测器 颜色管理支持
以及内核类和语言的


90
00:04:18,392 --> 00:04:20,827
某些
改进


91
00:04:21,827 --> 00:04:24,565
关于 “核心图像” 我要讲的
最重要的事情


92
00:04:24,932 --> 00:04:28,035
就是我们现在把它统一实现到了
我们的各个平台上


93
00:04:28,101 --> 00:04:32,072
因此只要我们不专门提起
那么大多数情况下


94
00:04:32,139 --> 00:04:34,775
“核心图像” 的行为在iOS
和OS X上是完全一致的


95
00:04:35,042 --> 00:04:37,244
是完全
等价的


96
00:04:37,311 --> 00:04:40,981
这是一个很棒的特性
开发者就可以依赖这个


97
00:04:41,048 --> 00:04:42,182
这个一致的行为


98
00:04:43,050 --> 00:04:46,053
这些可能是一些小事
比如


99
00:04:46,119 --> 00:04:47,888
当你包含 “核心图像”
头部时


100
00:04:48,155 --> 00:04:50,624
无论你是在哪个平台
你就可以包含 “核心图像”


101
00:04:50,824 --> 00:04:52,259
包含
“核心图像” H


102
00:04:52,326 --> 00:04:53,260
这样如果你编写的是


103
00:04:53,327 --> 00:04:55,562
跨平台的代码
那就容易了很多


104
00:04:55,963 --> 00:04:58,632
我们现在在两个平台之间


105
00:04:58,699 --> 00:05:01,668ddle
会进行API奇偶校验


106
00:04:58,699 --> 00:05:01,668
会进行API奇偶校验


107
00:05:03,971 --> 00:05:04,805
因此


108
00:05:04,872 --> 00:05:07,241
今天我们想说的一件
主要的事情就是


109
00:05:07,307 --> 00:05:09,676
“核心图像”
对Metal的支持


110
00:05:10,410 --> 00:05:13,514
我们稍后会在演示中
展开讲更多的细节


111
00:05:13,847 --> 00:05:15,482
不过现在我就想先向你们
强调这一点


112
00:05:15,883 --> 00:05:17,584
关键的一点在于


113
00:05:17,951 --> 00:05:19,453
现在Metal Textures


114
00:05:19,720 --> 00:05:21,255
既可以当做
“核心图像” 的输入


115
00:05:21,822 --> 00:05:24,124
又可以当做
“核心图像” 的输出


116
00:05:25,158 --> 00:05:27,628
从内部来说
“核心图像” 环境可以把


117
00:05:27,895 --> 00:05:30,430
Metal当作它们的
内部渲染器


118
00:05:31,231 --> 00:05:32,933
这就意味着
如果你在CI的内核语言中


119
00:05:32,999 --> 00:05:35,969
写好了一个内核
那么它就会自动即时翻译成


120
00:05:36,403 --> 00:05:38,338
Metal语言


121
00:05:40,240 --> 00:05:42,643
还有一件事要记住
我们的内置滤镜


122
00:05:42,709 --> 00:05:45,245
尤其是 “高斯” 和 “卷积”
滤镜


123
00:05:45,646 --> 00:05:47,714
现在是构建在
Metal性能材质的顶部


124
00:05:47,781 --> 00:05:51,718
为的就是在支持的多个平台上
获得尽可能好的性能


125
00:05:55,189 --> 00:05:56,590
关于滤镜还有一些要说


126
00:05:57,391 --> 00:05:58,725
就像我之前提到过的


127
00:05:58,792 --> 00:06:00,961
我们现在有一个统一的
“核心图像” 执行


128
00:06:01,028 --> 00:06:04,364
这就意味着我们现在在各个
平台上内置了二百种滤镜


129
00:06:04,898 --> 00:06:06,333
也就是说


130
00:06:07,267 --> 00:06:08,902
我们向iOS
“核心图像” 执行中


131
00:06:08,969 --> 00:06:10,737
添加了
海量的滤镜


132
00:06:10,871 --> 00:06:12,739
这次发版时添加了
超过四十种滤镜


133
00:06:13,140 --> 00:06:14,775
它们分别属于不同的
类别


134
00:06:14,842 --> 00:06:18,345
有些滤镜很有趣 比如
喜剧效果、CMYK半色调、


135
00:06:18,412 --> 00:06:20,280
德罗斯特以及卷页效果


136
00:06:20,347 --> 00:06:22,783
还有一些卷积滤镜
也很有用


137
00:06:22,850 --> 00:06:24,184
比如中值滤镜、


138
00:06:24,251 --> 00:06:27,321
边缘检测
以及噪声抑制


139
00:06:27,921 --> 00:06:31,792
我们还有一些对图像分析来说
非常有用的简化滤镜


140
00:06:31,859 --> 00:06:34,528
比如对一幅图像进行
“区域最大化”


141
00:06:34,595 --> 00:06:36,096
或者 “平均分布列”


142
00:06:37,831 --> 00:06:40,000
为了让你们体验一下它


143
00:06:40,367 --> 00:06:42,503
我想向你们展示我们的
一个示例应用程序的最新


144
00:06:42,569 --> 00:06:44,905
最新版本 名字叫
“核心图像奇幻屋”


145
00:06:45,606 --> 00:06:48,342
我们尽量每年都更新这个
应用程序


146
00:06:49,276 --> 00:06:52,346
我们现在已经有
二百个滤镜


147
00:06:52,913 --> 00:06:55,883
当你在这个应用程序中打开
滤镜弹窗时


148
00:06:55,949 --> 00:06:58,151
你可以看到我们现在把它们
分成了不同的种类


149
00:06:58,552 --> 00:07:00,654
你还可以看到我们用红色
高亮显示了我们新加的


150
00:07:00,721 --> 00:07:03,223
滤镜
这里有一个API


151
00:07:03,290 --> 00:07:06,493
可以帮助你确定某个滤镜
是在哪次发版时加进去的


152
00:07:07,828 --> 00:07:10,130
这个 当然了
展示了 “CMYK半色调” 特效在


153
00:07:11,164 --> 00:07:12,900
一台iPad上视网膜分辨率
情况下的


154
00:07:13,667 --> 00:07:14,701
良好性能


155
00:07:17,938 --> 00:07:20,107
这是我们应大家要求


156
00:07:20,541 --> 00:07:22,309
<br/>
添加到各个平台的


157
00:07:22,376 --> 00:07:24,244
“核心图像” 上的
两个新的滤镜


158
00:07:24,578 --> 00:07:26,413
这些滤镜可以用来


159
00:07:27,014 --> 00:07:28,081
生成
条形码


160
00:07:28,482 --> 00:07:31,151
因此在这个实例中
输入一个滤镜的就不是


161
00:07:31,218 --> 00:07:33,253
一个数字或者另一幅图像
而是一个文本串


162
00:07:34,021 --> 00:07:38,258
我们添加了这两个滤镜
以便生成PDF417条形码


163
00:07:38,325 --> 00:07:40,160
以及code 128条形码


164
00:07:43,597 --> 00:07:46,533
“核心图像” 还有一项特性
我们称之为我们的


165
00:07:46,600 --> 00:07:47,601
CI检测器类


166
00:07:47,868 --> 00:07:49,837
这些是我们过去发布的
类


167
00:07:49,903 --> 00:07:52,940
它们可以用来做像
检测图像中的人脸、


168
00:07:53,407 --> 00:07:55,342
检测图像中的QR codes码、


169
00:07:55,809 --> 00:07:57,377
检测图像中的矩形
等事情


170
00:07:57,644 --> 00:07:58,779
今年我们又新增了一个类


171
00:07:58,846 --> 00:08:01,582
它可以用来检测图像中的
文本区域


172
00:08:02,049 --> 00:08:04,952
这个滤镜的理念是
定位可能包含直立文本的


173
00:08:05,018 --> 00:08:06,887
区域


174
00:08:07,621 --> 00:08:10,657
我来在一台iPad上运行下
简单给你们做个演示


175
00:08:10,991 --> 00:08:13,760
我们已经把它连接到了
“核心图像奇幻屋”


176
00:08:14,194 --> 00:08:17,731
我的书架上有个旧盒子
如果我们打开文本检测器


177
00:08:17,798 --> 00:08:20,767
它就定位到了直立文本
定位到了


178
00:08:21,235 --> 00:08:24,238
文本的滚动以及
单独的字符


179
00:08:24,771 --> 00:08:27,774
当我们放大
并且旋转摄像头


180
00:08:28,141 --> 00:08:30,711
直立文本也检测到了
成一个角度的


181
00:08:30,777 --> 00:08:33,380
某些文本


182
00:08:34,414 --> 00:08:36,950
这就是我们的新文本检测器
开发者会用这个检测器来实现


183
00:08:37,017 --> 00:08:38,784
什么好玩的功能
我对此十分期待


184
00:08:42,523 --> 00:08:44,858
随着我们现在在iOS上的
“核心图像” 统一实现


185
00:08:44,925 --> 00:08:46,560
我们还有了 “自动颜色管理”


186
00:08:46,627 --> 00:08:48,362
这一
很棒的


187
00:08:48,428 --> 00:08:49,863
功能


188
00:08:50,130 --> 00:08:53,200
自从 “核心图像” 出现后
OS X上就可以使用


189
00:08:53,267 --> 00:08:56,470
这项功能了 但是现在
我们也把它弄到了iOS上


190
00:08:57,104 --> 00:09:01,275
这就意味着
现在 “核心图像” 完全支持


191
00:09:02,409 --> 00:09:04,945
基于ICC的CGColorSpac
eRefs了


192
00:09:05,846 --> 00:09:08,515
这些可以被用到输入文本、
输出文本上


193
00:09:08,582 --> 00:09:10,651
甚至还可以被当做
“核心图像” 的一个工作区


194
00:09:11,852 --> 00:09:14,488
这是因为完成了在iOS上
支持ColorSync这一


195
00:09:14,555 --> 00:09:19,459
很棒的工作
才实现的


196
00:09:21,061 --> 00:09:22,095
对用户来说 这就意味着


197
00:09:22,162 --> 00:09:25,332
你可以自动得到用色彩空间
标记的TIFF或者JPG


198
00:09:25,399 --> 00:09:27,768
正确
渲染


199
00:09:28,435 --> 00:09:29,770
很多图像是用sRGB标记的


200
00:09:29,837 --> 00:09:34,074
在之前的iOS版本上它们已经
可以正确渲染了


201
00:09:34,141 --> 00:09:38,979
不过现在如何你的图像是用
一个色彩空间而不是用sRGB


202
00:09:39,146 --> 00:09:41,114
来标记的 那么你也可以
得到正确的行为了


203
00:09:41,515 --> 00:09:43,684
这里有一个例子
是用Pro Photo色彩空间


204
00:09:43,750 --> 00:09:45,018
标记的一幅图像


205
00:09:45,085 --> 00:09:48,522
背景中的红色台子
不饱色


206
00:09:48,589 --> 00:09:50,190
肤色也很难看


207
00:09:50,691 --> 00:09:56,296
当你在这个上面正确看到
嵌入ICC轮廓时


208
00:09:56,463 --> 00:09:57,698
图像就正确进行了渲染


209
00:09:58,866 --> 00:10:00,934
这是你在 “核心图像” 上
自动得到的


210
00:10:04,071 --> 00:10:07,708
我们还对CI内核类做了一些
新的支持


211
00:10:07,774 --> 00:10:09,343
现在在OS X上已经可用了


212
00:10:09,409 --> 00:10:11,144
当然它在iOS上早就可以
用了


213
00:10:11,211 --> 00:10:13,447
这是我们的统一执行的
另外一项福利


214
00:10:14,615 --> 00:10:17,784
举例来说 我们有两个类
分别叫做CI颜色内核


215
00:10:17,851 --> 00:10:19,019
以及CI扭曲内核


216
00:10:19,319 --> 00:10:22,022
这些类背后的理念
是让你能够更容易地


217
00:10:22,089 --> 00:10:23,957
最常见的
基础滤镜


218
00:10:24,791 --> 00:10:27,928
之前在OS X上
如果你想要写一个简单的融合滤镜


219
00:10:27,995 --> 00:10:29,530
用给定的遮罩把这三个图像


220
00:10:29,596 --> 00:10:32,666
融合到一起 那么你就需要


221
00:10:32,799 --> 00:10:34,468
写几行代码
对采样器


222
00:10:34,835 --> 00:10:36,036
正确进行取样


223
00:10:36,670 --> 00:10:38,338
然后你需要写好遮罩


224
00:10:38,572 --> 00:10:39,806
把这三幅图形组合到一起


225
00:10:40,741 --> 00:10:42,609
而如果你用CI颜色
内核类


226
00:10:43,010 --> 00:10:44,244
那么代码就简单的多了


227
00:10:44,778 --> 00:10:48,315
现在内核的输入就是一个
采样器 下划线


228
00:10:48,382 --> 00:10:51,251
下划线采样参数
那么内核的代码就只不过是


229
00:10:51,318 --> 00:10:54,254
把三个结果混合到一起的
数字游戏


230
00:10:54,821 --> 00:10:57,391
对开发者来说
这是件大好事 事情更简单了


231
00:10:57,457 --> 00:11:01,328
“核心图像” 简化、连接
项目的工作


232
00:11:01,895 --> 00:11:04,031
就更加容易了


233
00:11:07,134 --> 00:11:09,036
我们还对OS X上可用的
CI内核语言


234
00:11:09,102 --> 00:11:12,005
做了大量的
优化


235
00:11:12,606 --> 00:11:16,009
我们的统一执行
当我们把CI内核语言


236
00:11:16,076 --> 00:11:18,979
编译进
目的环境语言时


237
00:11:19,913 --> 00:11:22,349
我们会通过Apple的
LLVM技术来实现


238
00:11:22,416 --> 00:11:26,787
这样 我们的语言中
就有了一项新的特性


239
00:11:27,387 --> 00:11:30,224
比如If、For以及While
这些之前都是不可用的


240
00:11:31,458 --> 00:11:33,694
现有的apps中的CI内核
应该不会受到影响


241
00:11:34,094 --> 00:11:36,563
不过有了新的编译器
我们的报警更严谨了


242
00:11:36,630 --> 00:11:38,365
所以如果你的app链接到了


243
00:11:38,432 --> 00:11:40,133
El Capitan
或者稍后会链接它


244
00:11:40,400 --> 00:11:42,302
请密切留意
编译器报警


245
00:11:44,571 --> 00:11:47,174
举例来说
这是一个内核的简单示例


246
00:11:47,241 --> 00:11:51,411
之前在OS X使用内核语言
是不可能的


247
00:11:51,778 --> 00:11:54,481
因为这个特定的滤镜
有一个输入参数


248
00:11:54,548 --> 00:11:55,916
这个参数是一个计数


249
00:11:56,550 --> 00:11:58,652
我们想在这个内核中有一个
For循环


250
00:11:58,952 --> 00:12:00,687
会基于那个计数变量
进行循环


251
00:12:01,455 --> 00:12:03,490
在这个特定的例子中
我们想要对n点进行


252
00:12:03,557 --> 00:12:06,026
矢量
动态模糊


253
00:12:06,627 --> 00:12:08,529
现在写这个内核
就很容易了


254
00:12:09,429 --> 00:12:12,266
你可以更加天马行空
你可以有一个


255
00:12:12,332 --> 00:12:13,767
提前退出的For循环


256
00:12:14,601 --> 00:12:17,271
在这个例子中
我们会对那副图像进行采样


257
00:12:17,337 --> 00:12:21,508
直到我们得到了图像上的
一个不透明区域 然后我们


258
00:12:21,575 --> 00:12:24,678
For循环
仅仅返回图像中的


259
00:12:24,745 --> 00:12:29,750
颜色的
平均色


260
00:12:29,917 --> 00:12:32,252
因此你要记住


261
00:12:32,319 --> 00:12:35,055
我们的内核语言
就是我们这个语言的整体目标


262
00:12:35,489 --> 00:12:38,492
我们想实现的
就是让你仅仅写一次内核


263
00:12:38,559 --> 00:12:42,696
然后不管你的内核运行在
什么样的设备上


264
00:12:42,763 --> 00:12:44,031
你的内核
就都可以运行


265
00:12:44,531 --> 00:12:46,800
这样它就可以独立运行
不管运行在什么样的系统中


266
00:12:46,867 --> 00:12:50,838
不管是iOS还是OS X
不管你的输入图像尺寸如何


267
00:12:51,171 --> 00:12:54,842
内核语言也同样支持
目的核心


268
00:12:54,908 --> 00:12:58,078
以及采样器转变因此我们也支持图像自
动镶嵌图案


269
00:12:59,513 --> 00:13:02,115e
此外
CI内核语义和我们的


270
00:12:59,513 --> 00:13:02,115
此外
CI内核语义和我们的


271
00:13:02,182 --> 00:13:03,650
后端渲染器
是独立工作的


272
00:13:03,851 --> 00:13:05,285
因为无论我们用到是
Metal


273
00:13:05,352 --> 00:13:07,120
还是OpenCL，还是OpenGL


274
00:13:07,187 --> 00:13:10,424
还是OpenGL ES
你在CI内核语言中


275
00:13:10,591 --> 00:13:11,992
写一次你的算法就可以了


276
00:13:16,496 --> 00:13:19,366
这就是今年“核心图像”上
有什么新料的重点内容


277
00:13:20,067 --> 00:13:22,035
我们接下来的主题
是要讲一讲如何


278
00:13:22,102 --> 00:13:23,871
把 “核心图像”
和其他框架桥接起来


279
00:13:24,071 --> 00:13:25,939
具体来说 指的就是


280
00:13:26,006 --> 00:13:28,742
我们的平台上可用的
某些很棒的图形资源


281
00:13:30,410 --> 00:13:33,614
我们的平台上有很棒的


282
00:13:34,281 --> 00:13:35,182
成像框架


283
00:13:35,249 --> 00:13:36,683
比如 “核心动画” 、


284
00:13:37,150 --> 00:13:39,653
SceneKit、
SpriteKit、Metal、


285
00:13:39,720 --> 00:13:41,088
AV Foundation、


286
00:13:41,154 --> 00:13:43,824
IOSurfaces
以及多个视图类


287
00:13:44,291 --> 00:13:47,928
我们今年花了大量的时间
来让它们能够


288
00:13:48,695 --> 00:13:49,863
和 “核心图像” 兼容


289
00:13:49,997 --> 00:13:51,798
开始讨论前


290
00:13:51,932 --> 00:13:55,068
我想介绍下托尼·朱
他会展开讲一下


291
00:13:55,135 --> 00:13:56,904
“核心图像”
以及Metal


292
00:14:05,112 --> 00:14:05,979
谢谢 大卫


293
00:14:06,113 --> 00:14:07,781
早上好
我的名字是托尼


294
00:14:08,182 --> 00:14:10,017
首先我要告诉你们关于
“核心图像”


295
00:14:10,384 --> 00:14:12,119
以及Metal
更多的信息


296
00:14:14,188 --> 00:14:17,090
就像大卫之前提到的
今年我们在 “核心图像” 中


297
00:14:17,157 --> 00:14:18,892
添加了Metal渲染
支持


298
00:14:19,393 --> 00:14:21,828
我们这样做的一个原因
是为了增加我们的


299
00:14:21,895 --> 00:14:24,264
图像类型支持
扩展套件


300
00:14:24,731 --> 00:14:26,834
例如IOSurface以及CGIm
ag


301
00:14:27,367 --> 00:14:29,169
无论你的CIContext类型是什
么


302
00:14:29,236 --> 00:14:31,271
你都可以把它们用作


303
00:14:31,338 --> 00:14:33,240
一个CI滤镜的
输入或者输出


304
00:14:34,107 --> 00:14:36,743
不过如果你有一个基于OpenGL的
CIContext


305
00:14:37,044 --> 00:14:39,646
你也可以渲染进、
渲染出OpenGL纹理


306
00:14:40,981 --> 00:14:43,717
今年 如果现在你有一个
基于Metal的CIContext


307
00:14:43,884 --> 00:14:45,919
那么你也可以渲染进、渲染出
Metal纹理


308
00:14:46,653 --> 00:14:48,222
之前没有这项支持时


309
00:14:48,422 --> 00:14:51,692
你就必须把一个Metal纹理
转换成某种现有的图像类型


310
00:14:52,159 --> 00:14:54,161
这就有可能在CPU和GPU之间


311
00:14:54,228 --> 00:14:56,897
造成 “昂贵的”
数据复制


312
00:14:57,564 --> 00:14:59,433
有了这项支持
我们就可以高效


313
00:14:59,499 --> 00:15:01,268le
渲染进、渲染出
这些资源


314
00:14:59,499 --> 00:15:01,268
渲染进、渲染出
这些资源


315
00:15:03,871 --> 00:15:06,173
我们再来看看 “核心图像” 内
用于Metal支持的


316
00:15:06,240 --> 00:15:08,175
一些新的APIs


317
00:15:09,009 --> 00:15:12,546
首先是一个允许你用一个
输入Metal纹理对一个


318
00:15:12,913 --> 00:15:14,348
CI图像进行初始化的API


319
00:15:14,982 --> 00:15:18,051
以及一本你可以在其中


320
00:15:18,118 --> 00:15:20,554
指定
诸如纹理标记颜色空间


321
00:15:21,121 --> 00:15:22,589
等事情的
可选字典


322
00:15:23,223 --> 00:15:25,025
这是一个使用高层框架的
优点的


323
00:15:25,092 --> 00:15:27,427
一个示例
例如 “核心图像”


324
00:15:27,828 --> 00:15:29,162
优点是它会自动帮你处理
类似


325
00:15:29,229 --> 00:15:31,298
颜色管理等等
细节问题


326
00:15:34,268 --> 00:15:35,636
要使用这些基于Metal的


327
00:15:35,702 --> 00:15:37,504
资源进行渲染
你需要通过给它你的


328
00:15:37,704 --> 00:15:40,007
应用程序正在用的Metal设备


329
00:15:40,073 --> 00:15:41,842
<br/>
来创建一个基于Metal的


330
00:15:42,176 --> 00:15:45,012
CIContext
新的CIContext


331
00:15:45,979 --> 00:15:49,216
再说一遍 你可以为
中间缓冲器指定


332
00:15:49,283 --> 00:15:52,819
类似工作颜色空间或者
工作地垫的


333
00:15:52,886 --> 00:15:54,488
选项字典


334
00:15:54,555 --> 00:15:56,823
你甚至还可以说明


335
00:15:56,890 --> 00:16:00,027
你想要使用某个
次优GPU


336
00:16:03,530 --> 00:16:04,364
无论是哪种情况


337
00:16:04,431 --> 00:16:06,834
有了这个新的基于Metal的CIC
ontext


338
00:16:06,900 --> 00:16:09,670
我们就有了新的渲染API
允许你把任何


339
00:16:09,736 --> 00:16:12,973
CI图像渲染到一个
输出Metal纹理


340
00:16:14,007 --> 00:16:15,709
这个API有个很棒的特性
我想要


341
00:16:15,776 --> 00:16:17,744
专门提出来
就是可以指定


342
00:16:17,811 --> 00:16:19,580
任选
命令缓冲区


343
00:16:21,114 --> 00:16:23,750
如果你想又快又好地做事
你可以指定为 “无”


344
00:16:24,418 --> 00:16:26,720
此时 “核心图像” 就会在内部
创建一个


345
00:16:27,287 --> 00:16:29,056
然后把所有必要的命令
编码到那里


346
00:16:29,590 --> 00:16:31,091
然后在返回之前
把它提交上去


347
00:16:31,658 --> 00:16:34,661
这样就可以高效调度
GPU上的渲染调用


348
00:16:36,496 --> 00:16:39,199
不过你也可以给那个调用
提高一个命令缓冲区


349
00:16:39,566 --> 00:16:42,603
此时 “核心图像” 只会
向它编码命令


350
00:16:42,903 --> 00:16:44,872
然后不经过提交
就把它返回回来


351
00:16:45,372 --> 00:16:48,342
这样的话
你就可以完全控制你对


352
00:16:48,408 --> 00:16:53,413
命令缓冲区的调度
以便在GPU上进行渲染


353
00:16:53,480 --> 00:16:56,416
你也就有了在命令缓冲区
的任何地方插入CI滤镜


354
00:16:56,483 --> 00:16:57,451
灵活性


355
00:16:59,219 --> 00:17:00,821iddle
我来详细
解释下这点


356
00:16:59,219 --> 00:17:00,821
我来详细
解释下这点


357
00:17:01,755 --> 00:17:03,323
对于那些第一次使用Metal的


358
00:17:03,390 --> 00:17:06,093
人来说 使用Metal进行渲染
基本上就是向一个命令缓冲区


359
00:17:06,159 --> 00:17:08,060
编码一系列的
渲染命令


360
00:17:08,561 --> 00:17:10,664
在这个例子中
我们有两组命令


361
00:17:11,531 --> 00:17:14,300
用我们刚才看到的那个新的
API


362
00:17:14,935 --> 00:17:16,103
你现在就可以向


363
00:17:16,170 --> 00:17:17,671
这个命令缓冲区的任何地方


364
00:17:17,738 --> 00:17:19,673
插入那个CI滤镜


365
00:17:19,740 --> 00:17:20,741
比如在缓冲区的开头、


366
00:17:21,675 --> 00:17:22,509
结尾


367
00:17:23,377 --> 00:17:26,146
甚至可以是在那两个渲染命令的
正中间


368
00:17:26,847 --> 00:17:29,082
你想象一下这种情况
你需要对某些纹理进行


369
00:17:29,149 --> 00:17:32,152
某些绘制、引发
或者渲染


370
00:17:32,553 --> 00:17:35,656
然后把纹理送入一系列的
CI滤镜


371
00:17:36,690 --> 00:17:38,125
并由此生成一些
输入纹理


372
00:17:38,192 --> 00:17:39,493
在上面进行更多的渲染


373
00:17:42,396 --> 00:17:46,099
然后 “核心图像” 会从内部
为你的图像图表中可能有的


374
00:17:46,266 --> 00:17:48,468
每个滤镜编码
全部命令


375
00:17:50,637 --> 00:17:52,306
实际上
就像大卫之前提到过的


376
00:17:52,806 --> 00:17:55,042
我们的某些内置滤镜也会
使用Metal性能材质


377
00:17:55,108 --> 00:17:56,510
来利用这些专门为


378
00:17:56,577 --> 00:17:59,446
支持Metal的设备进行了调整的
高度优化的


379
00:17:59.513 --> 00:18:00.781 align:middle
材质


380
00:17:59,513 --> 00:18:00,781
材质


381
00:18:04,218 --> 00:18:06,286
最后我想提一下
这种调用协定


382
00:18:06,353 --> 00:18:09,056
完美地赋予了它自身
使用CI、直接向一个


383
00:18:09,122 --> 00:18:11,992
MetalKit视图进行渲染的
能力


384
00:18:12,559 --> 00:18:15,095
我想向你们演示一个


385
00:18:15,162 --> 00:18:16,630
示例代码
以便进一步向你们解释


386
00:18:17,931 --> 00:18:20,601
这是一个示例代码
如果你需要基于新的MetalKit


387
00:18:20,667 --> 00:18:23,203
框架、创建一个新的
应用程序


388
00:18:23,270 --> 00:18:25,405
那么你就需要写这个代码了


389
00:18:26,206 --> 00:18:28,742
你需要做的第一件事
就是当你想要设置视图时


390
00:18:28,909 --> 00:18:30,644
你要在这里做
几件事


391
00:18:31,512 --> 00:18:32,880
第一件关键的事


392
00:18:33,280 --> 00:18:37,150
是把那个视图的 “仅帧
缓存器” 属性设置为 “假”


393
00:18:37,618 --> 00:18:40,120
这样 “核心图像” 就可以使用
Metal计算着色器来向


394
00:18:40,187 --> 00:18:42,322
那个视图的输出纹理
进行渲染


395
00:18:44,424 --> 00:18:45,359
你下一步要做的


396
00:18:45,425 --> 00:18:48,328
就是使用一台Metal设备
来把那个CIContext初始化


397
00:18:48,795 --> 00:18:51,598
这样做的原因是
在一个应用程序中


398
00:18:51,665 --> 00:18:54,268
类似初始化一个CIContext
这种事情 你只想做一次


399
00:18:56,904 --> 00:18:59,439
然后在 “绘制和视图委托”
功能中


400
00:18:59,940 --> 00:19:01,875
要通过那个视图渲染某些
CI滤镜


401
00:19:01,942 --> 00:19:03,544
你就需要写这样的
代码


402
00:19:03,810 --> 00:19:05,712
让我来带领你们
逐句通过这个代码


403
00:19:06,713 --> 00:19:08,615
首先
你要创建一个命令缓冲区


404
00:19:09,049 --> 00:19:11,385
这个缓冲区最终
会给到这个可绘制物


405
00:19:13,720 --> 00:19:16,190
然后我们要用一些给定的
输入Metal纹理


406
00:19:16,290 --> 00:19:18,325
来对一个CI图像
进行初始化


407
00:19:18,659 --> 00:19:22,629
现在 这个CI图像可以通过
其它方式出现 举例来说


408
00:19:22,696 --> 00:19:25,065
我们有的某些其它图像类型
比如一个CGImage


409
00:19:25,132 --> 00:19:28,902
不过在这个例子中 我们只是
向你们演示下如何使用新API


410
00:19:28,969 --> 00:19:32,105
一旦你有了一张
CI图像


411
00:19:32,206 --> 00:19:36,210
你就可以把一系列的CI滤镜
链接到它上面


412
00:19:36,276 --> 00:19:39,446
在这个例子中 我们要使用
一个CI高斯模糊滤镜


413
00:19:42,149 --> 00:19:44,985
然后一旦你有了你想要渲染的
CI图像


414
00:19:45,485 --> 00:19:48,555
你就想要抓取当前绑定到
那个视图的当前可绘制物上


415
00:19:48,622 --> 00:19:52,659
的纹理
然后使用我们在这里想用的


416
00:19:52,759 --> 00:19:56,230
命令缓冲区 把CI图像渲染到
那个纹理


417
00:19:58,198 --> 00:20:00,167
最后 一旦我们编码好了
这个渲染命令


418
00:20:00,234 --> 00:20:03,504
你就还需要向命令缓冲区
插入另外的一个Metal命令


419
00:20:03,770 --> 00:20:05,772
目的是为了显示视图的当前
可绘制物


420
00:20:06,440 --> 00:20:08,342
然后你只需要在缓冲区调用
提交即可


421
00:20:09,676 --> 00:20:11,044
把一些 “核心图像” 滤镜


422
00:20:11,111 --> 00:20:13,080
集成到
一个MetalKit应用程序


423
00:20:13,213 --> 00:20:14,748
就是这么简单


424
00:20:18,652 --> 00:20:19,920
接下来我想谈一谈


425
00:20:19,987 --> 00:20:22,422
如何桥接 “核心图像”
以及AV Foundation


426
00:20:24,992 --> 00:20:26,960
有了我们今年在这些框架中
做的最新的变更


427
00:20:27,027 --> 00:20:30,597
现在向你的AVFoundation
应用程序添加 “核心图像”


428
00:20:30,664 --> 00:20:31,865
滤镜就很容易了


429
00:20:33,133 --> 00:20:34,434
这是因为现在 “核心图像”


430
00:20:34,635 --> 00:20:37,204
已经方便地和AVVideo
Composition类


431
00:20:37,271 --> 00:20:38,472
集成到了一起


432
00:20:39,907 --> 00:20:42,209
默认你会得到自动
颜色管理


433
00:20:42,609 --> 00:20:44,444
但是如果你不需要
你也可以禁用它


434
00:20:46,380 --> 00:20:48,649
我们来通过几个例子
看看如何把CI滤镜


435
00:20:48,715 --> 00:20:50,350
应用到视频上


436
00:20:50,918 --> 00:20:52,986
首先是在导出视频的语境中
其次是在实况回放


437
00:20:53,053 --> 00:20:54,855
一个视频的
语境中


438
00:20:55,422 --> 00:20:59,927dle
要演示这些
例子


439
00:21:00,093 --> 00:21:01,295
我们要使用几年前我们在


440
00:21:01,361 --> 00:21:03,497
苹果全球开发者大会上
演示给你们的一个滤镜


441
00:21:03,564 --> 00:21:08,001
在这个滤镜中
对于视频图像的每一帧


442
00:21:08,068 --> 00:21:12,806
我们都会首先在它上面
应用一个棕黑色调滤镜以及


443
00:21:12,873 --> 00:21:19,046
随机噪声
最后是在它的顶部进行一些


444
00:21:19,112 --> 00:21:21,849
垂直刮痕覆盖


445
00:21:21,915 --> 00:21:27,754
你们中如果有人记得的话
这是一个老电影滤镜


446
00:21:28,355 --> 00:21:31,592
是几年前我们在苹果全球
开发者大会上演示给你们的


447
00:21:31,725 --> 00:21:34,127
第一个滤镜非常
直接


448
00:21:34,194 --> 00:21:37,664
它只需要一个单一的
输入图像


449
00:21:37,731 --> 00:21:39,800
以及一个输入时间参数
你可以用这个参数来


450
00:21:39,867 --> 00:21:42,669
以可重复的方式、
可预见的结果


451
00:21:42,936 --> 00:21:44,171
来向视频应用特效


452
00:21:44,872 --> 00:21:49,843
我们回来看看导出那个
视频时 我们应该怎样


453
00:21:49,910 --> 00:21:50,878
应用这个滤镜


454
00:21:52,279 --> 00:21:55,249
你首先需要做的 就是创建
一个经过过滤的合成


455
00:21:55,883 --> 00:21:59,720
赋予它你想要导出的音频视频
资产以及一个回调块


456
00:21:59,786 --> 00:22:04,658
你在这个回调块中可以指定
渲染视频的每一帧时


457
00:22:05,192 --> 00:22:09,596
应用的一个
滤镜 “配方”


458
00:22:10,497 --> 00:22:13,166
从这个回调块中 我们就可以
得到一个请求对象


459
00:22:13,233 --> 00:22:16,336
这个对象就是一个输入参数
你就可以得到把你的


460
00:22:16,703 --> 00:22:18,071
CI滤镜链接在一起的


461
00:22:18,305 --> 00:22:20,407
合成时间
以及源图像


462
00:22:22,009 --> 00:22:26,013
一旦你有了自己的
经过过滤的CI图像


463
00:22:26,380 --> 00:22:28,849
你就可以调用请求对象上的
Finish With图像


464
00:22:29,449 --> 00:22:31,818
你可以向那个调用传递一个
“无” 语境


465
00:22:32,186 --> 00:22:34,321
然后AVVideo
Composition


466
00:22:34,388 --> 00:22:36,657
默认
就会创建一个CIContext


467
00:22:37,324 --> 00:22:38,425
就像我之前提到的


468
00:22:38,492 --> 00:22:40,294
CIContext会自动得到
颜色管理


469
00:22:40,994 --> 00:22:42,696
如果你想禁用它
那么你只需要创建一个


470
00:22:42,763 --> 00:22:44,665
你自己的
CIContext


471
00:22:45,232 --> 00:22:48,669
指定一个空颜色工作区
然后把它传递到那个


472
00:22:48,735 --> 00:22:50,437
Finish With图像调用中


473
00:22:53,240 --> 00:22:57,110
我们刚刚向你展示的滤镜
是一个十分简单的滤镜


474
00:22:57,678 --> 00:23:00,447dle
并不涉及
卷积滤镜


475
00:22:57,678 --> 00:23:00,447
并不涉及
卷积滤镜


476
00:23:00,981 --> 00:23:03,217
但是在这个例子中
你确实有了卷积滤镜


477
00:23:03,550 --> 00:23:07,454
你要小心的一件事是
不良的结果


478
00:23:08,021 --> 00:23:10,991
即干净的像素
渗透进了


479
00:23:11,058 --> 00:23:12,793
那副图像的边缘


480
00:23:13,827 --> 00:23:17,331
要解决这个问题
我们有一个简单的方法


481
00:23:17,564 --> 00:23:19,666
我们在很多类中都会用到
这个方法 也包括那个类


482
00:23:20,400 --> 00:23:21,969
你首先要做的


483
00:23:22,636 --> 00:23:25,973
就是有了源图像 你就想把
卷积滤镜应用到它上面


484
00:23:26,039 --> 00:23:28,609
你想通过夹紧延伸
来调用图像


485
00:23:29,243 --> 00:23:32,846
它会无限边缘复制那个图像的
全部像素


486
00:23:32,913 --> 00:23:34,248
以及图像的边缘


487
00:23:35,082 --> 00:23:37,985
这样的话
当你应用这个滤镜时


488
00:23:39,353 --> 00:23:42,923
你就不会再出现清晰的像素
和图像融合这个问题了


489
00:23:44,591 --> 00:23:47,427
因为如果那样做 你最后得到的
就是一张无限大的图像


490
00:23:47,794 --> 00:23:51,431
滤镜应用结束时
你想要通过剪切矩形


491
00:23:51,498 --> 00:23:54,101
来增加图像
以便把那个图像剪切回到


492
00:23:54,168 --> 00:23:55,636
源图像的范围


493
00:23:57,604 --> 00:24:01,642
通过使用这个简单的方法
你看到的图像就更简洁了


494
00:24:02,042 --> 00:24:04,811
边缘边界也非常漂亮、
明快、敏锐


495
00:24:08,782 --> 00:24:09,883
因此一旦我们有了那个


496
00:24:09,950 --> 00:24:11,752
AVVideo
Composition


497
00:24:12,119 --> 00:24:15,556
如果你想要创建一个
导出会话以便导出一个视频


498
00:24:15,622 --> 00:24:16,723
你就可以通过创建这个


499
00:24:17,491 --> 00:24:19,893
音频视频导出会话
并且指定你想要导出的


500
00:24:20,561 --> 00:24:23,664
一个输出URL位置
来实现


501
00:24:23,730 --> 00:24:27,100
你也可以指定我们刚刚创建的
视频组成的导出位置


502
00:24:28,168 --> 00:24:30,304
要记住的一点是
你可能想要...


503
00:24:31,004 --> 00:24:34,208
你想要调用 “从URL删除项目”
来删除任何可能已经存在于


504
00:24:34,274 --> 00:24:36,376
那个导出位置的
项目


505
00:24:37,211 --> 00:24:38,979
一旦你完成后
你就可以在导出会话上


506
00:24:39,046 --> 00:24:41,648
调用Export
Asynchronously


507
00:24:42,082 --> 00:24:43,483
这样就会开始一个进程
导出那个


508
00:24:44,218 --> 00:24:47,955
视频
并且把CI滤镜应用到


509
00:24:48,021 --> 00:24:49,489
你的视频的每一个
单一的帧上


510
00:24:50,390 --> 00:24:53,293
如果你想要更新你的UI上的
某些进度


511
00:24:53,360 --> 00:24:56,296
以便显示
那个导出的进度


512
00:24:56,530 --> 00:24:59,867
你就可以在你的调用块中
使用 “合成时间” 参数


513
00:25:00,000 --> 00:25:01,935
来更新这样的UI元素


514
00:25:06,039 --> 00:25:07,841
现在它导出了


515
00:25:08,141 --> 00:25:11,044
如果是回放一个音频视频资产
你需要写的代码


516
00:25:11,111 --> 00:25:12,880
实际上
也非常类似


517
00:25:13,313 --> 00:25:16,750
创建视频组成的代码
和我们之前看到的一模一样


518
00:25:17,451 --> 00:25:19,953
唯一的不同之处在于
你不需要再创建一个


519
00:25:20,020 --> 00:25:21,288
导出会话


520
00:25:21,722 --> 00:25:24,491
你需要用那个音频视频资产
以及我们刚刚创建的视频组成


521
00:25:24,892 --> 00:25:27,461
来创建一个
AVPlayerItem


522
00:25:28,395 --> 00:25:30,797
然后再用那个播放器项目
创建一个AVPlayer


523
00:25:30,864 --> 00:25:33,100
之后在你的播放器内
调用“播放”


524
00:25:33,734 --> 00:25:39,640
现在我要向你们展示一个
视频 让你们看看我们是如何


525
00:25:39,706 --> 00:25:44,378
在回放时 把那个老电影滤镜
应用到一个音频视频资产的


526
00:25:48,148 --> 00:25:49,950
这里要注意的一件事是


527
00:25:50,017 --> 00:25:51,718
当你清洗这个
视频时


528
00:25:51,985 --> 00:25:53,921
你可以看到同样的特效
以可重复的方式、


529
00:25:53,987 --> 00:25:56,990
可预期的结果
应用到了这个视频上


530
00:25:58,025 --> 00:25:59,393
因此 “核心图像”


531
00:25:59,459 --> 00:26:02,729
和AV Foundation高效
互操作在了一起


532
00:26:03,230 --> 00:26:07,201
接下来我想请
亚历克斯


533
00:26:07,267 --> 00:26:09,269
来再给你们讲讲
“核心图像” 提供程序


534
00:26:09,870 --> 00:26:10,737
谢谢


535
00:26:15,509 --> 00:26:16,343
谢谢 托尼


536
00:26:17,211 --> 00:26:19,847
我的名字是亚历山大·纳曼
我要讲讲 “核心图像”


537
00:26:19,913 --> 00:26:21,381
提供程序
然后我们再讲讲我们的


538
00:26:21,448 --> 00:26:23,717
系统上的更多的API
还有STKs


539
00:26:23,784 --> 00:26:26,119
以及它们是如何
和 “核心图像” 一起工作


540
00:26:26,353 --> 00:26:27,788
创造有趣的
应用程序


541
00:26:29,423 --> 00:26:30,257
我们从


542
00:26:30,324 --> 00:26:31,692
CIImageProvider
开始吧


543
00:26:31,758 --> 00:26:33,360
CIImageProvider是


544
00:26:33,427 --> 00:26:35,662
我们在CI图像上的一个类型
之前OS X上就有了


545
00:26:35,729 --> 00:26:37,865
但是现在 作为我们的


546
00:26:38,265 --> 00:26:40,267
统一执行的一部分
现在iOS上也有了


547
00:26:40,334 --> 00:26:44,171
对你来说
你就可以把输入图像带入


548
00:26:44,238 --> 00:26:48,108
你的系统 而如果没有它
这就是不可能的


549
00:26:48,175 --> 00:26:49,743
举例来说
如果你有一个不被支持的


550
00:26:50,310 --> 00:26:52,179
文件格式
你想要创建一个基于


551
00:26:52,246 --> 00:26:55,015
那个文件格式的
CI图像


552
00:26:55,682 --> 00:26:58,485
或者说 如果你有某些
从某些站点流出的数据


553
00:26:58,552 --> 00:27:00,187le
而且你想创建一个CI图像


554
00:26:58,552 --> 00:27:00,187
而且你想创建一个CI图像


555
00:27:00,254 --> 00:27:02,756
那么你就可以使用一个CIImage
Provider


556
00:27:03,323 --> 00:27:05,292
它们是通过
回调实现的


557
00:27:06,159 --> 00:27:10,264
你可以坐享其成
当我们需要填写数据时


558
00:27:10,330 --> 00:27:13,433
我们会通知你、告诉你
你就可以得到自动镶嵌图案


559
00:27:13,500 --> 00:27:15,969
而我们就会为你处理轻便性
以及缓存


560
00:27:16,970 --> 00:27:18,272
我们来看看
它是怎样实现的


561
00:27:18,939 --> 00:27:20,908
先说重要的
你创建你自己的类


562
00:27:20,974 --> 00:27:23,510
在这个例子中 我们创建
一个叫做图块提供程序的类


563
00:27:24,678 --> 00:27:27,447
然后我们用这个图块提供程序
创建一个CI图像


564
00:27:27,915 --> 00:27:30,450
除了这个
我们让它的尺寸和我们试图


565
00:27:30,651 --> 00:27:33,387
创建的图像尺寸一致
无论我们想用什么样的格式


566
00:27:33,453 --> 00:27:37,057
来创建这幅图像
一个可选择的颜色空间


567
00:27:37,357 --> 00:27:40,160
在这个例子中
我们在选项字典中


568
00:27:40,227 --> 00:27:42,796
给出图块尺寸


569
00:27:44,464 --> 00:27:45,866
要把这个用起来


570
00:27:46,834 --> 00:27:49,937
我们只需要实现一种叫做
“提高图像资料” 的方法


571
00:27:50,003 --> 00:27:52,406
“核心图像” 就会通知你、
告诉你


572
00:27:52,472 --> 00:27:53,841
填写这个信息


573
00:27:55,075 --> 00:27:56,977
你必须在那个
数据指针中填写这个信息


574
00:27:57,211 --> 00:28:01,615
数据指针有给定的行字节值
在X和Y轴上有确定的位置


575
00:28:01,715 --> 00:28:03,684
有确定的宽度和高度
如果你愿意的话


576
00:28:03,750 --> 00:28:05,285
你还可以标记一些用户信息


577
00:28:05,352 --> 00:28:06,854
要实现你自己的
图像提供程序


578
00:28:06,920 --> 00:28:09,857
你要做的
就是这些


579
00:28:09,923 --> 00:28:15,462
现在我们再来谈谈我们拥有的
各种视图类


580
00:28:15,529 --> 00:28:16,964
谈谈你可以在iOS和OS X上


581
00:28:17,030 --> 00:28:19,032
和 “核心图像” 一起用的
各种视图类


582
00:28:20,200 --> 00:28:23,237
我们对使用 “核心图像”
进行渲染就有了一个广谱


583
00:28:23,303 --> 00:28:25,005
支持
所处的系统可以是


584
00:28:25,072 --> 00:28:29,176
非常高级的
例如UIImageView


585
00:28:29,476 --> 00:28:30,677
这样对应用了一种


586
00:28:31,011 --> 00:28:32,713
“核心图像” 特效的
图像进行渲染


587
00:28:32,779 --> 00:28:33,647
就非常容易


588
00:28:34,081 --> 00:28:36,083
也可以是
非常低级的系统


589
00:28:36,550 --> 00:28:40,754
或者可能是高级性能APIs
比如GLKView


590
00:28:40,821 --> 00:28:45,325
或者MTK视图
你就可以对你所做的事情


591
00:28:45,392 --> 00:28:46,460
有细粒度更高的控制


592
00:28:50,197 --> 00:28:52,099
那么让我们来看看
UIImageView


593
00:28:53,267 --> 00:28:54,668
UIImageView可能是


594
00:28:54,735 --> 00:28:57,538
在iOS上展示一幅CI图像的
最简单的方式


595
00:28:57,871 --> 00:28:59,840
你需要在你的
UIImageView上


596
00:28:59,907 --> 00:29:03,377
做的 就是把图像属性
设置成一个UI图像...


597
00:29:03,944 --> 00:29:06,213
在这个例子中
是一个基于CI的图像


598
00:29:07,514 --> 00:29:10,184
问题在于
虽然使用这个方法非常简单


599
00:29:10,817 --> 00:29:13,387
它并不是展示一幅CI图像的
性能最高的方法


600
00:29:13,987 --> 00:29:15,923
那么最后我们不得不做的


601
00:29:16,657 --> 00:29:18,759
就是把它渲染回CPU


602
00:29:18,825 --> 00:29:21,128
然后把它
发送回GPU


603
00:29:21,195 --> 00:29:22,763
效率不是
尽可能地高


604
00:29:22,829 --> 00:29:24,698
如果我们看一个
简单的示例


605
00:29:24,765 --> 00:29:25,832
在这个例子中


606
00:29:25,899 --> 00:29:27,868
我们通过使用一个
UIImageView


607
00:29:28,101 --> 00:29:29,536
来运行一个像素化滤镜


608
00:29:29,970 --> 00:29:32,906
我们可以看到
应用了这种特性后


609
00:29:32,973 --> 00:29:38,178
我们在视网膜尺寸图像上
得到了大约每秒二十帧


610
00:29:40,347 --> 00:29:44,952
如果我们改用
OpenGL ES-based视图


611
00:29:45,719 --> 00:29:48,255
并且应用同样的滤镜


612
00:29:49,256 --> 00:29:52,426
我们就可以看到
我们现在是每秒四十八帧


613
00:29:54,561 --> 00:29:57,064
如果我们再进一步


614
00:29:57,531 --> 00:29:58,932
进行一次基于Metal的查看


615
00:30:01,268 --> 00:30:02,903
我们在这里还有些许提升


616
00:30:02,970 --> 00:30:04,304
我们就是每秒五十二帧


617
00:30:04,671 --> 00:30:07,975
虽然这并不特别了不起
但是我们仅仅应用了一个滤镜


618
00:30:08,609 --> 00:30:11,011
因此我们得到的优势
并不那么明显


619
00:30:11,078 --> 00:30:14,114
不像我们应用多个滤镜
或者我们有一堆较小的


620
00:30:14,781 --> 00:30:17,117
渲染时
我们得到的优势那么明显


621
00:30:18,185 --> 00:30:19,286
但是基本理念就是这个


622
00:30:20,921 --> 00:30:23,724
现在让我们看看 “核心图像”
以及 “核心动画”


623
00:30:23,790 --> 00:30:25,425
看看我们怎样可以让它们
一起工作


624
00:30:27,661 --> 00:30:29,296
这是一个我们在iOS以及OS X上


625
00:30:29,363 --> 00:30:31,532
有所不同的例子
非常少见


626
00:30:31,665 --> 00:30:36,136
在OS X上 我们只需要
应用即可 要让 “核心图像”


627
00:30:36,570 --> 00:30:39,273
以及 “核心动画” 一起工作
我们只需要做两件事


628
00:30:39,673 --> 00:30:40,774
先说重要的


629
00:30:41,708 --> 00:30:44,178
在你的NSview
你只需要说view.layer


630
00:30:44,244 --> 00:30:48,215
使用 “核心图像” 滤镜
把它设为


631
00:30:48,282 --> 00:30:51,585
“真” 然后可选择地
指定你想要应用到


632
00:30:51,652 --> 00:30:53,587
你有的无论哪个层的
滤镜


633
00:30:54,121 --> 00:30:55,088
阵列


634
00:30:55,656 --> 00:30:56,990
你需要做的
就这些


635
00:30:59,893 --> 00:31:01,328iddle
而在iOS上


636
00:30:59,893 --> 00:31:01,328
而在iOS上


637
00:31:02,196 --> 00:31:04,097
我们就没有这种支持了


638
00:31:04,164 --> 00:31:06,133
因此
你可以做的就是直接OpenGL


639
00:31:07,634 --> 00:31:10,737
你可以通过衍生于GLKView
来这么做


640
00:31:11,138 --> 00:31:14,942
或者通过创建一个UIView
确保你覆写了层类方法


641
00:31:15,008 --> 00:31:17,010
并且返回了
CA鹰layer.self


642
00:31:17,244 --> 00:31:19,646
来
这么做


643
00:31:19,713 --> 00:31:22,850
当你这么做的时候
你就会得到一个GL基于ES的对象


644
00:31:23,984 --> 00:31:26,320
然后你就可以用它创建
你自己的CIContext


645
00:31:26,587 --> 00:31:28,422
那样就可以确保
你获得最优性能


646
00:31:28,922 --> 00:31:31,391
这些都很棒
不过你需要牢记一件事


647
00:31:31,458 --> 00:31:33,760
如果你想要获得
很棒的性能


648
00:31:33,827 --> 00:31:35,829
那么这就不仅仅是
使用最好的API这么简单


649
00:31:35,896 --> 00:31:37,364
更是要有效地使用最好的API


650
00:31:37,431 --> 00:31:39,466
在这个例子中
你要记住的第一件事就是


651
00:31:39,533 --> 00:31:42,269
仅仅创建你的CIContext一次
因为缓存就发生在那里


652
00:31:42,336 --> 00:31:43,470
那里也保持了


653
00:31:43,937 --> 00:31:46,139
一大堆的状态


654
00:31:46,707 --> 00:31:47,875
因此


655
00:31:47,941 --> 00:31:51,044
当你使用低层APIs时
要记住这点


656
00:31:54,147 --> 00:31:55,516
现在 我想谈谈


657
00:31:55,582 --> 00:31:57,284
IOSurface上的
“核心图像”


658
00:31:58,185 --> 00:32:01,655
我们在 “核心图像” 执行的
内部


659
00:32:01,722 --> 00:32:03,223
大量使用IOSurface


660
00:32:03,724 --> 00:32:06,159
作为一个API 我们超爱它
因为它给我们提供了


661
00:32:06,226 --> 00:32:08,195
一堆系统中
其它API不存在的


662
00:32:09,730 --> 00:32:10,931
功能性


663
00:32:10,998 --> 00:32:13,400
因此大体上
我们就有了很棒的轻便性


664
00:32:13,767 --> 00:32:15,836
一些锁定语义
因此我们就可以让数据在


665
00:32:15,903 --> 00:32:19,239
IOSurfaces上进进出出
非常适合用来把数据从CPU


666
00:32:19,306 --> 00:32:20,908
搬到GPU
或者从GPU搬到CPU


667
00:32:21,408 --> 00:32:24,211
我们对不同格式的支持
广谱


668
00:32:24,278 --> 00:32:26,380
令人难以置信
我们认为可能有些是


669
00:32:26,446 --> 00:32:27,581
整个系统上
最棒的


670
00:32:27,648 --> 00:32:29,783
举例来说 我们有420、444、


671
00:32:29,850 --> 00:32:32,386
RGBA半浮动
以及很多其它的支持


672
00:32:34,288 --> 00:32:37,324
现在在iOS上
作为一个开发者


673
00:32:37,391 --> 00:32:40,727
要直接使用IOSurface就比较
难了 但是你可以通知 “核心图像”


674
00:32:40,794 --> 00:32:42,529
你想要通过创建
“像素缓冲区” 的方式


675
00:32:42,963 --> 00:32:44,398
来使用IOSurface


676
00:32:45,766 --> 00:32:48,035
IOSurface上
KCV像素缓冲区


677
00:32:48,101 --> 00:32:49,970
IOSurface属性键
是指定了的


678
00:32:50,838 --> 00:32:52,973
当你那样做的时候
如果你从一个CV像素缓冲区


679
00:32:53,273 --> 00:32:55,809
创建了一个CV图像
并且图像有这个键


680
00:32:56,710 --> 00:32:58,045
那么内部结束时
就是


681
00:32:58,312 --> 00:32:59,880
“核心图像” 知道它是一个


682
00:32:59,947 --> 00:33:02,115
IOSurface支持的CV像素缓
冲区


683
00:33:02,182 --> 00:33:04,251
我们就可以尽可能高效地
进行渲染


684
00:33:04,952 --> 00:33:06,920
因此如果你想在iOS上
享受IOSurface的全部好处


685
00:33:06,987 --> 00:33:09,022
那么你就需要
记住这个


686
00:33:11,425 --> 00:33:13,460
接下来我想再谈
几个其他的APIs


687
00:33:13,527 --> 00:33:16,230
我们会仔细看几个例子 看看
我们可以怎样实际一起使用


688
00:33:16,630 --> 00:33:21,168
“核心图像” 以及STKs、非常
容易地创建示例应用程序


689
00:33:21,235 --> 00:33:23,370
那么我们从SpriteKit
开始吧


690
00:33:24,438 --> 00:33:29,810
如果我们在XCode中开始
创建一个新的应用程序


691
00:33:30,177 --> 00:33:34,214
我们选择 “游戏”
然后选择一种


692
00:33:34,281 --> 00:33:36,517
游戏技术SpriteKit


693
00:33:36,950 --> 00:33:41,922
然后我们构建、运行
我们就得到了这个应用程序


694
00:33:41,989 --> 00:33:46,393
这样当你点击屏幕时
新的飞船就会显示出来


695
00:33:46,793 --> 00:33:51,632
你可以看到我们是
每秒六十帧


696
00:33:51,698 --> 00:33:54,568
我们现在可以用少量的代码
把 “核心图像”


697
00:33:54,635 --> 00:33:58,305
添加到
这个应用程序


698
00:33:58,639 --> 00:33:59,473
在这个例子中


699
00:33:59,540 --> 00:34:01,742
我们会在Game
Scene.swift中修改


700
00:34:01,808 --> 00:34:03,710
Touches Began方法
那么一开始


701
00:34:04,845 --> 00:34:06,079
每次点击后会发生的事情


702
00:34:06,380 --> 00:34:09,616
就是会把那个子画面
添加到根节点


703
00:34:10,484 --> 00:34:12,018
我们再修改下


704
00:34:12,853 --> 00:34:15,489
我们要使用一个SK特效节点


705
00:34:15,556 --> 00:34:18,859
一个SK特效节点会把整个环境
渲染进一个缓冲区


706
00:34:19,393 --> 00:34:21,828
然后你就可以向它应用
一系列的滤镜


707
00:34:23,230 --> 00:34:24,731
因此我们添加一个SK特效节点


708
00:34:25,065 --> 00:34:27,234
我们就不像之前那样
把子画面增加到根


709
00:34:27,301 --> 00:34:28,668
我们会把子画面添加到特效


710
00:34:29,735 --> 00:34:31,672
我们说 我们想启用
某些特效


711
00:34:33,273 --> 00:34:35,475
我们要创建一个滤镜
在这里例子中


712
00:34:35,542 --> 00:34:36,743
我们要使用一个像素化滤镜


713
00:34:37,311 --> 00:34:39,012
它和我们之前看到的滤镜
是一模一样的


714
00:34:40,813 --> 00:34:41,982
然后我们把那个特效


715
00:34:42,649 --> 00:34:43,650
添加到
根


716
00:34:43,717 --> 00:34:44,784
我们需要做的就这些


717
00:34:45,252 --> 00:34:48,188
如果你想要添加 “核心图像”
到一个SpriteKit应用程序


718
00:34:48,589 --> 00:34:51,491
那么你需要写的代码
正是这个


719
00:34:51,859 --> 00:34:54,228
如果我们现在运行
我们有的同样的示例


720
00:34:54,862 --> 00:34:56,163
并且开始点击


721
00:34:57,063 --> 00:34:59,700
我们就在
我们的应用程序内得到了


722
00:34:59,867 --> 00:35:00,834le
美丽的像素化子画面


723
00:34:59,867 --> 00:35:00,834
美丽的像素化子画面


724
00:35:01,401 --> 00:35:03,470
而且运行的帧率
也一样


725
00:35:05,906 --> 00:35:06,840
现在


726
00:35:06,907 --> 00:35:08,308
我们再谈谈SceneKit


727
00:35:11,545 --> 00:35:13,847
理念是相同的我们通过 “开始”
来创建一个应用程序


728
00:35:14,581 --> 00:35:16,617
我们选择SceneKit
作为一个游戏技术


729
00:35:16,917 --> 00:35:18,619
如果我们直接构建、运行
这个app


730
00:35:19,786 --> 00:35:20,654
我们就得到了


731
00:35:20,721 --> 00:35:22,122
这艘以交互速度旋转的
宇宙飞船


732
00:35:23,624 --> 00:35:24,925
以及驶离我们方向的宇宙飞船


733
00:35:26,293 --> 00:35:28,562
如果我们想要向这个应用程序
添加 “核心图像”


734
00:35:28,629 --> 00:35:30,397
那么我们需要做的


735
00:35:30,731 --> 00:35:33,734
就是到GameView
Controllerswift中的


736
00:35:35,135 --> 00:35:36,503
View Did
Load方法找到飞船


737
00:35:36,570 --> 00:35:39,439
飞船在示例代码中
是对齐的


738
00:35:41,909 --> 00:35:44,645
然后我们就再次创建
像素化滤镜


739
00:35:45,612 --> 00:35:48,549
给飞船指定一个
滤镜可选阵列


740
00:35:49,483 --> 00:35:52,085
如果我们这么做了后运行app


741
00:35:52,486 --> 00:35:54,788
就得到一艘美丽的像素化飞船


742
00:35:55,622 --> 00:35:57,624
你可以把它应用到你的场景中
的任何节点 并且


743
00:35:59,092 --> 00:36:00,360
我们再次得到了很棒的帧率


744
00:36:02,095 --> 00:36:05,132
同时使用SceneKit以及
“核心 图像” 的一大优势在于


745
00:36:05,199 --> 00:36:07,701
你可以使用 “核心动画”


746
00:36:08,202 --> 00:36:10,170
来动画绘制属性


747
00:36:11,505 --> 00:36:13,106
在这里例子中
我们要创建一个


748
00:36:13,173 --> 00:36:15,742
CA基础动画
我们要动画绘制


749
00:36:15,809 --> 00:36:17,444
输入规模
因此我们会得到一个


750
00:36:17,511 --> 00:36:21,615
变化的规模像素化特效
随着时间推移


751
00:36:21,682 --> 00:36:23,917
这个特效会被应用一个
零到五十的值


752
00:36:24,585 --> 00:36:28,121
在两秒内
它会悄悄地来、悄悄地走


753
00:36:28,655 --> 00:36:30,290
如果我们添加这个代码


754
00:36:32,492 --> 00:36:33,493
我们的飞船就会有一个


755
00:36:34,761 --> 00:36:37,698
美丽的


756
00:36:40,167 --> 00:36:41,201
动画绘制像素化特效


757
00:36:42,736 --> 00:36:44,538
并且 帧率仍然很棒


758
00:36:46,840 --> 00:36:49,810
这个并不是一定需要
应用到一个节点上


759
00:36:49,877 --> 00:36:51,745
你可以把它应用到你的
整个场景上


760
00:36:51,812 --> 00:36:53,113
这里我们推出了一个
示例


761
00:36:53,580 --> 00:36:55,716
你可以下载它
它叫 “香蕉”


762
00:36:56,450 --> 00:36:59,019
和动画一起 我们应用了
相同的特效


763
00:37:00,320 --> 00:37:04,057
并且我们会在这里实时改变
像素化规模


764
00:37:04,925 --> 00:37:07,327
当它像素化后
我可以比全分辨率更好地


765
00:37:07,394 --> 00:37:12,232
玩这个游戏了
这让我有点吃惊


766
00:37:12,399 --> 00:37:15,035
不过除了创建游戏外
你可以用这个


767
00:37:15,102 --> 00:37:18,272
在游戏结尾添加一个
特效


768
00:37:18,338 --> 00:37:23,277
举例来说
如果你想让你的资产的不同


769
00:37:23,343 --> 00:37:24,478
版本被不同的


770
00:37:24,845 --> 00:37:26,246
图像处理特效
渲染


771
00:37:26,313 --> 00:37:28,315
你就可以和这些APIs一起


772
00:37:28,382 --> 00:37:30,284
来使用 “核心图像”
完全没问题的


773
00:37:32,452 --> 00:37:36,256
到现在为止 我们今天看了
很多东西


774
00:37:36,323 --> 00:37:37,858
看了怎样一起使用 “核心图像”


775
00:37:37,925 --> 00:37:39,927
以及Metal和AV
Foundation


776
00:37:39,993 --> 00:37:42,429
为什么IOSurface对我们
如此重要


777
00:37:43,096 --> 00:37:46,099
我们还看了如果你仅仅创建了
一幅图像一次


778
00:37:46,733 --> 00:37:47,701
并且不需要频繁更新


779
00:37:47,768 --> 00:37:50,337
那么使用UIImageView的
最简单的方法是什么


780
00:37:50,404 --> 00:37:52,306
仅仅应用一个特效一次
是一种很棒的方法


781
00:37:52,873 --> 00:37:54,908
我们也向你演示了如何使用
“核心动画”


782
00:37:55,242 --> 00:37:58,078
如何CIImageProvider
带入定制数据


783
00:37:58,145 --> 00:38:01,815
以及如何在游戏语境或者
其他应用程序语境中使用它


784
00:38:02,115 --> 00:38:05,419
你如何可以用SceneKit或者S
priteKit非常简单地创建它


785
00:38:07,955 --> 00:38:08,889
要获取更多信息


786
00:38:09,156 --> 00:38:12,326
我们在developer.
apple.com有很多的资源


787
00:38:12,392 --> 00:38:14,261
可以在线获取


788
00:38:15,128 --> 00:38:17,431
如何你有任何其它咨询


789
00:38:17,831 --> 00:38:19,433
你可以通过
chick@apple.com


790
00:38:19,499 --> 00:38:20,667
联系斯蒂芬·奇克


791
00:38:22,369 --> 00:38:25,639
你可能想要参加其它会议


792
00:38:25,706 --> 00:38:27,941
包括 “在AV
Foundation 中编辑电影”


793
00:38:28,342 --> 00:38:31,345
这场会议几天前已经举行过了
不过你可以在线观看视频


794
00:38:31,545 --> 00:38:35,482
还有昨天举行的
“Metal中有什么新料第二部分”


795
00:38:38,218 --> 00:38:40,454
如上所述
谢谢你们来参会


796
00:38:40,521 --> 00:38:43,123
希望你们会爱上在你们的
应用程序中使用 “核心图像”


797
00:38:43,190 --> 00:38:45,259
祝你们在会议剩余的
时间里过得愉快  谢谢！

