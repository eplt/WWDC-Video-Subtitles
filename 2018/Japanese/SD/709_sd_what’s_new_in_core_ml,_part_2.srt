
1
00:00:07,107 --> 00:00:16,550
(音楽)

2
00:00:21,688 --> 00:00:24,758
(拍手)

3
00:00:24,858 --> 00:00:25,759
こんにちは

4
00:00:25,859 --> 00:00:28,362
(拍手)

5
00:00:31,532 --> 00:00:34,067
Core MLの２回目の
セッションです

6
00:00:34,334 --> 00:00:38,272
私はCore MLチームのエンジニア
アセームです

7
00:00:40,807 --> 00:00:45,145
Core MLはデバイス上で
推論可能な Appleの―

8
00:00:45,245 --> 00:00:47,214
機械学習フレームワークです

9
00:00:48,382 --> 00:00:54,354
Appleのすべてのハードウェアに
最適化されています

10
00:00:55,455 --> 00:00:58,091
昨年は多くの
アプリケーションが

11
00:00:58,192 --> 00:01:02,696
Appleプラットフォームで
配信されました

12
00:00:58,192 --> 00:01:02,696
Appleプラットフォームで
配信されました

13
00:01:03,030 --> 00:01:04,932
すばらしいことです

14
00:01:05,265 --> 00:01:10,103
さらに今年は
新しい機能が追加されました

15
00:01:10,637 --> 00:01:15,475
アプリケーションのサイズを
大幅に縮小できます

16
00:01:16,543 --> 00:01:21,882
新しいバッチ予測APIを使えば
速度も向上します

17
00:01:23,016 --> 00:01:26,086
カスタマイズ機能を使えば

18
00:01:26,186 --> 00:01:30,357
最先端のリサーチを
組み込むことも簡単です

19
00:01:31,692 --> 00:01:34,094
ここまでが前回の復習です

20
00:01:34,461 --> 00:01:39,466
聞き逃した方は
スライドを確認してください

21
00:01:41,435 --> 00:01:44,071
今回はこれらの機能を

22
00:01:44,271 --> 00:01:47,341
実際にどう使うのか見てみます

23
00:01:47,975 --> 00:01:51,478
具体的には
いくつかの例を挙げて

24
00:01:51,712 --> 00:01:57,751
Core ML Toolsを使った
簡単な活用法を紹介します

25
00:01:57,985 --> 00:02:03,223
モデルのサイズを小さくしたり
機能をカスタマイズできます

26
00:01:57,985 --> 00:02:03,223
モデルのサイズを小さくしたり
機能をカスタマイズできます

27
00:02:04,558 --> 00:02:06,326
今回の議題です

28
00:02:07,060 --> 00:02:11,165
まず Core ML Toolsの
エコシステムを確認します

29
00:02:11,698 --> 00:02:15,669
それから量子化と
カスタムコンバージョンの

30
00:02:15,802 --> 00:02:17,771
デモをお見せします

31
00:02:17,971 --> 00:02:19,806
では 始めましょう

32
00:02:23,210 --> 00:02:25,612
まず MLModelは

33
00:02:26,046 --> 00:02:30,217
オンライン上で見つかります

34
00:02:32,319 --> 00:02:35,455
ダウンロードするだけです

35
00:02:36,056 --> 00:02:40,160
Appleの機械学習サイトからも

36
00:02:40,260 --> 00:02:44,598
いくつかのモデルを
ダウンロードできます

37
00:02:45,499 --> 00:02:50,103
自分のデータセット上で
モデルを学習させるには

38
00:02:50,204 --> 00:02:53,740
Create MLを使用します

39
00:02:53,841 --> 00:02:57,177
発表したばかりの
新しいフレームワークです

40
00:02:57,845 --> 00:03:01,181
機械学習に詳しくなくても

41
00:02:57,845 --> 00:03:01,181
機械学習に詳しくなくても

42
00:03:01,281 --> 00:03:04,284
簡単に使えるXcodeの機能です

43
00:03:04,384 --> 00:03:07,321
ぜひ試してください

44
00:03:08,455 --> 00:03:11,225
他の機械学習ツールに

45
00:03:11,325 --> 00:03:15,829
すでに精通している方も
いるでしょう

46
00:03:15,996 --> 00:03:18,398
そのため
Core ML Toolsという

47
00:03:18,499 --> 00:03:22,302
Pythonのパッケージを
リリースしました

48
00:03:22,503 --> 00:03:27,107
同時にコンバータも
いくつかリリースしました

49
00:03:28,342 --> 00:03:32,513
昨年は この分野で
活発な動きがあり

50
00:03:32,946 --> 00:03:35,249
現状はこうなっています

51
00:03:37,417 --> 00:03:42,756
数多くのコンバータが
リリースされています

52
00:03:42,890 --> 00:03:47,361
どのフレームワークを選ぶかは
あなた次第です

53
00:03:48,695 --> 00:03:52,933
すべてのコンバータは
Core ML Toolsの上位です

54
00:03:55,369 --> 00:03:59,406
２つのコンバータを
強調しておきましょう

55
00:04:01,141 --> 00:04:05,078
昨年 私たちは
Googleと協力し

56
00:04:05,179 --> 00:04:09,082
TensorFlowコンバータを
リリースしました

57
00:04:10,684 --> 00:04:15,556
新しいレイヤを試したい
研究者のために

58
00:04:15,689 --> 00:04:19,827
カスタムレイヤの
サポートを追加しました

59
00:04:21,094 --> 00:04:26,033
トレーニング中の量子化の
サポートもリリースしました

60
00:04:26,166 --> 00:04:28,936
Core ML 2が
サポートする量子化で

61
00:04:29,102 --> 00:04:31,538
まもなく追加される予定です

62
00:04:33,140 --> 00:04:38,178
さらにFacebookや
Prismaとの協力により

63
00:04:38,278 --> 00:04:41,248
ONNXを開発しました

64
00:04:42,182 --> 00:04:44,418
ONNXの魅力は

65
00:04:45,586 --> 00:04:50,123
様々なタイプの
トレーニングライブラリを

66
00:04:50,224 --> 00:04:54,695
Core MLに変換できることです

67
00:04:56,196 --> 00:05:00,734
以上がCore ML Toolsの
エコシステムの要約です

68
00:04:56,196 --> 00:05:00,734
以上がCore ML Toolsの
エコシステムの要約です

69
00:05:00,834 --> 00:05:05,806
量子化については
ソハイブに任せましょう

70
00:05:06,306 --> 00:05:11,678
(拍手)

71
00:05:14,081 --> 00:05:17,985
Core MLチームのエンジニア
ソハイブです

72
00:05:18,085 --> 00:05:19,953
Core ML Tools 2.0の

73
00:05:20,053 --> 00:05:23,457
新しい量子化ユーティリティを
紹介します

74
00:05:28,095 --> 00:05:32,533
Core ML Tools 2.0は最新の
Core MLフォーマットをサポートし

75
00:05:32,766 --> 00:05:37,070
モデルの変形や
量子化を簡単に実現する―

76
00:05:37,171 --> 00:05:39,873
ユーティリティを備えています

77
00:05:40,240 --> 00:05:44,444
モデルのサイズを
小さくするだけでなく

78
00:05:44,545 --> 00:05:49,383
アプリケーションのモデル数や
フットプリントを削減できます

79
00:05:50,317 --> 00:05:53,654
量子化から見ていきましょう

80
00:05:54,822 --> 00:05:57,457
トレーニング後の量子化を
サポートします

81
00:05:57,624 --> 00:06:00,460
オリジナルは Core ML
ニューラルネットワークの

82
00:05:57,624 --> 00:06:00,460
オリジナルは Core ML
ニューラルネットワークの

83
00:06:00,561 --> 00:06:03,564
32ビットフロートのモデルです

84
00:06:03,697 --> 00:06:07,734
Core ML Toolsを使って
これを量子化すると

85
00:06:08,101 --> 00:06:10,437
サイズが小さくなります

86
00:06:10,771 --> 00:06:16,343
量子化のビット数によって
サイズ縮小率は変わります

87
00:06:17,778 --> 00:06:21,181
量子化とは
どういうことでしょう？

88
00:06:21,281 --> 00:06:23,584
サイズを変える方法は？

89
00:06:23,984 --> 00:06:26,653
詳しく見ていきます

90
00:06:30,357 --> 00:06:35,662
ニューラルネットワークは
関数のレイヤで構成されています

91
00:06:36,063 --> 00:06:39,299
この関数をウェイトと呼び

92
00:06:39,700 --> 00:06:43,070
通常は32ビットフロートで
格納します

93
00:06:44,304 --> 00:06:47,474
前回はResnet50を紹介しました

94
00:06:47,674 --> 00:06:52,212
画像分類に使われる
機械学習モデルです

95
00:06:52,446 --> 00:06:56,617
2500万ものウェイトパラメータを
含んでいます

96
00:06:57,050 --> 00:07:00,420
少ないビット数で
表すことができれば

97
00:06:57,050 --> 00:07:00,420
少ないビット数で
表すことができれば

98
00:07:00,521 --> 00:07:05,526
モデルのサイズを
大幅に縮小できます

99
00:07:06,894 --> 00:07:09,997
このプロセスが量子化です

100
00:07:10,430 --> 00:07:13,467
量子化では
最小値と最大値の間の

101
00:07:13,567 --> 00:07:16,336
レイヤのウェイトを抜き取ります

102
00:07:16,503 --> 00:07:20,107
そして符号なし整数に
マッピングします

103
00:07:20,908 --> 00:07:23,544
APICの量子化の場合―

104
00:07:23,644 --> 00:07:26,947
マッピングの範囲は
０から255となります

105
00:07:27,047 --> 00:07:31,185
７ビットの場合は０から127です

106
00:07:31,385 --> 00:07:35,789
１ビットのマッピングは
０もしくは１となります

107
00:07:36,290 --> 00:07:40,794
ビット数が少ないほど
サイズは小さくなります

108
00:07:42,362 --> 00:07:47,568
浮動小数点の値を整数に
マッピングしています

109
00:07:48,202 --> 00:07:51,171
いくらか精度が落ちることは

110
00:07:51,672 --> 00:07:54,241
否定できません

111
00:07:54,741 --> 00:07:58,312
経験的には量子化の
ビット数が小さいほど

112
00:07:58,579 --> 00:08:00,948
モデルの精度は損なわれます

113
00:07:58,579 --> 00:08:00,948
モデルの精度は損なわれます

114
00:08:01,048 --> 00:08:02,783
後ほど解説します

115
00:08:03,851 --> 00:08:05,752
これが量子化です

116
00:08:05,986 --> 00:08:09,056
では どうやって
マッピングするのか

117
00:08:09,456 --> 00:08:13,594
多くのアルゴリズムや
テクニックが知られています

118
00:08:13,694 --> 00:08:16,797
Core MLが
サポートしているのは

119
00:08:17,164 --> 00:08:20,000
直線量子化と
ルックアップテーブル量子化です

120
00:08:20,634 --> 00:08:22,436
簡単に説明しましょう

121
00:08:26,306 --> 00:08:27,908
直線量子化は

122
00:08:28,008 --> 00:08:32,078
すべてのパラメータを
均等にマッピングします

123
00:08:32,913 --> 00:08:37,083
スケールとバイアスで
パラメータ化する方法です

124
00:08:37,183 --> 00:08:42,655
その値は量子化するレイヤの
パラメータに基づいて計算されます

125
00:08:43,056 --> 00:08:46,627
マッピングの効果を
簡単にイメージするには

126
00:08:46,793 --> 00:08:51,565
量子化されたウェイトを
元の浮動小数点数に

127
00:08:51,665 --> 00:08:53,433
戻せばいいだけです

128
00:08:53,834 --> 00:08:57,704
直線量子化では
スケールにバイアスを加え

129
00:08:57,805 --> 00:09:00,307
単純にウェイトを増やします

130
00:08:57,805 --> 00:09:00,307
単純にウェイトを増やします

131
00:09:02,142 --> 00:09:04,912
もう１つの量子化の方法は

132
00:09:05,012 --> 00:09:06,647
ルックアップテーブル量子化

133
00:09:07,181 --> 00:09:10,918
文字どおり
ルックアップテーブルを作成します

134
00:09:11,952 --> 00:09:17,090
ウェイトがどのように
元に戻るかイメージしてください

135
00:09:17,257 --> 00:09:22,996
量子化後のウェイトは
元の指数でしかありません

136
00:09:23,964 --> 00:09:27,301
直線量子化の場合とは違って

137
00:09:27,835 --> 00:09:32,139
ウェイトが等間隔で
並んでいる必要はありません

138
00:09:33,841 --> 00:09:38,045
つまり Core ML Toolsの
２種類の量子化で

139
00:09:38,679 --> 00:09:42,783
ニューラルネットワークの
精度の高いモデルの―

140
00:09:42,883 --> 00:09:45,752
ウェイトを量子化できます

141
00:09:46,186 --> 00:09:50,390
サイズを小さくする方法は
分かりましたが

142
00:09:50,824 --> 00:09:54,194
パラメータの計算は手間ですね

143
00:09:54,661 --> 00:09:57,998
直線量子化の
スケールとバイアスの値は？

144
00:09:58,332 --> 00:10:02,369
ルックアップテーブルは
どうやって作れば？

145
00:09:58,332 --> 00:10:02,369
ルックアップテーブルは
どうやって作れば？

146
00:10:03,036 --> 00:10:06,540
何も心配する必要はありません

147
00:10:06,940 --> 00:10:10,777
ビット数とアルゴリズムを
決めるだけで

148
00:10:10,878 --> 00:10:15,482
あとはCore ML Toolsが
処理してくれます

149
00:10:16,049 --> 00:10:16,984
実際のところ…

150
00:10:17,084 --> 00:10:22,022
(拍手)

151
00:10:22,656 --> 00:10:27,294
モデルを入手し量子化するのは
とても簡単です

152
00:10:27,394 --> 00:10:30,097
数行のPythonコードでできます

153
00:10:30,397 --> 00:10:32,966
デモをお見せしましょう

154
00:10:40,340 --> 00:10:42,609
デモを行うには

155
00:10:42,709 --> 00:10:46,280
ニューラルネットワークの
モデルが必要です

156
00:10:46,680 --> 00:10:51,919
Core ML機械学習サイトで
見つかります

157
00:10:52,019 --> 00:10:55,155
１つダウンロードしましょう

158
00:10:55,522 --> 00:10:58,659
SqueezeNetを選択して開きます

159
00:11:00,627 --> 00:11:03,464
サイズは５メガバイトですね

160
00:11:03,564 --> 00:11:08,602
入力画像は227×227画素

161
00:11:08,702 --> 00:11:10,103
出力は２種類です

162
00:11:10,437 --> 00:11:13,440
１つはclassLabelという文字列

163
00:11:13,540 --> 00:11:17,611
通常は入力画像のための
ラベルです

164
00:11:17,711 --> 00:11:22,349
もう１つの出力は
確率のマッピングです

165
00:11:23,183 --> 00:11:26,954
何の画像なのか候補を挙げます

166
00:11:28,789 --> 00:11:30,824
これを量子化します

167
00:11:31,458 --> 00:11:34,862
まず Pythonの環境を
確保します

168
00:11:34,962 --> 00:11:39,933
Jupyter Notebookが
使いやすいので開きます

169
00:11:46,673 --> 00:11:48,308
新規作成をします

170
00:11:49,109 --> 00:11:50,510
ズームして

171
00:11:51,311 --> 00:11:55,349
Core ML Toolsを
インポートします

172
00:11:58,919 --> 00:11:59,987
実行します

173
00:12:00,220 --> 00:12:04,992
次に量子化ユーティリティを
すべてインポートします

174
00:12:05,092 --> 00:12:07,294
これを実行します

175
00:12:16,169 --> 00:12:19,039
量子化するモデルが必要です

176
00:12:19,139 --> 00:12:23,410
先ほどのSqueezeNetの
モデルを取り込みます

177
00:12:32,719 --> 00:12:34,388
デスクトップに送ります

178
00:12:38,058 --> 00:12:38,826
これでよし

179
00:12:39,026 --> 00:12:43,330
たった１度のAPIコールで
量子化できます

180
00:12:43,464 --> 00:12:47,501
直線量子化を試してみます

181
00:12:51,572 --> 00:12:54,575
APIコールはquantize weights

182
00:12:54,808 --> 00:12:59,179
最初のパラメータは
オリジナルのモデルです

183
00:12:59,513 --> 00:13:03,650
量子化後のビット数を８ビットに

184
00:12:59,513 --> 00:13:03,650
量子化後のビット数を８ビットに

185
00:13:04,685 --> 00:13:08,755
量子化アルゴリズムは
linearを指定します

186
00:13:10,257 --> 00:13:14,995
ニューラルネットワークの
すべてのレイヤに対して

187
00:13:15,095 --> 00:13:19,099
反復処理が行われて
量子化が終了しました

188
00:13:20,467 --> 00:13:23,437
量子化することによって

189
00:13:23,537 --> 00:13:27,541
モデルの精度が落ちると
述べましたね

190
00:13:27,908 --> 00:13:31,578
元のモデルとの差は
どの程度でしょう

191
00:13:32,212 --> 00:13:36,250
それを確かめる
最も簡単な方法は

192
00:13:36,350 --> 00:13:40,154
まず 元のモデルの
データを推論します

193
00:13:40,587 --> 00:13:44,291
そして 量子化後のモデルの
同じデータと

194
00:13:44,391 --> 00:13:48,762
比較して一致率を求めるのです

195
00:13:49,029 --> 00:13:51,431
Core ML Toolsの
機能を使います

196
00:13:51,532 --> 00:13:55,869
compare modelsと入力します

197
00:13:56,203 --> 00:13:58,238
精度の高い元のモデルと

198
00:13:58,505 --> 00:14:01,275
量子化後のモデルを渡します

199
00:13:58,505 --> 00:14:01,275
量子化後のモデルを渡します

200
00:14:01,875 --> 00:14:07,481
これは入力が１つだけの
シンプルな画像分類モデルなので

201
00:14:08,115 --> 00:14:12,986
サンプル画像が入った
フォルダを使いましょう

202
00:14:13,086 --> 00:14:17,991
デスクトップに画像が入った
フォルダがあります

203
00:14:18,091 --> 00:14:23,230
一時的パラメータとして
このフォルダにパスを渡します

204
00:14:28,035 --> 00:14:31,605
フォルダの中の画像を解析します

205
00:14:31,705 --> 00:14:36,477
精度の高い元のモデルで推論したら

206
00:14:36,577 --> 00:14:40,447
量子化後のモデルでも
推論して比較します

207
00:14:41,348 --> 00:14:42,883
終わったようです

208
00:14:43,750 --> 00:14:47,254
“Top 1 Agreement 94.8％”と
出ています

209
00:14:47,721 --> 00:14:51,291
“トップ１合致率”の意味は？

210
00:14:51,525 --> 00:14:54,094
例えば犬の画像を入力したら

211
00:14:55,395 --> 00:15:00,934
元のモデルも量子化後のモデルも
犬だと予測したとします

212
00:14:55,395 --> 00:15:00,934
元のモデルも量子化後のモデルも
犬だと予測したとします

213
00:15:01,034 --> 00:15:04,471
その確率が94.8％でした

214
00:15:05,772 --> 00:15:08,609
このモデルでも十分です

215
00:15:08,709 --> 00:15:12,813
でも もう１つの方法も
試したいですね

216
00:15:13,514 --> 00:15:16,950
Core MLは
直線量子化だけでなく

217
00:15:17,050 --> 00:15:19,786
ルックアップテーブル量子化も
可能です

218
00:15:19,887 --> 00:15:24,324
その方法で このモデルを
量子化してみます

219
00:15:30,898 --> 00:15:34,935
元のモデルとビット数を指定します

220
00:15:35,636 --> 00:15:37,738
そしてアルゴリズム

221
00:15:39,273 --> 00:15:40,674
ミスタイプですね

222
00:15:48,882 --> 00:15:50,150
実行します

223
00:15:50,617 --> 00:15:53,687
k-meansは
ウェイトの分布を概算する―

224
00:15:53,787 --> 00:15:56,590
クラスター分析の手法です

225
00:15:56,690 --> 00:15:59,726
この分布を使って

226
00:15:59,827 --> 00:16:02,396
ルックアップテーブルを
作成します

227
00:15:59,827 --> 00:16:02,396
ルックアップテーブルを
作成します

228
00:16:02,496 --> 00:16:07,167
ニューラルネットワークの
すべてのレイヤを反復処理し

229
00:16:07,267 --> 00:16:11,705
量子化後のルックアップテーブルを
計算するのです

230
00:16:12,172 --> 00:16:17,010
モデルのアーキテクチャを
知り尽くしている専門家には

231
00:16:17,244 --> 00:16:19,713
k-meansは最適とは言えません

232
00:16:19,813 --> 00:16:23,750
その場合は
このアルゴリズムでなくても

233
00:16:24,651 --> 00:16:29,756
カスタムの関数を入力して
ルックアップテーブルが作れます

234
00:16:30,791 --> 00:16:34,795
この方法での
量子化が終わりました

235
00:16:35,128 --> 00:16:38,432
元のモデルと比較します

236
00:16:38,532 --> 00:16:41,835
再びモデル比較のAPIを呼び

237
00:16:42,236 --> 00:16:46,673
元のモデルと
量子化後のモデルを渡します

238
00:16:47,007 --> 00:16:49,076
そして先ほどと同じく

239
00:16:50,611 --> 00:16:52,079
サンプル画像のフォルダ

240
00:16:54,681 --> 00:16:58,752
元のモデルと
量子化後のモデルを使って

241
00:16:59,553 --> 00:17:01,488
画像を推論します

242
00:16:59,553 --> 00:17:01,488
画像を推論します

243
00:17:01,688 --> 00:17:05,992
Top 1 Agreementの数値が
先ほどより高いので

244
00:17:06,193 --> 00:17:10,164
ルックアップテーブルの方が
適していると分かります

245
00:17:10,329 --> 00:17:14,300
直線量子化が
適しているモデルもあります

246
00:17:14,635 --> 00:17:19,138
私のアプリケーションには
これで十分なので

247
00:17:19,239 --> 00:17:20,973
保存しましょう

248
00:17:23,410 --> 00:17:25,779
“save”と入力します

249
00:17:30,450 --> 00:17:34,721
“QuantizedSqueezenet”と
名前を付けます

250
00:17:40,994 --> 00:17:43,597
これで完了です

251
00:17:43,730 --> 00:17:47,834
元のモデルは５メガバイトでしたね

252
00:17:48,135 --> 00:17:50,370
量子化したモデルは？

253
00:17:52,606 --> 00:17:57,878
わずか1.3メガバイトに
なっているのが分かります

254
00:17:57,978 --> 00:18:03,417
(拍手)

255
00:17:57,978 --> 00:18:03,417
(拍手)

256
00:18:04,051 --> 00:18:08,689
量子化したモデルの
細かい部分については

257
00:18:08,789 --> 00:18:11,091
元のモデルと同じです

258
00:18:11,191 --> 00:18:14,862
入力は１つで出力は２種類です

259
00:18:15,162 --> 00:18:19,700
アプリケーションに使うモデルを
置き換える場合は

260
00:18:20,033 --> 00:18:24,037
量子化したモデルを
ドラッグするだけで

261
00:18:24,137 --> 00:18:26,540
サイズを縮小できます

262
00:18:32,346 --> 00:18:35,149
以上が量子化の方法です

263
00:18:38,619 --> 00:18:43,991
Core ML Toolsを使えば
こんなにも簡単です

264
00:18:44,324 --> 00:18:46,827
シンプルなAPIで

265
00:18:47,361 --> 00:18:51,298
元のモデルと量子化のビット数

266
00:18:51,532 --> 00:18:53,867
アルゴリズムを指定するだけです

267
00:18:54,201 --> 00:18:56,603
Core ML Toolsには

268
00:18:56,703 --> 00:19:02,009
量子化後と元のモデルを
比較するユーティリティもあります

269
00:18:56,703 --> 00:19:02,009
量子化後と元のモデルを
比較するユーティリティもあります

270
00:19:03,477 --> 00:19:05,646
デモで見たように

271
00:19:05,746 --> 00:19:09,182
量子化後のモデルは
精度が落ち―

272
00:19:09,817 --> 00:19:13,987
その程度はモデルと
データに依存します

273
00:19:14,555 --> 00:19:18,926
量子化してよくなる
モデルもあります

274
00:19:19,293 --> 00:19:23,897
一般的には
量子化ビット数が小さいほど

275
00:19:24,331 --> 00:19:26,133
精度が損なわれます

276
00:19:26,567 --> 00:19:30,304
デモでは
Top 1 Agreementの値で

277
00:19:30,404 --> 00:19:34,908
量子化後のモデルを
元のモデルと比較しました

278
00:19:35,442 --> 00:19:40,114
しかし 量子化後のモデルは
実際の使用事例に

279
00:19:40,214 --> 00:19:43,150
適合する必要があります

280
00:19:43,984 --> 00:19:47,588
前回のセッションでは
スタイル変換を行いました

281
00:19:48,188 --> 00:19:51,024
入力画像に対して

282
00:19:51,158 --> 00:19:54,728
図案化された画像が出力されます

283
00:19:55,462 --> 00:19:59,166
量子化レベルによる
違いを見てみましょう

284
00:20:00,067 --> 00:20:04,605
左上の画像をご覧ください

285
00:20:04,738 --> 00:20:10,410
32ビット 6.7メガバイトの
オリジナルの画像です

286
00:20:10,677 --> 00:20:14,715
８ビットの直線量子化で
わずか1.7メガバイトになります

287
00:20:14,815 --> 00:20:20,087
スタイル変換のデモには
十分な画質だと思われます

288
00:20:20,721 --> 00:20:23,891
４ビットまで下げても

289
00:20:23,991 --> 00:20:26,160
劣ってはいません

290
00:20:26,493 --> 00:20:30,330
個人的には３ビットでも十分です

291
00:20:30,664 --> 00:20:34,234
２ビットでは
アーチファクトが多く

292
00:20:34,434 --> 00:20:36,437
使いものになりません

293
00:20:38,872 --> 00:20:41,475
以上が量子化の解説です

294
00:20:42,075 --> 00:20:46,513
カスタムコンバージョンについては
アセームが解説します

295
00:20:46,613 --> 00:20:52,186
(拍手)

296
00:20:52,286 --> 00:20:53,420
ありがとう

297
00:20:55,122 --> 00:20:57,391
機械学習の分野において

298
00:20:57,491 --> 00:21:01,762
不可欠な機能について
話したいと思います

299
00:20:57,491 --> 00:21:01,762
不可欠な機能について
話したいと思います

300
00:21:02,262 --> 00:21:03,664
ご存じのように

301
00:21:04,164 --> 00:21:07,468
この分野は急速に拡大しています

302
00:21:07,701 --> 00:21:10,571
それを支援するソフトの提供は

303
00:21:10,737 --> 00:21:14,875
Core MLの重要な課題です

304
00:21:15,809 --> 00:21:17,211
例を挙げましょう

305
00:21:17,945 --> 00:21:22,516
Core MLがサポートしていない
新しいモデル

306
00:21:22,616 --> 00:21:25,385
もしくはサポートしていても

307
00:21:25,552 --> 00:21:29,256
一部のレイヤがまだ存在しない―

308
00:21:29,556 --> 00:21:32,092
モデルがあるとします

309
00:21:32,826 --> 00:21:35,829
そのような場合でも

310
00:21:35,929 --> 00:21:38,999
Core MLは使えるでしょうか

311
00:21:39,299 --> 00:21:41,268
答えはイエスです

312
00:21:41,635 --> 00:21:45,172
カスタマイズ機能を
使えばいいのです

313
00:21:46,173 --> 00:21:51,078
ニューラルネットワークに
新しいレイヤが

314
00:21:51,178 --> 00:21:53,781
追加された場合です

315
00:21:53,881 --> 00:21:57,217
それを変換して
アプリケーションに

316
00:21:57,317 --> 00:21:59,786
実装する方法を解説します

317
00:22:00,821 --> 00:22:03,323
まずはモデルの変換です

318
00:22:03,957 --> 00:22:07,494
Appleのコンバータを
使用したことがなくても

319
00:22:07,661 --> 00:22:10,964
とてもシンプルなAPIです

320
00:22:11,965 --> 00:22:15,335
Kerasコンバータを探します

321
00:22:15,435 --> 00:22:20,474
ONNXやTensorFlowを
探す場合と似ています

322
00:22:21,742 --> 00:22:25,879
ほとんどの場合は
これだけで機能しますが

323
00:22:25,979 --> 00:22:29,516
まれにエラーメッセージが
表示されます

324
00:22:30,717 --> 00:22:34,721
“この操作は
サポートしていません”など

325
00:22:35,055 --> 00:22:37,191
このような場合も―

326
00:22:37,291 --> 00:22:41,328
ちょっとした操作で
回避できます

327
00:22:41,628 --> 00:22:46,533
具体的に言えば
このような時に使うのが

328
00:22:46,633 --> 00:22:47,834
カスタムレイヤです

329
00:22:48,902 --> 00:22:53,073
変換の方法を説明する前に

330
00:22:53,874 --> 00:22:58,078
カスタムレイヤが必要な
事例を紹介します

331
00:23:01,315 --> 00:23:03,650
画像分類モデルを使うとします

332
00:23:03,750 --> 00:23:08,622
これがXcodeによる
このモデルの詳細です

333
00:23:08,856 --> 00:23:12,926
ニューラルネットワークの
可能性が高いですね

334
00:23:13,126 --> 00:23:15,963
しかも畳み込み
ニューラルネットワークで

335
00:23:16,063 --> 00:23:19,600
たくさんのレイヤや
活性化関数が含まれます

336
00:23:20,300 --> 00:23:25,706
Core MLがサポートしていない
関数だとしましょう

337
00:23:25,806 --> 00:23:30,210
機械学習のカンファレンスでは

338
00:23:30,377 --> 00:23:34,147
常に新しいレイヤが
開発されています

339
00:23:35,048 --> 00:23:38,485
このような場合は単純に

340
00:23:38,585 --> 00:23:42,489
新しいレイヤを
実装するだけです

341
00:23:42,656 --> 00:23:45,959
元のモデルとの違いは
下の部分の

342
00:23:46,059 --> 00:23:48,362
依存関係の欄だけです

343
00:23:49,363 --> 00:23:54,802
カスタムレイヤの存在が
記載されています

344
00:23:55,202 --> 00:23:56,937
もう１つの例です

345
00:23:57,037 --> 00:24:00,207
単純な分類子があります

346
00:23:57,037 --> 00:24:00,207
単純な分類子があります

347
00:24:01,175 --> 00:24:04,912
最近 Spatial Transformer
ネットワークの

348
00:24:05,012 --> 00:24:07,214
研究論文を見つけました

349
00:24:07,548 --> 00:24:10,384
これがその機能です

350
00:24:10,484 --> 00:24:13,954
数字の後ろに
ニューラルネットワークを挿入し

351
00:24:14,121 --> 00:24:16,957
この数字をローカライズします

352
00:24:17,257 --> 00:24:20,127
それを
グリッドサンプラレイヤに送り

353
00:24:20,260 --> 00:24:22,930
再び数字にレンダリングしますが

354
00:24:23,030 --> 00:24:25,465
すでに数字を認識しています

355
00:24:25,566 --> 00:24:28,302
ここから先は
通常の検出メソッドです

356
00:24:29,069 --> 00:24:32,272
詳細はともかく大事なことは

357
00:24:32,372 --> 00:24:37,244
Core MLがサポートしているのは
緑の部分です

358
00:24:37,377 --> 00:24:40,848
赤の部分の
新しいグリッドサンプラレイヤは

359
00:24:40,948 --> 00:24:44,017
Core MLがサポートしていない
試験的なレイヤです

360
00:24:44,351 --> 00:24:46,887
このモデルを使って

361
00:24:47,254 --> 00:24:51,325
Core ML Toolsの使い方を
見てみましょう

362
00:24:51,892 --> 00:24:53,760
デモをご覧ください

363
00:25:00,033 --> 00:25:02,102
うまくいくでしょうか

364
00:25:03,470 --> 00:25:05,439
画面を切り替えます

365
00:25:07,241 --> 00:25:10,277
ウインドウを閉じます

366
00:25:14,815 --> 00:25:17,951
MLもクリアにしましょう

367
00:25:18,051 --> 00:25:23,257
Jupyter Notebookを使います

368
00:25:29,863 --> 00:25:33,700
学習済みの
ネットワークに移動します

369
00:25:34,268 --> 00:25:39,406
“spatial transformer MNIST.h5”
というファイルがあります

370
00:25:39,506 --> 00:25:41,875
Kerasのモデルです

371
00:25:42,743 --> 00:25:46,013
モデルの入手法が
気になるでしょう

372
00:25:48,182 --> 00:25:49,683
とても簡単です

373
00:25:50,083 --> 00:25:53,921
空間変換の
オープンソースから見つけ

374
00:25:54,021 --> 00:25:57,357
Kerasにスクリプトを
提供しただけです

375
00:25:58,158 --> 00:26:02,796
同時にPythonのスクリプトも
手に入れました

376
00:25:58,158 --> 00:26:02,796
同時にPythonのスクリプトも
手に入れました

377
00:26:03,230 --> 00:26:06,099
本来
このグリッドサンプラレイヤは

378
00:26:06,300 --> 00:26:09,069
Kerasでもサポートされていません

379
00:26:09,269 --> 00:26:12,005
そのため実装するために

380
00:26:12,105 --> 00:26:16,143
Kerasのカスタムレイヤを
使用しました

381
00:26:16,310 --> 00:26:20,681
Core ML独自の
概念ではありません

382
00:26:20,781 --> 00:26:24,651
一般的な
機械学習フレームワークと同じ―

383
00:26:24,751 --> 00:26:27,387
新しいレイヤの試行法です

384
00:26:27,988 --> 00:26:30,724
このKerasモデルから

385
00:26:30,824 --> 00:26:34,061
どうやってCore MLモデルを
得ましょうか

386
00:26:34,328 --> 00:26:36,597
ここから…

387
00:26:40,267 --> 00:26:43,036
Python Notebookを
新たに開きます

388
00:26:44,104 --> 00:26:48,442
Kerasモデルを
Pythonにインポートします

389
00:26:51,812 --> 00:26:54,515
Kerasをインポートし

390
00:26:55,215 --> 00:26:58,051
Kerasのカスタムレイヤも
インポート

391
00:26:58,252 --> 00:27:01,221
それからモデルをロードします

392
00:26:58,252 --> 00:27:01,221
それからモデルをロードします

393
00:27:02,656 --> 00:27:06,059
Kerasモデルをロードしたら

394
00:27:06,160 --> 00:27:10,197
モデルやカスタムレイヤに
パーツを割り振ります

395
00:27:10,964 --> 00:27:14,802
このモデルをCore MLに
変換しましょう

396
00:27:15,602 --> 00:27:19,473
Core ML Toolsをインポートし
実行します

397
00:27:19,907 --> 00:27:23,844
先ほどもお見せしたように

398
00:27:23,944 --> 00:27:27,347
１度のコールで変換できます

399
00:27:28,448 --> 00:27:32,419
エラーが表示されるのは
想定内です

400
00:27:33,387 --> 00:27:36,023
大量のエラーメッセージですが

401
00:27:36,123 --> 00:27:40,194
肝心なのは最後の行だけです

402
00:27:40,294 --> 00:27:41,361
見てみましょう

403
00:27:46,733 --> 00:27:51,605
“このレイヤは
サポートしていない”と出ました

404
00:27:51,805 --> 00:27:55,142
これを解決するためには…

405
00:27:55,242 --> 00:27:58,312
閉じたほうが見やすいですね

406
00:27:58,412 --> 00:28:00,948
変換のコールを書き換えます

407
00:27:58,412 --> 00:28:00,948
変換のコールを書き換えます

408
00:28:01,048 --> 00:28:03,350
まずはCore MLモデル

409
00:28:05,953 --> 00:28:09,056
引数を１つ加えます

410
00:28:09,156 --> 00:28:11,558
“custom…”

411
00:28:13,227 --> 00:28:15,562
“conversion functions”

412
00:28:19,399 --> 00:28:23,070
これが辞書になって
レイヤの名前から

413
00:28:23,303 --> 00:28:27,708
私が定義する関数まで含み
“GridSampler”とします

414
00:28:27,841 --> 00:28:30,344
まずは おさらいしましょう

415
00:28:30,510 --> 00:28:35,916
コンバータはKerasの
すべてのレイヤを解析します

416
00:28:36,783 --> 00:28:40,687
解析したレイヤごとに
パラメータを―

417
00:28:40,787 --> 00:28:43,857
Core MLに翻訳します

418
00:28:44,658 --> 00:28:47,394
カスタムレイヤは
対応できません

419
00:28:47,728 --> 00:28:51,665
そこで グリッドサンプラの
関数を与えると

420
00:28:51,932 --> 00:28:54,701
変換が可能になります

421
00:28:54,868 --> 00:28:57,504
関数を見てみましょう

422
00:29:00,941 --> 00:29:02,309
これが関数です

423
00:29:02,810 --> 00:29:06,480
やっていることは３つだけです

424
00:29:07,381 --> 00:29:11,685
まず クラスの名前を与えます

425
00:29:11,919 --> 00:29:15,722
ここにはレイヤは
実装されていません

426
00:29:15,856 --> 00:29:21,128
アプリケーションに実装され
クラスにカプセル化されます

427
00:29:21,228 --> 00:29:24,498
その時のクラスの名前です

428
00:29:24,631 --> 00:29:28,802
変換の時には
名前を指定するだけです

429
00:29:29,136 --> 00:29:33,240
続いて誰が見ても分かるように

430
00:29:33,340 --> 00:29:38,645
モデルの詳細な情報を提供します

431
00:29:39,246 --> 00:29:42,516
最後にKerasのレイヤから
Core MLに

432
00:29:42,616 --> 00:29:44,885
翻訳するパラメータです

433
00:29:44,985 --> 00:29:49,189
このレイヤの場合は
出力の高さと幅を

434
00:29:49,289 --> 00:29:51,525
Core MLに翻訳します

435
00:29:51,825 --> 00:29:54,127
パラメータがない場合は

436
00:29:54,228 --> 00:29:57,931
こんなことをする必要は
ありません

437
00:29:58,298 --> 00:30:00,300
パラメータが多い場合は

438
00:29:58,298 --> 00:30:00,300
パラメータが多い場合は

439
00:30:00,400 --> 00:30:05,405
この方法でCore MLモデルに
カプセル化できます

440
00:30:06,240 --> 00:30:11,612
クラスを定義する際の方法に
よく似ていますね

441
00:30:11,712 --> 00:30:14,848
名前と情報
パラメータを与えます

442
00:30:15,482 --> 00:30:17,084
これを実行します

443
00:30:19,853 --> 00:30:23,257
無事に変換が終了しました

444
00:30:25,492 --> 00:30:28,295
続いて…

445
00:30:28,962 --> 00:30:31,798
うまく動きませんね

446
00:30:35,569 --> 00:30:38,972
一度 すべて消します

447
00:30:40,507 --> 00:30:45,012
Core ML Toolsの機能を使えば
簡単に

448
00:30:45,812 --> 00:30:48,615
モデルを可視化できます

449
00:30:50,717 --> 00:30:54,421
モデルを可視化しました

450
00:30:54,521 --> 00:30:58,659
ローカライズしたレイヤが
並んでいます

451
00:30:58,759 --> 00:31:00,427
これはカスタムレイヤです

452
00:30:58,759 --> 00:31:00,427
これはカスタムレイヤです

453
00:31:00,527 --> 00:31:02,996
クリックでパラメータが開きます

454
00:31:03,096 --> 00:31:06,166
私がつけたクラスの名前と

455
00:31:06,667 --> 00:31:09,169
パラメータが表示されます

456
00:31:09,970 --> 00:31:13,807
ドラッグ＆ドロップする前に
問題がないか

457
00:31:13,907 --> 00:31:16,143
可視化して確かめましょう

458
00:31:19,279 --> 00:31:21,181
これは違いますね

459
00:31:21,281 --> 00:31:23,684
このモデルを保存します

460
00:31:31,158 --> 00:31:32,926
モデルを見てみます

461
00:31:33,660 --> 00:31:36,663
これは閉じて…

462
00:31:42,669 --> 00:31:45,539
ディレクトリを入力して

463
00:31:46,773 --> 00:31:48,275
移動します

464
00:31:51,945 --> 00:31:55,516
クリックしてXcodeを確認します

465
00:31:55,616 --> 00:32:00,554
カスタムレイヤの情報もありますね

466
00:31:55,616 --> 00:32:00,554
カスタムレイヤの情報もありますね

467
00:32:02,289 --> 00:32:03,624
スライドに戻ります

468
00:32:05,025 --> 00:32:10,197
(拍手)

469
00:32:10,297 --> 00:32:14,735
このように関数は
簡単なコードによって

470
00:32:14,835 --> 00:32:17,704
Core MLに変換できます

471
00:32:17,805 --> 00:32:22,409
TensorFlowコンバータや
ONNXコンバータと

472
00:32:22,509 --> 00:32:24,378
プロセスは同じです

473
00:32:25,212 --> 00:32:30,284
左がパラメータを含む
カスタムレイヤのモデルです

474
00:32:30,450 --> 00:32:33,320
Xcodeに
ドラッグ＆ドロップするには

475
00:32:33,420 --> 00:32:38,425
Swiftファイルにクラスを
実装させる必要があります

476
00:32:38,525 --> 00:32:40,060
見てみましょう

477
00:32:40,160 --> 00:32:41,862
クラスと

478
00:32:41,962 --> 00:32:45,866
初期化関数が含まれています

479
00:32:45,966 --> 00:32:50,337
モデルの中のパラメータを
初期化します

480
00:32:50,804 --> 00:32:56,243
そして このクラスの
主な関数はevaluateです

481
00:32:58,145 --> 00:33:02,816
レイヤが実行する
数学関数の実装は

482
00:32:58,145 --> 00:33:02,816
レイヤが実行する
数学関数の実装は

483
00:33:02,916 --> 00:33:04,718
ここでなされます

484
00:33:05,185 --> 00:33:08,055
出力もしくは入力シェイプは

485
00:33:08,155 --> 00:33:12,426
レイヤが生成する
出力サイズを指定します

486
00:33:12,526 --> 00:33:16,663
アプリケーションが
効率的に実行されるように

487
00:33:16,930 --> 00:33:20,100
バッファサイズを分配します

488
00:33:21,902 --> 00:33:26,940
ここまで 新しいレイヤの
対処法を解説しました

489
00:33:27,474 --> 00:33:32,679
カスタムレイヤに概念が似た
カスタムモデルです

490
00:33:33,280 --> 00:33:37,084
考え方は同じですが
より一般的な方法で

491
00:33:37,184 --> 00:33:41,655
どんなネットワークにも
対応できます

492
00:33:41,755 --> 00:33:45,125
ニューラルネットワークに
限りません

493
00:33:45,559 --> 00:33:48,996
より柔軟性があると
言えるでしょう

494
00:33:50,531 --> 00:33:52,065
まとめましょう

495
00:33:52,332 --> 00:33:54,368
このセッションでは

496
00:33:54,468 --> 00:33:59,006
Core ML Toolsの
エコシステムを確認しました

497
00:33:59,106 --> 00:34:03,977
Core MLモデルには
様々な入手先があります

498
00:33:59,106 --> 00:34:03,977
Core MLモデルには
様々な入手先があります

499
00:34:04,444 --> 00:34:06,980
Core MLモデルは

500
00:34:08,181 --> 00:34:10,551
量子化も簡単です

501
00:34:10,784 --> 00:34:14,888
さらに 数行のコードで

502
00:34:14,987 --> 00:34:18,592
新しいカスタムレイヤを
加えられます

503
00:34:20,761 --> 00:34:23,464
詳しくはドキュメントを
ご覧ください

504
00:34:23,563 --> 00:34:27,333
ラボでもお待ちしています
ありがとう

505
00:34:27,434 --> 00:34:30,404
(拍手)