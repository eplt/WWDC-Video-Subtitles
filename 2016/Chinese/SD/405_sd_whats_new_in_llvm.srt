1
00:00:19,520 --> 00:00:21,221
LLVM的新内容


2
00:00:29,630 --> 00:00:31,131
大家好
我是Alex Rosenberg


3
00:00:31,198 --> 00:00:33,834
我很兴奋
能在此跟你们分享一些


4
00:00:33,901 --> 00:00:36,069
Apple LLVM编译器的新特性


5
00:00:36,803 --> 00:00:39,740
但首先我想讲一下LLVM


6
00:00:40,107 --> 00:00:43,110
基于这个项目我们创建了
Apple LLVM编译器


7
00:00:44,111 --> 00:00:48,482
LLVM是一个模块框架
用来建立编译器和其他相关工具


8
00:00:49,149 --> 00:00:52,352
但它的使用
不一定非要按照传统方法


9
00:00:53,187 --> 00:00:55,222
我们都了解并且喜爱Xcode


10
00:00:55,722 --> 00:00:58,292
它使用了大量的
LLVM框架在里面


11
00:00:59,826 --> 00:01:03,664
这个很棒的新应用Swift
Playgrounds也加入了


12
00:01:04,063 --> 00:01:06,133
也在内部使用LLVM


13
00:01:07,935 --> 00:01:10,771
LLVM也是组成
Metal应用内部工作的一部分


14
00:01:10,838 --> 00:01:12,706
以及其他绘图应用编程接口


15
00:01:14,741 --> 00:01:16,243
LVVM是开放资源


16
00:01:16,743 --> 00:01:20,280
Apple长期以来一直
坚持开放编译器和语言资源


17
00:01:20,881 --> 00:01:24,218
Swift语言就诞生于
LLVM工程


18
00:01:24,818 --> 00:01:27,921
我们很高兴你们
还有所有的贡献者


19
00:01:28,355 --> 00:01:31,892
能推动Swift在
Swift.org的进化中不断发展


20
00:01:32,860 --> 00:01:35,729
这个进程
和Swift的发展进程


21
00:01:35,796 --> 00:01:39,433
受到的启发
都来自LLVM项目的发展


22
00:01:40,367 --> 00:01:42,736
LLVM有一个广阔的
开放资源社区


23
00:01:42,970 --> 00:01:45,372
由非盈利
LLVM Foundation支持


24
00:01:47,808 --> 00:01:50,410
LLVM有很强的自定义性
和可组合性


25
00:01:51,111 --> 00:01:53,747
通过利用同样强健
和成熟的基础设施


26
00:01:53,847 --> 00:01:55,449
支持Clang前端


27
00:01:55,782 --> 00:01:57,551
我们为Swift编译器提供动力


28
00:01:59,286 --> 00:02:02,256
想要了解有关Swift的更多信息
请回顾之前的演讲


29
00:02:03,357 --> 00:02:06,660
现在来简单看一些
开放资源里的可用框架


30
00:02:06,727 --> 00:02:08,127
以及可以如何使用它们


31
00:02:09,997 --> 00:02:13,433
Clang是编译器前端
支持C Objective-C和C++语言


32
00:02:14,301 --> 00:02:16,537
它的代码库里
有很多先进的功能


33
00:02:16,603 --> 00:02:18,205
比如静态分析


34
00:02:18,272 --> 00:02:22,276
编写中会用到
代码迁移和代码改写


35
00:02:23,343 --> 00:02:26,246
它也支持开发环境集成


36
00:02:26,313 --> 00:02:27,548
比如源代码索引


37
00:02:27,915 --> 00:02:31,084
以及代码智能补全
这是Xcode最受欢迎的功能


38
00:02:32,819 --> 00:02:34,188
开放资源工具库


39
00:02:34,988 --> 00:02:38,892
帮助你利用Clang的力量
使用你自定义的命令行工具


40
00:02:38,959 --> 00:02:40,294
来处理源代码


41
00:02:40,928 --> 00:02:43,197
想想看你能做到
多少不可思议的事情


42
00:02:43,664 --> 00:02:47,334
有这样完善的语法分析器
运行于你的代码


43
00:02:52,539 --> 00:02:56,043
LLVM优化程序
这个我们会多讲一点


44
00:02:56,109 --> 00:02:59,146
有一套完整的现代编译器优化


45
00:02:59,713 --> 00:03:02,382
就是这个功能实现了
链接时间优化


46
00:03:03,083 --> 00:03:05,586
敬请期待
LTO的新发展


47
00:03:09,790 --> 00:03:12,926
然后我们有个后端
就是最终代码生成的地方


48
00:03:13,527 --> 00:03:16,029
这里是目标文件操作库


49
00:03:16,096 --> 00:03:18,232
功能有汇编和反汇编


50
00:03:18,298 --> 00:03:19,499
还有更高级的功能


51
00:03:19,566 --> 00:03:22,769
比如即时编译
可以很简单的编在一起


52
00:03:24,805 --> 00:03:28,208
LLVM还有很多其他的工具
由它的框架组成


53
00:03:28,408 --> 00:03:29,510
让我们来看一看


54
00:03:31,011 --> 00:03:33,413
作为完整的
LLVM工具链的一部分


55
00:03:33,814 --> 00:03:36,416
就是常见的一套
二进制文件组件


56
00:03:36,483 --> 00:03:39,386
包括开源社区
努力做出的一个框架


57
00:03:39,453 --> 00:03:41,355
用来制作链接器和其他相关工具


58
00:03:41,421 --> 00:03:42,256
其他工具概览


59
00:03:42,322 --> 00:03:45,559
但也许之中最出色的
工程就是LLDB


60
00:03:46,093 --> 00:03:49,663
LLDB结合了许多库
包括Clang Swift


61
00:03:49,963 --> 00:03:52,999
Code Generator
以及它自己的一套调试框架


62
00:03:53,867 --> 00:03:56,904
在周五 有一场很棒的演讲


63
00:03:58,338 --> 00:03:59,973
关于LLDB使用技巧和窍门


64
00:04:00,040 --> 00:04:03,110
这些好的特性无论是
Xcode还是Swift Playgrounds


65
00:04:03,177 --> 00:04:05,779
还是Apple LLVM编译器
都不可能实现


66
00:04:06,013 --> 00:04:09,449
如果没有
LLVM开放资源社区的贡献的话


67
00:04:10,117 --> 00:04:13,120
这个社区里
都是跟你们一样的开发者


68
00:04:13,554 --> 00:04:16,523
他们很有思想
并把他们的想法带入LLVM框架


69
00:04:19,059 --> 00:04:22,162
LLVM开放资源工程
发展速度之快令人咂舌


70
00:04:22,629 --> 00:04:25,199
这颇有挑战性
无论是团队里的哪一个人


71
00:04:25,265 --> 00:04:27,201
或者哪一个公司
都很难赶上


72
00:04:29,169 --> 00:04:32,639
我们想邀请你来
LLVM.org参与这个工程


73
00:04:32,840 --> 00:04:36,276
看看你能否融入这个群体
贡献你独到的见解


74
00:04:38,579 --> 00:04:40,414
现在我来为大家介绍Duncan


75
00:04:40,480 --> 00:04:42,516
他会跟大家讲一些
很棒的语言新特性


76
00:04:42,583 --> 00:04:44,585
在Apple LLVM编译器里


77
00:04:47,955 --> 00:04:51,124
语言支持


78
00:04:53,260 --> 00:04:54,962
我们来讲讲语言支持


79
00:04:55,863 --> 00:04:58,332
首先我们来讲新的语言特性


80
00:04:58,398 --> 00:05:00,868
然后再讲升级C++库


81
00:05:00,934 --> 00:05:04,204
最后讲新的错误和警告
来帮助你完善代码


82
00:05:06,073 --> 00:05:08,041
就从新的语言特性开始讲吧


83
00:05:09,176 --> 00:05:11,845
Objective-C现支持类属性


84
00:05:12,346 --> 00:05:15,082
这个功能一开始是Swift中的
类型属性


85
00:05:15,215 --> 00:05:17,017
我们将它带入Objective-C


86
00:05:17,417 --> 00:05:19,086
互操作运行良好


87
00:05:20,787 --> 00:05:24,424
这个例子中
类属性someString声明了


88
00:05:24,658 --> 00:05:28,028
使用属性语法
通过添加class标志


89
00:05:28,829 --> 00:05:32,299
之后这个someString属性
使用点语法访问


90
00:05:34,034 --> 00:05:36,203
类属性永远无法合成


91
00:05:36,270 --> 00:05:40,807
你可以提供储存 一个getter
一个setter在执行的时候


92
00:05:40,874 --> 00:05:41,875
Objective C类属性


93
00:05:41,942 --> 00:05:45,312
或者你可以用@dynamic
来推迟解析到运行时


94
00:05:47,581 --> 00:05:48,815
转过来看C++


95
00:05:49,216 --> 00:05:50,117
C++线程本地存储（TLS）


96
00:05:50,184 --> 00:05:54,188
LLVM很好地支持
C++11很多年了


97
00:05:54,521 --> 00:05:57,624
唯一不支持的
是线性本地关键字


98
00:05:58,425 --> 00:06:00,027
今年 我们添加了这个支持


99
00:06:00,527 --> 00:06:02,396
我这就讲一下


100
00:06:03,730 --> 00:06:06,867
如果一个变量是以
线程本地关键字来声明


101
00:06:06,934 --> 00:06:09,903
LLVM会创建一个
单独的变量给每个线程


102
00:06:10,971 --> 00:06:14,775
调出初始化器
在第一次进入线程开始使用之前


103
00:06:14,842 --> 00:06:17,010
退出线程的时候调出析构函数


104
00:06:18,445 --> 00:06:22,950
C++类的线程本地存储
支持任何C++类型


105
00:06:26,820 --> 00:06:30,157
它的语法可以
移植到其他C++编译器中


106
00:06:32,125 --> 00:06:36,964
Apple LLVM编译器
已经支持C-style线程本地存储


107
00:06:37,030 --> 00:06:39,333
即便是在编译C++代码的时候


108
00:06:39,800 --> 00:06:41,502
有两种可用的语法


109
00:06:41,802 --> 00:06:45,839
一种是带GCC关键字
另一种来自C11标准


110
00:06:46,907 --> 00:06:51,512
C风格线程本地存储负载较低
较C++本地线程而言


111
00:06:51,578 --> 00:06:53,247
但是它也受限制


112
00:06:53,313 --> 00:06:56,717
它要求使用连贯的初始化器
和简单的老数据类型


113
00:06:56,884 --> 00:06:57,918
哪种TLS适合我？


114
00:06:57,985 --> 00:06:59,987
如果你的代码符合这些限制


115
00:07:00,053 --> 00:07:03,156
你就可以继续使用
C-style线程本地存储


116
00:07:03,223 --> 00:07:04,658
以便获得最高性能


117
00:07:05,192 --> 00:07:07,995
如果不符合
就用C++线程本地关键字


118
00:07:08,328 --> 00:07:09,296
这两个都很好用


119
00:07:10,864 --> 00:07:14,801
线程本地变量可以帮助修复
用户线程代码中的错误


120
00:07:15,269 --> 00:07:17,004
要了解更多线程相关错误的信息


121
00:07:17,771 --> 00:07:20,941
请观看演讲
线程检查工具和静态分析


122
00:07:22,676 --> 00:07:24,411
这就是我要讲的新的语言特性


123
00:07:25,245 --> 00:07:26,313
C++库升级


124
00:07:26,380 --> 00:07:29,049
接下来我们看C++标准库


125
00:07:30,350 --> 00:07:34,721
Libc++多年来一直是
默认的C++标准库


126
00:07:35,189 --> 00:07:38,659
我们一直建议你们
弃用Libstandardc++


127
00:07:38,725 --> 00:07:41,995
在Xcode8的所有平台
我们都已弃用


128
00:07:42,529 --> 00:07:44,531
请你也尽快升级


129
00:07:44,598 --> 00:07:45,699
Libstdc++要弃用


130
00:07:45,766 --> 00:07:49,203
如果你的Xcode工程
仍使用Libstandardc++


131
00:07:49,503 --> 00:07:51,438
你必须要升级到Libc++


132
00:07:51,505 --> 00:07:54,708
通过更改C++标准库的建立设置


133
00:07:55,209 --> 00:07:58,712
Xcode工程现代化会
自动完成这个升级


134
00:08:00,280 --> 00:08:04,885
Libc++.dylib
今年在我们所有平台上做了很大改进


135
00:08:04,952 --> 00:08:10,257
它的库现在完全支持C++14
还有其他的改善


136
00:08:10,557 --> 00:08:11,425
Libc++Availability属性


137
00:08:11,491 --> 00:08:16,096
需要dylib的标准库特性
现也有Availability属性


138
00:08:16,763 --> 00:08:20,133
当Apple框架要
部署给过去的目标


139
00:08:20,200 --> 00:08:21,802
鼓励在运行时检查


140
00:08:22,102 --> 00:08:26,273
C++标准库的有效性检查
在编译时就已经完成


141
00:08:27,241 --> 00:08:30,644
要使用C++功能
需要最新的dylib


142
00:08:30,911 --> 00:08:33,480
所以你指向的平台
必须支持它们


143
00:08:34,615 --> 00:08:36,549
这就是C++库


144
00:08:38,552 --> 00:08:40,621
在Xcode7和Xcode8之间


145
00:08:41,355 --> 00:08:43,890
我们添加了100多个
新的错误与警告


146
00:08:43,957 --> 00:08:45,626
来帮助你找到代码中的故障


147
00:08:46,159 --> 00:08:47,861
我们简单讲讲其中几个


148
00:08:49,863 --> 00:08:51,198
在Xcode 7


149
00:08:51,865 --> 00:08:55,435
我们给Objective-C添加了很棒的新特性
叫做Lightweight Generics


150
00:08:56,103 --> 00:08:59,173
这种_kindof类型修饰符
具有十分重要的作用


151
00:08:59,239 --> 00:09:03,377
允许隐式转换
到_kindof任意子类


152
00:09:03,443 --> 00:09:04,278
_kindof类层次结构之外的方法


153
00:09:04,344 --> 00:09:09,316
在Xcode 8我们完善了
_kindof类型的方法查找诊断


154
00:09:10,417 --> 00:09:11,451
看这个例子


155
00:09:11,518 --> 00:09:14,788
getAwesomeNumber在
My Custom Type中声明


156
00:09:15,055 --> 00:09:16,790
这是NSObject的继承类


157
00:09:17,457 --> 00:09:21,261
之后getAwesomeNumber
在kindof UIView中调出


158
00:09:21,862 --> 00:09:26,033
这个代码是坏的
因为My Custom Type与UIView没有关联


159
00:09:27,167 --> 00:09:29,036
Xcode 8这里就会报错


160
00:09:29,469 --> 00:09:31,839
方法类型检查
调出_kindof类型


161
00:09:31,905 --> 00:09:34,141
限制于同一类层次结构


162
00:09:34,608 --> 00:09:37,845
完善后的类型检查
也可以避免误导性的警告


163
00:09:37,911 --> 00:09:41,348
当一个无关的类型
声明一个名字相同的方法


164
00:09:41,849 --> 00:09:45,552
在Xcode 8 _kindof
类型使用起来方便多了


165
00:09:46,954 --> 00:09:48,755
容器的循环依赖


166
00:09:48,822 --> 00:09:53,060
接下来 Objective-C容器
比如NSArray和NSMutableSet


167
00:09:53,126 --> 00:09:54,661
可以包含任意对象


168
00:09:54,995 --> 00:10:00,033
NSMutableSet调出“s”
在这个例子里添加给了自身


169
00:10:01,401 --> 00:10:05,539
这就造成了循环依赖
导致了Xcode 8的警告


170
00:10:06,507 --> 00:10:08,675
除了创建循环强引用


171
00:10:08,742 --> 00:10:12,779
循环依赖可以避免
一些方法被明确定义


172
00:10:15,883 --> 00:10:17,251
无限递归


173
00:10:18,185 --> 00:10:20,854
这个例子执行了
阶乘函数


174
00:10:21,622 --> 00:10:25,058
如果n是正值
就会返回n乘以阶乘n-1


175
00:10:25,125 --> 00:10:26,960
不断递归来计算答案


176
00:10:27,828 --> 00:10:31,798
如果n是0 返回阶乘1
还是会递归


177
00:10:32,933 --> 00:10:34,801
编译器这时会收到一个警告


178
00:10:34,868 --> 00:10:37,437
说所有通过此函数的路径
都会调出自己


179
00:10:38,005 --> 00:10:40,807
这是最典型的无限递归


180
00:10:42,876 --> 00:10:46,580
这里的一个可能的解决办法就是
当n是0的时候返回1


181
00:10:49,016 --> 00:10:50,284
无用移动
阻止返回值优化（RVO）


182
00:10:50,350 --> 00:10:53,453
标准转移是
C++最好的语言特性之一


183
00:10:54,121 --> 00:10:56,790
它允许你定义
所有者可以被传递


184
00:10:56,857 --> 00:10:58,492
从一个container到另一个


185
00:10:59,293 --> 00:11:02,396
转移资源
比深拷贝要快


186
00:11:04,031 --> 00:11:07,434
但是要将标准转移
用于返回值


187
00:11:07,501 --> 00:11:09,970
就阻止了
具名返回值优化


188
00:11:10,804 --> 00:11:13,907
通常当一个本地变量
以值来返回


189
00:11:13,974 --> 00:11:16,710
编译器就可以
完全避免复制


190
00:11:17,211 --> 00:11:22,783
在generateBars里
调用标准转移使编译器移动bars


191
00:11:24,117 --> 00:11:27,521
虽然移动很快
但是什么都不做不是更快


192
00:11:28,088 --> 00:11:31,091
LLVM现在就会警告
这种无用移动


193
00:11:32,593 --> 00:11:35,495
这种修复是为了避免
标准移动返回值


194
00:11:35,562 --> 00:11:37,264
使性能再次下降


195
00:11:38,699 --> 00:11:42,002
同样 当一个函数
以值接收一个参数


196
00:11:42,069 --> 00:11:43,704
返回的也是一个值


197
00:11:44,037 --> 00:11:47,508
编译器会自动用
标准转移返回


198
00:11:47,574 --> 00:11:49,209
无需额外调出


199
00:11:49,276 --> 00:11:50,410
多余移动
干扰样板


200
00:11:50,477 --> 00:11:54,848
如标准移动在rewriteText
的返回值是多余的


201
00:11:55,482 --> 00:11:57,885
尽管这不会实质上
减低性能


202
00:11:57,951 --> 00:11:59,386
但还是降低了代码的可读性


203
00:12:00,220 --> 00:12:02,389
最好还是直接返回文本


204
00:12:02,456 --> 00:12:06,393
这更方便保持和连贯返回本地变量


205
00:12:08,962 --> 00:12:10,264
参考隐式变换
C+- range-based循环


206
00:12:10,330 --> 00:12:13,967
最后这个新的警告是
关于临时引用


207
00:12:14,034 --> 00:12:16,170
在C++ range-based
循环


208
00:12:17,237 --> 00:12:20,574
这里这个循环
是通过一个shorts矢量


209
00:12:20,641 --> 00:12:24,278
但是循环变量 i
是一个常用引量到而不是int


210
00:12:25,145 --> 00:12:27,147
由于隐形变换


211
00:12:27,214 --> 00:12:30,851
出现在short和int之间
i 就是一个临时量


212
00:12:32,719 --> 00:12:34,488
这会导致一些细微的故障


213
00:12:34,555 --> 00:12:38,425
因为看上去i是在范围内指向
但实际不是


214
00:12:39,059 --> 00:12:42,262
编译器这时就会警告
这个意外变换


215
00:12:42,796 --> 00:12:45,599
一个解决办法是将 i
改成一个short常用引量


216
00:12:46,700 --> 00:12:51,305
另外一个方法是声明i是个临时量
通过去掉引用


217
00:12:52,739 --> 00:12:53,941
类似的警告也会出现


218
00:12:54,341 --> 00:12:56,577
如果range没有返回
任何一个引用


219
00:12:56,643 --> 00:12:57,678
引用复制


220
00:12:57,744 --> 00:13:01,582
一个用博尔值的标准矢量迭代器
无法返回引用


221
00:13:01,915 --> 00:13:05,285
所以迭代器变量b
在这里就是临时量


222
00:13:06,520 --> 00:13:10,190
出乎意料的是
b并不指向矢量之内


223
00:13:10,257 --> 00:13:12,793
于是编译器警告
这个意外复制


224
00:13:15,495 --> 00:13:19,499
解决办法就是去掉引用
明确定义b是临时量


225
00:13:21,502 --> 00:13:24,071
这些新警告包括无限递归
标准移动,


226
00:13:24,137 --> 00:13:27,508
和C++ range-based
循环是默认启用的


227
00:13:28,008 --> 00:13:30,210
要在你的expo进程中实验它们


228
00:13:30,611 --> 00:13:33,213
就把它们添加到
其他警告标志的设置中


229
00:13:33,981 --> 00:13:35,582
新的诊断就讲完了


230
00:13:36,183 --> 00:13:37,017
编译器优化


231
00:13:37,084 --> 00:13:40,220
下面来讲讲编译器优化的进步


232
00:13:43,957 --> 00:13:46,827
我们整体上完善了
LLVM编译器


233
00:13:46,894 --> 00:13:49,730
来优化你的代码的
运行时性能


234
00:13:50,531 --> 00:13:52,533
我们只选择了几个
在今天着重讲解


235
00:13:53,400 --> 00:13:56,503
我们会讲到
链接时间优化的改进


236
00:13:56,570 --> 00:13:59,139
重点讲
新代码生成优化


237
00:13:59,206 --> 00:14:02,376
然后再讲讲
arm64缓存调整


238
00:14:04,444 --> 00:14:07,614
链接时间优化


239
00:14:07,681 --> 00:14:10,984
在过去几年里
我们讨论过了链接时间优化


240
00:14:11,051 --> 00:14:13,053
现在我们有重大进步要跟大家分享


241
00:14:13,820 --> 00:14:16,156
链接时间优化
也叫LTO


242
00:14:16,223 --> 00:14:19,393
它优化了可执行文件
把它们作为单一的完整单元


243
00:14:20,027 --> 00:14:23,697
它在源文件中内联函数
删除死代码


244
00:14:23,797 --> 00:14:26,967
执行其他功能强大
完整的工程优化


245
00:14:27,034 --> 00:14:27,868
什么是链接时间优化（LTO）？


246
00:14:27,935 --> 00:14:31,738
LTO消除了
编译器和链接器间的界限


247
00:14:32,873 --> 00:14:34,975
要了解LTO的工作原理


248
00:14:35,075 --> 00:14:37,511
首先要看看
传统的编译模型


249
00:14:38,679 --> 00:14:40,447
假设我们有四个源文件


250
00:14:41,281 --> 00:14:45,052
第一步是编译
产生四个目标文件


251
00:14:46,353 --> 00:14:50,057
目标文件链接到框架
产生应用


252
00:14:52,326 --> 00:14:54,561
LTO的建立
一开始是一样的


253
00:14:55,329 --> 00:14:57,798
都是编译源文件
到目标文件


254
00:14:58,799 --> 00:15:03,637
在LTO里的这些目标文件
包含了额外的优化信息


255
00:15:03,704 --> 00:15:07,074
这些信息让链接器可以执行
链接时间优化


256
00:15:07,140 --> 00:15:10,277
从而产生单一的
单片集成目标文件


257
00:15:10,344 --> 00:15:11,411
LTO编译模型


258
00:15:11,478 --> 00:15:13,580
LTO的输出
与框架相连


259
00:15:13,647 --> 00:15:17,217
比如Foundation
从而形成应用


260
00:15:19,419 --> 00:15:21,755
LTO能让性能最大化


261
00:15:23,590 --> 00:15:26,760
Apple大量运用LTO
在我们的软件里


262
00:15:27,294 --> 00:15:32,032
通常可执行档的速度可以提高10%
相较于其他普通的发布版本


263
00:15:33,033 --> 00:15:36,737
它的效果会更明显
如果跟性能分析引导优化结合使用


264
00:15:36,803 --> 00:15:38,138
LTO运行时性能
用LTO使性能最大化


265
00:15:38,205 --> 00:15:42,709
它还可以极大地降低代码长度
在优化大小的时候


266
00:15:44,845 --> 00:15:47,214
但是在编译时会产生成本


267
00:15:47,281 --> 00:15:48,148
LTO编译时间的折中


268
00:15:48,215 --> 00:15:52,019
集成优化步骤
会需要大量的记忆


269
00:15:52,085 --> 00:15:54,021
不能利用你所有的核


270
00:15:54,454 --> 00:15:56,523
而且会不断重复
出现在增量编译中


271
00:15:57,824 --> 00:16:02,596
带有调试信息的大型C++项目
编译成本是最高的


272
00:16:03,897 --> 00:16:07,267
在过去的两年里
我们一直致力于降低负载


273
00:16:08,335 --> 00:16:10,204
比如研究内存用量


274
00:16:10,270 --> 00:16:15,275
条件是Apple LLVM编译器
与LTO和调试信息相链接


275
00:16:15,342 --> 00:16:16,610
这个条越短越好


276
00:16:17,044 --> 00:16:20,180
在Xcode 6占用400亿字节


277
00:16:20,247 --> 00:16:21,081
LTO内存用量
完整调试信息


278
00:16:21,148 --> 00:16:24,017
从那时起
我们就将内存用量减少了4倍


279
00:16:24,518 --> 00:16:27,287
也将编译时间减少了33%


280
00:16:29,089 --> 00:16:33,827
Line Tables Only
调试信息水平占用的内存比LTO还少


281
00:16:34,294 --> 00:16:38,165
链接LLVM自己
现在只占7千兆


282
00:16:38,232 --> 00:16:39,433
LTO内存用量
Line Tables Only


283
00:16:39,633 --> 00:16:42,369
LTO从来没有这么好过


284
00:16:43,470 --> 00:16:45,572
但现在还是有
编译时间折中的问题


285
00:16:45,639 --> 00:16:47,441
特别是对增量编译


286
00:16:50,143 --> 00:16:53,480
但我们有一个很棒的新技术
可以减免这些成本


287
00:16:54,882 --> 00:16:57,684
增量LTO能够扩展你的系统


288
00:16:58,752 --> 00:17:03,023
它执行整体分析和内联
不需要结合目标文件


289
00:17:03,090 --> 00:17:04,090
增量LTO


290
00:17:04,156 --> 00:17:08,729
它的建立更加快速
因为它可以同时优化每个目标文件


291
00:17:09,262 --> 00:17:13,133
另外由于目标文件都是单独的


292
00:17:13,200 --> 00:17:17,637
而且你的缓存建立在链接器上
因此增量编译能超速运行


293
00:17:19,373 --> 00:17:22,376
我们来看
增量LTO编译如何运行


294
00:17:22,442 --> 00:17:23,676
增量LTO编译模型


295
00:17:23,743 --> 00:17:26,547
编译步骤与单片集成LTO一样


296
00:17:26,880 --> 00:17:29,449
为每个源文件
产生一个目标文件


297
00:17:31,084 --> 00:17:33,153
不需要合成目标文件


298
00:17:33,220 --> 00:17:36,423
链接器运行LTO分析
在整个工程里


299
00:17:37,658 --> 00:17:41,094
这个分析为每个目标文件
传送优化


300
00:17:41,161 --> 00:17:43,897
使各个目标文件的函数内联


301
00:17:43,964 --> 00:17:47,134
也会内联其他强大的
全工程优化


302
00:17:48,802 --> 00:17:53,240
LTO优化的目标文件
储存在链接器缓存里


303
00:17:54,374 --> 00:17:57,377
之后才会链接到框架以形成应用


304
00:17:59,513 --> 00:18:02,049
根据计算后的运行期性能


305
00:18:02,115 --> 00:18:06,153
增量LTO创立的工程
与单片集成LTO差不多


306
00:18:06,620 --> 00:18:09,790
有几个benchmark慢点儿
另外几个快点儿


307
00:18:11,191 --> 00:18:12,893
但是编译时间很快


308
00:18:13,794 --> 00:18:17,264
那么来看看
我最喜欢的C++工程的创立时间


309
00:18:17,331 --> 00:18:19,233
Apple LLVM编译器本身


310
00:18:20,300 --> 00:18:22,236
在这个表里
条越短越好


311
00:18:22,569 --> 00:18:25,072
最上面这一条
是不用LTO建立的时间


312
00:18:26,039 --> 00:18:29,142
单片集成LTO建立所用的时间
远远超过上面的


313
00:18:29,209 --> 00:18:31,612
用了将近20分钟
可不是6分钟


314
00:18:31,678 --> 00:18:32,546
创建大型C++工程的时间


315
00:18:32,613 --> 00:18:35,516
增量LTO要快很多
用时少于8分钟


316
00:18:35,582 --> 00:18:37,484
负载只增加了25%


317
00:18:39,152 --> 00:18:41,955
再单独来看一下链接步骤
LTO就在这里运行


318
00:18:43,056 --> 00:18:45,792
不用LTO只链接
Apple LLVM编译器自身


319
00:18:45,859 --> 00:18:47,361
所用时间小于两秒


320
00:18:47,895 --> 00:18:49,496
在图上看不到条


321
00:18:49,563 --> 00:18:52,766
因为链接器不执行任何编译器优化


322
00:18:53,967 --> 00:18:59,806
单片集成LTO用时将近14分钟
因为它可以用到所有的核


323
00:18:59,873 --> 00:19:02,276
增量LTO用时2分14秒


324
00:19:02,342 --> 00:19:05,012
比单片集成LTO快了6倍多


325
00:19:06,446 --> 00:19:08,015
内存用量也很小


326
00:19:08,715 --> 00:19:12,186
不用LTO单连
Apple LLVM编译器所占内存


327
00:19:12,252 --> 00:19:13,554
也就200多兆


328
00:19:14,254 --> 00:19:17,758
跟我们之前看到的一样
单片集成LTO占了70亿字节


329
00:19:19,092 --> 00:19:21,895
增量LTO占用内存
小于800兆


330
00:19:22,162 --> 00:19:23,630
这个比例令人不可思议


331
00:19:32,906 --> 00:19:34,708
所有这些结果
都是新版本


332
00:19:34,942 --> 00:19:36,043
以后还会更好


333
00:19:37,244 --> 00:19:38,512
有了增量LTO


334
00:19:38,579 --> 00:19:41,615
增量编译
不会再重复无用功


335
00:19:42,316 --> 00:19:45,118
再看一个例子
当控制器改变时


336
00:19:45,252 --> 00:19:47,554
怎么开始
App的增量编译


337
00:19:47,621 --> 00:19:48,789
增量编译示例


338
00:19:48,856 --> 00:19:51,625
改变控制器
会让链接失效


339
00:19:52,025 --> 00:19:55,495
但其他的LTO目标文件
还存在链接器缓存里


340
00:19:56,029 --> 00:20:00,033
但若一个控制器函数被内联到主方法


341
00:20:00,100 --> 00:20:03,470
那么主方法需要重新优化
在LTO时间


342
00:20:06,006 --> 00:20:09,576
那么我们开始构建
只有控制器需要重新编译


343
00:20:10,744 --> 00:20:14,481
重新运行LTO分析之后
controller.O和main.O


344
00:20:14,548 --> 00:20:18,619
都被优化了
新的LTO目标文件存入链接器缓存


345
00:20:19,486 --> 00:20:23,190
LTO目标文件就如以往一样
连在一起产生应用


346
00:20:25,392 --> 00:20:30,063
增量LTO提供的性能
正是对增量编译性能的期待


347
00:20:30,864 --> 00:20:34,134
当带有小辅助函数的
源文件被更改


348
00:20:34,201 --> 00:20:36,570
使用它们的目标文件
会被重新优化


349
00:20:37,337 --> 00:20:39,706
但对于典型的增量编译


350
00:20:39,773 --> 00:20:43,677
大部分LTO目标文件
直接从链接器缓存链接


351
00:20:45,078 --> 00:20:49,249
最后再看一下链接到
Apple LLVM编译器本身时间


352
00:20:49,883 --> 00:20:53,120
最上面三条显示的时间
是从之前的fresh build


353
00:20:53,187 --> 00:20:54,354
大型C++工程的增量链接


354
00:20:54,421 --> 00:20:57,191
如果我们更改了优化遍数的执行


355
00:20:57,791 --> 00:21:00,527
单片集成LTO用时是一样的


356
00:21:00,594 --> 00:21:02,062
跟fresh build一样


357
00:21:03,597 --> 00:21:06,333
但是增量LTO只需要8秒


358
00:21:06,834 --> 00:21:12,239
这比初始化版本快16倍
比单片集成LTO快100倍


359
00:21:16,910 --> 00:21:17,878
真是令人惊叹


360
00:21:19,379 --> 00:21:21,682
最新的科技
链接时间优化


361
00:21:21,748 --> 00:21:25,919
低内存用量
快速增量编译


362
00:21:26,486 --> 00:21:28,222
今天就去试一下增量LTO吧


363
00:21:28,288 --> 00:21:29,623
启用增量LTO


364
00:21:30,691 --> 00:21:33,460
LTO的改进十分出色


365
00:21:33,527 --> 00:21:36,463
但如果你用LTO
处理大型C++工程


366
00:21:36,530 --> 00:21:39,533
编译时间要降到最低就只用
line tablesonly


367
00:21:39,600 --> 00:21:41,034
调试信息层


368
00:21:41,602 --> 00:21:45,172
这样调试器里可以获得许多追踪信息
而且成本最低


369
00:21:45,239 --> 00:21:47,040
LTO和调试信息


370
00:21:47,107 --> 00:21:48,976
以上就是链接时间优化


371
00:21:49,643 --> 00:21:53,480
现在有请Gerolf上台为大家讲讲
新的代码生成优化


372
00:21:54,147 --> 00:21:56,083
代码生成


373
00:21:59,753 --> 00:22:03,290
好 接下来就讲讲
代码生成优化


374
00:22:03,690 --> 00:22:08,362
我们努力研究Xcode 8
Apple LLVM编译器


375
00:22:08,428 --> 00:22:11,164
为了能提高所有应用的性能


376
00:22:12,199 --> 00:22:14,735
在这一环节
我要讲其中三个


377
00:22:15,169 --> 00:22:17,437
Stack packing
和shrink wrapping


378
00:22:18,238 --> 00:22:20,440
以及选择混合型乘加运算


379
00:22:20,974 --> 00:22:22,576
首先来讲stack packing


380
00:22:23,510 --> 00:22:27,614
这是关于本地变量
运行时栈内存


381
00:22:27,781 --> 00:22:30,984
Apple LLVM编译器
一直都带有优化


382
00:22:31,051 --> 00:22:34,821
努力压缩栈内存大小


383
00:22:35,155 --> 00:22:39,393
Xcode 8的编译器
是优化最好的


384
00:22:40,294 --> 00:22:42,462
原因就是这个
来看看这个例子


385
00:22:42,863 --> 00:22:48,402
注意x的定义要在
if陈述的作用域之内


386
00:22:48,836 --> 00:22:52,072
然后看一下y的定义
在if陈述之后


387
00:22:52,573 --> 00:22:55,175
如果编译器不去优化
这个代码片段


388
00:22:55,242 --> 00:22:58,245
那么就是说
x和y这两个变量


389
00:22:58,312 --> 00:23:01,882
在运行时内存栈上
不同的两个栈单元


390
00:23:03,183 --> 00:23:07,087
但是
根据C-style语言规则


391
00:23:07,154 --> 00:23:10,924
一个变量的生存期
结束于它所定义的作用域


392
00:23:11,525 --> 00:23:14,161
这也就是编译器所利用的一点


393
00:23:14,661 --> 00:23:17,831
那么来看看
这对我们的两个变量有何影响


394
00:23:20,234 --> 00:23:22,936
x被定义于if陈述之内


395
00:23:23,403 --> 00:23:26,907
if陈述的作用域
就在y被定义之前结束


396
00:23:28,375 --> 00:23:31,712
当y被定义之后
y就有了一个生存期


397
00:23:31,778 --> 00:23:33,280
在这张图上你可以看到


398
00:23:33,347 --> 00:23:37,217
x和y 以及x和y的生存期
不会重叠


399
00:23:37,718 --> 00:23:40,854
于是编译器就可以给它们
一个相同的栈单元


400
00:23:44,157 --> 00:23:48,862 line:1
这就减少了
程序用的总栈内存


401
00:23:48,929 --> 00:23:52,366 line:1
就可能会提高应用的性能


402
00:23:54,368 --> 00:23:55,969 line:1
目前一切都是完美


403
00:23:57,237 --> 00:23:59,840 line:1
但是这里有一个小小的警告


404
00:24:01,775 --> 00:24:05,879
编程语言的规则有时很难去检查


405
00:24:06,647 --> 00:24:08,081
所以一旦出错


406
00:24:09,149 --> 00:24:12,853
你的程序
可能就会产生意外的结果


407
00:24:12,920 --> 00:24:16,490
技术术语就是
未定义行为


408
00:24:16,657 --> 00:24:18,325
我们来看个例子


409
00:24:19,526 --> 00:24:21,795
注意这个指针变量


410
00:24:21,995 --> 00:24:25,866
在if代码块中
它的赋值是x的地址


411
00:24:25,933 --> 00:24:27,401
现在看这个print陈述


412
00:24:27,835 --> 00:24:31,672
这个时候
x的地址通过这个指针变量而使用


413
00:24:31,738 --> 00:24:33,373
这么这里所看到的


414
00:24:33,440 --> 00:24:37,744
就是x的地址
跑出了if陈述的作用域


415
00:24:37,811 --> 00:24:41,281
这样我们的语言规则
被视为是未定义行为


416
00:24:41,348 --> 00:24:42,883
脱离本地地址


417
00:24:42,950 --> 00:24:45,085
所幸这个修复很简单


418
00:24:45,152 --> 00:24:47,087
这只是个需要注意的地方


419
00:24:47,154 --> 00:24:50,424
修复的方法很简单
只要拓展作用域


420
00:24:50,490 --> 00:24:54,161
给x的生存期
通过删除x的定义


421
00:24:54,228 --> 00:24:59,566
在if陈述之外的定义
在条件被检查之前


422
00:24:59,867 --> 00:25:05,172
那么现在x的定义
所在的作用域


423
00:25:05,239 --> 00:25:07,441
就与print陈述一致了


424
00:25:08,675 --> 00:25:10,644
删除很简单


425
00:25:11,211 --> 00:25:13,981
请一定要尽所有努力


426
00:25:14,581 --> 00:25:17,551
让你的程序符合
编程语言规则


427
00:25:17,618 --> 00:25:20,320
这能带来更好的体验
给你


428
00:25:20,387 --> 00:25:23,624
给编译器
以及我们的用户


429
00:25:24,625 --> 00:25:26,226
以上就是stack packing


430
00:25:27,961 --> 00:25:29,663
下面来说shrink wrapping


431
00:25:30,631 --> 00:25:35,102
Shrink wrapping
是关于编译器生成的代码


432
00:25:35,169 --> 00:25:37,371
在函数进入和退出的时候


433
00:25:37,771 --> 00:25:39,306
这是一个资源管理代码


434
00:25:39,573 --> 00:25:42,276
管理运行时堆栈和寄存器


435
00:25:43,076 --> 00:25:44,645
这里观察到的是


436
00:25:44,711 --> 00:25:48,782
这个代码并不需要
作用于函数的所有路径


437
00:25:49,082 --> 00:25:53,754
shrink wrapping
会把这个资源管理指令


438
00:25:53,820 --> 00:25:56,023
放在真正需要它们的地方


439
00:25:57,024 --> 00:25:59,526
那么来看一个简单的例子


440
00:26:01,895 --> 00:26:05,399
这是一个简单函数
有两个参数a和b


441
00:26:05,599 --> 00:26:06,867
将它们进行简单比较


442
00:26:07,634 --> 00:26:10,504
如果a小于b
就会调出一个函数foo


443
00:26:10,804 --> 00:26:14,741
它以本地变量的位置
作为一个参数


444
00:26:14,875 --> 00:26:16,310
最后返回


445
00:26:16,710 --> 00:26:20,714
了解shrink wrapping
来看一下伪汇编代码


446
00:26:20,781 --> 00:26:23,684
类似于编译器
真正生成的代码


447
00:26:24,184 --> 00:26:27,921
这里你看到的入口码
分配堆栈内存


448
00:26:27,988 --> 00:26:30,924
节省寄存器
运行比较和分行


449
00:26:30,991 --> 00:26:33,360
出口代码块
会储存寄存器


450
00:26:33,427 --> 00:26:36,063
删除堆栈并返回


451
00:26:36,129 --> 00:26:39,066
如果条件正确
函数foo会被调出


452
00:26:39,132 --> 00:26:42,836
所以这里看到
我们的程序中有两个路径


453
00:26:42,903 --> 00:26:45,305
一个是直接从入口码到出口代码块


454
00:26:45,372 --> 00:26:50,177
另一个从入口代码块到
出口代码块


455
00:26:50,244 --> 00:26:54,448
这里主要的发现就是
这个资源管理指令


456
00:26:54,781 --> 00:26:59,920
指令运行时栈内存
和指令寄存器


457
00:26:59,987 --> 00:27:04,892
只需要用在
调出函数指令时


458
00:27:05,759 --> 00:27:08,795
shrink wrapping
所做的是识别这个条件


459
00:27:09,129 --> 00:27:13,734
将这些指令
移出入口代码块


460
00:27:13,800 --> 00:27:17,004
移出出口代码块
放到真正需要的地方


461
00:27:17,070 --> 00:27:18,939
因此它缩短了生存期


462
00:27:19,306 --> 00:27:22,876
资源管理指令的生存期
并在这个region中将它们打包


463
00:27:22,943 --> 00:27:24,077
转移到真正需要的地方


464
00:27:24,144 --> 00:27:26,413
这里的region就只是调令


465
00:27:26,713 --> 00:27:29,650
现在设想一下
这个热代码


466
00:27:29,716 --> 00:27:34,087
在你的函数里
是从入到出的路径


467
00:27:34,254 --> 00:27:38,592
我们就不再需要执行
资源分配指令


468
00:27:39,159 --> 00:27:42,663
如果这是个热点函数
你会有很多这样的热点函数


469
00:27:42,763 --> 00:27:45,232
你可以想象
这种方法可以节省几百万个


470
00:27:45,299 --> 00:27:47,935
指令
让性能更好的提升


471
00:27:48,001 --> 00:27:50,237
也节省应用的用电量


472
00:27:50,971 --> 00:27:52,739
以上即shrink wrapping


473
00:27:59,947 --> 00:28:02,549
接着我们谈谈混合加乘运算


474
00:28:03,016 --> 00:28:06,253
这把我们带回到
很简单的数学运算


475
00:28:06,320 --> 00:28:07,988
加法和乘法


476
00:28:08,388 --> 00:28:10,157
arm64处理器


477
00:28:11,592 --> 00:28:14,995
有一个指令
就是混合加乘指令


478
00:28:15,495 --> 00:28:17,698
这个指令会计算一个表达式


479
00:28:17,898 --> 00:28:21,435
比如a加b乘以c
只用一个指令


480
00:28:21,502 --> 00:28:22,769
选择性加乘运算


481
00:28:22,836 --> 00:28:26,940
你可能会天真地以为
无论何时看到这样一个表达式


482
00:28:27,007 --> 00:28:30,744
最好的方法
就是只生产这个指令


483
00:28:30,811 --> 00:28:33,380
这也就是
编译器现在所做的事情


484
00:28:35,015 --> 00:28:36,350
但这一定出乎你的意料


485
00:28:36,416 --> 00:28:40,721
在某些情况下
生产两个指令实际上比一个要快


486
00:28:40,787 --> 00:28:43,857
一个加法指令
和一个乘法指令


487
00:28:43,924 --> 00:28:45,959
这会让你的应用的性能变得更快


488
00:28:46,827 --> 00:28:47,728
为什么？


489
00:28:48,095 --> 00:28:50,998
我准备了一个简单的例子
来进行演示


490
00:28:52,432 --> 00:28:55,435
这个函数使用四个整数参数


491
00:28:55,502 --> 00:28:57,671
并计算一个简单表达


492
00:28:57,738 --> 00:28:59,873
a乘以b加c乘以d


493
00:28:59,940 --> 00:29:01,308
选择性混合加乘运算


494
00:29:01,375 --> 00:29:03,177
代码会是什么样子？


495
00:29:03,243 --> 00:29:07,080
当编译器生成
一个单一混合加乘指令的时候？


496
00:29:08,115 --> 00:29:10,851
它会计算a乘以b


497
00:29:10,918 --> 00:29:13,887
然后加乘运算
需要等待这个结果


498
00:29:15,255 --> 00:29:19,660
然后加乘运算
会计算这个表达式的值


499
00:29:20,093 --> 00:29:21,295
要用多长时间？


500
00:29:21,562 --> 00:29:26,066
乘法需要四个循环
加法也是


501
00:29:26,133 --> 00:29:29,503
所以这个简单序列
总共需要八个循环


502
00:29:32,773 --> 00:29:36,176
当我们要生成
2个乘法和1个加法


503
00:29:36,777 --> 00:29:38,378
怎么可能更快呢？


504
00:29:38,512 --> 00:29:40,280
那么我们来看看这个序列


505
00:29:40,981 --> 00:29:45,519
首先编译器发出乘法指令
a乘以b


506
00:29:45,586 --> 00:29:47,187
然后计算c乘以d


507
00:29:47,254 --> 00:29:50,190
最后把结果相加


508
00:29:50,824 --> 00:29:55,762
秘诀在于现代处理器
可以指令级并行


509
00:29:55,963 --> 00:29:59,499
它们可以执行2个甚至更多乘法


510
00:29:59,566 --> 00:30:00,934
两个乘法 代码更快


511
00:30:01,001 --> 00:30:03,704
同时并列计算


512
00:30:03,770 --> 00:30:05,272
因此在这里


513
00:30:05,339 --> 00:30:08,208
两个乘法是
并列执行的


514
00:30:08,342 --> 00:30:12,479
所以在四个循环中
我们得到的不是一个乘法的结果


515
00:30:12,546 --> 00:30:14,448
而是两个


516
00:30:14,515 --> 00:30:17,518
然后我们只要把结果相加
一个循环里完成


517
00:30:18,018 --> 00:30:22,756
现在我们看到
要计算这个表达式的值


518
00:30:22,856 --> 00:30:24,758
我们只需要五个循环


519
00:30:24,825 --> 00:30:27,594
现在比较一下这个序列


520
00:30:28,495 --> 00:30:31,231
与一个最少加乘的序列


521
00:30:31,298 --> 00:30:36,069
那么在这个简单序列中
运算速度快了两倍


522
00:30:37,171 --> 00:30:39,673
因此使用选择性加乘运算


523
00:30:39,740 --> 00:30:43,844
就可以加速计算
应用里的许多简单表达式


524
00:30:44,077 --> 00:30:46,246
以上就是混合加乘运算


525
00:30:54,054 --> 00:30:56,990
接着我们讲arm64缓存优化


526
00:30:58,258 --> 00:31:00,761
这里我要讲两个技术


527
00:31:00,827 --> 00:31:05,599
编译器决定
哪些数据会存在缓存里


528
00:31:06,233 --> 00:31:08,535
而缓存中的数据


529
00:31:08,602 --> 00:31:10,938
决定了应用的性能


530
00:31:11,805 --> 00:31:15,108
在我们详细讲解
编译器的工作原理之前


531
00:31:15,175 --> 00:31:18,011
我想快速的
回顾一下存储层次


532
00:31:18,412 --> 00:31:22,683
在顶部你看到的是主存储
控制程序变量


533
00:31:24,117 --> 00:31:25,953
这是上面这一条


534
00:31:26,053 --> 00:31:27,688
在最底下
你看到是寄存器


535
00:31:27,754 --> 00:31:31,692
从主存储器下载数据
到寄存器十分缓慢


536
00:31:31,758 --> 00:31:35,462
要链接这两个部分需要一个缓存
就是临时存储


537
00:31:35,529 --> 00:31:40,434
它比主存储小
1万到10万倍


538
00:31:40,501 --> 00:31:43,804
但是从缓存下载数据的速度
要快很多


539
00:31:43,871 --> 00:31:46,273
大概快10到100倍


540
00:31:47,007 --> 00:31:49,243
然后数据从主存储中下载


541
00:31:50,244 --> 00:31:53,146
我们下载的
不仅仅是单一的寄存值


542
00:31:53,213 --> 00:31:56,149
而是把一整个缓存行
从主存储中下载下来


543
00:31:56,216 --> 00:31:59,152
所以缓存行中包括了
不止一个注册值


544
00:32:00,053 --> 00:32:02,623
这个设计之所以
能如此成功


545
00:32:02,689 --> 00:32:07,060
是因为你的程序数据
有两个局部属性


546
00:32:07,127 --> 00:32:10,063
时间局部性
和空间局部性


547
00:32:10,597 --> 00:32:14,401
时间局部性指的是
程序现在访问的数据


548
00:32:14,468 --> 00:32:16,436
很快会被再次访问


549
00:32:16,837 --> 00:32:20,707
空间局部性指的是
程序现在访问的数据


550
00:32:20,774 --> 00:32:24,378
随后还会访问相邻的数据


551
00:32:24,645 --> 00:32:29,383
所以当你访问一个数组区域
它还会访问相邻的域


552
00:32:29,516 --> 00:32:33,220
当它访问你数据结构里的一个域


553
00:32:33,287 --> 00:32:35,589
它还会访问相邻的一个域


554
00:32:35,756 --> 00:32:36,957
以此类推


555
00:32:37,024 --> 00:32:39,026
现在你看着这个设计


556
00:32:39,927 --> 00:32:42,462
而且你觉得


557
00:32:42,529 --> 00:32:46,333
从缓存里下载数据很快


558
00:32:46,600 --> 00:32:50,304
那是不是可以
将数据预先加载到缓存里


559
00:32:50,370 --> 00:32:54,441
从主储存中加载
在处理器处理其他操作的时候


560
00:32:54,508 --> 00:32:56,376
这样所有数据的加载都很快


561
00:32:56,443 --> 00:32:58,712
当我们需要这些数据时
当程序需要这些数据时


562
00:33:00,881 --> 00:33:02,316
你可能会感到吃惊


563
00:33:03,217 --> 00:33:07,087
因为你的iPhone处理器
已经实现了这个神奇的事情


564
00:33:07,754 --> 00:33:09,089
这就是硬件预取


565
00:33:09,389 --> 00:33:13,393
处理器会观察
加载的每一个地址


566
00:33:13,694 --> 00:33:16,196
试图在这些地址里找到模式


567
00:33:16,263 --> 00:33:17,598
一旦这个模式找到


568
00:33:17,664 --> 00:33:21,535
就可以预测你的程序
在将来需要什么样的数据


569
00:33:21,602 --> 00:33:24,471
从主存储中再次预取这个数据


570
00:33:24,538 --> 00:33:26,773
在其他并行处理
还在运行中的时候


571
00:33:26,840 --> 00:33:30,577
将数据存进缓存
最后当程序需要他们


572
00:33:30,644 --> 00:33:33,180
程序可以很快的将它们
从缓存中加载


573
00:33:34,181 --> 00:33:37,251
那么今年
我们研究了硬件结构


574
00:33:37,451 --> 00:33:41,288
来看看编译器可以做到什么


575
00:33:41,355 --> 00:33:44,358
让这个神奇预取
使应用运行得更好


576
00:33:44,424 --> 00:33:45,759
软件预取


577
00:33:45,826 --> 00:33:46,994
我们找到了几个模式


578
00:33:47,060 --> 00:33:51,198
所以编译器现在做的
就是分析源代码


579
00:33:51,532 --> 00:33:54,635
预测以后应用可能需要的数据


580
00:33:55,269 --> 00:34:00,207
发出预取指令
让应用获取这个数据


581
00:34:00,274 --> 00:34:01,775
在应用运行的时候


582
00:34:01,975 --> 00:34:03,944
预取指令执行


583
00:34:04,011 --> 00:34:07,481
从主存储获取数据
放入缓存中


584
00:34:09,116 --> 00:34:12,119
当程序需要这些数据时


585
00:34:12,351 --> 00:34:14,855
就可以很快很简单的
从缓存中下载


586
00:34:14,922 --> 00:34:18,824
程序就不需要再等待
数据从主存储中下载


587
00:34:19,493 --> 00:34:21,728
这就是软件预取
所实现的魔法


588
00:34:25,032 --> 00:34:25,966
到这儿....


589
00:34:32,139 --> 00:34:36,909
我讲的这个优化
是编译器自动为你做好的


590
00:34:37,911 --> 00:34:39,580
下一个我要讲的优化


591
00:34:39,713 --> 00:34:42,216
非临时存储
是需要你帮助的


592
00:34:42,449 --> 00:34:47,855
要了解怎么回事
我们要看一看


593
00:34:47,920 --> 00:34:52,292
数据存进主存储的过程


594
00:34:54,261 --> 00:34:58,165
那么让我们再来看看
存储层次结构


595
00:34:58,232 --> 00:35:02,369
假设程序要做一个简单的任务


596
00:35:02,436 --> 00:35:05,105
赋值的话
假设100


597
00:35:05,405 --> 00:35:09,810
给主存储变量
现在的值是55


598
00:35:10,711 --> 00:35:12,613
第一件事就是


599
00:35:13,146 --> 00:35:16,650
本想把新值存到的
旧数据的地址


600
00:35:16,717 --> 00:35:18,418
加载到了缓存


601
00:35:19,920 --> 00:35:21,822
由于我们从主存储加载数据


602
00:35:21,889 --> 00:35:25,125
不只是加载变量的旧数据


603
00:35:25,325 --> 00:35:28,562
还有相邻的数据


604
00:35:28,629 --> 00:35:30,564
因为我们填写了整个缓存行


605
00:35:31,798 --> 00:35:36,570
第二步
把值存入寄存器


606
00:35:37,104 --> 00:35:38,505
存到缓存行


607
00:35:40,908 --> 00:35:41,909
存到缓存里


608
00:35:43,210 --> 00:35:44,645
最后


609
00:35:44,711 --> 00:35:48,515
缓存行的数据
或者是需要其他数据的缓存行


610
00:35:48,916 --> 00:35:52,419
还有值会在第三步
从主存储返回


611
00:35:52,686 --> 00:35:54,988
所以总共是三步


612
00:35:56,089 --> 00:35:58,458
从主存储加载数据到缓存


613
00:35:58,525 --> 00:36:00,727
缓存寄存器的值


614
00:36:00,794 --> 00:36:04,264
最后将数据返回主存储


615
00:36:05,866 --> 00:36:08,202
这么做的原因是数据


616
00:36:08,268 --> 00:36:12,472
通常都有局部性
特别是时间局部性


617
00:36:12,840 --> 00:36:16,610
但是如果你的数据
没有空间局部性呢？


618
00:36:17,311 --> 00:36:22,549
会不会能更快速
更方便的将值直接从


619
00:36:22,616 --> 00:36:26,653
寄存器存入主存储...


620
00:36:26,720 --> 00:36:27,554
更快地储存数据？


621
00:36:27,621 --> 00:36:29,389
...只用一个步骤？


622
00:36:30,557 --> 00:36:34,228
这正是非临时存储的做法


623
00:36:34,294 --> 00:36:36,897
它能避免下载多余的缓存行


624
00:36:37,497 --> 00:36:41,535
还有一个好处就是


625
00:36:42,169 --> 00:36:47,107
这个数据不再需要
不会再存入缓存


626
00:36:47,174 --> 00:36:50,611
那么缓存中就存储其他数据
能对应用更有用


627
00:36:51,545 --> 00:36:53,447
如何指令编译器


628
00:36:53,514 --> 00:36:57,117
生成非临时存储
是通过一个编译器内置组件


629
00:36:57,184 --> 00:36:58,652
非临时存储


630
00:36:59,686 --> 00:37:02,022
那么你用这个内置
来指令编译器


631
00:37:02,089 --> 00:37:03,957
生成非临时存储


632
00:37:04,091 --> 00:37:05,526
这需要两个参数


633
00:37:05,592 --> 00:37:09,830
一个是你要存的值
一个是你要存的地址


634
00:37:11,532 --> 00:37:14,368
什么时候要用
非临时存储？


635
00:37:14,434 --> 00:37:17,437
当没有重复使用
没有时间局部性


636
00:37:17,704 --> 00:37:21,642
在你的代码中
你可复制一大段数据


637
00:37:21,708 --> 00:37:24,178
最好比缓存还多


638
00:37:24,745 --> 00:37:27,214
让应用更有价值


639
00:37:27,281 --> 00:37:29,149
在性能缺失的地方


640
00:37:29,249 --> 00:37:30,751
所以这必须是个热循环


641
00:37:31,552 --> 00:37:33,854
当全部条件无法满足时


642
00:37:33,921 --> 00:37:36,723
你不会想使用非临时存储


643
00:37:39,059 --> 00:37:40,460
你能获得什么？


644
00:37:40,994 --> 00:37:42,296
在这一张幻灯片


645
00:37:42,963 --> 00:37:47,334
我们演示的是
非临时存储带来的好处


646
00:37:47,401 --> 00:37:50,504
从三个含有热循环的
benchmark


647
00:37:50,571 --> 00:37:53,640
这个看上去
跟我之前展示的例子差不多


648
00:37:54,041 --> 00:37:58,512
所以这个数据告诉你
对于普遍的循环体


649
00:37:58,979 --> 00:38:05,219
速度可以加快30%到40%


650
00:38:05,919 --> 00:38:08,155
这就是非临时存储


651
00:38:08,222 --> 00:38:11,225
可以为应用热循环所做的事情


652
00:38:19,499 --> 00:38:20,767
这是个漫长的进程


653
00:38:21,735 --> 00:38:26,773
我们看过了很多新特性
和很棒的新优化


654
00:38:27,474 --> 00:38:30,177
都是新的编译器提供给应用


655
00:38:30,444 --> 00:38:32,112
我们也讲了


656
00:38:32,179 --> 00:38:36,350
Apple LLVM编译器
是基于开放资源工程


657
00:38:36,416 --> 00:38:39,520
你可以与我们互动
到我们的开放资源社区来


658
00:38:39,586 --> 00:38:42,189
甚至提供一些补丁
给你喜爱的编译器


659
00:38:42,689 --> 00:38:44,625
我们看到了这么多新的特性


660
00:38:44,691 --> 00:38:50,230
比如objective类属性
和C++线程本地存储支持


661
00:38:50,531 --> 00:38:51,398
现在...


662
00:38:52,099 --> 00:38:57,638
新的Libc ++
完全支持C++14


663
00:38:57,871 --> 00:39:00,207
而且有了许多新的改进特性


664
00:39:00,774 --> 00:39:04,511
但是要记住
Libstandardc++是弃用的


665
00:39:05,012 --> 00:39:06,914
现在有更多的警告和诊断


666
00:39:06,980 --> 00:39:09,016
让你的代码
比以前更清楚


667
00:39:09,650 --> 00:39:12,386
你也听到了这个神奇的新特性


668
00:39:12,452 --> 00:39:16,056
增量LTO
为你提供一样的性能


669
00:39:16,123 --> 00:39:20,027
与单片集成LTO相比
而且编译时间令人惊叹


670
00:39:20,494 --> 00:39:24,331
之后我们讲了一些
代码生成优化


671
00:39:24,398 --> 00:39:28,268
可以自动加速
所有应用的运行


672
00:39:28,702 --> 00:39:32,272
最后我们讲的是
长期的专业存储


673
00:39:32,339 --> 00:39:34,408
就是编译器提供方法


674
00:39:34,842 --> 00:39:37,277
而你用你的智慧
然后去使用他们


675
00:39:39,213 --> 00:39:41,148
所以我希望这些能说服你


676
00:39:41,215 --> 00:39:43,984
我们做的新编译器
是一个真的很棒的版本


677
00:39:44,518 --> 00:39:46,386
我们高兴极了


678
00:39:46,453 --> 00:39:47,821
请一定试一试


679
00:39:47,888 --> 00:39:50,490
看看它能为你的应用做什么


680
00:39:53,060 --> 00:39:55,562
你可以在我们网站上
找到更多信息


681
00:39:57,164 --> 00:40:00,267
这里还有更多
精彩的演讲...


682
00:40:00,334 --> 00:40:01,401
相关演讲


683
00:40:01,468 --> 00:40:03,003
...应该会让你感兴趣


684
00:40:03,136 --> 00:40:04,004
关注一下


685
00:40:04,171 --> 00:40:05,606
谢谢观看


686
00:40:05,672 --> 00:40:06,707
谢谢你们来到现场


687
00:40:07,207 --> 00:40:09,009
祝你们在大会中过得愉快

