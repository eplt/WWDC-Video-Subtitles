
1
00:00:07,040 --> 00:00:16,283
(音楽)

2
00:00:23,390 --> 00:00:25,492
ありがとうございます

3
00:00:25,592 --> 00:00:26,827
(拍手)

4
00:00:27,361 --> 00:00:31,231
Core Imageのセッションへ
ようこそ

5
00:00:31,331 --> 00:00:32,566
デビッド･ヘイワードです

6
00:00:32,665 --> 00:00:35,802
本日は
新しくなったCore Imageと

7
00:00:35,903 --> 00:00:40,841
プロトタイピング機能について
お話しします

8
00:00:41,041 --> 00:00:44,011
早速 本題に入りましょう

9
00:00:44,545 --> 00:00:48,982
まずはアプリケーションの
動作の改善に役立つ―

10
00:00:49,082 --> 00:00:52,085
新しいAPIを紹介します

11
00:00:52,319 --> 00:00:56,490
次に新たなアルゴリズムの
開発に向けた―

12
00:00:56,590 --> 00:00:59,026
Core Imageの使い方を
お伝えします

13
00:00:59,159 --> 00:01:02,529
機械学習の
アプリケーションでの

14
00:00:59,159 --> 00:01:02,529
機械学習の
アプリケーションでの

15
00:01:02,629 --> 00:01:05,933
Core Imageの
活用法も紹介します

16
00:01:07,568 --> 00:01:11,538
APIによる
パフォーマンス向上については

17
00:01:11,638 --> 00:01:15,475
主に２つの領域に
取り組みました

18
00:01:15,576 --> 00:01:21,715
１つは 中間バッファ挿入のための
コントロールの追加

19
00:01:21,982 --> 00:01:27,955
２つ目は CIカーネル言語の
新機能の追加です

20
00:01:28,055 --> 00:01:31,658
まずは
中間バッファのお話です

21
00:01:33,193 --> 00:01:38,131
Core Imageでは
フィルタのシーケンスを

22
00:01:38,232 --> 00:01:40,033
簡単につなげられます

23
00:01:40,133 --> 00:01:43,871
フィルタは１つ以上の
カーネルから成ります

24
00:01:43,971 --> 00:01:49,209
Core Imageでは
カーネルを連結させて

25
00:01:49,309 --> 00:01:52,012
中間バッファの数を
最小限にします

26
00:01:52,112 --> 00:01:56,817
多くの場合
それでパフォーマンスが向上します

27
00:01:57,484 --> 00:02:03,524
しかし できるだけ
連結を避けたいケースもあります

28
00:01:57,484 --> 00:02:03,524
しかし できるだけ
連結を避けたいケースもあります

29
00:02:03,857 --> 00:02:08,794
例えばフィルタチェインに
高負荷なフィルタを使っていて

30
00:02:09,229 --> 00:02:14,768
ユーザがフィルタを調整する
可能性があるケースです

31
00:02:15,102 --> 00:02:19,439
その場合には
間に中間バッファが―

32
00:02:20,007 --> 00:02:22,409
あったほうがよいでしょう

33
00:02:22,809 --> 00:02:26,046
中間バッファが
メリットを生みます

34
00:02:26,146 --> 00:02:30,551
高負荷なフィルタにかかる
コストを

35
00:02:30,651 --> 00:02:33,887
再びかける必要が
なくなるのです

36
00:02:34,121 --> 00:02:35,822
それを実現するのは

37
00:02:35,923 --> 00:02:40,194
insertingIntermediateという
新しいAPIです

38
00:02:40,761 --> 00:02:43,597
次のような仕組みです

39
00:02:43,697 --> 00:02:46,433
単に多く連結するのではなく

40
00:02:46,533 --> 00:02:52,005
中間バッファの周辺で
できるだけ多く連結します

41
00:02:53,173 --> 00:02:59,246
デフォルトのCore Imageは
全ての中間バッファのキャッシュで

42
00:02:59,346 --> 00:03:03,984
後続のレンダリングを
できる限り速く行います

43
00:02:59,346 --> 00:03:03,984
後続のレンダリングを
できる限り速く行います

44
00:03:04,151 --> 00:03:09,122
しかしキャッシュを
無効にしたい場合もあるでしょう

45
00:03:09,423 --> 00:03:14,628
例えば100の画像を
バッチエクスポートする際に

46
00:03:14,862 --> 00:03:20,300
最初の画像をキャッシュしても
レンダリングでは使いません

47
00:03:20,667 --> 00:03:25,205
従ってコンテキストオプションの
cacheIntermediatesを使い

48
00:03:25,305 --> 00:03:27,241
その値をfalseに設定します

49
00:03:28,475 --> 00:03:32,513
しかし新しいAPIは
コンテキストオプションが無効でも

50
00:03:32,679 --> 00:03:38,185
中間バッファのキャッシュを
有効にできます

51
00:03:38,285 --> 00:03:42,956
何を格納するかを
選択しているのです

52
00:03:45,492 --> 00:03:50,797
次にお話しするテーマは
画像処理を行うための―

53
00:03:50,898 --> 00:03:53,834
カーネル言語の
新しい機能です

54
00:03:55,002 --> 00:03:59,973
Core Imageにカーネルを
書き込む方法は２つあります

55
00:04:00,240 --> 00:04:03,777
従来の方法は
“CIカーネル言語の使用”

56
00:04:03,877 --> 00:04:09,416
この場合 ソースファイルに
文字列が含まれ

57
00:04:09,516 --> 00:04:14,021
実行時に“CIKernel(source:)”で
呼び出します

58
00:04:14,655 --> 00:04:18,358
そのカーネルをベースに
画像を作る時―

59
00:04:18,458 --> 00:04:21,128
その画像を
CIのコンテキストに書き込みます

60
00:04:21,228 --> 00:04:25,799
MetalとOpenGLの
いずれのバックアップでもです

61
00:04:26,867 --> 00:04:30,070
レンダリングには
そのソースの変換が必要です

62
00:04:30,170 --> 00:04:35,909
MetalかGLSLに変換する際
コストがかかります

63
00:04:36,343 --> 00:04:41,215
コードがGPUの命令セットに
コンパイルされ 実行されます

64
00:04:42,583 --> 00:04:48,956
昨年iOS 11を立ち上げた際
新たな手法を追加しました

65
00:04:49,056 --> 00:04:52,226
Metalシェーディング言語に基づく
CIカーネルです

66
00:04:52,526 --> 00:04:55,462
プロジェクト内にあるソースが

67
00:04:55,562 --> 00:05:00,534
実行時ではなく
構築時にコンパイルされます

68
00:04:55,562 --> 00:05:00,534
実行時ではなく
構築時にコンパイルされます

69
00:05:01,435 --> 00:05:05,739
Metalの関数名と
バイナリデータを使い

70
00:05:05,839 --> 00:05:10,511
このコードに基づいて
カーネルを具体化します

71
00:05:12,012 --> 00:05:16,283
この時
コンパイルの追加コストなしで

72
00:05:16,383 --> 00:05:19,219
データを適用できます

73
00:05:19,486 --> 00:05:23,924
Metalバックの
CIコンテキストが必要ですが

74
00:05:24,224 --> 00:05:26,293
パフォーマンス上の
利点があります

75
00:05:27,895 --> 00:05:33,534
今回のリリースから
CIカーネル言語を非推奨とします

76
00:05:33,634 --> 00:05:36,537
今後もサポートは続けますが

77
00:05:36,870 --> 00:05:42,242
Metalカーネルの新手法が
デベロッパに有利だからです

78
00:05:42,342 --> 00:05:45,379
パフォーマンス上の
利点だけでなく

79
00:05:45,479 --> 00:05:50,984
シンタックスカラーリングが
プログラム構築時に得られます

80
00:05:51,084 --> 00:05:55,756
デバッギングツールを
取得することもできます

81
00:05:57,858 --> 00:05:59,326
素晴らしいですね

82
00:05:59,593 --> 00:06:02,362
(拍手)

83
00:05:59,593 --> 00:06:02,362
(拍手)

84
00:06:03,630 --> 00:06:09,436
カーネル言語に追加した機能を
ご紹介しましょう

85
00:06:09,536 --> 00:06:11,939
１つ目は
ハーフフロートサポートです

86
00:06:12,072 --> 00:06:14,541
多くの場合―

87
00:06:14,641 --> 00:06:20,614
ハーフフロートがもたらす精度が
CIカーネルに有効に働きます

88
00:06:20,714 --> 00:06:24,918
RGB値で作業する際には
十分な精度です

89
00:06:25,452 --> 00:06:29,490
カーネルでハーフフロートを使うと
作業が速くなります

90
00:06:29,656 --> 00:06:32,759
iPhone Xなど
A11では顕著です

91
00:06:33,293 --> 00:06:37,598
更には より小さなレジスタで済み

92
00:06:37,698 --> 00:06:41,802
GPUが有効に活用でき
パフォーマンスが向上します

93
00:06:42,302 --> 00:06:47,140
もう１つの追加機能は
グループ読み込みのサポート

94
00:06:47,241 --> 00:06:52,279
これによりシェーダは
１つの入力画像から１回の指示で

95
00:06:52,379 --> 00:06:55,582
４つの単一チャネルを
読み込めます

96
00:06:56,483 --> 00:07:00,921
また ピクセルのグループも
書き込めます

97
00:06:56,483 --> 00:07:00,921
また ピクセルのグループも
書き込めます

98
00:07:01,021 --> 00:07:03,190
シェーダ内の１コールで

99
00:07:03,290 --> 00:07:07,060
１つの画像の４ピクセルを
書き込めます

100
00:07:08,362 --> 00:07:12,366
これらの３つの特性を
シェーダで使用でき

101
00:07:12,466 --> 00:07:15,235
パフォーマンスが改善されます

102
00:07:15,335 --> 00:07:18,272
一例をご紹介しましょう

103
00:07:18,539 --> 00:07:23,277
１つの画像の
１チャネルのみに適用される―

104
00:07:23,544 --> 00:07:26,513
３ｘ３の畳み込みカーネルを
想定します

105
00:07:26,613 --> 00:07:31,051
画像の輝度を
シャープにするための作業です

106
00:07:31,451 --> 00:07:35,756
カーネルを呼び出す度に
アウトプットピクセルを

107
00:07:35,856 --> 00:07:39,626
１つ生成することになります

108
00:07:39,827 --> 00:07:42,529
３ｘ３の畳み込みなので

109
00:07:42,629 --> 00:07:47,134
カーネルは９ピクセルを
読み込む必要があります

110
00:07:47,234 --> 00:07:50,404
１ピクセルに対し ９ピクセルです

111
00:07:51,371 --> 00:07:56,143
新規のグループ書き込み機能で
これを改善できます

112
00:07:56,343 --> 00:08:03,150
２ｘ２ピクセルグループを
一度の呼び出しで書き込めます

113
00:07:56,343 --> 00:08:03,150
２ｘ２ピクセルグループを
一度の呼び出しで書き込めます

114
00:08:03,350 --> 00:08:07,955
２ｘ２のグループは
１ピクセルより大きいので

115
00:08:08,055 --> 00:08:13,927
３ｘ３の代わりに
４ｘ４のピクセルが必要です

116
00:08:14,328 --> 00:08:19,533
４ピクセルの書き込みに対し
16ピクセルとなります

117
00:08:19,633 --> 00:08:22,402
これが１つの特長です

118
00:08:24,905 --> 00:08:28,909
もう１つの特性は
集積能力です

119
00:08:29,009 --> 00:08:33,480
この例では４ｘ４で
16ピクセルを読み込んでいますが

120
00:08:33,580 --> 00:08:39,086
この時 ４つの指示で
16ピクセルの作業ができます

121
00:08:39,720 --> 00:08:45,125
４ピクセルの書き込みに対し
４グループを読み込み

122
00:08:45,225 --> 00:08:47,628
パフォーマンスが向上します

123
00:08:47,728 --> 00:08:50,931
このプロセスを
カーネルのコードで見ましょう

124
00:08:51,865 --> 00:08:57,237
先ほどのような
シンプルな畳み込みのコードです

125
00:08:57,471 --> 00:09:01,308
入力画像から
９つのサンプルを作り

126
00:08:57,471 --> 00:09:01,308
入力画像から
９つのサンプルを作り

127
00:09:01,408 --> 00:09:03,343
赤のチャネルのみ使用

128
00:09:04,111 --> 00:09:09,183
９つの値を平均化し
vec4のピクセル値を返すという―

129
00:09:09,283 --> 00:09:12,286
従来の方法で
書き込みを行います

130
00:09:14,087 --> 00:09:16,924
処理を速くするため
Metalに変換します

131
00:09:17,024 --> 00:09:18,192
作業はシンプルで

132
00:09:18,292 --> 00:09:22,396
従来のCIカーネル言語の
コードから始めます

133
00:09:22,496 --> 00:09:26,233
コードを置き換えて
Metalベースの―

134
00:09:26,333 --> 00:09:29,169
新しいCIカーネル言語に
更新します

135
00:09:29,269 --> 00:09:34,708
デスティネーションパラメータを
カーネルに追加しました

136
00:09:34,808 --> 00:09:40,280
これはカーネルのシェーダ内の
デスティネーション座標を

137
00:09:40,380 --> 00:09:42,416
確認する場合に重要です

138
00:09:42,983 --> 00:09:46,386
最新式のシンタックスを用いて
サンプリングするため

139
00:09:46,487 --> 00:09:50,257
“s.sample”と
“s.transform”とします

140
00:09:51,058 --> 00:09:56,930
それから従来のvec4とvec2の
パラメータタイプを

141
00:09:57,030 --> 00:09:59,366
float4とfloat2に変更

142
00:10:00,634 --> 00:10:04,972
でもカーネルのフローは
変わりません

143
00:10:06,640 --> 00:10:09,910
続いてハーフフロートを
使ってみます

144
00:10:10,010 --> 00:10:16,416
これはハーフフロートの精度を
明度以外にも活用できる例です

145
00:10:16,517 --> 00:10:20,087
再びコードにシンプルな
変更を加えます

146
00:10:20,220 --> 00:10:23,824
浮動小数点の精度を
利用するコードでは

147
00:10:23,924 --> 00:10:27,127
ハーフフロートの精度も
利用します

148
00:10:27,227 --> 00:10:30,364
サンプラのパラメータと
デスティネーションパラメータに

149
00:10:30,464 --> 00:10:32,900
“ h”が付いています

150
00:10:33,333 --> 00:10:37,471
そしてfloat4の部分はhalf4に

151
00:10:38,071 --> 00:10:39,840
非常にシンプルです

152
00:10:39,940 --> 00:10:42,943
コードに一貫性があれば

153
00:10:43,043 --> 00:10:47,314
“/ 9.0”のように
末尾に“h”を追加します

154
00:10:48,815 --> 00:10:50,250
シンプルですね

155
00:10:51,018 --> 00:10:57,191
最後はグループの読み込みと
書き込みの活用です

156
00:10:57,291 --> 00:11:00,027
コードを見てみましょう

157
00:10:57,291 --> 00:11:00,027
コードを見てみましょう

158
00:11:00,627 --> 00:11:03,630
２ｘ２のピクセルグループを
書き込み

159
00:11:03,730 --> 00:11:07,434
４ｘ４のピクセルグループを
読み込みます

160
00:11:08,035 --> 00:11:12,840
グループデスティネーションと
明記します

161
00:11:12,940 --> 00:11:17,711
“group::destination h”と
ありますね

162
00:11:18,345 --> 00:11:22,816
そしてデスティネーションの
座標を得ます

163
00:11:22,916 --> 00:11:29,823
実際には２ｘ２の
ピクセルグループの座標を示します

164
00:11:30,624 --> 00:11:37,431
ピクセルを埋めるために
画像から多くを読み込みます

165
00:11:37,898 --> 00:11:43,003
最初の読み込みは
２ｘ２のピクセルグループから

166
00:11:43,103 --> 00:11:46,707
ここでは
16ピクセルの左下端からです

167
00:11:47,007 --> 00:11:53,947
これは赤のチャネルの値を
half4の配列で戻します

168
00:11:54,715 --> 00:12:00,087
４つのパラメータが
x y z wの順番で

169
00:11:54,715 --> 00:12:00,087
４つのパラメータが
x y z wの順番で

170
00:12:00,187 --> 00:12:02,523
反時計周りに収められます

171
00:12:02,623 --> 00:12:09,096
これはMetalにおける集積の
オペレーションと同じ方向です

172
00:12:10,364 --> 00:12:15,936
このプロセスを
別の３グループで繰り返します

173
00:12:16,036 --> 00:12:20,307
グループ２ ３ ４と続けます

174
00:12:20,641 --> 00:12:25,979
次は どの値を
どこに収めるかが問題です

175
00:12:26,079 --> 00:12:32,019
まず３ｘ３のサブグループの
適切なチャネルを取得して

176
00:12:32,486 --> 00:12:34,154
平均化します

177
00:12:34,421 --> 00:12:39,193
それらのチャネルを
変数result1に格納します

178
00:12:39,560 --> 00:12:43,997
このプロセスを
４つの結果ピクセル―

179
00:12:44,464 --> 00:12:47,034
r1 r2 r3 r4で繰り返します

180
00:12:47,467 --> 00:12:54,107
最後は“dest.write”で
４ピクセルを一括処理します

181
00:12:54,241 --> 00:13:00,581
CIカーネルでの値を
カーネルから戻す手法とは違い

182
00:12:54,241 --> 00:13:00,581
CIカーネルでの値を
カーネルから戻す手法とは違い

183
00:13:00,681 --> 00:13:03,684
“dest.write”を使うのです

184
00:13:05,485 --> 00:13:10,123
わずかな努力で
素晴らしい結果になります

185
00:13:10,224 --> 00:13:13,627
このシェーダで
倍のパフォーマンスを得られます

186
00:13:13,727 --> 00:13:17,798
特に畳み込みを行う
他のシェーダでも

187
00:13:17,898 --> 00:13:20,267
似たような結果が得られます

188
00:13:20,601 --> 00:13:24,338
カーネルのパフォーマンスが
向上します

189
00:13:25,105 --> 00:13:31,578
従来のCIカーネル言語と
MetalがベースのCIカーネルの―

190
00:13:31,678 --> 00:13:36,383
両方について書かれた
新しい資料があります

191
00:13:36,483 --> 00:13:39,286
ぜひ読んでください

192
00:13:39,419 --> 00:13:43,257
以上がカーネルのパフォーマンスの
改善についてです

193
00:13:43,357 --> 00:13:45,726
ここからはエマヌエルに―

194
00:13:45,826 --> 00:13:51,064
新しいアルゴリズムの開発について
話してもらいます

195
00:13:51,164 --> 00:13:55,536
(拍手)

196
00:13:55,636 --> 00:13:56,603
どうも

197
00:13:59,106 --> 00:14:00,674
こんにちは

198
00:13:59,106 --> 00:14:00,674
こんにちは

199
00:14:00,774 --> 00:14:04,344
Core Imageのエンジニア
エマヌエルです

200
00:14:05,279 --> 00:14:07,648
Core Imageを使った―

201
00:14:07,748 --> 00:14:14,321
新しいプロトタイピングの
方法について探っていきましょう

202
00:14:14,755 --> 00:14:19,526
機械学習アプリケーションでの
Core Imageの活用法も紹介します

203
00:14:19,993 --> 00:14:21,128
始めましょう

204
00:14:22,396 --> 00:14:28,101
まずは画像のフィルタ処理の
ライフサイクルからです

205
00:14:30,103 --> 00:14:35,642
それでは前景と背景の区分けを
してみましょう

206
00:14:35,742 --> 00:14:41,915
前景で1.0 背景で0.0の
マスクを取得して

207
00:14:42,182 --> 00:14:45,619
合間に継続的な値を設けます

208
00:14:46,720 --> 00:14:51,425
データの質によって
難しさは変わります

209
00:14:51,525 --> 00:14:56,163
深度バッファが大きい場合は

210
00:14:56,263 --> 00:15:00,367
RGB画像に沿って
容易になります

211
00:14:56,263 --> 00:15:00,367
RGB画像に沿って
容易になります

212
00:15:00,467 --> 00:15:04,571
深度情報でRGB画像を
結合するなら

213
00:15:04,838 --> 00:15:09,376
写真やビデオ効果の
セッションをお勧めします

214
00:15:10,444 --> 00:15:16,550
今日はプロトタイピングの
一般的な事柄にフォーカスします

215
00:15:18,785 --> 00:15:23,156
よくドラフトされた
このフィルタは

216
00:15:23,257 --> 00:15:27,928
前景と背景のマスクの効果が
発揮されています

217
00:15:28,395 --> 00:15:31,365
次のステップはこうです

218
00:15:31,465 --> 00:15:35,569
好きなプロトタイプを選んで

219
00:15:35,669 --> 00:15:39,673
異なるフィルタを結合させます

220
00:15:39,773 --> 00:15:42,709
フィルタ効果を付けるのです

221
00:15:43,844 --> 00:15:45,412
処理が完了し

222
00:15:45,512 --> 00:15:50,751
ここに前景と背景の
マスクの例ができました

223
00:15:51,585 --> 00:15:58,192
iOSもしくはmacOSの環境なら
次はアルゴリズムの展開です

224
00:15:58,392 --> 00:16:02,429
CPUに留まる場合 Core Imageや

225
00:15:58,392 --> 00:16:02,429
CPUに留まる場合 Core Imageや

226
00:16:04,565 --> 00:16:09,403
Metal Performance Shaders
vlmageなどが使えます

227
00:16:10,304 --> 00:16:14,141
プロトタイプからの初期ポートは
時間がかかるし

228
00:16:14,241 --> 00:16:18,645
最初のレンダリングが
期待どおりとは限りません

229
00:16:19,246 --> 00:16:24,418
ピクセルの相違を生むソースは
多くありますが

230
00:16:24,518 --> 00:16:29,122
フィルタがフレームワークで
実行される方法の違いもその１つ

231
00:16:29,690 --> 00:16:36,296
左側の例は前景と背景に
いい感じのぼかしが施されています

232
00:16:36,463 --> 00:16:41,735
このフィルタは
内部のパフォーマンスを最適化し

233
00:16:41,835 --> 00:16:43,871
処理速度を上げています

234
00:16:44,271 --> 00:16:47,407
こうした最適化は
数的なエラーを招き

235
00:16:47,508 --> 00:16:49,576
それがフィルタに伝わります

236
00:16:49,977 --> 00:16:54,281
フィルタの出力に
影響を与えることがあります

237
00:16:55,649 --> 00:17:02,322
他の問題は メモリ管理の大半が
代理で行われることです

238
00:16:55,649 --> 00:17:02,322
他の問題は メモリ管理の大半が
代理で行われることです

239
00:17:02,422 --> 00:17:08,428
メモリ関連の問題は
気付くのが遅れてしまうことも

240
00:17:10,230 --> 00:17:15,935
もう１つ考慮すべき
重要なトピックは性能です

241
00:17:16,036 --> 00:17:19,071
プロトタイプでは
よくCPUコードを使用します

242
00:17:19,172 --> 00:17:23,277
CPコードから
GPコードに向けた処理は

243
00:17:23,377 --> 00:17:27,314
リアルタイムで
取得できると思いがちです

244
00:17:28,415 --> 00:17:34,388
プロトタイピングとワークフローで
問題を早期発見するには？

245
00:17:35,522 --> 00:17:39,326
PyCoreImageという
解決策があります

246
00:17:39,426 --> 00:17:41,361
Core Imageのための
Python結合です

247
00:17:42,262 --> 00:17:46,600
Core Imageの
高性能レンダリングと―

248
00:17:46,733 --> 00:17:50,571
Pythonプログラム言語の
柔軟性の結合です

249
00:17:51,038 --> 00:17:55,843
iOSとmacOS両方のための
サポートと

250
00:17:55,943 --> 00:17:58,378
200以上の内蔵フィルタを
取得できます

251
00:17:58,879 --> 00:18:02,549
PyCoreImageの内部はこちら

252
00:17:58,879 --> 00:18:02,549
PyCoreImageの内部はこちら

253
00:18:04,151 --> 00:18:06,954
主に３つに分かれています

254
00:18:07,754 --> 00:18:10,390
Core Imageをレンダリングに使い

255
00:18:10,858 --> 00:18:14,127
プログラミングインターフェイス
としてPythonを使います

256
00:18:14,828 --> 00:18:17,731
NumPyグルーコードの
薄い層で

257
00:18:18,065 --> 00:18:21,602
コードベースとの
相互運用性を持ちます

258
00:18:23,136 --> 00:18:28,442
プロダクト対応コードと
プロトタイプ間の摩擦を軽減します

259
00:18:29,209 --> 00:18:33,714
Swift中心の環境の場合は
Swift Playgroundの使用や

260
00:18:33,814 --> 00:18:39,152
その定期購読に関する
セッションをお勧めします

261
00:18:41,788 --> 00:18:45,659
PyCoreImageの主な要素を
見ていきましょう

262
00:18:46,126 --> 00:18:50,430
Objective-Cの結合で
Pythonを活用します

263
00:18:50,697 --> 00:18:55,402
Mac OS X 10.5 Leopard以来
PyObjCの出荷は続いています

264
00:18:56,703 --> 00:19:00,574
Cocoa開発の流れで
PythonとObjective-Cの

265
00:18:56,703 --> 00:19:00,574
Cocoa開発の流れで
PythonとObjective-Cの

266
00:19:00,674 --> 00:19:07,080
双方向のブリッジとして
当初 実施されたものです

267
00:19:09,316 --> 00:19:12,519
PyObjCをシンタックスで
呼び出すには

268
00:19:12,619 --> 00:19:15,689
Objective-Cコードで
コラムを配置します

269
00:19:15,789 --> 00:19:20,427
もっと複雑なので
詳細はAPIをご覧ください

270
00:19:20,961 --> 00:19:24,097
ここではCIVectorのクラスを
取り上げます

271
00:19:24,431 --> 00:19:28,969
CIVectorは
Objective-Cコードで作成されます

272
00:19:29,670 --> 00:19:32,473
呼び出すのは
X Y Z WのCIVectorです

273
00:19:32,839 --> 00:19:34,541
PyObjCコードを見ましょう

274
00:19:34,675 --> 00:19:38,512
CIVectorをQuartzアンブレラ
パッケージからインポートし

275
00:19:39,012 --> 00:19:42,616
X Y Z WのCIVectorと
CIVectorクラスを呼び出します

276
00:19:44,284 --> 00:19:47,621
コードがPythonとは違います

277
00:19:47,955 --> 00:19:50,357
これは あとでお話しします

278
00:19:53,193 --> 00:19:56,029
PyCoreImageを見ましょう

279
00:19:56,196 --> 00:20:00,567
Core Imageはハードウェアに近く
フィルタしたコールを

280
00:19:56,196 --> 00:20:00,567
Core Imageはハードウェアに近く
フィルタしたコールを

281
00:20:00,667 --> 00:20:06,540
最も適切な形で表示するため
多くの作業ができます

282
00:20:07,374 --> 00:20:13,013
PyObjCは
Quartzアンブレラパッケージで

283
00:20:13,113 --> 00:20:15,382
Python結合を通して
通信できます

284
00:20:15,616 --> 00:20:21,688
QuartzはCore Graphicsのような
画像処理用フレームワークや

285
00:20:21,788 --> 00:20:26,894
CIVector CIImage CIContext
全てのクラスを含むパッケージです

286
00:20:28,629 --> 00:20:32,733
PyCoreImageは
PyObjCのトップに存在し

287
00:20:33,433 --> 00:20:37,371
PyObjCがCore Imageと
通信するために活用します

288
00:20:37,471 --> 00:20:40,541
機械内部で簡素化を行うので

289
00:20:40,707 --> 00:20:45,946
Core Imageで作業する時は
多くの設定コードを必要としません

290
00:20:46,914 --> 00:20:49,283
cimgクラスで多くをこなし

291
00:20:49,383 --> 00:20:53,253
ベンダーコールを介して
NumPyでの解釈にも使えます

292
00:20:53,754 --> 00:20:58,458
クラスを使い
NumPyのバッファもまとめます

293
00:21:00,260 --> 00:21:06,467
次はPyCoreImageを使って
フィルタを採用する例です

294
00:21:07,201 --> 00:21:11,472
cimgクラスをPyCoreImageの
パッケージからインポートします

295
00:21:12,039 --> 00:21:14,341
ファイルから画像を
ロードするためです

296
00:21:15,375 --> 00:21:18,912
この時点では
ピクセルのバッファがありません

297
00:21:19,012 --> 00:21:23,851
Core Imageが画像のための
レシピを作成し

298
00:21:24,117 --> 00:21:26,553
ロードする指示を出します

299
00:21:27,754 --> 00:21:32,960
CIフィルタを呼び出して
入力プライマリを送りますが

300
00:21:33,060 --> 00:21:35,596
このケースではradiusとします

301
00:21:35,696 --> 00:21:37,965
更に複雑なグラフを作ります

302
00:21:38,065 --> 00:21:42,302
ズームすると
ぼかしのプロセッサが見えます

303
00:21:43,637 --> 00:21:48,809
cimgインスタンスで
レンダリングをコールすると

304
00:21:48,909 --> 00:21:52,246
バッファで適切なユニットを
取得できます

305
00:21:55,749 --> 00:22:02,189
そのためには簡素化した
コード設定を行う必要があります

306
00:21:55,749 --> 00:22:02,189
そのためには簡素化した
コード設定を行う必要があります

307
00:22:02,422 --> 00:22:08,529
Core Imageをご存じの方は
驚かないと思います

308
00:22:08,629 --> 00:22:12,399
初めての方は
最後までお付き合いください

309
00:22:12,499 --> 00:22:17,404
簡素化をご覧になれば
明確に分かると思います

310
00:22:18,705 --> 00:22:24,311
Core ImageはGPU画像処理用の
フレームワークで

311
00:22:24,411 --> 00:22:26,914
iOSやmacOSなどをサポートします

312
00:22:27,848 --> 00:22:29,817
大半のピクセルフォーマットが
対象です

313
00:22:30,450 --> 00:22:35,422
ビットマップデータや
幅広いベンダーからのRAWファイル

314
00:22:36,523 --> 00:22:39,626
大部分のファイル形式を
サポートしています

315
00:22:40,627 --> 00:22:46,300
これらのピクセル形式は
大抵 分けられています

316
00:22:46,400 --> 00:22:50,804
計算やハーフフロートや
32ビットフロートで

317
00:22:50,904 --> 00:22:55,075
８ビットの符号なし画像を
ロードできます

318
00:22:56,343 --> 00:23:00,948
Core Imageは画像の
メタデータを抽出します

319
00:22:56,343 --> 00:23:00,948
Core Imageは画像の
メタデータを抽出します

320
00:23:01,048 --> 00:23:04,718
キャプチャタイム 既存タグ
ポートレートマップ

321
00:23:04,818 --> 00:23:07,287
ポートレートの深度情報などです

322
00:23:09,323 --> 00:23:15,495
多くのフレームワークで扱われない
色彩管理も行います

323
00:23:16,230 --> 00:23:20,434
バウンダリーコンディションや
無限のイメージもサポートし

324
00:23:20,534 --> 00:23:24,271
200以上の内蔵フィルタが
すぐに使えます

325
00:23:25,272 --> 00:23:28,709
かなり盛りだくさんですね

326
00:23:28,809 --> 00:23:32,713
プロトタイプやワークフローで
Core Imageを試せば

327
00:23:33,647 --> 00:23:35,182
学習曲線は上昇します

328
00:23:35,282 --> 00:23:37,918
いくつかの簡素化を行いましたが

329
00:23:38,018 --> 00:23:42,856
一度でオーバーライドすることが
できます

330
00:23:42,956 --> 00:23:44,758
重み付きコードを提供するので

331
00:23:44,858 --> 00:23:48,662
これらの変更事項を
ハードコード化できます

332
00:23:49,696 --> 00:23:52,432
Core Imageは高性能で

333
00:23:52,533 --> 00:23:55,969
Metalバックエンドを
レンダリングします

334
00:23:56,437 --> 00:23:58,906
大半の形式は
サポートされており

335
00:23:59,106 --> 00:24:05,045
キャプチャタイムや
マット情報などを抽出できます

336
00:23:59,106 --> 00:24:05,045
キャプチャタイムや
マット情報などを抽出できます

337
00:24:05,512 --> 00:24:09,049
200以上の内蔵フィルタも
あります

338
00:24:09,783 --> 00:24:15,222
全てのレンダリングで
32ビットフロートを使えます

339
00:24:16,857 --> 00:24:20,494
sRGBカラースペースで
全てを行えます

340
00:24:21,528 --> 00:24:24,898
バウンダリーコンディションには
固定やトリミングで対応

341
00:24:24,998 --> 00:24:31,939
つまり畳み込みや作成の際
画像が無限にリピートされ

342
00:24:32,105 --> 00:24:36,577
フィルタによって画像は
入力サイズにトリミングされます

343
00:24:36,977 --> 00:24:40,714
これも一度でオーバーライドが
可能な設定です

344
00:24:42,249 --> 00:24:47,721
ピクセルバッファの画像が
取得可能になるように―

345
00:24:49,590 --> 00:24:53,260
無限のイメージが有限となります

346
00:24:54,027 --> 00:24:58,832
これらをデモで実際に
見ていただく前に

347
00:24:58,932 --> 00:25:02,536
手短にお話ししたいと思います

348
00:24:58,932 --> 00:25:02,536
手短にお話ししたいと思います

349
00:25:02,636 --> 00:25:04,404
APIを見てみましょう

350
00:25:04,838 --> 00:25:09,343
cimgクラスをPyCoreImageの
パッケージからインポートします

351
00:25:10,110 --> 00:25:13,480
画像をロードするのに使います

352
00:25:14,147 --> 00:25:18,819
Swift対応では
コンテンツ用にCIImageを使えます

353
00:25:20,821 --> 00:25:25,125
ポートレートマット情報や
ポートレート深度を

354
00:25:25,225 --> 00:25:28,862
ファイルからロードできます

355
00:25:31,265 --> 00:25:37,271
CIImageコンストラクタで
NumPyバッファをまとめるか

356
00:25:37,371 --> 00:25:41,108
CIImageでレンダラを呼び出し
NumPyを解釈します

357
00:25:43,443 --> 00:25:48,115
Swiftの場合
CIRenderDestinationを作成し

358
00:25:48,515 --> 00:25:50,984
過去のバッファを割り当てます

359
00:25:51,752 --> 00:25:58,525
CIContextとqTestのレンダリングの
インスタンスを作成します

360
00:25:59,660 --> 00:26:01,828
これで全て完了です

361
00:25:59,660 --> 00:26:01,828
これで全て完了です

362
00:26:02,830 --> 00:26:07,468
色彩やジェネレータから
作成した画像の

363
00:26:07,701 --> 00:26:09,670
残像のサポートもします

364
00:26:11,772 --> 00:26:13,574
次はフィルタの適用方法です

365
00:26:15,008 --> 00:26:18,212
CIImageインスタンスで
フィルタ名を呼び出し

366
00:26:18,312 --> 00:26:22,549
入力プライマリのリストを送ります

367
00:26:22,883 --> 00:26:27,955
各CIImageインスタンスは200以上の
ラムダ式で拡張されており

368
00:26:28,055 --> 00:26:31,291
Core Imageのフィルタに
直接マップします

369
00:26:31,859 --> 00:26:35,929
Swiftの場合
これがシンタックスで

370
00:26:36,029 --> 00:26:41,835
フィルタを適用して
フィルタ名と入力引数を送ります

371
00:26:43,604 --> 00:26:47,775
applyKernelで
カーネルを適用できます

372
00:26:47,875 --> 00:26:50,911
カーネルコードと そのカーネルの

373
00:26:51,278 --> 00:26:56,183
入力パラメータのリストを送ります

374
00:26:57,417 --> 00:27:00,354
カーネルを適用する度合いを特定し

375
00:26:57,417 --> 00:27:00,354
カーネルを適用する度合いを特定し

376
00:27:00,454 --> 00:27:05,092
バッファでサンプリングの
領域を特定します

377
00:27:07,227 --> 00:27:10,797
PyCoreImageには合成に使える―

378
00:27:10,898 --> 00:27:14,101
便利なAPIの
セレクションがあります

379
00:27:14,334 --> 00:27:21,208
他にも移動 スケーリング
回転 トリミングなどができます

380
00:27:23,410 --> 00:27:28,248
GPUカーネルについて
もう少しお話しします

381
00:27:28,348 --> 00:27:31,552
プロトタイピングには
とても役に立ちます

382
00:27:31,685 --> 00:27:36,457
GPUフラグメントシェーダの
コードを含む文字列があります

383
00:27:36,557 --> 00:27:42,229
効果をリアルタイムで
プロトタイプする方法を紹介します

384
00:27:43,597 --> 00:27:48,202
５つのタップのラプラシアンを
シャープ加工で使います

385
00:27:48,302 --> 00:27:51,572
５つのサンプルを作り

386
00:27:51,805 --> 00:27:55,342
局所微分の計算のため合体させ

387
00:27:55,442 --> 00:27:58,178
中心ピクセルに組み込みます

388
00:27:58,812 --> 00:28:01,615
呼び出し方に焦点を当てます

389
00:27:58,812 --> 00:28:01,615
呼び出し方に焦点を当てます

390
00:28:02,115 --> 00:28:05,886
cimgインスタンスで
applyKernelを呼び出します

391
00:28:06,487 --> 00:28:09,223
次のソースコードは
トリプルコードの

392
00:28:09,323 --> 00:28:11,291
Python文字列を使います

393
00:28:12,493 --> 00:28:15,495
カーネルを適用する
度合いを決めます

394
00:28:17,197 --> 00:28:21,301
サンプリングの表現に沿って
領域を定義します

395
00:28:21,735 --> 00:28:26,707
デスティネーションのドメインの
コンセプトや領域については

396
00:28:26,874 --> 00:28:31,812
オンライン資料と過去の
WWDCセッションをご覧ください

397
00:28:32,045 --> 00:28:34,281
ここに畳み込みカーネルが
ありますが

398
00:28:34,381 --> 00:28:36,984
１つのピクセルを読み込みます

399
00:28:37,451 --> 00:28:41,822
Core Imageがバウンダリー
コンディションをハンドルします

400
00:28:43,023 --> 00:28:48,295
たくさん話しましたが
APIを見ること自体は簡潔です

401
00:28:48,395 --> 00:28:52,032
デモで実際の操作をご覧ください

402
00:28:54,268 --> 00:28:58,505
(拍手)

403
00:29:01,775 --> 00:29:04,978
Jupyter Notebookを使います

404
00:29:05,078 --> 00:29:09,016
ブラウザベースでリアルタイムに
Pythonを変換できます

405
00:29:09,349 --> 00:29:14,621
Core Imageを使って
リアルタイムのレンダリングを

406
00:29:14,721 --> 00:29:17,257
今この場で行います

407
00:29:18,325 --> 00:29:23,597
まずユーティリティクラスを
インポートします

408
00:29:23,764 --> 00:29:27,334
PyCoreImageのパッケージにとって
cimgクラスで最も重要です

409
00:29:27,968 --> 00:29:32,539
画像を視覚化するために
コード設定を行います

410
00:29:32,840 --> 00:29:33,841
始めます

411
00:29:35,309 --> 00:29:38,178
画像をロードしましょう

412
00:29:38,479 --> 00:29:41,615
私のオブジェクトのタイプは

413
00:29:42,449 --> 00:29:45,886
PyCoreImage cimgです

414
00:29:46,053 --> 00:29:50,891
適切なCore Imageオブジェクトで
バックアップされています

415
00:29:51,525 --> 00:29:53,727
画像をレンダリングします

416
00:29:53,827 --> 00:29:59,666
マットを使った
実際のピクセルの画像です

417
00:30:00,100 --> 00:30:01,535
この画像に―

418
00:30:02,369 --> 00:30:05,305
フィルタを適用します

419
00:30:05,405 --> 00:30:09,977
Core Imageは200以上の
フィルタをサポートしています

420
00:30:13,046 --> 00:30:15,883
GaussianBlurを使います

421
00:30:15,983 --> 00:30:21,221
サポート確認のため cimgクラスで
インプットを呼び出すと

422
00:30:21,522 --> 00:30:26,760
入力画像を
サポートしているのが分かります

423
00:30:27,261 --> 00:30:29,029
やってみましょう

424
00:30:29,730 --> 00:30:30,998
画像を取り出します

425
00:30:31,331 --> 00:30:34,902
GaussianBlurフィルタを
100ピクセルで適用し

426
00:30:35,135 --> 00:30:37,004
適用前と並べます

427
00:30:38,605 --> 00:30:39,540
非常に―

428
00:30:40,807 --> 00:30:41,875
簡単ですね

429
00:30:42,009 --> 00:30:44,178
では 進めましょう

430
00:30:44,511 --> 00:30:48,015
Core Imageで
プロシージャルイメージも作れます

431
00:30:48,115 --> 00:30:50,617
ジェネレータを見てみましょう

432
00:30:51,485 --> 00:30:55,823
ジェネレータの名称を特定します

433
00:30:56,256 --> 00:30:57,891
ここではCIQRコードを

434
00:30:58,258 --> 00:31:01,828
メッセージで送り
エンコードを試みます

435
00:30:58,258 --> 00:31:01,828
メッセージで送り
エンコードを試みます

436
00:31:02,296 --> 00:31:06,166
リアルタイムでは
メッセージを変更できます

437
00:31:06,266 --> 00:31:09,736
QRコードへの影響を
見てみましょう

438
00:31:11,572 --> 00:31:16,310
Core Imageは画像を
標識化するサポートもします

439
00:31:16,777 --> 00:31:18,345
これが例です

440
00:31:18,745 --> 00:31:22,082
San Franciscoフォントを
使っています

441
00:31:23,050 --> 00:31:24,718
進めていきます

442
00:31:25,419 --> 00:31:29,256
NumPyで相互運用性を
サポートしています

443
00:31:29,356 --> 00:31:31,258
やってみましょう

444
00:31:32,192 --> 00:31:37,798
元の画像から始めて
ボルテックス変形を行います

445
00:31:39,266 --> 00:31:42,035
次にバッファが取得する―

446
00:31:44,238 --> 00:31:47,608
NumPyエリアをレンダリングします

447
00:31:47,775 --> 00:31:52,446
タイプと形と深度 ある程度の
統計も確認できます

448
00:31:52,546 --> 00:31:56,083
最小値 中央値
最大値もあります

449
00:31:58,685 --> 00:32:02,189
NumPyからCore Imageにも
いけます

450
00:31:58,685 --> 00:32:02,189
NumPyからCore Imageにも
いけます

451
00:32:02,890 --> 00:32:06,026
まずはNumPy配列から
始めます

452
00:32:06,126 --> 00:32:11,965
75％の値が黒の
ランダムバッファです

453
00:32:13,567 --> 00:32:17,604
cimgコンストラクタに
NumPy配列をまとめると

454
00:32:17,738 --> 00:32:22,609
cimgクラスのインスタンスと
CIImageが見えます

455
00:32:24,678 --> 00:32:28,081
さまざまなフィルタを
これに適用できます

456
00:32:28,182 --> 00:32:33,720
ここでは ぼかしと
光トンネルを適用します

457
00:32:34,154 --> 00:32:39,126
コントラストの変更と
露出調整とガンマ補正も

458
00:32:39,827 --> 00:32:42,162
横に並べましょう

459
00:32:42,863 --> 00:32:46,366
ぼかし 光トンネル
露出調整 ガンマ補正

460
00:32:46,500 --> 00:32:47,801
これが最終結果です

461
00:32:48,368 --> 00:32:50,370
楽しく簡単にできました

462
00:32:52,439 --> 00:32:55,709
今度は別の画像で作業をします

463
00:32:56,376 --> 00:33:00,747
次のデモでお見せするのは
結合です

464
00:32:56,376 --> 00:33:00,747
次のデモでお見せするのは
結合です

465
00:33:01,048 --> 00:33:05,018
Pythonの画像分割を
使っている方もいるでしょう

466
00:33:05,119 --> 00:33:09,189
ここでは
水平分割した画像にのみ

467
00:33:09,289 --> 00:33:11,892
フィルタを適用します

468
00:33:12,459 --> 00:33:14,728
まずはコードを見ましょう

469
00:33:15,129 --> 00:33:17,264
これが結合機能です

470
00:33:17,498 --> 00:33:23,504
一番下に２つの構成要素で
レンダリングした様子が見えます

471
00:33:23,604 --> 00:33:25,906
右側にCIImageがあります

472
00:33:26,440 --> 00:33:31,912
Core Imageをこの一群の中でのみ
レンダリングしました

473
00:33:32,012 --> 00:33:35,649
ですから効率がいいのです

474
00:33:37,484 --> 00:33:42,523
画像を５つに分割し
最終結果を見てみましょう

475
00:33:45,092 --> 00:33:48,762
ここに書かれているラベルは

476
00:33:48,962 --> 00:33:51,498
適用したフィルタと
一致しています

477
00:33:51,899 --> 00:33:54,068
PyCoreImageは
本当にシンプルです

478
00:33:54,468 --> 00:33:58,739
性能について
手短に説明しましょう

479
00:33:58,839 --> 00:34:03,544
CIImageインスタンスで
レンダリングを呼び出すたび

480
00:33:58,839 --> 00:34:03,544
CIImageインスタンスで
レンダリングを呼び出すたび

481
00:34:03,644 --> 00:34:06,813
NumPyがベイクされ
格納されます

482
00:34:07,047 --> 00:34:11,451
例えばGaussianBlurを適用した
画像を作成します

483
00:34:11,552 --> 00:34:15,188
最初の呼び出しに56ミリ秒
２回目は２ミリ秒かかりました

484
00:34:15,956 --> 00:34:18,692
大きな畳み込みも
見てみましょう

485
00:34:18,792 --> 00:34:20,793
Core Imageはスピードが速く

486
00:34:20,928 --> 00:34:24,398
大きな畳み込みを
簡単にこなします

487
00:34:24,498 --> 00:34:31,972
ここではCIGaussianBlurを
200のシグマで適用

488
00:34:32,072 --> 00:34:33,139
かなりの大きさです

489
00:34:33,239 --> 00:34:36,810
画像をお見せしましょう

490
00:34:36,909 --> 00:34:40,347
scikit-imageを使って
同じ作業をすると

491
00:34:40,447 --> 00:34:42,783
約16秒かかりました

492
00:34:42,882 --> 00:34:47,087
同じことをCore Imageで行うと
130ミリ秒です

493
00:34:47,187 --> 00:34:49,822
かなり速いですね

494
00:34:50,023 --> 00:34:50,824
どうも

495
00:34:50,924 --> 00:34:52,458
(拍手)

496
00:34:52,559 --> 00:34:53,327
続けます

497
00:34:53,427 --> 00:34:56,597
PyCoreImageは
カスタムGPカーネルを

498
00:34:56,697 --> 00:35:01,268
インラインで作成して
複数の処理をまとめて行います

499
00:34:56,697 --> 00:35:01,268
インラインで作成して
複数の処理をまとめて行います

500
00:35:01,368 --> 00:35:03,136
修正も同様です

501
00:35:03,237 --> 00:35:04,638
お見せしましょう

502
00:35:08,775 --> 00:35:09,443
さて―

503
00:35:10,510 --> 00:35:13,247
まずは色彩カーネルの使い方です

504
00:35:13,347 --> 00:35:17,718
色彩カーネルは１つのピクセルを
取り入れて排出し

505
00:35:17,818 --> 00:35:21,088
他のサンプルは作成しません

506
00:35:21,421 --> 00:35:23,590
入力画像とカーネルです

507
00:35:23,690 --> 00:35:27,761
ここで取得した色をオフにします

508
00:35:28,195 --> 00:35:34,635
赤と青のチャネルを
青と赤のチャネルと入れ替えて

509
00:35:34,735 --> 00:35:36,169
反転させます

510
00:35:36,670 --> 00:35:41,775
画期的な効果とは言えませんが
ご覧ください

511
00:35:42,542 --> 00:35:47,014
赤のチャネルを
青のチャネルでレベルを変えて

512
00:35:47,347 --> 00:35:51,251
レベルを少しいじります

513
00:35:51,351 --> 00:35:56,123
0.25から
かなり高い値まで上げると

514
00:35:56,356 --> 00:35:58,392
面白い効果が得られます

515
00:35:59,026 --> 00:36:03,330
リアルタイムで
非常にパワフルです

516
00:35:59,026 --> 00:36:03,330
リアルタイムで
非常にパワフルです

517
00:36:03,430 --> 00:36:06,533
望んだ効果を得られます

518
00:36:08,302 --> 00:36:11,638
続いて 更に複雑なカーネルです

519
00:36:11,739 --> 00:36:15,542
先にお見せしたカーネルに
少し似ています

520
00:36:15,642 --> 00:36:18,779
各ピクセル付近で
タップをします

521
00:36:19,413 --> 00:36:22,950
ファイルから画像を起動すると

522
00:36:23,050 --> 00:36:25,152
カーネルコードがあります

523
00:36:25,252 --> 00:36:29,890
エッジ以外をぼかす
バイラテラルフィルタです

524
00:36:30,891 --> 00:36:35,396
パラメータで
カーネルを適用します

525
00:36:36,864 --> 00:36:37,664
非常に―

526
00:36:38,665 --> 00:36:42,169
優れた効果が得られます

527
00:36:42,269 --> 00:36:48,142
ここで行ったのは
非冗長の高周波成分の切り取りです

528
00:36:48,242 --> 00:36:51,812
更に よく見てみましょう

529
00:36:53,180 --> 00:36:54,948
この花をご覧ください

530
00:36:55,048 --> 00:37:00,087
エッジは残っていますが
高周波成分が消えています

531
00:36:55,048 --> 00:37:00,087
エッジは残っていますが
高周波成分が消えています

532
00:37:00,654 --> 00:37:03,991
このフィルタは
さまざまな目的で使えます

533
00:37:04,091 --> 00:37:06,560
ここでは鮮明化に使いました

534
00:37:06,927 --> 00:37:11,098
左側の画像を元に
右側の画像を減じ

535
00:37:11,198 --> 00:37:15,669
高周波のマップか
画像の詳細を取得します

536
00:37:15,836 --> 00:37:17,037
やってみます

537
00:37:17,905 --> 00:37:21,542
これは画像のレンダリングで
NumPyバッファです

538
00:37:21,642 --> 00:37:26,380
フィルタを適用した画像を
レンダリングして

539
00:37:26,747 --> 00:37:31,285
NumPyからのオペレータ
オーバーロードで差し引きます

540
00:37:31,685 --> 00:37:33,320
レイヤーの詳細です

541
00:37:34,922 --> 00:37:39,827
左は画像全体の詳細
右は中央の部分です

542
00:37:40,694 --> 00:37:45,132
これを元の画像の上に
追加します

543
00:37:45,866 --> 00:37:52,072
この追加を二度行うことで
鮮明になります

544
00:37:52,906 --> 00:37:54,074
シンプルですね

545
00:37:54,408 --> 00:37:57,711
フィルタカーネルの
文字列に戻って

546
00:37:58,045 --> 00:38:01,281
リアルタイムで変更を行えます

547
00:37:58,045 --> 00:38:01,281
リアルタイムで変更を行えます

548
00:38:03,217 --> 00:38:07,387
次は画像からメタデータを
ロードする方法です

549
00:38:07,754 --> 00:38:13,160
ポートレート効果を施した画像と
深度データがあります

550
00:38:14,061 --> 00:38:16,029
画像を横に並べました

551
00:38:16,296 --> 00:38:20,000
左側の画像はRGBで
中央が深度データ

552
00:38:20,100 --> 00:38:24,938
右側は高品質の
ポートレート効果のマットです

553
00:38:25,973 --> 00:38:30,444
cimgインスタンスと
プロパティの呼び出しで

554
00:38:30,544 --> 00:38:34,314
CIImageから既存のタグを
見ることができます

555
00:38:34,882 --> 00:38:38,185
キャプチャに関する情報を
取得できます

556
00:38:39,920 --> 00:38:42,356
ポートレート効果の
マットについては

557
00:38:42,456 --> 00:38:46,160
セッション503で紹介します

558
00:38:46,326 --> 00:38:49,997
ここでは
このフィルタを選択します

559
00:38:50,097 --> 00:38:56,069
工程について興味があれば
そのセッションをお勧めします

560
00:38:57,104 --> 00:38:58,105
非常に楽しめます

561
00:38:59,707 --> 00:39:00,440
(拍手)

562
00:38:59,707 --> 00:39:00,440
(拍手)

563
00:39:00,541 --> 00:39:01,408
ありがとう

564
00:39:01,508 --> 00:39:04,678
(拍手)

565
00:39:05,879 --> 00:39:08,482
では プレゼンテーションに
戻ります

566
00:39:08,582 --> 00:39:11,218
少しギアチェンジをして

567
00:39:11,318 --> 00:39:16,490
Core Imageと
Core MLを合わせます

568
00:39:23,330 --> 00:39:29,636
ポートレートマットと
ポートレート深度情報については

569
00:39:29,737 --> 00:39:33,607
写真とビデオ効果の
セッションがお勧めです

570
00:39:35,042 --> 00:39:37,744
Core ImageとCore MLを
合わせましょう

571
00:39:38,812 --> 00:39:45,419
CI Core MLモデルのフィルタを
紹介できて光栄です

572
00:39:45,719 --> 00:39:49,256
２つの入力だけで使用できます

573
00:39:49,923 --> 00:39:53,594
１つ目はフィルタを用いた
画像自体です

574
00:39:54,294 --> 00:39:55,929
Core MLモデルを入出力し

575
00:39:58,432 --> 00:40:01,635
ニューラルネットワークで
稼働します

576
00:39:58,432 --> 00:40:01,635
ニューラルネットワークで
稼働します

577
00:40:01,735 --> 00:40:04,271
本当にシンプルでパワフルです

578
00:40:04,438 --> 00:40:07,841
Swiftを見てみましょう

579
00:40:09,109 --> 00:40:12,980
フィルタの適用を
呼び出すだけです

580
00:40:13,380 --> 00:40:18,318
今年 発表した
新しいフィルタで

581
00:40:18,418 --> 00:40:19,753
とてもシンプルです

582
00:40:19,987 --> 00:40:24,491
他の手法については
別のセッションをお勧めします

583
00:40:24,591 --> 00:40:30,864
“A Guide to Turi Create”と
“Vision with Core ML”です

584
00:40:32,966 --> 00:40:38,639
機械学習のトレーニング用
データベースで共通の仕様は

585
00:40:38,739 --> 00:40:39,873
データ拡張です

586
00:40:40,474 --> 00:40:46,013
ニューラルネットワークを
増大することができます

587
00:40:46,113 --> 00:40:50,083
オブジェクト分類で
画像が橋なのかや

588
00:40:50,217 --> 00:40:54,555
海があるのかを見極めます

589
00:40:56,857 --> 00:41:01,228
元のトレンドの
データセットが拡張して

590
00:40:56,857 --> 00:41:01,228
元のトレンドの
データセットが拡張して

591
00:41:01,328 --> 00:41:07,067
新しい画像を集める必要なく
数を増やせます

592
00:41:07,301 --> 00:41:08,869
これは無料です

593
00:41:09,403 --> 00:41:12,873
外見を変えることもできます

594
00:41:12,973 --> 00:41:16,410
例えば色温度や白色点を調整したり

595
00:41:17,077 --> 00:41:20,247
ノイズを追加し
光のプロパティを変更したり

596
00:41:21,448 --> 00:41:24,084
形状を変えたりもできます

597
00:41:24,952 --> 00:41:28,422
どれもCore Imageで
簡単に行えます

598
00:41:28,855 --> 00:41:33,460
データ拡張の方法を
見ていきましょう

599
00:41:34,628 --> 00:41:36,597
左側に画像があります

600
00:41:37,764 --> 00:41:41,101
CITemperatureAndTintで
色温度と色合いを変え

601
00:41:41,668 --> 00:41:48,175
CIColorControlsで明るさと
コントラストと彩度を調整し

602
00:41:48,909 --> 00:41:53,280
CIDitherとCIGaussianBlurで
周波数スペクトルを変更

603
00:41:54,615 --> 00:41:57,985
AffineTransformで
形を変えました

604
00:41:59,186 --> 00:42:00,754
ご覧ください

605
00:41:59,186 --> 00:42:00,754
ご覧ください

606
00:42:09,029 --> 00:42:13,300
Jupyter Notebookで
さっきと同様の設定です

607
00:42:13,467 --> 00:42:16,703
Core Imageを使った
拡張から始めます

608
00:42:17,004 --> 00:42:21,675
画像をロードし
拡張機能を定義します

609
00:42:21,775 --> 00:42:24,812
定義した各フィルタに

610
00:42:24,912 --> 00:42:26,947
ランダムスペースから
サンプリング

611
00:42:27,081 --> 00:42:31,084
適用するのはGaussianBlurと
スケーリングと回転

612
00:42:31,185 --> 00:42:36,123
色相･露出･彩度調整
そしてディザリング

613
00:42:37,724 --> 00:42:39,827
この機能を格納して

614
00:42:40,460 --> 00:42:45,032
どうなるかを見てみましょう

615
00:42:46,467 --> 00:42:50,470
このスライダーがシードを
コントロールしています

616
00:42:52,606 --> 00:42:53,607
いいですね

617
00:42:53,807 --> 00:42:58,779
200のフィルタが
リアルタイムで処理され

618
00:42:58,912 --> 00:43:03,116
実際にディスクに保存されます

619
00:42:58,912 --> 00:43:03,116
実際にディスクに保存されます

620
00:43:03,217 --> 00:43:04,251
続けましょう

621
00:43:04,585 --> 00:43:06,487
速さに注目です

622
00:43:10,324 --> 00:43:11,558
パワフルですね

623
00:43:15,095 --> 00:43:15,996
さて―

624
00:43:16,763 --> 00:43:21,101
次はCore Imageで
Core MLを使う方法です

625
00:43:21,869 --> 00:43:26,340
まずはCore MLモデルを
ロードします

626
00:43:27,341 --> 00:43:31,912
ガラスのモデルで
興味深い効果を生み出します

627
00:43:32,012 --> 00:43:35,582
前にも登場した元の画像に

628
00:43:36,850 --> 00:43:39,653
質感を加えていきます

629
00:43:40,754 --> 00:43:43,156
マルチバンドのノイズと―

630
00:43:45,359 --> 00:43:48,795
ぼかしを加えます

631
00:43:50,664 --> 00:43:53,267
他の学習済みモデルと同様に

632
00:43:53,367 --> 00:43:57,871
ニューラルネットワークに
フィードさせる画像です

633
00:43:59,106 --> 00:44:01,074
やってみましょう

634
00:43:59,106 --> 00:44:01,074
やってみましょう

635
00:44:09,650 --> 00:44:12,820
皆さんのために作りました

636
00:44:13,687 --> 00:44:19,326
本日はお越しいただき
ありがとうございました

637
00:44:19,660 --> 00:44:23,530
楽しんでいただけたでしょうか

638
00:44:23,730 --> 00:44:29,169
明日午後３時のCore Imageの
技術ラボにも参加してください

639
00:44:30,070 --> 00:44:31,805
ありがとうございました

640
00:44:31,905 --> 00:44:37,277
(拍手)