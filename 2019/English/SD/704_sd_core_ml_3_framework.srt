1
00:00:00,506 --> 00:00:05,516
[ Music ]


2
00:00:06,516 --> 00:00:13,566
[ Applause ]


3
00:00:14,066 --> 00:00:15,986
>> Hey, everyone.


4
00:00:16,436 --> 00:00:17,476
My name is Michael Brennan.


5
00:00:17,576 --> 00:00:19,116
I'm a software engineer here at


6
00:00:19,116 --> 00:00:20,386
Apple working on Core ML.


7
00:00:21,336 --> 00:00:23,026
And I'm thrilled to be able to


8
00:00:23,026 --> 00:00:23,996
share with you some of the


9
00:00:23,996 --> 00:00:25,636
amazing new features we've


10
00:00:25,636 --> 00:00:27,726
introduced this year for Core ML


11
00:00:27,776 --> 00:00:27,976
3.


12
00:00:30,336 --> 00:00:31,856
Core ML makes it as easy as


13
00:00:31,856 --> 00:00:33,946
possible to seamlessly integrate


14
00:00:33,946 --> 00:00:35,076
machine learning into your


15
00:00:35,076 --> 00:00:37,156
application allowing you to


16
00:00:37,156 --> 00:00:38,686
create a wide variety of novel


17
00:00:39,136 --> 00:00:40,336
and compelling experiences.


18
00:00:41,376 --> 00:00:43,156
At the center of all of this is


19
00:00:43,246 --> 00:00:46,856
the model itself.


20
00:00:47,046 --> 00:00:48,716
You can get a model from a


21
00:00:48,716 --> 00:00:49,776
number of supported training


22
00:00:49,776 --> 00:00:51,736
libraries by converting them


23
00:00:51,736 --> 00:00:53,026
using the converters we have as


24
00:00:53,546 --> 00:00:55,066
a part of our Core ML tools


25
00:00:55,226 --> 00:00:57,146
which we provide.


26
00:00:57,276 --> 00:00:59,966
And with the addition of the new


27
00:00:59,966 --> 00:01:01,716
Create ML app, we've made it


28
00:01:01,716 --> 00:01:03,906
even easier than before to get a


29
00:01:03,906 --> 00:01:04,256
model.


30
00:01:06,596 --> 00:01:07,816
So in this session we're going


31
00:01:07,816 --> 00:01:09,926
to cover a number of topics from


32
00:01:10,006 --> 00:01:11,276
personalizing those models on


33
00:01:11,276 --> 00:01:13,106
device to additional support


34
00:01:13,106 --> 00:01:14,296
we've added for neural networks


35
00:01:14,936 --> 00:01:16,196
and even more.


36
00:01:17,476 --> 00:01:18,436
So let's get started by talking


37
00:01:18,436 --> 00:01:20,116
a little bit about personalizing


38
00:01:20,116 --> 00:01:21,496
your models on-device.


39
00:01:24,396 --> 00:01:27,046
Traditionally, these models are


40
00:01:27,046 --> 00:01:28,196
either bundled with or


41
00:01:28,196 --> 00:01:29,506
downloaded to your application.


42
00:01:30,066 --> 00:01:31,206
And once on your device are


43
00:01:31,206 --> 00:01:33,136
completely mutable being


44
00:01:33,136 --> 00:01:34,426
optimized heavily for


45
00:01:34,426 --> 00:01:36,306
performance within your app.


46
00:01:38,596 --> 00:01:39,506
The great thing about


47
00:01:39,506 --> 00:01:40,596
associating a model with your


48
00:01:40,596 --> 00:01:42,036
app is it means you can provide


49
00:01:42,036 --> 00:01:43,756
the same great experience across


50
00:01:43,756 --> 00:01:44,776
all of your users.


51
00:01:45,326 --> 00:01:47,626
But each user is unique.


52
00:01:48,206 --> 00:01:49,856
They each have their own


53
00:01:49,856 --> 00:01:51,696
specialized needs, their own


54
00:01:51,736 --> 00:01:53,526
individual ways of interacting


55
00:01:53,526 --> 00:01:54,256
with your application.


56
00:01:55,416 --> 00:01:56,366
I think this creates an


57
00:01:56,366 --> 00:01:56,946
opportunity.


58
00:01:57,506 --> 00:02:00,626
What if each user could get a


59
00:02:00,626 --> 00:02:02,746
model personalized specifically


60
00:02:02,836 --> 00:02:03,356
for them?


61
00:02:03,906 --> 00:02:06,746
Well, let's look at the case of


62
00:02:06,746 --> 00:02:07,966
one user on how to do this.


63
00:02:08,955 --> 00:02:10,306
We can take data from that user,


64
00:02:11,156 --> 00:02:12,226
set up some sort of cloud


65
00:02:12,226 --> 00:02:14,636
service, send that data to that


66
00:02:14,636 --> 00:02:17,026
cloud service, and in the cloud


67
00:02:17,126 --> 00:02:18,216
create that new model


68
00:02:18,446 --> 00:02:20,056
personalized on that data which


69
00:02:20,056 --> 00:02:21,096
will then deploy back to that


70
00:02:21,096 --> 00:02:21,386
user.


71
00:02:23,276 --> 00:02:23,956
This creates a number of


72
00:02:23,956 --> 00:02:25,076
challenges, both to you, the


73
00:02:25,076 --> 00:02:26,956
developers, and to our users.


74
00:02:28,486 --> 00:02:30,086
For you, it creates the


75
00:02:30,086 --> 00:02:32,756
challenge of added expenses with


76
00:02:32,756 --> 00:02:33,976
making these cloud services


77
00:02:34,026 --> 00:02:35,886
managing that service and


78
00:02:35,886 --> 00:02:36,836
creating an infrastructure that


79
00:02:36,836 --> 00:02:38,316
could scale to million of users.


80
00:02:38,976 --> 00:02:41,036
And for the user, obviously they


81
00:02:41,036 --> 00:02:43,266
have to expose all their data.


82
00:02:43,266 --> 00:02:43,976
It's unwanted.


83
00:02:44,146 --> 00:02:44,856
It's invasive.


84
00:02:44,856 --> 00:02:46,346
They have to expose this and


85
00:02:46,346 --> 00:02:47,116
send it up to the cloud where


86
00:02:47,116 --> 00:02:48,766
it'll be managed by some other


87
00:02:48,766 --> 00:02:49,116
party.


88
00:02:49,716 --> 00:02:53,786
On Core ML 3, you can do this


89
00:02:53,786 --> 00:02:55,946
kind of personalization all on


90
00:02:55,946 --> 00:02:56,376
device.


91
00:02:57,516 --> 00:03:03,176
[ Applause ]


92
00:03:03,676 --> 00:03:05,006
Simply take that general model


93
00:03:05,566 --> 00:03:06,806
and with the data the users


94
00:03:06,806 --> 00:03:09,186
created or regenerated, you can


95
00:03:09,186 --> 00:03:10,676
personalize that model with that


96
00:03:11,276 --> 00:03:14,756
data for that user.


97
00:03:14,906 --> 00:03:16,376
This means that the data stays


98
00:03:16,476 --> 00:03:16,816
private.


99
00:03:17,426 --> 00:03:18,686
It never leaves the device.


100
00:03:19,676 --> 00:03:20,856
This means there's no need for a


101
00:03:20,856 --> 00:03:21,946
server to do this kind of


102
00:03:21,946 --> 00:03:22,616
interactivity.


103
00:03:22,616 --> 00:03:24,566
And this means you can do it


104
00:03:24,566 --> 00:03:24,896
anywhere.


105
00:03:25,356 --> 00:03:26,956
You're not tying your users down


106
00:03:26,956 --> 00:03:29,426
to Wi-Fi or some data plan just


107
00:03:29,426 --> 00:03:30,106
to update their model.


108
00:03:33,306 --> 00:03:34,376
Before we continue, let's look


109
00:03:34,376 --> 00:03:36,056
inside one of these models and


110
00:03:36,496 --> 00:03:38,706
see what's there today.


111
00:03:38,876 --> 00:03:40,176
Currently, your model consists


112
00:03:40,176 --> 00:03:42,046
of mostly parameters, things


113
00:03:42,046 --> 00:03:43,506
like the weights of the layers


114
00:03:43,506 --> 00:03:44,346
if it's a neural network for


115
00:03:44,346 --> 00:03:44,776
example.


116
00:03:45,396 --> 00:03:46,556
And some metadata describing


117
00:03:46,556 --> 00:03:48,196
things like licensing and


118
00:03:48,196 --> 00:03:50,056
authors, as well as an


119
00:03:50,056 --> 00:03:50,716
interface.


120
00:03:50,716 --> 00:03:51,736
And this where your app concerns


121
00:03:51,736 --> 00:03:52,226
itself with.


122
00:03:52,776 --> 00:03:53,756
It describes how you can


123
00:03:53,756 --> 00:03:55,736
interact with this model.


124
00:03:56,516 --> 00:03:58,396
On Core ML 3, we've added a new


125
00:03:58,436 --> 00:04:00,026
set of parameters to help


126
00:04:00,026 --> 00:04:00,496
updating.


127
00:04:00,496 --> 00:04:01,496
It describes what parts of the


128
00:04:01,496 --> 00:04:02,986
model are updatable and how it's


129
00:04:02,986 --> 00:04:03,446
updatable.


130
00:04:03,976 --> 00:04:04,966
We've added a new update


131
00:04:04,966 --> 00:04:06,146
interface your app can leverage


132
00:04:06,146 --> 00:04:07,096
to make these updates happen.


133
00:04:10,216 --> 00:04:11,396
This means that all the


134
00:04:11,396 --> 00:04:13,206
functionality is accessed


135
00:04:13,206 --> 00:04:14,396
directly through that interface.


136
00:04:14,686 --> 00:04:16,136
We encapsulate away a lot of


137
00:04:16,136 --> 00:04:18,366
those heavy details and it's all


138
00:04:18,366 --> 00:04:19,755
contained within that one model


139
00:04:19,755 --> 00:04:20,096
file.


140
00:04:20,726 --> 00:04:23,166
So just like in making a


141
00:04:23,166 --> 00:04:24,616
prediction, we supply a set of


142
00:04:24,616 --> 00:04:25,446
inputs and you get a


143
00:04:25,446 --> 00:04:26,756
corresponding set of outputs.


144
00:04:27,756 --> 00:04:29,146
Making an update is easy, you


145
00:04:29,146 --> 00:04:30,216
just supply a set of training


146
00:04:30,216 --> 00:04:31,796
examples and you'll get out a


147
00:04:31,796 --> 00:04:33,006
new variant of that model that


148
00:04:33,106 --> 00:04:34,636
was fit or fine-tuned to that


149
00:04:34,636 --> 00:04:34,856
data.


150
00:04:38,096 --> 00:04:40,356
For Core ML 3, we support making


151
00:04:40,356 --> 00:04:41,736
updatable models of nearest


152
00:04:41,736 --> 00:04:43,586
neighbor classifiers as well as


153
00:04:43,586 --> 00:04:44,416
neural networks.


154
00:04:44,646 --> 00:04:45,496
And we're going to support


155
00:04:45,496 --> 00:04:46,706
embedding an updatable model


156
00:04:46,706 --> 00:04:48,296
within your pipeline, meaning


157
00:04:48,296 --> 00:04:49,626
your pipelines are updatable


158
00:04:49,626 --> 00:04:49,896
too.


159
00:04:50,486 --> 00:04:54,576
And with that, I think we should


160
00:04:54,576 --> 00:04:55,386
see this in action.


161
00:04:55,746 --> 00:04:56,976
So I'd like to hand it over to


162
00:04:56,976 --> 00:04:58,286
my colleague Anil Katti.


163
00:04:59,016 --> 00:04:59,336
Anil.


164
00:05:00,516 --> 00:05:06,176
[ Applause ]


165
00:05:06,676 --> 00:05:07,516
>> Thanks, Michael.


166
00:05:07,896 --> 00:05:11,756
Hello. Today I show how I build


167
00:05:11,756 --> 00:05:12,846
an experience that was


168
00:05:12,916 --> 00:05:15,536
customized for my users using


169
00:05:15,906 --> 00:05:17,126
model personalization.


170
00:05:17,716 --> 00:05:19,486
For this I have an app that


171
00:05:19,486 --> 00:05:21,216
helps teachers grade students'


172
00:05:21,216 --> 00:05:21,616
homework.


173
00:05:22,536 --> 00:05:23,846
I added a cool new feature to


174
00:05:23,846 --> 00:05:25,176
this app using model


175
00:05:25,176 --> 00:05:25,826
personalization.


176
00:05:26,046 --> 00:05:27,186
But before we talk about the


177
00:05:27,186 --> 00:05:28,426
feature, let's see what the app


178
00:05:28,426 --> 00:05:28,946
does first.


179
00:05:28,946 --> 00:05:30,456
Let me switch over to the demo


180
00:05:30,456 --> 00:05:30,976
screen.


181
00:05:37,376 --> 00:05:40,136
Great. So here's the app.


182
00:05:40,136 --> 00:05:41,306
It's called a Personalized


183
00:05:41,306 --> 00:05:41,886
Grading App.


184
00:05:42,396 --> 00:05:44,356
What it allows you to do is take


185
00:05:44,356 --> 00:05:47,626
a picture of the homework and


186
00:05:47,626 --> 00:05:49,896
start grading the way our


187
00:05:49,896 --> 00:05:51,006
teacher would on a sheet of


188
00:05:51,006 --> 00:05:51,396
paper.


189
00:05:52,266 --> 00:05:53,846
You'd mark something as correct


190
00:05:53,846 --> 00:05:55,556
like that and something as wrong


191
00:05:55,856 --> 00:05:56,436
like that.


192
00:05:56,736 --> 00:05:58,166
It's pretty straightforward.


193
00:05:58,356 --> 00:05:59,626
Pretty simple.


194
00:06:00,186 --> 00:06:02,416
The app uses PencilKit to


195
00:06:02,416 --> 00:06:04,126
capture the input and the


196
00:06:04,126 --> 00:06:05,736
pretrained Core ML model to


197
00:06:05,736 --> 00:06:07,746
recognize the grading samples.


198
00:06:08,856 --> 00:06:10,726
Now recently, I added a new


199
00:06:10,726 --> 00:06:12,686
feature that allows teachers


200
00:06:13,086 --> 00:06:14,556
give something special for the


201
00:06:14,556 --> 00:06:16,026
kids for encouragement.


202
00:06:17,216 --> 00:06:18,066
And that is stickers.


203
00:06:19,136 --> 00:06:21,026
Kids absolutely love collecting


204
00:06:21,026 --> 00:06:22,026
stickers on their homework.


205
00:06:22,436 --> 00:06:23,306
So we thought it might be a


206
00:06:23,306 --> 00:06:24,816
really nice enhancement to the


207
00:06:25,006 --> 00:06:26,736
app if they could allow-- if we


208
00:06:26,736 --> 00:06:27,566
could allow them to give


209
00:06:27,566 --> 00:06:27,936
stickers.


210
00:06:29,356 --> 00:06:31,056
So to give a sticker, I could


211
00:06:31,056 --> 00:06:32,596
tap on this plus button up here.


212
00:06:32,596 --> 00:06:35,396
Scroll through the list of


213
00:06:35,396 --> 00:06:38,236
stickers, maybe pick one, and


214
00:06:38,236 --> 00:06:40,466
drag it to the right location


215
00:06:40,466 --> 00:06:40,726
[inaudible].


216
00:06:40,726 --> 00:06:41,146
This works.


217
00:06:41,146 --> 00:06:46,396
But I think we can make the flow


218
00:06:46,396 --> 00:06:48,356
even better and absolutely


219
00:06:48,356 --> 00:06:49,576
magical for our users.


220
00:06:49,846 --> 00:06:52,266
Let's think about it a little


221
00:06:52,766 --> 00:06:52,866
bit.


222
00:06:53,776 --> 00:06:55,786
The user is only using an Apple


223
00:06:55,786 --> 00:06:57,156
Pencil for grading.


224
00:06:57,156 --> 00:06:59,296
How cool would it be if they


225
00:06:59,296 --> 00:07:00,646
could quickly sketch something


226
00:07:01,046 --> 00:07:03,246
anywhere on the entire screen


227
00:07:03,476 --> 00:07:04,936
and the app automatically pick


228
00:07:04,936 --> 00:07:06,316
the right sticker of the correct


229
00:07:06,316 --> 00:07:07,766
size and place it at the right


230
00:07:07,766 --> 00:07:09,876
location for them.


231
00:07:10,096 --> 00:07:11,656
Well, we can definitely do


232
00:07:11,656 --> 00:07:12,806
something like that with machine


233
00:07:12,806 --> 00:07:13,306
learning, right?


234
00:07:13,306 --> 00:07:15,036
So let's explore some options.


235
00:07:15,296 --> 00:07:16,686
Let me switch over to the


236
00:07:16,686 --> 00:07:16,956
slides.


237
00:07:17,666 --> 00:07:18,496
Well, some of you who have


238
00:07:18,496 --> 00:07:20,646
already worked on Core ML might


239
00:07:20,646 --> 00:07:21,826
be thinking, well, we could


240
00:07:21,826 --> 00:07:25,426
actually pre-train a model that


241
00:07:25,426 --> 00:07:27,286
can recognize stickers and ship


242
00:07:27,286 --> 00:07:29,316
it as part of the app.


243
00:07:29,406 --> 00:07:30,496
Well, we could do that but there


244
00:07:30,496 --> 00:07:31,476
are a few issues with this


245
00:07:31,476 --> 00:07:31,966
approach.


246
00:07:32,586 --> 00:07:34,836
For one, there are a lot of


247
00:07:34,836 --> 00:07:36,556
stickers out there and we might


248
00:07:36,556 --> 00:07:37,746
have to collect a lot of


249
00:07:37,746 --> 00:07:39,176
training data in order to


250
00:07:39,176 --> 00:07:41,966
pre-train these models, although


251
00:07:41,966 --> 00:07:43,326
a particular user might only be


252
00:07:43,326 --> 00:07:46,026
interested in a small subset of


253
00:07:46,756 --> 00:07:47,336
these stickers.


254
00:07:47,336 --> 00:07:50,436
Second, how does this pretrained


255
00:07:50,436 --> 00:07:52,196
model work if I plan to


256
00:07:52,196 --> 00:07:53,426
introduce a bunch of new


257
00:07:53,426 --> 00:07:55,826
stickers in the future?


258
00:07:56,006 --> 00:07:57,386
Well, I might have to re-train


259
00:07:57,386 --> 00:07:59,666
the model and ship it as an app


260
00:07:59,666 --> 00:08:01,716
update or maybe allow the app to


261
00:08:01,716 --> 00:08:02,986
download it.


262
00:08:04,136 --> 00:08:05,766
Lastly, and I think this is the


263
00:08:05,766 --> 00:08:07,706
most crucial point, how does


264
00:08:07,706 --> 00:08:08,956
this pretrained model work for


265
00:08:08,956 --> 00:08:09,786
different users?


266
00:08:12,316 --> 00:08:14,496
Different users have different


267
00:08:14,496 --> 00:08:15,326
ways of sketching.


268
00:08:16,376 --> 00:08:18,076
If I went out and I asked a


269
00:08:18,076 --> 00:08:19,516
hundred different people to


270
00:08:19,516 --> 00:08:20,896
quickly sketch this mind-blowing


271
00:08:20,896 --> 00:08:22,606
sticker, I'll get at least 50


272
00:08:22,606 --> 00:08:23,276
different answers.


273
00:08:24,006 --> 00:08:25,476
Now, it's truly mind-blowing how


274
00:08:25,476 --> 00:08:26,376
different people are.


275
00:08:26,906 --> 00:08:28,546
So what should the app do in


276
00:08:28,546 --> 00:08:29,626
this case?


277
00:08:30,616 --> 00:08:32,856
Should we-- Should the app train


278
00:08:32,856 --> 00:08:35,655
the users on how to sketch


279
00:08:35,655 --> 00:08:39,626
something, or should the users


280
00:08:39,626 --> 00:08:41,666
train the app, enhance the model


281
00:08:41,876 --> 00:08:43,816
how to recognize your sketches?


282
00:08:44,826 --> 00:08:46,516
Well, that's exactly what model


283
00:08:46,516 --> 00:08:49,556
personalization is all about.


284
00:08:49,756 --> 00:08:51,626
What I did was use model


285
00:08:51,626 --> 00:08:53,926
personalization to train-- to


286
00:08:53,926 --> 00:08:55,856
define a model using the data


287
00:08:55,856 --> 00:08:56,866
that I collected about the


288
00:08:56,866 --> 00:08:59,206
user-- from the user to suit


289
00:08:59,206 --> 00:08:59,816
their needs.


290
00:08:59,966 --> 00:09:01,246
Let me show how that translates


291
00:09:01,246 --> 00:09:02,536
to user experience.


292
00:09:08,516 --> 00:09:09,636
I'll switch back to the demo


293
00:09:09,636 --> 00:09:11,286
screen to continue my grading.


294
00:09:12,046 --> 00:09:13,336
So the third answer-- third


295
00:09:13,336 --> 00:09:14,666
question there is pretty tricky


296
00:09:14,666 --> 00:09:15,846
for kindergarten care, but I


297
00:09:15,846 --> 00:09:17,246
think Jane got it spot on.


298
00:09:17,396 --> 00:09:18,796
There are four triangles in that


299
00:09:18,796 --> 00:09:19,646
diagram.


300
00:09:20,016 --> 00:09:20,996
So, good job, Jane.


301
00:09:21,896 --> 00:09:23,856
Well, now I want to give her a


302
00:09:23,856 --> 00:09:25,476
sticker to recognize the


303
00:09:25,476 --> 00:09:26,716
attention to detail, but I want


304
00:09:26,716 --> 00:09:27,946
to do it by quickly sketching


305
00:09:27,946 --> 00:09:28,286
something.


306
00:09:28,886 --> 00:09:29,956
Let's try doing that.


307
00:09:30,466 --> 00:09:35,526
So the app seems to tell me that


308
00:09:35,526 --> 00:09:36,826
it could not recognize what I


309
00:09:36,826 --> 00:09:38,406
sketch, which is pretty fair


310
00:09:38,406 --> 00:09:39,396
because this is the first time


311
00:09:39,396 --> 00:09:40,176
I'm using this app.


312
00:09:40,616 --> 00:09:42,406
So let me try to add a sticker,


313
00:09:42,666 --> 00:09:43,946
but this time I'll say I want to


314
00:09:43,946 --> 00:09:45,966
create a shortcut, right.


315
00:09:45,966 --> 00:09:47,146
And I'll pick the same sticker


316
00:09:47,146 --> 00:09:48,836
that I used last time.


317
00:09:49,876 --> 00:09:52,446
So now the app is asking me to


318
00:09:52,446 --> 00:09:54,646
give an example of how I would


319
00:09:54,646 --> 00:09:55,896
sketch this particular sticker.


320
00:09:56,616 --> 00:09:57,876
It doesn't have to be perfect.


321
00:09:57,876 --> 00:09:59,466
It doesn't even have to resemble


322
00:09:59,466 --> 00:09:59,926
the sticker.


323
00:10:00,296 --> 00:10:02,566
It's just my own representation


324
00:10:02,916 --> 00:10:05,336
of how I would want to sketch


325
00:10:05,336 --> 00:10:05,976
that sticker, right?


326
00:10:06,286 --> 00:10:09,516
So I'll just use a single star


327
00:10:10,136 --> 00:10:13,576
to represent that particular


328
00:10:13,576 --> 00:10:13,996
sticker.


329
00:10:13,996 --> 00:10:16,926
The app asked me for a couple of


330
00:10:16,926 --> 00:10:18,226
more examples, which is pretty


331
00:10:18,226 --> 00:10:19,726
fair, and it just took a few


332
00:10:19,726 --> 00:10:21,726
seconds but now it looks like


333
00:10:21,726 --> 00:10:23,126
the app-- the shortcut has been


334
00:10:23,126 --> 00:10:23,916
registered.


335
00:10:24,586 --> 00:10:26,516
Now I see the sticker as well as


336
00:10:26,516 --> 00:10:28,186
examples I provided in the


337
00:10:28,186 --> 00:10:28,736
screen.


338
00:10:29,866 --> 00:10:31,356
Before I go back, let me add one


339
00:10:31,356 --> 00:10:33,416
more sticker to my library.


340
00:10:34,536 --> 00:10:35,806
So, there was this really nice


341
00:10:35,966 --> 00:10:37,616
high five sticker that I wanted


342
00:10:37,616 --> 00:10:39,026
to use, which is right here.


343
00:10:39,676 --> 00:10:42,236
I wonder what I should use as


344
00:10:42,236 --> 00:10:42,976
shortcut for this.


345
00:10:43,706 --> 00:10:45,186
I wanted-- I want something that


346
00:10:45,186 --> 00:10:46,596
is easy to remember, easy to


347
00:10:46,596 --> 00:10:47,076
sketch.


348
00:10:47,426 --> 00:10:49,236
How about the number 5, which


349
00:10:49,236 --> 00:10:52,406
kind of says high five?


350
00:10:53,276 --> 00:10:55,926
Great. So just two more examples


351
00:10:55,926 --> 00:10:56,576
and I'm done.


352
00:10:58,006 --> 00:11:00,006
Let's go back to the screen and


353
00:11:00,006 --> 00:11:01,166
try giving that sticker that


354
00:11:01,166 --> 00:11:02,456
Jane has been desperately


355
00:11:02,456 --> 00:11:03,156
waiting for.


356
00:11:04,626 --> 00:11:05,826
Isn't that cool?


357
00:11:06,516 --> 00:11:10,966
[ Applause ]


358
00:11:11,466 --> 00:11:12,986
I'm so glad I didn't have the go


359
00:11:12,986 --> 00:11:14,656
through the sticker picker and


360
00:11:14,656 --> 00:11:15,756
move the sticker around and all


361
00:11:15,756 --> 00:11:16,746
those mess.


362
00:11:17,736 --> 00:11:19,256
Great. For the next one-- yeah,


363
00:11:19,256 --> 00:11:20,166
that's right as well.


364
00:11:20,166 --> 00:11:21,526
So let me give another small


365
00:11:21,526 --> 00:11:22,416
star there.


366
00:11:23,176 --> 00:11:24,456
I'm super happy with the way the


367
00:11:24,456 --> 00:11:26,256
app behaves, so a big high five


368
00:11:26,256 --> 00:11:27,026
at the top.


369
00:11:27,446 --> 00:11:28,976
How about that?


370
00:11:29,516 --> 00:11:35,786
[ Applause ]


371
00:11:36,286 --> 00:11:38,166
So this was just an example.


372
00:11:38,166 --> 00:11:39,316
You guys can think about really


373
00:11:39,316 --> 00:11:41,566
amazing experiences that you can


374
00:11:41,566 --> 00:11:42,856
kind of solve using this new


375
00:11:42,856 --> 00:11:43,226
feature.


376
00:11:43,876 --> 00:11:45,516
So before I wrap up, let me


377
00:11:45,516 --> 00:11:46,696
quickly go with the things that


378
00:11:46,696 --> 00:11:47,856
I had to do in order to


379
00:11:47,856 --> 00:11:48,736
implement this feature.


380
00:11:49,856 --> 00:11:51,376
So the first thing I had to do


381
00:11:51,866 --> 00:11:54,416
was import an updatable Core ML


382
00:11:54,416 --> 00:11:56,366
model into my project.


383
00:11:57,096 --> 00:11:58,186
And this is how it looks in


384
00:11:58,186 --> 00:11:58,856
Xcode.


385
00:12:00,656 --> 00:12:01,626
Since I was trying to


386
00:12:01,626 --> 00:12:03,396
personalize the model by adding


387
00:12:03,396 --> 00:12:05,776
new stickers or classes, using


388
00:12:05,776 --> 00:12:07,046
the nearest neighbor classifier


389
00:12:07,046 --> 00:12:10,356
made a lot of sense, although


390
00:12:10,356 --> 00:12:12,176
that is a pretrained neural


391
00:12:12,176 --> 00:12:14,046
network feature extractor, that


392
00:12:14,046 --> 00:12:15,216
is filling in into the nearest


393
00:12:15,216 --> 00:12:16,676
neighbor classifier to help


394
00:12:16,676 --> 00:12:18,096
improve the prediction


395
00:12:18,096 --> 00:12:19,116
efficiency and robustness.


396
00:12:20,016 --> 00:12:21,696
But that's it, you don't have to


397
00:12:21,696 --> 00:12:23,306
worry about any of model details


398
00:12:23,666 --> 00:12:25,466
since Core ML abstracts the way


399
00:12:25,866 --> 00:12:27,026
all the model details from the


400
00:12:27,026 --> 00:12:27,946
API surface.


401
00:12:31,576 --> 00:12:32,906
You can use this model for


402
00:12:32,906 --> 00:12:33,276
prediction.


403
00:12:33,276 --> 00:12:34,586
There is no change there.


404
00:12:35,486 --> 00:12:36,606
In Xcode you will see the


405
00:12:36,606 --> 00:12:37,976
prediction inputs and outputs


406
00:12:37,976 --> 00:12:38,636
like before.


407
00:12:40,096 --> 00:12:42,276
But what's new this year is an


408
00:12:42,276 --> 00:12:43,066
update section.


409
00:12:44,366 --> 00:12:45,666
This describes the set of


410
00:12:45,666 --> 00:12:47,446
inputs, yeah, this model


411
00:12:47,446 --> 00:12:48,656
requires for personalization.


412
00:12:49,226 --> 00:12:50,646
And as expected, it requires a


413
00:12:50,646 --> 00:12:51,896
sticker which is a grayscale


414
00:12:51,896 --> 00:12:54,066
image, and a corresponding


415
00:12:54,066 --> 00:12:55,086
sketch which is a grayscale


416
00:12:55,086 --> 00:12:56,496
image, and a corresponding


417
00:12:56,496 --> 00:12:57,856
sticker which serves as a true


418
00:12:57,856 --> 00:12:59,346
label in order to personalize.


419
00:13:00,326 --> 00:13:02,206
In terms of code, you may recall


420
00:13:02,206 --> 00:13:04,326
that Core ML auto-generates a


421
00:13:04,326 --> 00:13:06,196
set of classes to help you with


422
00:13:06,196 --> 00:13:06,786
the prediction.


423
00:13:07,296 --> 00:13:09,086
And now it generates new class


424
00:13:09,596 --> 00:13:10,716
that helps you provide the


425
00:13:10,716 --> 00:13:11,896
training data in a [inaudible]


426
00:13:11,896 --> 00:13:12,246
manner.


427
00:13:13,336 --> 00:13:14,606
If you peek into this class,


428
00:13:14,986 --> 00:13:16,466
you'll see a set of properties


429
00:13:16,676 --> 00:13:17,906
which are in line with what you


430
00:13:17,906 --> 00:13:19,156
saw in Xcode, right?


431
00:13:19,156 --> 00:13:21,646
So we see the sketch and the


432
00:13:21,646 --> 00:13:22,596
sticker here.


433
00:13:24,556 --> 00:13:26,986
So once you have collected all


434
00:13:26,986 --> 00:13:29,056
the training data from the user


435
00:13:29,556 --> 00:13:31,596
that is required to personalize


436
00:13:31,596 --> 00:13:34,016
a model for-- or for the user,


437
00:13:34,746 --> 00:13:36,076
the actual personalization


438
00:13:36,076 --> 00:13:37,746
itself can happen in three easy


439
00:13:37,746 --> 00:13:38,106
steps.


440
00:13:38,106 --> 00:13:40,206
First, you need to get the


441
00:13:40,206 --> 00:13:43,356
updatable model URL that you


442
00:13:43,356 --> 00:13:44,886
could get either from the bundle


443
00:13:45,136 --> 00:13:46,526
or from a previous snapshot of


444
00:13:46,526 --> 00:13:47,576
the updated model.


445
00:13:47,876 --> 00:13:50,616
Next, you would prepare the


446
00:13:50,616 --> 00:13:52,056
training data in the expected


447
00:13:52,056 --> 00:13:52,556
format.


448
00:13:53,176 --> 00:13:55,236
For this, you could either use


449
00:13:55,666 --> 00:13:57,786
the origin rated class that I


450
00:13:57,786 --> 00:13:59,336
showed or build a feature


451
00:13:59,336 --> 00:14:00,416
provider of your own.


452
00:14:01,616 --> 00:14:03,766
And lastly, you would kick off


453
00:14:03,766 --> 00:14:04,596
an update task.


454
00:14:05,176 --> 00:14:07,736
Once the update is complete,


455
00:14:08,146 --> 00:14:09,686
completion handler gets invoked


456
00:14:10,176 --> 00:14:11,636
which provides you the updated


457
00:14:11,636 --> 00:14:13,666
model that you can use for


458
00:14:13,666 --> 00:14:14,766
predictions immediately.


459
00:14:15,236 --> 00:14:16,026
It's that simple.


460
00:14:16,026 --> 00:14:18,246
I can't wait to see all the cool


461
00:14:18,246 --> 00:14:19,446
things that you will build on


462
00:14:19,446 --> 00:14:21,006
top of this in your apps and


463
00:14:21,006 --> 00:14:21,576
frameworks.


464
00:14:21,916 --> 00:14:23,016
With that, let me hand it back


465
00:14:23,046 --> 00:14:24,756
to Michael to recap and cover


466
00:14:24,756 --> 00:14:26,036
some more complex scenarios and


467
00:14:26,036 --> 00:14:26,976
model personalization.


468
00:14:27,236 --> 00:14:27,586
Thank you.


469
00:14:28,516 --> 00:14:32,500
[ Applause ]


470
00:14:36,526 --> 00:14:37,506
>> All right.


471
00:14:37,586 --> 00:14:38,156
Thanks, Anil.


472
00:14:41,436 --> 00:14:43,476
So just a recap, Anil just


473
00:14:43,476 --> 00:14:44,396
showed us, we took our base


474
00:14:44,396 --> 00:14:46,886
model and we tried to make a


475
00:14:46,886 --> 00:14:48,066
personal experience out of that


476
00:14:48,676 --> 00:14:50,306
by supplying some drawings which


477
00:14:50,396 --> 00:14:52,706
were just beautiful to our model


478
00:14:52,706 --> 00:14:53,566
and seeing what we got as an


479
00:14:53,566 --> 00:14:53,936
output.


480
00:14:54,946 --> 00:14:56,936
Initially, we didn't get much.


481
00:14:58,016 --> 00:14:59,546
That's because internally, even


482
00:14:59,546 --> 00:15:00,446
though we have that pretrained


483
00:15:00,446 --> 00:15:02,216
neural network, it feeds into a


484
00:15:02,216 --> 00:15:02,996
K-nearest neighbor base


485
00:15:02,996 --> 00:15:04,816
classifier which is actually


486
00:15:04,816 --> 00:15:05,146
empty.


487
00:15:05,146 --> 00:15:06,476
It has no neighbors to classify


488
00:15:06,476 --> 00:15:06,596
on.


489
00:15:10,046 --> 00:15:11,156
So we actually update this and


490
00:15:11,156 --> 00:15:11,936
give us some neighbors.


491
00:15:11,936 --> 00:15:13,896
Well, as Anil showed us, we took


492
00:15:13,896 --> 00:15:15,516
our training data, the stickers


493
00:15:15,516 --> 00:15:16,656
we chose and the drawings we


494
00:15:16,656 --> 00:15:17,916
drew to correspond with that,


495
00:15:17,916 --> 00:15:19,896
and we feed those along with our


496
00:15:19,896 --> 00:15:22,186
base model, with that updatable


497
00:15:22,186 --> 00:15:23,256
K-nearest neighbor base model in


498
00:15:23,256 --> 00:15:24,696
it to our update task.


499
00:15:25,966 --> 00:15:27,056
And this gives us that new


500
00:15:27,056 --> 00:15:27,916
variant of our model.


501
00:15:31,046 --> 00:15:32,216
And this new variant can more


502
00:15:32,216 --> 00:15:34,136
reliably recognize what it was


503
00:15:34,136 --> 00:15:36,866
trained on while internally the


504
00:15:36,866 --> 00:15:38,196
only thing that's changed was


505
00:15:38,196 --> 00:15:39,426
that updatable K-nearest


506
00:15:39,426 --> 00:15:43,896
neighbor base model.


507
00:15:44,056 --> 00:15:45,106
So let's look at the ML update


508
00:15:45,106 --> 00:15:45,976
task class, which we've


509
00:15:45,976 --> 00:15:47,576
introduced this year to help


510
00:15:47,576 --> 00:15:48,536
with managing these update


511
00:15:48,566 --> 00:15:49,146
processes.


512
00:15:50,606 --> 00:15:52,066
So it has a state associated


513
00:15:52,066 --> 00:15:53,006
with it where it's at in the


514
00:15:53,006 --> 00:15:54,326
process as well as the ability


515
00:15:54,326 --> 00:15:56,066
to resume and cancel that task.


516
00:15:56,596 --> 00:15:58,566
And to construct one you just


517
00:15:58,566 --> 00:16:00,756
pass in that base URL for your


518
00:16:00,756 --> 00:16:03,246
model along with configuration


519
00:16:03,416 --> 00:16:05,076
and the training data.


520
00:16:05,656 --> 00:16:07,086
And as Anil showed, you need to


521
00:16:07,086 --> 00:16:08,336
pass in a completion handler as


522
00:16:08,336 --> 00:16:08,556
well.


523
00:16:09,526 --> 00:16:11,096
As completion handler, we'll


524
00:16:11,096 --> 00:16:11,926
call when you're done with the


525
00:16:11,926 --> 00:16:13,106
update task and it gives you an


526
00:16:13,106 --> 00:16:14,046
update context.


527
00:16:14,736 --> 00:16:16,376
And you can use this to write


528
00:16:16,376 --> 00:16:17,426
out that model when you're done


529
00:16:17,426 --> 00:16:19,076
with your update, to make


530
00:16:19,076 --> 00:16:20,746
predictions on it, and query


531
00:16:20,746 --> 00:16:22,006
other parts of that task which


532
00:16:22,006 --> 00:16:23,206
allows us to get part of this


533
00:16:24,126 --> 00:16:26,436
update context.


534
00:16:26,436 --> 00:16:27,616
In code, as Anil showed us,


535
00:16:27,886 --> 00:16:28,696
really straightforward to


536
00:16:28,696 --> 00:16:29,046
implement.


537
00:16:29,746 --> 00:16:31,036
You just construct an


538
00:16:31,036 --> 00:16:33,586
MLupdateTask provided that URL,


539
00:16:33,636 --> 00:16:35,106
your configuration, and your


540
00:16:35,106 --> 00:16:36,636
completion handler, which here


541
00:16:36,636 --> 00:16:38,166
we use to check for accuracy,


542
00:16:38,766 --> 00:16:40,056
retain the model outside the


543
00:16:40,056 --> 00:16:42,266
scope of this block and save out


544
00:16:42,266 --> 00:16:42,606
that model.


545
00:16:43,286 --> 00:16:43,776
This is great.


546
00:16:44,056 --> 00:16:45,556
It works really well and it got


547
00:16:45,556 --> 00:16:46,216
us through this demo.


548
00:16:46,766 --> 00:16:49,096
But what about the more complex


549
00:16:49,096 --> 00:16:49,916
use cases, right?


550
00:16:49,916 --> 00:16:51,146
What about neural networks?


551
00:16:51,686 --> 00:16:53,756
Well, a neural network in its


552
00:16:53,756 --> 00:16:55,066
simplest case is just a


553
00:16:55,066 --> 00:16:57,046
collection of layers, each with


554
00:16:57,096 --> 00:16:58,426
some inputs and some weights


555
00:16:58,776 --> 00:17:00,146
that it uses in combination to


556
00:17:00,146 --> 00:17:02,376
create an output.


557
00:17:02,556 --> 00:17:03,766
To adjust that output, we'll


558
00:17:03,766 --> 00:17:04,836
need to adjust the weights in


559
00:17:04,836 --> 00:17:05,536
those layers.


560
00:17:05,786 --> 00:17:07,036
And to do that, we need to mark


561
00:17:07,036 --> 00:17:08,215
these layers as updatable.


562
00:17:08,726 --> 00:17:11,556
And we need some way of telling


563
00:17:11,556 --> 00:17:12,886
it by how much our output was


564
00:17:12,886 --> 00:17:13,215
off.


565
00:17:13,715 --> 00:17:15,415
If we expected a star smiley


566
00:17:15,415 --> 00:17:17,146
face and we got a high five, we


567
00:17:17,146 --> 00:17:17,915
need to correct for that.


568
00:17:17,915 --> 00:17:18,945
And that's going to be done to


569
00:17:18,945 --> 00:17:20,366
our loss functions, which


570
00:17:20,366 --> 00:17:21,586
describes that delta there.


571
00:17:22,796 --> 00:17:23,816
And finally we need to provide


572
00:17:23,816 --> 00:17:25,026
this to our optimizer.


573
00:17:25,026 --> 00:17:26,536
And this takes that loss, our


574
00:17:26,536 --> 00:17:27,876
output, and it figures out by


575
00:17:27,876 --> 00:17:29,146
how much to actually adjust the


576
00:17:29,146 --> 00:17:30,086
weights in these layers.


577
00:17:30,616 --> 00:17:35,316
On Core ML 3, we support


578
00:17:35,316 --> 00:17:37,406
updating of convolution and


579
00:17:37,406 --> 00:17:38,956
fully collect-- fully connected


580
00:17:38,956 --> 00:17:40,906
layers as well as having the


581
00:17:40,906 --> 00:17:42,016
ability to back-propagate


582
00:17:42,016 --> 00:17:42,606
through many more.


583
00:17:43,166 --> 00:17:44,426
And we support categorical


584
00:17:44,426 --> 00:17:46,256
cross-entropy and mean squared


585
00:17:46,256 --> 00:17:46,986
error loss types.


586
00:17:48,036 --> 00:17:49,436
In addition, we support


587
00:17:49,436 --> 00:17:51,166
stochastic gradient descent and


588
00:17:51,166 --> 00:17:52,646
Adam optimization strategies.


589
00:17:53,166 --> 00:17:56,076
This is awesome, right?


590
00:17:56,516 --> 00:17:58,316
But there's other parameters


591
00:17:58,316 --> 00:17:59,536
associated with neural networks,


592
00:17:59,946 --> 00:18:00,766
like learning rate and the


593
00:18:00,766 --> 00:18:01,936
number of epoch to run for.


594
00:18:02,816 --> 00:18:03,556
This is all are going to be


595
00:18:03,556 --> 00:18:05,036
encapsulated within that model.


596
00:18:06,436 --> 00:18:07,796
We understand that some of you


597
00:18:07,796 --> 00:18:08,676
may want to change that at


598
00:18:08,676 --> 00:18:09,746
runtime though.


599
00:18:10,536 --> 00:18:12,126
And you can do that.


600
00:18:12,206 --> 00:18:13,286
By overriding the update


601
00:18:13,316 --> 00:18:14,866
parameters dictionary and your


602
00:18:14,866 --> 00:18:16,476
model configuration, you can


603
00:18:16,476 --> 00:18:17,736
override those values within,


604
00:18:18,606 --> 00:18:20,096
using MLParameterKey and just


605
00:18:20,096 --> 00:18:21,216
specifying values for them,


606
00:18:21,746 --> 00:18:23,406
giving you a lot of flexibility


607
00:18:24,006 --> 00:18:24,096
here.


608
00:18:26,216 --> 00:18:27,936
In addition, if you're wondering


609
00:18:27,936 --> 00:18:28,956
what parameters are actually


610
00:18:28,956 --> 00:18:30,436
embedded within my model anyway,


611
00:18:31,026 --> 00:18:32,136
you can check out the parameter


612
00:18:32,136 --> 00:18:33,716
section of that model view in


613
00:18:33,766 --> 00:18:35,106
Xcode and it will give you


614
00:18:35,106 --> 00:18:36,606
details for the values of those


615
00:18:36,636 --> 00:18:37,826
parameters as well as what


616
00:18:37,826 --> 00:18:39,056
parameters are actually defined


617
00:18:39,056 --> 00:18:39,646
within that model.


618
00:18:43,676 --> 00:18:45,766
You may want more flexibility


619
00:18:45,766 --> 00:18:47,136
than the API we showed earlier


620
00:18:47,776 --> 00:18:48,576
and we provide that.


621
00:18:49,666 --> 00:18:50,986
In your MLUpdateTask, you can


622
00:18:50,986 --> 00:18:51,486
provide an


623
00:18:51,486 --> 00:18:53,896
MLupdateProgressHandler instead


624
00:18:53,896 --> 00:18:55,566
of the completion handler and


625
00:18:55,566 --> 00:18:56,756
supply progress handlers and


626
00:18:56,756 --> 00:18:58,356
that completion handler that


627
00:18:58,356 --> 00:18:59,246
will allow you to key in


628
00:18:59,246 --> 00:19:00,096
specific events.


629
00:19:00,176 --> 00:19:01,626
So when your training began or


630
00:19:01,626 --> 00:19:03,896
when an epoch ended, we'll call


631
00:19:03,896 --> 00:19:06,066
your progress handler and we'll


632
00:19:06,066 --> 00:19:07,316
provide you that update context


633
00:19:07,316 --> 00:19:08,536
just as we did in the completion


634
00:19:09,006 --> 00:19:09,236
handler.


635
00:19:10,696 --> 00:19:12,526
In addition, we'll tell you what


636
00:19:12,526 --> 00:19:13,976
event caused us to call that


637
00:19:13,976 --> 00:19:16,176
callback as well as giving you


638
00:19:16,176 --> 00:19:17,416
key metrics, so you can query


639
00:19:17,416 --> 00:19:19,126
for your training loss as each


640
00:19:19,126 --> 00:19:20,446
mini batch or each epoch gets


641
00:19:20,476 --> 00:19:20,936
processed.


642
00:19:21,416 --> 00:19:24,546
And in code, still really


643
00:19:24,546 --> 00:19:25,186
straightforward.


644
00:19:25,536 --> 00:19:26,186
You construct this


645
00:19:26,246 --> 00:19:28,126
MLupdateProgressHandler, tell it


646
00:19:28,126 --> 00:19:29,046
what events you're interested


647
00:19:29,046 --> 00:19:30,596
in, and supply a block to be


648
00:19:30,596 --> 00:19:30,926
called.


649
00:19:31,476 --> 00:19:33,666
In addition, you'll just provide


650
00:19:33,666 --> 00:19:34,656
the completion handler there as


651
00:19:34,656 --> 00:19:37,246
well and the MLUpdateTask you


652
00:19:37,246 --> 00:19:38,696
just provide the set of progress


653
00:19:38,696 --> 00:19:39,086
handlers.


654
00:19:43,276 --> 00:19:44,456
So we've talked about how to


655
00:19:44,456 --> 00:19:45,696
update your models and what it


656
00:19:45,696 --> 00:19:46,556
means to update them.


657
00:19:46,926 --> 00:19:47,746
Well, we haven't really


658
00:19:47,746 --> 00:19:49,446
discussed yet so far is when


659
00:19:49,446 --> 00:19:50,356
it's appropriate to do that.


660
00:19:51,506 --> 00:19:52,446
Now, on the grading app we


661
00:19:52,446 --> 00:19:53,666
showed earlier, we're doing it


662
00:19:54,156 --> 00:19:55,246
the second he interacted with


663
00:19:55,286 --> 00:19:56,756
the app and drew a drawing.


664
00:19:57,126 --> 00:19:58,686
And we took that data and sent


665
00:19:58,686 --> 00:19:59,266
it off to the model.


666
00:19:59,266 --> 00:20:00,976
But that may not be appropriate.


667
00:20:01,116 --> 00:20:02,886
What if you have thousands or


668
00:20:02,886 --> 00:20:03,936
millions of data points?


669
00:20:04,946 --> 00:20:05,826
And what if your model's


670
00:20:05,826 --> 00:20:06,896
incredibly complicated?


671
00:20:07,966 --> 00:20:09,406
Well, I'm thrilled to say that


672
00:20:09,406 --> 00:20:10,596
using the BackgroundTask


673
00:20:10,596 --> 00:20:12,876
framework will allot several


674
00:20:12,876 --> 00:20:13,956
minutes of runtime to your


675
00:20:13,956 --> 00:20:14,566
application.


676
00:20:15,076 --> 00:20:16,336
Even if the user isn't using


677
00:20:16,336 --> 00:20:17,566
your app or even if they're not


678
00:20:17,596 --> 00:20:19,636
interacting with the device, you


679
00:20:19,636 --> 00:20:21,666
just use the BGTaskScheduler and


680
00:20:21,666 --> 00:20:23,566
make a BGProcessingTaskRequest


681
00:20:24,046 --> 00:20:24,726
and we'll give you several


682
00:20:24,726 --> 00:20:26,216
minutes to do further updates


683
00:20:26,586 --> 00:20:27,696
and further computations.


684
00:20:29,016 --> 00:20:29,916
And to see more about this--


685
00:20:29,916 --> 00:20:29,983
Yeah


686
00:20:30,516 --> 00:20:33,506
[ Applause ]


687
00:20:34,006 --> 00:20:34,726
It's great.


688
00:20:34,796 --> 00:20:35,846
And to see more about this, I


689
00:20:35,846 --> 00:20:37,746
highly recommend you check out


690
00:20:37,746 --> 00:20:39,046
Advances in App Background


691
00:20:39,046 --> 00:20:39,636
Execution.


692
00:20:42,976 --> 00:20:44,276
In addition, how do you get an


693
00:20:44,276 --> 00:20:44,956
updatable model?


694
00:20:44,956 --> 00:20:46,246
Well, as we talked about earlier


695
00:20:46,246 --> 00:20:47,766
in the session, you can get a


696
00:20:47,766 --> 00:20:49,156
model by converting them from a


697
00:20:49,156 --> 00:20:50,296
number of supported training


698
00:20:50,296 --> 00:20:52,216
libraries, that story has not


699
00:20:52,216 --> 00:20:52,586
changed.


700
00:20:53,986 --> 00:20:55,186
You simply pass the respect


701
00:20:55,186 --> 00:20:56,886
trainable flag in when you're


702
00:20:56,886 --> 00:20:58,616
converting your model and it'll


703
00:20:58,616 --> 00:20:59,986
take those trainable parameters


704
00:20:59,986 --> 00:21:00,636
- the things like what


705
00:21:00,636 --> 00:21:01,936
optimization strategy you want,


706
00:21:02,376 --> 00:21:04,136
what layers are updatable -- and


707
00:21:04,136 --> 00:21:05,366
we'll take that and embed that


708
00:21:05,366 --> 00:21:06,096
within your model.


709
00:21:06,516 --> 00:21:07,336
And then the rest of it, it's


710
00:21:07,336 --> 00:21:08,256
just as what it was before.


711
00:21:08,786 --> 00:21:11,036
And for those of you who want to


712
00:21:11,036 --> 00:21:12,226
modify the model itself


713
00:21:12,226 --> 00:21:13,886
directly, that's still fully


714
00:21:13,886 --> 00:21:17,646
supported as well.


715
00:21:18,056 --> 00:21:19,056
So we've talked about how to


716
00:21:19,056 --> 00:21:20,496
make a more personal experience


717
00:21:20,496 --> 00:21:22,386
for a user in your application,


718
00:21:22,766 --> 00:21:24,066
using on-device model


719
00:21:24,066 --> 00:21:26,376
personalization, and you can do


720
00:21:26,376 --> 00:21:27,366
that through our new flexible


721
00:21:27,366 --> 00:21:28,026
yet simple API.


722
00:21:29,276 --> 00:21:29,716
It's great.


723
00:21:30,046 --> 00:21:30,966
You can do this completely


724
00:21:30,966 --> 00:21:31,546
on-device.


725
00:21:32,206 --> 00:21:34,346
And with that, I'd like to hand


726
00:21:34,346 --> 00:21:35,796
it over to my colleague Aseem


727
00:21:35,796 --> 00:21:36,906
Wadhwa to tell you more about


728
00:21:36,906 --> 00:21:37,906
some of the amazing new features


729
00:21:37,906 --> 00:21:39,226
we've added this year for neural


730
00:21:39,516 --> 00:21:39,976
networks.


731
00:21:40,516 --> 00:21:47,376
[ Applause ]


732
00:21:47,876 --> 00:21:49,566
>> OK. So I'm very excited to


733
00:21:49,566 --> 00:21:52,256
talk about what's new in Core ML


734
00:21:52,256 --> 00:21:53,906
this year for neural networks.


735
00:21:54,676 --> 00:21:57,126
But before we jump into that, I


736
00:21:57,126 --> 00:21:58,946
do want to spend a few minutes


737
00:21:58,976 --> 00:22:01,016
talking about neural networks in


738
00:22:02,096 --> 00:22:02,346
general.


739
00:22:02,866 --> 00:22:04,686
Well, we all know that neural


740
00:22:04,686 --> 00:22:06,816
networks are great at solving


741
00:22:06,816 --> 00:22:08,906
challenging task, such as


742
00:22:08,906 --> 00:22:10,176
understanding the content of an


743
00:22:10,176 --> 00:22:12,786
image or a document or an audio


744
00:22:12,786 --> 00:22:13,096
clip.


745
00:22:14,516 --> 00:22:17,006
And we can use this capability


746
00:22:17,006 --> 00:22:18,436
to build some amazing apps


747
00:22:18,436 --> 00:22:20,806
around them.


748
00:22:21,836 --> 00:22:23,726
Now, if you look inside a neural


749
00:22:23,726 --> 00:22:25,416
network and try to see its


750
00:22:25,416 --> 00:22:27,646
structure, we can maybe get a


751
00:22:27,646 --> 00:22:28,926
better understanding about it.


752
00:22:29,746 --> 00:22:31,666
So let's try to do that.


753
00:22:31,826 --> 00:22:33,176
But instead of looking from a


754
00:22:33,176 --> 00:22:35,066
point of view of a researcher,


755
00:22:35,416 --> 00:22:36,396
let's try a different


756
00:22:36,396 --> 00:22:36,866
perspective.


757
00:22:37,286 --> 00:22:39,276
Let's try to look at it from a


758
00:22:39,636 --> 00:22:40,716
programmer's perspective.


759
00:22:41,316 --> 00:22:43,576
So if you visualize inside a


760
00:22:43,576 --> 00:22:45,966
Core ML model, what we see is


761
00:22:45,966 --> 00:22:47,466
something like a graph.


762
00:22:47,856 --> 00:22:50,056
And if you look closely, we


763
00:22:50,056 --> 00:22:52,286
realize that graph is just


764
00:22:52,286 --> 00:22:54,116
another representation of a


765
00:22:54,116 --> 00:22:54,526
program.


766
00:22:55,386 --> 00:22:57,766
Let's look at it again.


767
00:22:58,446 --> 00:23:00,406
So here is a very simple code


768
00:23:00,406 --> 00:23:02,056
snippet that we all understand.


769
00:23:02,766 --> 00:23:04,456
And here is its corresponding


770
00:23:04,596 --> 00:23:05,536
graph representation.


771
00:23:06,016 --> 00:23:07,806
So as you might have noticed


772
00:23:07,806 --> 00:23:09,356
that the operations in the code


773
00:23:09,736 --> 00:23:11,386
have become these notes in the


774
00:23:11,386 --> 00:23:13,846
graph and the readable such as


775
00:23:13,846 --> 00:23:16,786
X, Y, Z, are these edges in the


776
00:23:16,786 --> 00:23:17,196
graph.


777
00:23:18,026 --> 00:23:19,416
Now, if you go back to a neural


778
00:23:19,416 --> 00:23:22,236
network graph and now show a


779
00:23:22,236 --> 00:23:24,216
corresponding code snippet, it


780
00:23:24,216 --> 00:23:25,616
looks pretty similar to what we


781
00:23:25,616 --> 00:23:26,166
had before.


782
00:23:26,586 --> 00:23:27,856
But there are a couple of


783
00:23:27,886 --> 00:23:32,286
differences I want to point out.


784
00:23:32,326 --> 00:23:35,206
One, instead of those simple


785
00:23:35,396 --> 00:23:37,156
numeric variables, we now have


786
00:23:37,186 --> 00:23:39,236
these multidimensional variables


787
00:23:39,646 --> 00:23:41,096
that have couple of attributes.


788
00:23:41,166 --> 00:23:43,226
So it has an attribute called


789
00:23:43,226 --> 00:23:46,276
shape and something called rank,


790
00:23:46,436 --> 00:23:47,596
which is a number of dimensions


791
00:23:47,596 --> 00:23:48,056
that it has.


792
00:23:48,476 --> 00:23:50,526
And the second thing is the


793
00:23:50,526 --> 00:23:52,246
functions operating on these


794
00:23:52,246 --> 00:23:53,866
multidimensional variables are


795
00:23:53,866 --> 00:23:55,626
now these specialized math


796
00:23:55,626 --> 00:23:57,276
functions, which is sometimes


797
00:23:57,336 --> 00:23:59,236
called as layers or operations.


798
00:24:00,546 --> 00:24:06,646
So if you really look at the


799
00:24:07,406 --> 00:24:09,056
neural network, we see that it's


800
00:24:09,056 --> 00:24:12,206
essentially either a graph or a


801
00:24:12,206 --> 00:24:15,506
program that involves these very


802
00:24:15,506 --> 00:24:17,426
large multidimensional variables


803
00:24:17,746 --> 00:24:19,226
and these very heavy


804
00:24:19,366 --> 00:24:20,336
mathematical functions.


805
00:24:20,656 --> 00:24:21,806
So essentially it's a very


806
00:24:21,806 --> 00:24:23,646
compute and memory intensive


807
00:24:24,006 --> 00:24:24,986
program.


808
00:24:24,986 --> 00:24:27,276
And the nice thing about Core ML


809
00:24:27,276 --> 00:24:30,306
is that it encapsulates all


810
00:24:30,306 --> 00:24:32,236
these complexity into a single


811
00:24:32,236 --> 00:24:34,526
file format, which the Core ML


812
00:24:34,526 --> 00:24:35,796
framework and then sort of


813
00:24:35,796 --> 00:24:37,626
optimize and execute very


814
00:24:37,626 --> 00:24:38,246
efficiently.


815
00:24:39,516 --> 00:24:41,906
So if we go back last year and


816
00:24:41,906 --> 00:24:43,286
see what we had in Core ML 2,


817
00:24:43,286 --> 00:24:45,766
well, we could easily represent


818
00:24:45,956 --> 00:24:47,856
straight-line code using acyclic


819
00:24:47,856 --> 00:24:48,246
graphs.


820
00:24:48,846 --> 00:24:50,976
And we had about 40 different


821
00:24:50,976 --> 00:24:52,526
layer types using which we could


822
00:24:52,526 --> 00:24:54,246
represent most of the common


823
00:24:54,396 --> 00:24:56,436
convolutional and recurrent


824
00:24:56,816 --> 00:24:57,726
architectures.


825
00:24:58,496 --> 00:24:59,666
So what's new this year?


826
00:25:00,356 --> 00:25:02,086
Well, as you might have noticed


827
00:25:02,506 --> 00:25:05,806
with my analogy to program, we


828
00:25:05,806 --> 00:25:07,376
all know that code can be much


829
00:25:07,376 --> 00:25:08,516
more complex than simple


830
00:25:08,516 --> 00:25:09,546
straight-line code, right?


831
00:25:09,886 --> 00:25:12,556
For instance, it's quite common


832
00:25:12,556 --> 00:25:14,996
to use a control flow like a


833
00:25:14,996 --> 00:25:16,946
branch as shown in the code


834
00:25:16,976 --> 00:25:17,636
snippet here.


835
00:25:18,106 --> 00:25:19,966
And now, in Core ML 3, what's


836
00:25:19,966 --> 00:25:21,356
new is that we can represent the


837
00:25:21,446 --> 00:25:23,466
same concept of a branch within


838
00:25:23,466 --> 00:25:24,006
the neural network


839
00:25:24,006 --> 00:25:24,696
specification.


840
00:25:25,516 --> 00:25:30,346
[ Applause ]


841
00:25:30,846 --> 00:25:32,546
So another common form of


842
00:25:32,576 --> 00:25:34,566
control flow is obviously loops,


843
00:25:34,856 --> 00:25:36,356
and that too can be really


844
00:25:36,356 --> 00:25:38,496
easily expressed within a Core


845
00:25:38,496 --> 00:25:39,366
ML network.


846
00:25:40,116 --> 00:25:42,046
Moving on to another complex


847
00:25:42,046 --> 00:25:44,586
feature of code, something we do


848
00:25:44,586 --> 00:25:45,806
often when we're writing a


849
00:25:45,806 --> 00:25:49,026
dynamic code is allocate memory


850
00:25:49,026 --> 00:25:49,646
at runtime.


851
00:25:50,056 --> 00:25:51,356
As shown in this code snippet,


852
00:25:51,356 --> 00:25:52,836
we are allocating a memory that


853
00:25:52,836 --> 00:25:54,466
depends on the input of the


854
00:25:54,466 --> 00:25:56,026
program so it can change at


855
00:25:56,026 --> 00:25:56,406
runtime.


856
00:25:56,856 --> 00:25:58,406
Now we can do exactly the same


857
00:25:58,406 --> 00:26:00,696
in Core ML this year using what


858
00:26:00,696 --> 00:26:03,796
we call dynamic layers, which


859
00:26:03,796 --> 00:26:05,686
allows us to change the shape of


860
00:26:05,686 --> 00:26:07,116
the multi array based on the


861
00:26:07,116 --> 00:26:08,296
input of the graph.


862
00:26:08,296 --> 00:26:09,486
So you might be thinking that


863
00:26:09,486 --> 00:26:11,476
why are we adding sort of these


864
00:26:11,476 --> 00:26:14,446
new complex code constructs


865
00:26:14,446 --> 00:26:15,896
within the Core ML graph, and


866
00:26:15,896 --> 00:26:17,336
the answer is simple, because


867
00:26:17,476 --> 00:26:18,976
neural networks research is


868
00:26:18,976 --> 00:26:20,986
actively exploring these ideas


869
00:26:21,266 --> 00:26:22,916
to make even more powerful


870
00:26:22,916 --> 00:26:24,006
neural networks.


871
00:26:24,006 --> 00:26:25,546
In fact, many state of the art


872
00:26:25,546 --> 00:26:28,286
neural networks sort of-- have


873
00:26:28,286 --> 00:26:30,036
some sort of control flow built


874
00:26:30,036 --> 00:26:31,346
into them.


875
00:26:31,656 --> 00:26:33,136
Another aspect that researchers


876
00:26:33,486 --> 00:26:36,376
are constantly exploring is sort


877
00:26:36,376 --> 00:26:38,076
of new operations.


878
00:26:38,436 --> 00:26:41,186
And for that, we have added lots


879
00:26:41,186 --> 00:26:43,076
of new layers to Core ML this


880
00:26:43,136 --> 00:26:43,356
year.


881
00:26:43,986 --> 00:26:45,736
Not only have we made the


882
00:26:45,736 --> 00:26:47,606
existing layers more generic but


883
00:26:47,606 --> 00:26:49,756
we have added lots of new basic


884
00:26:49,756 --> 00:26:50,876
mathematical operations.


885
00:26:51,336 --> 00:26:53,186
So, if you come across a new


886
00:26:53,186 --> 00:26:55,046
layer, it's highly likely that


887
00:26:55,046 --> 00:26:56,556
it can be expressed in terms of


888
00:26:56,556 --> 00:26:58,416
the layers that are there in


889
00:26:58,416 --> 00:26:58,976
Core ML 3.


890
00:26:59,516 --> 00:27:06,186
[ Applause ]


891
00:27:06,686 --> 00:27:08,646
So with all these features of


892
00:27:08,646 --> 00:27:11,076
control flow, dynamic behavior,


893
00:27:11,076 --> 00:27:13,306
and new layers, the Core ML


894
00:27:13,306 --> 00:27:14,826
model has become much more


895
00:27:14,826 --> 00:27:16,006
expressive than before.


896
00:27:16,586 --> 00:27:18,406
And the great part of it is that


897
00:27:18,776 --> 00:27:20,466
most of the popular


898
00:27:20,466 --> 00:27:21,816
architectures out there can now


899
00:27:21,816 --> 00:27:23,686
be easily expressed in the Core


900
00:27:23,686 --> 00:27:24,176
ML format.


901
00:27:24,766 --> 00:27:26,006
So as you can see on this slide,


902
00:27:26,006 --> 00:27:27,736
we have listed a few of those.


903
00:27:28,066 --> 00:27:29,956
And the ones highlighted have


904
00:27:29,956 --> 00:27:31,996
really come in the last few


905
00:27:31,996 --> 00:27:33,016
months and they're really


906
00:27:33,016 --> 00:27:33,956
pushing the boundaries of


907
00:27:33,956 --> 00:27:34,996
machine learning research.


908
00:27:35,296 --> 00:27:36,976
And now you can easily express


909
00:27:37,026 --> 00:27:39,176
them in Core ML and integrate


910
00:27:39,176 --> 00:27:40,636
them in your apps.


911
00:27:40,756 --> 00:27:41,356
So that's great.


912
00:27:42,516 --> 00:27:47,476
[ Applause ]


913
00:27:47,976 --> 00:27:49,156
So now you might be wondering


914
00:27:49,156 --> 00:27:50,836
that how do I make use of these


915
00:27:51,066 --> 00:27:52,976
new features within a Core ML


916
00:27:53,016 --> 00:27:53,416
model.


917
00:27:53,656 --> 00:27:55,146
Well, the answer is same as it


918
00:27:55,146 --> 00:27:55,876
was last year.


919
00:27:56,326 --> 00:27:58,076
There are two options to build a


920
00:27:58,076 --> 00:27:59,876
Core ML model.


921
00:28:00,326 --> 00:28:02,626
One, since Core ML is an open


922
00:28:02,626 --> 00:28:04,366
source Protobuf specification,


923
00:28:04,746 --> 00:28:06,836
we can always specify a model


924
00:28:06,976 --> 00:28:08,556
programmatically using any


925
00:28:08,556 --> 00:28:09,536
programming language of your


926
00:28:09,536 --> 00:28:09,946
choice.


927
00:28:10,126 --> 00:28:12,026
So that option is always


928
00:28:12,026 --> 00:28:13,066
available to us.


929
00:28:13,506 --> 00:28:14,786
But in the majority of the


930
00:28:14,786 --> 00:28:16,596
cases, we like to use converters


931
00:28:16,666 --> 00:28:18,086
that can automatically do that


932
00:28:18,086 --> 00:28:20,486
for us by translating a graph


933
00:28:20,586 --> 00:28:22,186
from a different representation


934
00:28:22,716 --> 00:28:24,276
into the Core ML representation.


935
00:28:24,656 --> 00:28:25,996
So let's look at both of these


936
00:28:25,996 --> 00:28:27,296
approaches a little bit in


937
00:28:27,296 --> 00:28:27,626
detail.


938
00:28:28,916 --> 00:28:30,876
So here I'm showing a simple


939
00:28:30,976 --> 00:28:33,326
neural network and how it can be


940
00:28:33,326 --> 00:28:35,996
easily expressed using Core ML


941
00:28:35,996 --> 00:28:38,336
tools, which is a simple Python


942
00:28:38,336 --> 00:28:40,096
wrapper around the Protobuf


943
00:28:40,096 --> 00:28:40,776
specification.


944
00:28:41,716 --> 00:28:43,366
I personally like this approach,


945
00:28:43,536 --> 00:28:44,816
especially when I'm converting a


946
00:28:44,816 --> 00:28:46,726
model whose architecture I


947
00:28:46,726 --> 00:28:47,496
understand well.


948
00:28:47,896 --> 00:28:49,616
And if I have the pretrained


949
00:28:49,616 --> 00:28:51,206
weights available to me in a


950
00:28:51,206 --> 00:28:54,166
nice data such as numbered


951
00:28:54,166 --> 00:28:54,656
arrays.


952
00:28:55,316 --> 00:28:57,316
Having said that, neural


953
00:28:57,316 --> 00:28:58,906
networks are often much more


954
00:28:58,906 --> 00:29:01,156
complex, and we are better off


955
00:29:01,296 --> 00:29:03,346
using converters and we have a


956
00:29:03,346 --> 00:29:03,926
few of them.


957
00:29:04,166 --> 00:29:06,256
So we have a few converters


958
00:29:06,256 --> 00:29:08,406
available on GitHub using which


959
00:29:08,406 --> 00:29:10,746
you can target most of the


960
00:29:10,746 --> 00:29:11,906
machine learning frameworks out


961
00:29:11,956 --> 00:29:12,136
there.


962
00:29:12,666 --> 00:29:14,396
And the great news is that with


963
00:29:14,396 --> 00:29:15,736
the backing of Core ML 3


964
00:29:15,736 --> 00:29:17,416
specification, all these


965
00:29:17,416 --> 00:29:19,146
converters are getting updated


966
00:29:19,386 --> 00:29:20,556
and much more robust.


967
00:29:21,316 --> 00:29:23,276
So, for some of you who have


968
00:29:23,276 --> 00:29:24,686
used our converters in the past,


969
00:29:25,186 --> 00:29:26,856
you might have come across some


970
00:29:26,916 --> 00:29:28,666
error messages like this, like


971
00:29:28,846 --> 00:29:29,956
maybe it's complaining about a


972
00:29:29,956 --> 00:29:31,266
missing layer or a missing


973
00:29:31,266 --> 00:29:32,256
attribute in the layer.


974
00:29:33,166 --> 00:29:35,476
Now, all of this will go away as


975
00:29:35,476 --> 00:29:36,986
the converters are updated and


976
00:29:36,986 --> 00:29:39,016
they make full use of the Core


977
00:29:39,016 --> 00:29:39,976
ML 3 specification.


978
00:29:40,516 --> 00:29:46,156
[ Applause ]


979
00:29:46,656 --> 00:29:50,086
So, we went through a lot of


980
00:29:50,086 --> 00:29:50,616
slides.


981
00:29:50,616 --> 00:29:51,756
Now it's time to look at the


982
00:29:51,756 --> 00:29:52,706
model in action.


983
00:29:52,906 --> 00:29:54,026
And for that, I'll invite my


984
00:29:54,026 --> 00:29:54,676
friend Allen.


985
00:29:56,056 --> 00:29:58,056
[ Applause ]


986
00:29:58,136 --> 00:29:58,466
>> Thank you.


987
00:29:59,096 --> 00:30:01,076
Thank you, Aseem.


988
00:30:01,836 --> 00:30:03,416
Hi. I'm Allen.


989
00:30:03,786 --> 00:30:05,526
Today, I'm going to show you how


990
00:30:05,526 --> 00:30:07,166
to use the new features in Core


991
00:30:07,166 --> 00:30:09,436
ML 3 to bring state of the art


992
00:30:09,436 --> 00:30:10,606
machine learning models for


993
00:30:10,606 --> 00:30:12,196
natural language processing into


994
00:30:12,196 --> 00:30:12,576
our apps.


995
00:30:15,006 --> 00:30:16,736
So, I love reading about


996
00:30:16,736 --> 00:30:17,126
history.


997
00:30:17,836 --> 00:30:19,176
Whenever I come across some


998
00:30:19,176 --> 00:30:20,276
interesting articles about


999
00:30:20,276 --> 00:30:22,326
history, I often have some


1000
00:30:22,326 --> 00:30:23,786
questions on top of my head and


1001
00:30:23,786 --> 00:30:25,416
I really like to get answers for


1002
00:30:25,416 --> 00:30:25,546
that.


1003
00:30:26,316 --> 00:30:27,546
But sometimes I'm just


1004
00:30:27,546 --> 00:30:28,026
impatient.


1005
00:30:28,416 --> 00:30:29,486
I don't want to read through the


1006
00:30:29,486 --> 00:30:30,156
entire article.


1007
00:30:30,866 --> 00:30:33,256
So, wouldn't it be nice if I can


1008
00:30:33,256 --> 00:30:35,086
build an app that scan through


1009
00:30:35,086 --> 00:30:36,826
the document and then give the


1010
00:30:36,826 --> 00:30:37,496
answers for me?


1011
00:30:38,186 --> 00:30:40,186
So then I started out build this


1012
00:30:40,186 --> 00:30:41,746
app with the new features in


1013
00:30:41,746 --> 00:30:42,266
Core ML 3.


1014
00:30:42,656 --> 00:30:43,286
And let me show you.


1015
00:30:51,416 --> 00:30:52,806
OK. So, here's my app.


1016
00:30:54,056 --> 00:30:56,266
As you can see, it shows article


1017
00:30:56,266 --> 00:30:57,866
about history of a company


1018
00:30:57,866 --> 00:30:58,306
called NeXT.


1019
00:30:59,226 --> 00:31:01,456
So, as you can see, this is a


1020
00:31:01,456 --> 00:31:02,976
long article, and I certainly


1021
00:31:02,976 --> 00:31:03,946
don't have time to go through


1022
00:31:03,946 --> 00:31:04,096
it.


1023
00:31:04,096 --> 00:31:05,706
And I have some questions about


1024
00:31:05,706 --> 00:31:05,773
it.


1025
00:31:06,276 --> 00:31:10,326
So let me just ask this app.


1026
00:31:10,586 --> 00:31:12,306
Let's try my first question.


1027
00:31:13,416 --> 00:31:16,046
Who started NeXT?


1028
00:31:19,076 --> 00:31:20,806
>> Steve Jobs.


1029
00:31:21,516 --> 00:31:26,186
[ Applause ]


1030
00:31:26,686 --> 00:31:28,666
>> OK. I think that's right.


1031
00:31:29,276 --> 00:31:33,966
Let me try another one.


1032
00:31:34,176 --> 00:31:35,756
Where was the main office


1033
00:31:35,756 --> 00:31:36,406
located?


1034
00:31:39,546 --> 00:31:41,536
>> Redwood City, California


1035
00:31:42,516 --> 00:31:45,716
[ Applause ]


1036
00:31:46,216 --> 00:31:48,036
>> Now I also have a question


1037
00:31:48,036 --> 00:31:49,136
that I'm very interested in.


1038
00:31:49,556 --> 00:31:50,906
Let me try that.


1039
00:31:52,876 --> 00:31:55,086
How much were engineers paid?


1040
00:31:58,286 --> 00:31:59,826
>> Seventy-five thousand or


1041
00:31:59,826 --> 00:32:02,826
$50,000 [applause].


1042
00:32:03,136 --> 00:32:03,466
>> Interesting.


1043
00:32:04,016 --> 00:32:06,000
[ Applause ]


1044
00:32:09,436 --> 00:32:11,126
So, isn't this cool?


1045
00:32:11,846 --> 00:32:16,886
So now, let's get deeper into it


1046
00:32:17,076 --> 00:32:18,176
and see what the app really


1047
00:32:18,176 --> 00:32:18,386
does.


1048
00:32:20,486 --> 00:32:22,146
So, the central piece of this


1049
00:32:22,146 --> 00:32:24,026
app is a state of the art


1050
00:32:24,106 --> 00:32:25,596
machine learning model called


1051
00:32:25,986 --> 00:32:27,406
Bidirectional Encoder


1052
00:32:27,406 --> 00:32:28,566
Representation from


1053
00:32:28,566 --> 00:32:29,156
Transformers.


1054
00:32:29,666 --> 00:32:30,876
And this is a very long name.


1055
00:32:31,236 --> 00:32:32,786
So, let's just call it the BERT


1056
00:32:32,786 --> 00:32:34,426
model as other researchers do.


1057
00:32:35,216 --> 00:32:37,656
So, what does BERT model do?


1058
00:32:38,186 --> 00:32:40,636
Well, it is actually a-- it's


1059
00:32:40,776 --> 00:32:42,796
actually a neural network that


1060
00:32:42,796 --> 00:32:47,436
can perform multiple tasks for


1061
00:32:47,436 --> 00:32:48,846
natural language understanding.


1062
00:32:49,466 --> 00:32:52,986
But what's inside the BERT


1063
00:32:52,986 --> 00:32:53,326
model?


1064
00:32:54,766 --> 00:32:55,536
A bunch of modules.


1065
00:32:56,096 --> 00:32:57,466
And what's inside these modules?


1066
00:32:58,586 --> 00:33:00,296
Layers, many, many layers.


1067
00:33:01,316 --> 00:33:02,326
So you can see, it's rather


1068
00:33:02,326 --> 00:33:04,476
complicated, but with the new


1069
00:33:04,476 --> 00:33:06,106
features and tools in Core ML 3,


1070
00:33:06,476 --> 00:33:08,256
I can easily bring this model


1071
00:33:08,256 --> 00:33:09,506
into my app.


1072
00:33:10,896 --> 00:33:13,996
But first, the question is, how


1073
00:33:13,996 --> 00:33:14,676
do I get the model?


1074
00:33:15,406 --> 00:33:19,466
Well, you can get a model on our


1075
00:33:19,626 --> 00:33:22,976
model gallery website, or you


1076
00:33:22,976 --> 00:33:25,296
can-- if you like, you can train


1077
00:33:25,296 --> 00:33:26,806
a model and then convert it.


1078
00:33:28,016 --> 00:33:30,166
For example, the other night I


1079
00:33:30,166 --> 00:33:32,046
trained my BERT model with


1080
00:33:32,046 --> 00:33:32,566
TensorFlow.


1081
00:33:33,186 --> 00:33:35,336
And here is a screenshot of my


1082
00:33:35,486 --> 00:33:35,946
workspace.


1083
00:33:36,476 --> 00:33:38,286
Sorry for me being very messy


1084
00:33:38,286 --> 00:33:38,986
with my workspace.


1085
00:33:39,686 --> 00:33:41,916
But to use new Core ML


1086
00:33:42,426 --> 00:33:44,906
converter, I just need to export


1087
00:33:44,906 --> 00:33:47,606
a model into the Protobuf format


1088
00:33:48,146 --> 00:33:49,696
right here.


1089
00:33:50,936 --> 00:33:52,826
And after that, all I need to do


1090
00:33:53,086 --> 00:33:54,586
is to type three lines of Python


1091
00:33:54,586 --> 00:33:54,826
code.


1092
00:33:55,746 --> 00:33:57,436
Import TF Core ML converter,


1093
00:33:58,046 --> 00:33:59,086
call the convert function, and


1094
00:33:59,736 --> 00:34:02,966
then save out as an ML model.


1095
00:34:03,076 --> 00:34:04,476
So as you can see, it's rather


1096
00:34:04,476 --> 00:34:06,336
easy to bring a model into the


1097
00:34:06,336 --> 00:34:06,776
app.


1098
00:34:07,066 --> 00:34:08,116
But to use the app for a


1099
00:34:08,146 --> 00:34:09,735
question and answering, there


1100
00:34:09,735 --> 00:34:11,606
are few more steps and I like to


1101
00:34:11,606 --> 00:34:12,916
explain a little further.


1102
00:34:13,315 --> 00:34:15,795
So to use the Q and A model, I


1103
00:34:15,795 --> 00:34:17,916
need to prepare a question and a


1104
00:34:17,916 --> 00:34:19,956
paragraph and then separate them


1105
00:34:19,956 --> 00:34:20,906
as work tokens.


1106
00:34:21,366 --> 00:34:23,485
What the model will predict is


1107
00:34:23,596 --> 00:34:26,556
the location of the answer


1108
00:34:27,045 --> 00:34:28,146
that's in the paragraph.


1109
00:34:28,795 --> 00:34:30,186
Think of it as a highlighter as


1110
00:34:30,186 --> 00:34:33,275
you just saw in the demo.


1111
00:34:33,436 --> 00:34:34,775
So from there, I can start


1112
00:34:34,775 --> 00:34:35,735
building up my app.


1113
00:34:36,396 --> 00:34:37,626
The model itself does not make


1114
00:34:38,036 --> 00:34:38,706
the app.


1115
00:34:39,076 --> 00:34:40,856
And in addition to that, I also


1116
00:34:40,856 --> 00:34:43,676
utilize many features from other


1117
00:34:43,676 --> 00:34:45,335
frameworks that makes this app.


1118
00:34:45,775 --> 00:34:47,516
For example, I use the


1119
00:34:47,516 --> 00:34:49,525
speech-to-text API from speech


1120
00:34:49,525 --> 00:34:51,966
framework to translate my voice


1121
00:34:51,966 --> 00:34:52,516
into text.


1122
00:34:53,505 --> 00:34:56,536
I use natural language API to


1123
00:34:56,536 --> 00:34:58,066
help me build the tokenizer.


1124
00:34:58,756 --> 00:35:01,546
And finally, I use the


1125
00:35:01,936 --> 00:35:03,186
text-to-speech API from the


1126
00:35:03,186 --> 00:35:05,356
AVFoundation to play out the


1127
00:35:05,356 --> 00:35:06,266
audio of an answer.


1128
00:35:06,966 --> 00:35:08,316
So, all these components


1129
00:35:08,576 --> 00:35:09,986
utilizes machine learning


1130
00:35:10,046 --> 00:35:12,066
on-device, so that to use this


1131
00:35:12,066 --> 00:35:13,946
app, no internet access is


1132
00:35:13,946 --> 00:35:14,396
required.


1133
00:35:15,516 --> 00:35:17,776
[ Applause ]


1134
00:35:18,276 --> 00:35:19,456
Thank you.


1135
00:35:19,456 --> 00:35:21,636
Just think about how much more


1136
00:35:21,636 --> 00:35:24,126
possibility of new ideas and new


1137
00:35:24,246 --> 00:35:25,606
user experience you can bring


1138
00:35:25,606 --> 00:35:26,436
into our app.


1139
00:35:27,056 --> 00:35:27,646
That's all.


1140
00:35:27,646 --> 00:35:27,976
Thank you.


1141
00:35:28,516 --> 00:35:35,516
[ Applause ]


1142
00:35:36,016 --> 00:35:38,766
>> OK. Thank you, Allen.


1143
00:35:40,706 --> 00:35:42,876
OK. So before we conclude the


1144
00:35:42,876 --> 00:35:44,266
session, I want to highlight


1145
00:35:44,266 --> 00:35:45,416
three more features that we


1146
00:35:45,416 --> 00:35:48,096
added this year in Core ML that


1147
00:35:48,096 --> 00:35:50,086
I'm sure a lot of Core ML users


1148
00:35:50,086 --> 00:35:51,026
will find really useful.


1149
00:35:51,766 --> 00:35:56,926
So let's look at the first one.


1150
00:35:56,926 --> 00:35:58,876
So consider a scenario shown in


1151
00:35:58,876 --> 00:36:00,606
the slide, let's say we have two


1152
00:36:00,606 --> 00:36:02,886
models that classify different


1153
00:36:02,886 --> 00:36:03,796
breeds of animal.


1154
00:36:04,516 --> 00:36:06,556
And if you look inside, both


1155
00:36:06,556 --> 00:36:09,086
these models are pipeline models


1156
00:36:09,586 --> 00:36:10,976
that share a common feature


1157
00:36:10,976 --> 00:36:11,456
extractor.


1158
00:36:12,136 --> 00:36:13,406
Now this happens quite often.


1159
00:36:13,576 --> 00:36:15,976
It's quite common to share-- to


1160
00:36:15,976 --> 00:36:18,256
train deep neural network to get


1161
00:36:18,256 --> 00:36:20,056
features and those features can


1162
00:36:20,056 --> 00:36:21,436
be fed to different neural


1163
00:36:21,436 --> 00:36:21,956
networks.


1164
00:36:22,816 --> 00:36:25,906
So actually in the slide, we


1165
00:36:25,906 --> 00:36:27,876
note that we are using multiple


1166
00:36:27,876 --> 00:36:29,736
copies of the same model within


1167
00:36:29,736 --> 00:36:30,716
these two pipelines.


1168
00:36:31,146 --> 00:36:32,296
Now this is clearly not


1169
00:36:32,296 --> 00:36:32,756
efficient.


1170
00:36:33,446 --> 00:36:35,036
To get rid of this inefficiency,


1171
00:36:35,296 --> 00:36:36,426
we are launching a new model


1172
00:36:36,466 --> 00:36:38,596
type called linked model, as


1173
00:36:38,596 --> 00:36:38,996
shown here.


1174
00:36:38,996 --> 00:36:42,266
So just see, the idea is quite


1175
00:36:42,316 --> 00:36:42,696
simple.


1176
00:36:43,016 --> 00:36:44,936
Linked model is simply a


1177
00:36:44,936 --> 00:36:47,236
reference to a model sitting at


1178
00:36:47,236 --> 00:36:47,606
desk.


1179
00:36:48,266 --> 00:36:50,376
And this really makes it easy to


1180
00:36:50,376 --> 00:36:51,876
share a model across different


1181
00:36:52,096 --> 00:36:52,896
models.


1182
00:36:54,876 --> 00:36:56,006
Another way I like to think


1183
00:36:56,006 --> 00:36:58,146
about linked model is it behaves


1184
00:36:58,146 --> 00:36:59,806
like linking to a dynamic


1185
00:37:00,126 --> 00:37:01,296
library.


1186
00:37:01,686 --> 00:37:03,436
And it has only a couple of


1187
00:37:03,436 --> 00:37:04,166
parameters.


1188
00:37:04,166 --> 00:37:05,636
One, the name of the model that


1189
00:37:05,636 --> 00:37:07,466
it's linking to and a search


1190
00:37:07,466 --> 00:37:07,816
path.


1191
00:37:08,826 --> 00:37:10,396
So this would be very useful


1192
00:37:10,396 --> 00:37:12,126
for-- when we are using


1193
00:37:12,126 --> 00:37:13,856
updatable models or pipelines.


1194
00:37:14,676 --> 00:37:17,446
Let's look at the next feature.


1195
00:37:17,726 --> 00:37:19,296
Let's say you have a Core ML


1196
00:37:19,296 --> 00:37:21,206
model that takes an image as an


1197
00:37:21,206 --> 00:37:21,586
input.


1198
00:37:22,136 --> 00:37:23,776
Now as of now, Core ML expects


1199
00:37:23,816 --> 00:37:26,066
the image to be in the form of a


1200
00:37:26,066 --> 00:37:27,716
CVPixelBuffer.


1201
00:37:27,716 --> 00:37:29,806
But what happens if your image


1202
00:37:29,806 --> 00:37:30,786
is coming from a different


1203
00:37:30,786 --> 00:37:32,076
source and it's in a different


1204
00:37:32,076 --> 00:37:32,516
format?


1205
00:37:33,466 --> 00:37:34,706
Now, in most of the cases, you


1206
00:37:35,276 --> 00:37:36,996
could use the vision framework


1207
00:37:37,276 --> 00:37:39,746
so you can invoke Core ML via


1208
00:37:39,746 --> 00:37:41,566
the VNCoreMLRequest class.


1209
00:37:42,156 --> 00:37:43,736
And this has the advantage that


1210
00:37:43,736 --> 00:37:45,646
vision can handle many different


1211
00:37:45,646 --> 00:37:47,686
formats of images for us, and


1212
00:37:47,686 --> 00:37:49,526
they can also do preprocessing


1213
00:37:49,526 --> 00:37:51,486
like image scaling and cropping,


1214
00:37:51,486 --> 00:37:53,016
et cetera.


1215
00:37:53,216 --> 00:37:54,796
In some cases, though, we might


1216
00:37:54,796 --> 00:37:56,756
have to call the Core ML API


1217
00:37:56,756 --> 00:37:58,926
directly, for instance when we


1218
00:37:58,926 --> 00:38:01,046
are trying to invoke the update


1219
00:38:01,046 --> 00:38:01,366
APIs.


1220
00:38:01,766 --> 00:38:04,146
For such cases, we have launched


1221
00:38:04,146 --> 00:38:05,576
a couple of new initializer


1222
00:38:05,576 --> 00:38:07,186
methods, I showed on the slide.


1223
00:38:07,546 --> 00:38:09,206
So now we can directly get an


1224
00:38:09,206 --> 00:38:11,906
image from a URL or a CGimage.


1225
00:38:12,516 --> 00:38:17,776
[ Applause ]


1226
00:38:18,276 --> 00:38:19,976
So this should make it really


1227
00:38:19,976 --> 00:38:21,886
convenient to use images with


1228
00:38:21,886 --> 00:38:23,886
Core ML.


1229
00:38:24,366 --> 00:38:25,506
Moving on to the last feature I


1230
00:38:25,506 --> 00:38:26,896
want to highlight.


1231
00:38:26,896 --> 00:38:28,256
So there's a class in Core ML


1232
00:38:28,256 --> 00:38:30,486
API called MLModelConfiguration.


1233
00:38:30,486 --> 00:38:33,536
And it can be used to constrain


1234
00:38:33,536 --> 00:38:35,566
the set of devices on which a


1235
00:38:35,566 --> 00:38:36,966
Core ML model can execute.


1236
00:38:37,246 --> 00:38:39,476
For example, the default value


1237
00:38:39,476 --> 00:38:41,056
that the [inaudible] takes is


1238
00:38:41,166 --> 00:38:44,616
called all which gives all the


1239
00:38:44,616 --> 00:38:45,736
computer devices available


1240
00:38:45,876 --> 00:38:47,326
including the neural engine.


1241
00:38:48,136 --> 00:38:49,756
Now we have added a couple of


1242
00:38:49,796 --> 00:38:52,026
more options to this class.


1243
00:38:52,756 --> 00:38:55,546
The first one is the ability to


1244
00:38:55,546 --> 00:38:58,336
specify preferred metal device


1245
00:38:59,166 --> 00:39:00,696
on which the model can execute.


1246
00:39:01,236 --> 00:39:02,426
So as you can imagine, this


1247
00:39:02,426 --> 00:39:03,716
would be really useful if you


1248
00:39:03,716 --> 00:39:05,436
are running a Core ML model on a


1249
00:39:05,436 --> 00:39:06,846
Mac which can have many


1250
00:39:06,846 --> 00:39:09,706
different GPUs attached to it.


1251
00:39:10,106 --> 00:39:11,036
The other option that we've


1252
00:39:11,036 --> 00:39:13,066
added this called low precision


1253
00:39:13,066 --> 00:39:13,776
accumulation.


1254
00:39:13,776 --> 00:39:15,996
And the idea here is that if


1255
00:39:15,996 --> 00:39:17,576
your model is learning on the


1256
00:39:17,576 --> 00:39:19,906
GPU, instead of doing


1257
00:39:19,906 --> 00:39:21,766
accumulation in float32, that


1258
00:39:21,766 --> 00:39:22,946
happens in float60.


1259
00:39:23,296 --> 00:39:25,026
Now this can offer some really


1260
00:39:25,026 --> 00:39:27,566
nice speed enhancement for your


1261
00:39:27,566 --> 00:39:27,906
model.


1262
00:39:28,636 --> 00:39:29,896
But whenever we reduce the


1263
00:39:29,896 --> 00:39:31,616
precision, always remember to


1264
00:39:31,656 --> 00:39:33,416
check the accuracy of the model,


1265
00:39:33,826 --> 00:39:36,056
which might degrade or not


1266
00:39:36,056 --> 00:39:37,776
degrade, depending on the model


1267
00:39:37,776 --> 00:39:37,936
type.


1268
00:39:38,246 --> 00:39:41,436
So always try to experiment


1269
00:39:41,436 --> 00:39:43,266
whenever you vary the precision


1270
00:39:43,266 --> 00:39:43,726
of the model.


1271
00:39:43,866 --> 00:39:45,136
So I would highly encourage you


1272
00:39:45,136 --> 00:39:46,676
to go and try out this option to


1273
00:39:46,676 --> 00:39:49,706
see if it helps with your model.


1274
00:39:50,346 --> 00:39:52,306
OK. So, we talked about a lot of


1275
00:39:52,306 --> 00:39:53,276
stuff in this session.


1276
00:39:53,276 --> 00:39:55,206
Let briefly summarize it for


1277
00:39:55,206 --> 00:39:55,476
you.


1278
00:39:55,996 --> 00:39:58,976
We discussed how it's really


1279
00:39:58,976 --> 00:40:00,656
easy to make a personalized


1280
00:40:00,656 --> 00:40:02,426
experience for our users by


1281
00:40:02,426 --> 00:40:03,646
updating the Core ML model


1282
00:40:03,736 --> 00:40:04,346
on-device.


1283
00:40:05,126 --> 00:40:07,006
We discussed how we have added


1284
00:40:07,066 --> 00:40:08,066
many more features to our


1285
00:40:08,066 --> 00:40:09,386
specification and now we can


1286
00:40:09,386 --> 00:40:11,156
bring the state of the art


1287
00:40:11,156 --> 00:40:12,296
neural network architectures


1288
00:40:12,646 --> 00:40:14,266
into our apps.


1289
00:40:14,266 --> 00:40:15,746
And we talk about a few


1290
00:40:16,026 --> 00:40:17,466
convenience APIs and options


1291
00:40:17,466 --> 00:40:18,036
around GPU.


1292
00:40:18,536 --> 00:40:21,366
Here are a few sessions that you


1293
00:40:21,366 --> 00:40:22,796
might find interesting and


1294
00:40:22,796 --> 00:40:23,786
related to the session.


1295
00:40:24,346 --> 00:40:25,656
And thank you.


1296
00:40:26,516 --> 00:40:31,500
[ Applause ]

