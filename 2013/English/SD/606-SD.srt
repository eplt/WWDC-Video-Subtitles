1
00:00:00,506 --> 00:00:10,536
[ Silence ]


2
00:00:11,036 --> 00:00:16,966
>> Good afternoon.


3
00:00:16,966 --> 00:00:18,356
[ Applause ]


4
00:00:18,356 --> 00:00:21,446
Well my name is Sam Bushell
and I work on Media Frameworks.


5
00:00:21,896 --> 00:00:23,926
And that's what we're
going to be talking


6
00:00:23,926 --> 00:00:24,686
about in this session.


7
00:00:24,686 --> 00:00:28,886
We're going to talk about
Media Frameworks, old and new.


8
00:00:28,886 --> 00:00:31,416
We're going to talk
about QuickTime and QTKit


9
00:00:31,416 --> 00:00:34,906
and we're going to talk about
AV Foundation and AV Kit.


10
00:00:35,846 --> 00:00:38,086
In case you haven't heard,


11
00:00:38,086 --> 00:00:40,176
AV Foundation is a new media
infrastructure we've been


12
00:00:40,176 --> 00:00:42,256
working on at Apple
for the last few years.


13
00:00:42,976 --> 00:00:44,776
It's common on iOS and OS X.


14
00:00:44,776 --> 00:00:50,526
And it's focused on modern media
formats like H.264 and AAC.


15
00:00:50,526 --> 00:00:52,656
But AV Foundation was
built by engineers


16
00:00:52,656 --> 00:00:53,946
with deep media experience


17
00:00:53,946 --> 00:00:55,656
from building QuickTime
over many years.


18
00:00:59,456 --> 00:01:01,846
Let's give a bit of
history about QuickTime.


19
00:01:03,106 --> 00:01:06,106
QuickTime was a pioneering
framework


20
00:01:06,106 --> 00:01:08,536
for dealing with digital media.


21
00:01:09,806 --> 00:01:12,446
There were some early developer
seeds but it first shipped


22
00:01:12,446 --> 00:01:14,356
to the public in December 1991.


23
00:01:14,876 --> 00:01:19,456
And over the years since
1991, there have been a lot


24
00:01:19,456 --> 00:01:22,796
of QuickTime updates delivering
an enormous collection


25
00:01:22,796 --> 00:01:23,456
of features.


26
00:01:24,856 --> 00:01:28,316
One of our biggest individual
feature releases was QuickTime 7


27
00:01:28,316 --> 00:01:30,366
which is shipped as part
of Mac OS 10.4 Tiger.


28
00:01:31,166 --> 00:01:35,776
This introduced big
deal features like H.264


29
00:01:35,776 --> 00:01:37,786
and the QTKit Framework.


30
00:01:38,446 --> 00:01:41,446
The QTKit Framework
introduced an objective C API


31
00:01:41,716 --> 00:01:43,096
that wrapped the QuickTime C API


32
00:01:43,096 --> 00:01:46,206
for easier integration
into Cocoa Apps.


33
00:01:48,686 --> 00:01:52,466
Four years later, we introduced
Mac OS 10.6 Snow Leopard.


34
00:01:52,466 --> 00:01:54,976
And in that four years,


35
00:01:55,326 --> 00:01:58,606
we had built a new media
playback pipeline as part


36
00:01:58,606 --> 00:01:59,676
of building the iPhone.


37
00:02:00,386 --> 00:02:01,356
We called this Core Media.


38
00:02:02,906 --> 00:02:06,186
Now we weren't ready
to deliver a public API


39
00:02:06,286 --> 00:02:07,486
for Core Media at the time.


40
00:02:07,516 --> 00:02:10,816
But we delivered-- we
added a mode to QTKit


41
00:02:11,486 --> 00:02:13,406
where you could use the
Core Media playback pipeline


42
00:02:13,406 --> 00:02:16,536
to get optimized
playback of H.264 and AAC.


43
00:02:16,646 --> 00:02:17,946
We called this QuickTime X.


44
00:02:18,566 --> 00:02:24,996
And then in OS 10.7 Lion,


45
00:02:25,386 --> 00:02:27,956
we introduced AV
Foundation as a public API.


46
00:02:28,796 --> 00:02:34,176
In our framework hierarchy
AV Foundation sits lower


47
00:02:34,176 --> 00:02:36,986
than the UI frameworks
of UIKit and AppKit.


48
00:02:37,766 --> 00:02:39,576
This means that we can
deliver the same API


49
00:02:39,926 --> 00:02:41,676
across iOS and OS X.


50
00:02:42,496 --> 00:02:48,736
In the OS 10.8 Mountain Lion, we
enhanced the AV Foundation API


51
00:02:48,866 --> 00:02:51,546
and we introduced the Video
Toolbox as a public API.


52
00:02:52,356 --> 00:02:55,636
And this year in Mavericks,


53
00:02:55,776 --> 00:02:57,166
(I'm still getting
used to saying that.)


54
00:02:58,246 --> 00:03:00,236
We introduced-- we're
introducing AV Kit.


55
00:03:00,666 --> 00:03:03,316
AV Kit is the framework
where we will put APIs


56
00:03:03,896 --> 00:03:06,176
that let you integrate AV
Foundation with AppKit.


57
00:03:09,086 --> 00:03:11,396
So, you can see in the last
few years we have built


58
00:03:11,396 --> 00:03:14,736
in a new stack of
media frameworks.


59
00:03:15,786 --> 00:03:17,606
We call this the AV
Foundation family


60
00:03:18,096 --> 00:03:19,496
and this is the direction
we're headed.


61
00:03:19,496 --> 00:03:21,846
This is our focus in
the media systems group.


62
00:03:22,726 --> 00:03:24,626
We have not been adding
new APIs to QuickTime


63
00:03:24,626 --> 00:03:26,726
or QTKit for-- for
some time now.


64
00:03:26,726 --> 00:03:29,546
I said that with one small
asterisk to come back to later.


65
00:03:32,026 --> 00:03:36,376
So, as of Mavericks, the
QuickTime C Framework


66
00:03:36,706 --> 00:03:39,416
and the QTKit Framework
are deprecated.


67
00:03:39,926 --> 00:03:42,736
What this means is that
we've marked these APIs


68
00:03:42,786 --> 00:03:44,496
as deprecated in
the header files.


69
00:03:44,846 --> 00:03:48,946
And that means while your code
will still compile you will get


70
00:03:48,946 --> 00:03:50,486
deprecation warnings like these.


71
00:03:51,866 --> 00:03:53,836
But your apps will still run.


72
00:03:54,796 --> 00:03:56,306
Let's emphasize that.


73
00:03:56,306 --> 00:03:57,876
Your apps will still run.


74
00:03:57,876 --> 00:04:02,506
While were on the topic,


75
00:04:03,726 --> 00:04:07,766
the QuickTime Movie file format
is still the primary file format


76
00:04:07,926 --> 00:04:09,666
for AV Foundation and
for QuickTime Player.


77
00:04:10,276 --> 00:04:11,166
It's still supported.


78
00:04:11,166 --> 00:04:13,776
What we are deprecating
is the QuickTime C API


79
00:04:15,016 --> 00:04:18,486
and the QuickTime, I'm sorry,
the QTKit objective C API.


80
00:04:19,346 --> 00:04:20,896
The file format is
still supported.


81
00:04:23,216 --> 00:04:29,206
And also on topic the movie file
format's ISO cousin MPEG4 is


82
00:04:29,206 --> 00:04:31,246
also still supported.


83
00:04:31,786 --> 00:04:38,316
So AV Foundation is the future
of media applications on OS X.


84
00:04:38,496 --> 00:04:41,216
Let's talk a little bit about
how we built AV Foundation.


85
00:04:42,006 --> 00:04:44,916
As I said, AV Foundation
was built by engineers


86
00:04:44,916 --> 00:04:46,156
with deep media experience


87
00:04:46,156 --> 00:04:47,666
from building QuickTime
over many years.


88
00:04:48,226 --> 00:04:50,936
We wanted to build a
new platform for media


89
00:04:51,026 --> 00:04:53,186
that could do things that
QuickTime couldn't do


90
00:04:53,446 --> 00:04:57,456
and go places that QuickTime
couldn't do-- couldn't go.


91
00:04:58,456 --> 00:05:02,356
So we built it on the same
kinds of modern foundations


92
00:05:02,356 --> 00:05:06,076
that the rest of Apple has been
moving towards, core foundation


93
00:05:06,076 --> 00:05:08,816
and foundation, GCD and
Blocks and so forth.


94
00:05:10,086 --> 00:05:12,636
Now QuickTime was built
on a modern foundation.


95
00:05:12,706 --> 00:05:15,216
It's just that it was a
modern foundation in 1991


96
00:05:15,216 --> 00:05:16,386
when System 7 was new.


97
00:05:16,996 --> 00:05:20,546
So a lot of the technologies
that it was sitting on top


98
00:05:20,546 --> 00:05:22,816
of have or ones that we have
moved apart, moved away from.


99
00:05:26,716 --> 00:05:27,936
Where QuickTime's APIs--


100
00:05:27,936 --> 00:05:34,226
QuickTime is often said
to have a lot of APIs


101
00:05:34,226 --> 00:05:37,106
but if you count these up
by numbers and if you look


102
00:05:37,106 --> 00:05:38,466
into the header files, a lot


103
00:05:38,466 --> 00:05:40,676
of these APIs are simply
exposing the implementation


104
00:05:40,676 --> 00:05:41,246
of QuickTime.


105
00:05:41,876 --> 00:05:44,406
And sometimes that's a
good fit for how you want


106
00:05:44,406 --> 00:05:47,536
to extend QuickTime and use
QuickTime but sometimes its not.


107
00:05:48,266 --> 00:05:52,326
With AV Foundation we have
taken care to design our APIs


108
00:05:52,916 --> 00:05:55,106
to be a good fit for how
clients will use them.


109
00:05:55,646 --> 00:06:01,506
And so QuickTime's APIs
are monolithic and in some


110
00:06:01,506 --> 00:06:04,466
of these cases we have taken the
opportunity to re-factor them


111
00:06:04,646 --> 00:06:06,396
in AV Foundation into
multiple objects.


112
00:06:06,716 --> 00:06:09,796
In some cases these makes
the AV Foundation APIs much


113
00:06:09,796 --> 00:06:10,476
more flexible.


114
00:06:14,206 --> 00:06:17,306
Owing the QuickTime's
pre-OS X heritage,


115
00:06:18,126 --> 00:06:19,856
many of its APIs
were only designed


116
00:06:19,856 --> 00:06:21,156
to work on the main thread.


117
00:06:22,016 --> 00:06:23,806
Now we did some retrofitting.


118
00:06:23,806 --> 00:06:26,826
We did some refitting
and make many


119
00:06:26,826 --> 00:06:28,696
of the APIs multi-thread
savvy in later years.


120
00:06:29,456 --> 00:06:32,816
But that left the overall
rules if you had coming to it


121
00:06:32,816 --> 00:06:35,846
as a first timer the overall
rules were somewhat awkward


122
00:06:35,846 --> 00:06:36,486
and complicated.


123
00:06:37,436 --> 00:06:40,606
AV Foundation is designed
to be deeply multithreaded.


124
00:06:41,076 --> 00:06:42,306
There are two goals for this.


125
00:06:42,936 --> 00:06:44,536
One is to take maximum advantage


126
00:06:44,706 --> 00:06:46,896
of multi-core hardware
like we have today.


127
00:06:46,896 --> 00:06:49,686
And the other is to improve
application responsiveness


128
00:06:50,196 --> 00:06:52,736
by letting you take
slow, blocking operations


129
00:06:52,736 --> 00:06:54,156
and move them off
the main thread.


130
00:06:54,676 --> 00:06:58,416
AV Foundation is able
to take advantage


131
00:06:58,416 --> 00:07:01,776
of hardware acceleration in
ways that QuickTime could not


132
00:07:02,436 --> 00:07:03,696
such as video encoding.


133
00:07:04,076 --> 00:07:09,556
And we made major design
decisions in AV Foundation


134
00:07:09,846 --> 00:07:11,206
with the goal of
power efficiency.


135
00:07:11,876 --> 00:07:13,036
Remember this is a framework


136
00:07:13,096 --> 00:07:15,496
that was first delivered
on the iPhone.


137
00:07:15,616 --> 00:07:18,426
It is a device that we tested
and run on a battery that fits


138
00:07:18,426 --> 00:07:20,596
in your pocket and still
delivered long hours


139
00:07:20,596 --> 00:07:21,426
of playback time.


140
00:07:22,866 --> 00:07:25,996
Some of these power efficiency
design decisions could not have


141
00:07:25,996 --> 00:07:27,896
been made compatible with
the QuickTime architecture.


142
00:07:31,676 --> 00:07:33,986
And finally QuickTime's
integration,


143
00:07:34,506 --> 00:07:37,516
deep tight integration
with legacy frameworks,


144
00:07:38,176 --> 00:07:39,226
QuickDraw in particular,


145
00:07:39,606 --> 00:07:41,556
means that it cannot
escape the 32-bit world.


146
00:07:42,246 --> 00:07:43,506
Now you may know
that you are able


147
00:07:43,506 --> 00:07:46,136
to use QTKit a 64-bit
application.


148
00:07:47,356 --> 00:07:50,196
But for playback and editing
at least, what's happening


149
00:07:50,196 --> 00:07:52,596
when you do that is that it's
running a 32-bit background


150
00:07:52,596 --> 00:07:53,656
process to use QuickTime.


151
00:07:54,336 --> 00:07:55,566
AV Foundation has designed--


152
00:07:55,566 --> 00:07:58,386
been designed to be
64-bit native from day one.


153
00:07:59,616 --> 00:08:01,576
So do you get the message here?


154
00:08:02,056 --> 00:08:04,586
There are lots of great
reasons why AV Foundation is the


155
00:08:04,586 --> 00:08:05,646
direction that we're headed


156
00:08:05,766 --> 00:08:07,056
and why it should
also be the direction


157
00:08:07,056 --> 00:08:08,376
that your apps are
headed as well.


158
00:08:08,956 --> 00:08:14,146
And AV Foundation supports the
media types that matter, video,


159
00:08:14,146 --> 00:08:15,906
audio, closed captions
and subtitles,


160
00:08:15,906 --> 00:08:17,706
chapters, and time code.


161
00:08:18,686 --> 00:08:22,896
Now as I mentioned QuickTime
has a history, a vast history


162
00:08:22,896 --> 00:08:24,736
with many features
added over the years.


163
00:08:25,446 --> 00:08:28,766
And some of these were
breakthrough features


164
00:08:28,766 --> 00:08:32,006
when they were added
in the mid 1990s.


165
00:08:32,306 --> 00:08:34,436
But the world has moved on.


166
00:08:36,106 --> 00:08:38,676
If you look at this list you
would think to yourself many


167
00:08:38,676 --> 00:08:43,265
of theses APIs-- many of these
features would be superseded


168
00:08:43,265 --> 00:08:46,676
by basic things that we take
for granted today like HTML 5.


169
00:08:47,466 --> 00:08:51,636
And HTTP live streaming has
proved to be much more scalable


170
00:08:51,636 --> 00:08:53,896
for delivery than RTP
Streaming ever was.


171
00:08:54,406 --> 00:08:56,906
That brings us to codecs.


172
00:08:59,016 --> 00:09:00,886
So QuickTime has a vast history.


173
00:09:00,886 --> 00:09:03,596
It has collected many, many
codecs over its long history,


174
00:09:03,916 --> 00:09:08,146
and many of these are rather
old and have been superseded.


175
00:09:08,976 --> 00:09:10,526
The categories of codecs


176
00:09:10,606 --> 00:09:15,106
that are still relevant today
basically are in three groups.


177
00:09:15,336 --> 00:09:18,566
Those that are used for
delivery like H.264 and AAC


178
00:09:18,626 --> 00:09:21,226
and we use JPEG for
chapter images.


179
00:09:22,106 --> 00:09:24,186
Codecs that are used
for production workflows


180
00:09:24,186 --> 00:09:26,756
and editing, these are often
called Mezzanine codecs.


181
00:09:27,166 --> 00:09:32,586
And Codecs that are used
as-- for import from captures


182
00:09:32,586 --> 00:09:34,486
and device, standard
formats that we need


183
00:09:34,486 --> 00:09:35,546
to be able to import from.


184
00:09:36,196 --> 00:09:38,716
These three categories of
codecs are still supported


185
00:09:38,716 --> 00:09:39,556
by AV Foundation.


186
00:09:40,176 --> 00:09:45,966
And that leaves a number
that are left by the wayside.


187
00:09:47,086 --> 00:09:49,576
And if you have really good
eyesight, you might be able


188
00:09:49,576 --> 00:09:50,786
to look at this and
say well hang on some


189
00:09:50,786 --> 00:09:53,336
of those aren't really what I
think it as video codecs anyhow.


190
00:09:53,816 --> 00:09:55,826
And the way that QuickTime's
architecture was structured


191
00:09:56,726 --> 00:09:59,556
still image formats and video
filters and effects also had


192
00:09:59,556 --> 00:10:01,296
to be registered
as video decoders.


193
00:10:01,916 --> 00:10:04,026
Well nowadays, we have
the image IO Framework


194
00:10:04,026 --> 00:10:06,116
which delivers still
image format support


195
00:10:06,116 --> 00:10:08,606
and we have designed
different ways


196
00:10:08,606 --> 00:10:10,266
of integrating video
filters and effects


197
00:10:10,526 --> 00:10:12,056
into the playback pipeline.


198
00:10:14,826 --> 00:10:18,146
But our media is
personally important to us.


199
00:10:19,196 --> 00:10:21,526
Some of the media in these
formats is irreplaceable.


200
00:10:22,086 --> 00:10:25,726
And just because the
formats are out of date,


201
00:10:25,726 --> 00:10:27,576
it doesn't mean we want
to orphan the content.


202
00:10:29,526 --> 00:10:33,396
So we've provided a
mechanisms starting in Mavericks


203
00:10:34,676 --> 00:10:39,046
to help you-- to help
you migrate the content


204
00:10:39,296 --> 00:10:42,776
in these legacy containers,
legacy formats


205
00:10:43,466 --> 00:10:45,416
into AV Foundation-supported
formats.


206
00:10:45,956 --> 00:10:48,426
It's called QTMovieModernizer.


207
00:10:48,996 --> 00:10:51,786
It's automatically run
by QuickTime Player


208
00:10:51,786 --> 00:10:54,296
when it discovers a legacy codec
in a movie file you're opening.


209
00:10:54,706 --> 00:10:56,576
It works with third-party
QuickTime components.


210
00:10:57,076 --> 00:11:01,306
And it's provided as
a new API in Mavericks


211
00:11:01,616 --> 00:11:02,966
so you can do the
same in your apps.


212
00:11:04,156 --> 00:11:06,606
The way it works is it
produces a new copy of the movie


213
00:11:06,766 --> 00:11:08,346
in an AV Foundation
supported format.


214
00:11:08,706 --> 00:11:11,146
Normally this will
be H.264 in AAC.


215
00:11:11,216 --> 00:11:12,976
But there are some cases
for production workflows


216
00:11:12,976 --> 00:11:15,256
where you'd want to use
Apple ProRes and PCM instead.


217
00:11:15,986 --> 00:11:17,496
If the content has
an alpha channel,


218
00:11:17,716 --> 00:11:22,366
then the alpha channel can be
preserved in Apple ProRes 4444.


219
00:11:22,366 --> 00:11:25,286
Now, it's delivered
as part of QTKit.


220
00:11:25,286 --> 00:11:27,006
And this is something
we don't do very often.


221
00:11:27,006 --> 00:11:30,216
We're adding a new API to
a deprecated framework.


222
00:11:31,556 --> 00:11:34,496
But this is intentional because
there's a very specific message


223
00:11:34,496 --> 00:11:35,226
we want to send here.


224
00:11:36,376 --> 00:11:40,006
QTMovieModernizer will be
available to you exactly as long


225
00:11:40,386 --> 00:11:42,916
as QTKit and those legacy
codecs are still available.


226
00:11:43,946 --> 00:11:47,226
So now is a good time to
gather up your legacy media


227
00:11:47,226 --> 00:11:54,356
and bring it across the bridge.


228
00:11:54,356 --> 00:11:54,546
[ Pause ]


229
00:11:54,546 --> 00:11:58,646
So that's our story here
about QuickTime and QTKit.


230
00:11:59,976 --> 00:12:01,896
QuickTime and QTKit
are deprecated


231
00:12:01,896 --> 00:12:05,876
and we have been building a new
media framework brick-by-brick,


232
00:12:05,876 --> 00:12:08,326
foundation by foundation
as it were called the AV--


233
00:12:09,136 --> 00:12:11,126
the AV Foundation family.


234
00:12:11,736 --> 00:12:16,116
In the rest of this talk,
we're going to talk about how


235
00:12:16,116 --> 00:12:18,696
to migrate existing applications


236
00:12:19,156 --> 00:12:21,296
to the AV Foundation
framework family.


237
00:12:21,416 --> 00:12:26,556
And first I'll introduce
Stefan Hafeneger up to talk


238
00:12:26,556 --> 00:12:31,176
about AV kit and introduce
it to you for the first time.


239
00:12:31,191 --> 00:12:33,191
[ Applause ]


240
00:12:33,206 --> 00:12:36,486
>> Thanks Sam.


241
00:12:36,486 --> 00:12:41,036
So I see most of you sitting in
the audience here have some kind


242
00:12:41,036 --> 00:12:42,436
of media playback in
your applications.


243
00:12:43,536 --> 00:12:44,426
Let's see.


244
00:12:44,426 --> 00:12:46,566
How many of you still
use QT Movie View?


245
00:12:47,516 --> 00:12:50,576
Hands up. OK, so there's a few.


246
00:12:51,196 --> 00:12:53,096
And how many of you
already use AV Foundation?


247
00:12:53,816 --> 00:12:56,186
OK, so a few more.


248
00:12:57,036 --> 00:12:59,876
And who of you has ever written
their own playback controls


249
00:12:59,876 --> 00:13:01,526
on top of AVPlayer layer?


250
00:13:01,836 --> 00:13:03,916
OK, a few.


251
00:13:04,706 --> 00:13:06,056
Yeah, I have written
a few as well.


252
00:13:06,096 --> 00:13:09,356
Wouldn't it be nice
if it didn't have to--


253
00:13:09,356 --> 00:13:11,436
didn't have to deal with that?


254
00:13:11,996 --> 00:13:13,726
Here's something
new for all of you.


255
00:13:13,726 --> 00:13:17,146
We want to make your life
as developers easier.


256
00:13:18,096 --> 00:13:26,146
And that's why we are
adding AV Kit to our stand.


257
00:13:26,146 --> 00:13:27,956
AV Kit is a new high
level Cocoa Framework.


258
00:13:27,956 --> 00:13:31,446
Our goal is to provide
you view-level services


259
00:13:31,446 --> 00:13:34,376
for media operations on top
of AV Foundation and AppKit.


260
00:13:34,376 --> 00:13:39,356
AV Kit shows the AVPlayerView.


261
00:13:41,326 --> 00:13:43,836
AVPlayerView is an
NSView subclass


262
00:13:43,836 --> 00:13:45,156
for displaying audio-visual
media.


263
00:13:45,186 --> 00:13:47,426
It comes with a set


264
00:13:47,426 --> 00:13:49,226
of standardized playback
controls and behaviors.


265
00:13:49,226 --> 00:13:52,456
This means, you can get
the same look and feel


266
00:13:52,456 --> 00:13:53,976
that we have been using
in QuickTime Player


267
00:13:53,976 --> 00:13:55,876
since Snow Leopard, now
in your applications.


268
00:13:55,876 --> 00:14:02,196
And as a bonus, it takes care of
of localization, accessibility,


269
00:14:02,196 --> 00:14:04,756
high resolutions, state
restoration and so on.


270
00:14:04,866 --> 00:14:08,566
And we made it really easy
for you to adopt AVPlayerView


271
00:14:08,566 --> 00:14:11,086
in combination with the AV
Foundation in your applications.


272
00:14:11,696 --> 00:14:14,766
So let me walk you through the
necessary steps in the demo.


273
00:14:16,396 --> 00:14:20,236
All right, so in Xcode
you create a new project.


274
00:14:20,236 --> 00:14:26,606
And select OS X Cocoa
Application and press Next.


275
00:14:27,336 --> 00:14:33,106
The name is going to be
AVKitPlayer and we make sure


276
00:14:33,106 --> 00:14:35,496
that we created a
document-based application.


277
00:14:35,636 --> 00:14:38,736
Press Next and save
the document or the--


278
00:14:38,736 --> 00:14:40,006
the project on the desktop.


279
00:14:40,426 --> 00:14:43,496
Let me make the Window
a bit bigger here.


280
00:14:43,996 --> 00:14:50,236
[ Pause ]


281
00:14:50,736 --> 00:14:52,356
So the first thing
that you have to do is


282
00:14:52,356 --> 00:14:54,926
to add the AV Foundation and AV
Kit Frameworks to our project.


283
00:14:56,166 --> 00:14:58,546
So I'm here on the linked
frameworks and libraries.


284
00:14:58,546 --> 00:14:59,756
I click on the Add button.


285
00:14:59,956 --> 00:15:02,046
And then in the New sheet,


286
00:15:02,046 --> 00:15:04,276
we set first search
for AV Foundation.


287
00:15:05,726 --> 00:15:09,766
Oops. I select that, press Add


288
00:15:09,766 --> 00:15:17,976
and then we do the
same for AV Kit.


289
00:15:18,176 --> 00:15:19,956
Now go up with the
mouse to the Info tab.


290
00:15:19,956 --> 00:15:24,076
And on the document types,


291
00:15:24,806 --> 00:15:27,426
first thing we do is we
remove the MyDoc extension.


292
00:15:31,236 --> 00:15:37,996
Instead for identifier, we
use public.audiovisual-content


293
00:15:37,996 --> 00:15:39,516
so that we can open all kinds


294
00:15:39,516 --> 00:15:43,566
of audiovisual media
in our application.


295
00:15:43,626 --> 00:15:46,316
Finally, we switch the
row from editor to viewer.


296
00:15:46,546 --> 00:15:49,276
So that's-- NS Application
doesn't create a document


297
00:15:49,276 --> 00:15:50,386
for us automatically.


298
00:15:50,386 --> 00:15:56,416
Now on the left we select
the documents xib file.


299
00:15:57,216 --> 00:16:00,726
We remove the label
and then on the right,


300
00:16:00,726 --> 00:16:02,836
we search for AVPlayerView.


301
00:16:04,796 --> 00:16:06,906
We're dragging an
instance of AVPlayerView


302
00:16:06,906 --> 00:16:09,376
onto our document
window and resize it


303
00:16:09,376 --> 00:16:10,836
so it fits the entire window.


304
00:16:11,196 --> 00:16:15,566
In the inspector, we
change the control style


305
00:16:15,566 --> 00:16:16,846
from default to floating.


306
00:16:16,846 --> 00:16:19,446
And this would give us
the nice floating HUD


307
00:16:19,536 --> 00:16:23,726
that we have in QuickTime
player.


308
00:16:23,906 --> 00:16:26,816
Next, we show the
assistant editor.


309
00:16:27,416 --> 00:16:29,786
And here, switch to the
document header file.


310
00:16:30,086 --> 00:16:32,086
And now with the Control-click
we can add an outlet


311
00:16:32,086 --> 00:16:32,686
to our document.


312
00:16:33,416 --> 00:16:39,866
We call it playerView
and hit Connect.


313
00:16:40,976 --> 00:16:44,526
Xcode will now complain that
AVPlayerView is not declared.


314
00:16:44,526 --> 00:16:50,146
So, what's still left to do
is to add the header files.


315
00:16:51,136 --> 00:16:53,996
All right, so what
have you done so far?


316
00:16:53,996 --> 00:16:56,146
First, we create an OS
X document application.


317
00:16:56,736 --> 00:16:58,306
Second, we aadd the
AV Foundation,


318
00:16:58,306 --> 00:17:00,206
AV Kit frameworks
to our project.


319
00:17:00,776 --> 00:17:04,616
Third, we'd set a-- sorry,
modify the info plist


320
00:17:04,616 --> 00:17:06,626
so we can open all kinds
of audiovisual media.


321
00:17:06,826 --> 00:17:09,516
And fourth, we drop an
AVPlayerView into our document


322
00:17:09,516 --> 00:17:11,695
and create outlets so we can
reference it from the documents.


323
00:17:12,996 --> 00:17:14,286
So let's see how much
more we have to do


324
00:17:14,286 --> 00:17:20,915
to actually make it work.


325
00:17:20,915 --> 00:17:21,076
[ Pause ]


326
00:17:21,076 --> 00:17:22,766
So I close the assistant editor


327
00:17:22,766 --> 00:17:24,346
and select the document
implementation


328
00:17:24,346 --> 00:17:26,955
and we scroll all the
way down to the bottom.


329
00:17:26,955 --> 00:17:30,926
We're not going to
use readFromData,


330
00:17:32,166 --> 00:17:34,276
instead we implement
readFromURL.


331
00:17:39,056 --> 00:17:41,136
And here we just return yes.


332
00:17:41,706 --> 00:17:45,206
We want to use AV Foundation
to open the document for us.


333
00:17:46,876 --> 00:17:49,326
So we scroll up to
windowControllerDidLoadNib


334
00:17:49,826 --> 00:17:53,146
and implement [playerView
setPlayer:


335
00:17:53,856 --> 00:17:55,036
[AVPlayer playerWithURL:
[self fileURL]]] And now,


336
00:17:55,176 --> 00:17:59,756
press on Build and Run.


337
00:17:59,756 --> 00:17:59,823
[ Pause ]


338
00:17:59,823 --> 00:18:03,796
Go to File, Open.


339
00:18:09,296 --> 00:18:11,476
Select the movie, press Open.


340
00:18:11,476 --> 00:18:16,256
[Background Music] We have a
fully functional document-based


341
00:18:17,086 --> 00:18:18,896
application for playing videos.


342
00:18:19,646 --> 00:18:24,596
OK and it's- [applause]
thank you.


343
00:18:27,426 --> 00:18:29,396
Press the Play and Pause
button to Play and Pause.


344
00:18:29,526 --> 00:18:31,696
I can use this Slider
to scrub around


345
00:18:31,696 --> 00:18:34,836
and we use the Scan button
to scan forward and backward.


346
00:18:36,506 --> 00:18:39,176
But you can also use the
keyboards, for example space,


347
00:18:39,176 --> 00:18:41,256
just stops playback
and stops playback.


348
00:18:41,836 --> 00:18:43,406
We can step with
the arrow keys frame


349
00:18:43,406 --> 00:18:45,636
by frame, forward and backward.


350
00:18:45,636 --> 00:18:48,196
And for those of
you who are familiar


351
00:18:48,196 --> 00:18:49,266
with the J/K/L navigation


352
00:18:49,266 --> 00:18:55,976
in other applications
you have this as well.


353
00:18:55,976 --> 00:18:56,043
[ Pause ]


354
00:18:56,043 --> 00:18:56,496
All right.


355
00:18:57,576 --> 00:19:00,476
Wasn't that easy?


356
00:19:00,626 --> 00:19:03,046
So let's go one step further.


357
00:19:03,046 --> 00:19:05,046
Let's assume your users have
some content where they want


358
00:19:05,046 --> 00:19:07,776
to cut off the beginning
and/or the end of the movie,


359
00:19:08,446 --> 00:19:09,286
something we call trim.


360
00:19:09,286 --> 00:19:12,556
Let's see how much
work we have to do


361
00:19:12,556 --> 00:19:13,906
to add these features
to our application.


362
00:19:13,906 --> 00:19:21,506
So for that, I'm going to open
another version of this project.


363
00:19:22,006 --> 00:19:28,056
[ Pause ]


364
00:19:28,556 --> 00:19:30,466
As you can see, I already set


365
00:19:30,466 --> 00:19:32,596
up a trim menu item
in the Edit menu.


366
00:19:33,126 --> 00:19:37,026
So we now open the
document implementation.


367
00:19:37,236 --> 00:19:41,676
The only thing we have to
do is, in the trim IBAction


368
00:19:42,336 --> 00:19:44,736
to call our playerView,


369
00:19:44,736 --> 00:19:46,876
beginTrimming
WithCompletionHandler


370
00:19:46,876 --> 00:19:47,466
and just NULL.


371
00:19:47,466 --> 00:19:51,956
But as a good Cocoa Application,
we also want to enable


372
00:19:51,956 --> 00:19:53,316
and disable the trim menu item.


373
00:19:53,316 --> 00:19:57,546
So for that, in
validateUserInterfaceItem


374
00:19:57,546 --> 00:20:03,006
for the trim IBAction,
we implement for trim--


375
00:20:03,006 --> 00:20:04,506
playerView canBeginTrimming.


376
00:20:04,976 --> 00:20:11,656
If we now build and run, and we
open the same document as before


377
00:20:11,656 --> 00:20:16,796
and go to Edit and trim, you
get the same user interface


378
00:20:16,796 --> 00:20:17,866
in the QuickTime player.


379
00:20:18,926 --> 00:20:20,346
So we can direct
the trim handlers


380
00:20:20,346 --> 00:20:26,056
to select the shorter portion of
the video, hit the Trim button


381
00:20:26,956 --> 00:20:28,156
and now we're just playing
[Background Music] that--


382
00:20:28,276 --> 00:20:36,326
this portion of the video.


383
00:20:36,326 --> 00:20:37,516
[ Pause ]


384
00:20:37,516 --> 00:20:37,806
All right.


385
00:20:37,946 --> 00:20:39,876
So two lines of code-- sorry.


386
00:20:39,876 --> 00:20:41,856
Two lines of code
was all we had to do


387
00:20:41,856 --> 00:20:44,086
to create a very basic
video playback application,


388
00:20:44,086 --> 00:20:46,306
using AVPlayerView
and AV Foundation.


389
00:20:46,876 --> 00:20:49,306
Two more lines of code and we
have trimming working as well.


390
00:20:49,306 --> 00:20:52,486
Just imagine how long
it would have taken us


391
00:20:52,486 --> 00:20:53,776
to create these controls
from scratch.


392
00:20:55,016 --> 00:20:57,356
All this time, you can now
invest instead making your


393
00:20:57,356 --> 00:20:58,396
applications even better.


394
00:20:58,396 --> 00:20:58,463
[ Pause ]


395
00:20:58,463 --> 00:21:04,986
So let's talk about
a few details now.


396
00:21:05,666 --> 00:21:08,646
So how does AVPlayerView work


397
00:21:08,646 --> 00:21:10,936
with the AV Foundation
class hierarchy?


398
00:21:11,876 --> 00:21:14,906
AVPlayerView has a strong
reference to an AVPlayer object.


399
00:21:16,116 --> 00:21:19,056
This object provides
the content of course.


400
00:21:19,056 --> 00:21:22,446
AVPlayer itself mentions
AVPlayerItem which serves


401
00:21:22,446 --> 00:21:26,196
at mid-- which serves as
the mutable data structure


402
00:21:26,196 --> 00:21:27,986
for an immutable AVAsset.


403
00:21:29,156 --> 00:21:32,096
This means in order to provide
content for an AVPlayerView,


404
00:21:32,096 --> 00:21:34,196
you have to do the
following steps.


405
00:21:35,936 --> 00:21:41,876
First, you create an
AVAsset from an NSURL.


406
00:21:42,046 --> 00:21:44,406
Once you have an AVAsset, you
can create an AVPlayerItem.


407
00:21:44,406 --> 00:21:50,966
We have AVPlayerItem, you can
then create an AVPlayer object.


408
00:21:52,536 --> 00:21:54,936
And finally, you associate
this AVPlayer object


409
00:21:54,936 --> 00:21:56,666
with an AVPlayerView.


410
00:21:57,936 --> 00:22:00,396
However, if you really just
want to play the content


411
00:22:00,396 --> 00:22:02,886
of the movie file on disc, you
can do all four steps at once.


412
00:22:02,886 --> 00:22:03,366
[ Pause ]


413
00:22:03,366 --> 00:22:08,956
So as we showed you
earlier in the demo,


414
00:22:09,066 --> 00:22:11,896
you can directly create an
AVPlayer object from an NSURL


415
00:22:11,896 --> 00:22:14,656
and then pass this object
to the AVPlayerView.


416
00:22:14,846 --> 00:22:18,586
Let's go back to the object
graph from earlier for a second.


417
00:22:19,176 --> 00:22:22,836
I told you, the first step
in order to provide content


418
00:22:22,836 --> 00:22:25,916
from AVPlayerView is to create
an AVAsset from an NSURL.


419
00:22:25,916 --> 00:22:29,206
But what if you're
using AVCompositions


420
00:22:29,206 --> 00:22:31,026
in your applications instead?


421
00:22:32,276 --> 00:22:33,056
All I'm showing today


422
00:22:33,056 --> 00:22:35,376
that AVPlayerView
would just work fine


423
00:22:35,376 --> 00:22:42,046
for AVCompositions as well.


424
00:22:42,046 --> 00:22:43,566
[ Pause ]


425
00:22:43,566 --> 00:22:45,096
AVPlayerView let's you choose


426
00:22:45,096 --> 00:22:47,516
from four different
standardized control styles.


427
00:22:48,426 --> 00:22:50,756
Which one you pick for your
applications is up to you.


428
00:22:51,776 --> 00:22:53,606
It really depends on the
type of application you have


429
00:22:53,606 --> 00:22:55,616
and what looks best in
your user interface.


430
00:22:55,616 --> 00:22:59,306
Let me walk through the
difference real quick.


431
00:23:00,916 --> 00:23:02,856
The first style doesn't
show any controls,


432
00:23:02,856 --> 00:23:06,056
but instead it gives you all
the gesture and keyboard events


433
00:23:06,056 --> 00:23:07,096
that AVPlayerView implements.


434
00:23:07,776 --> 00:23:13,526
The second style has the
controls at bottom of the view.


435
00:23:13,906 --> 00:23:18,126
This is the closest match that
we provide to the QTMovieView.


436
00:23:18,396 --> 00:23:23,186
The third control
style has controls


437
00:23:23,186 --> 00:23:24,966
in this-- in the floating HUD.


438
00:23:25,266 --> 00:23:26,476
This is exactly the same UI


439
00:23:26,476 --> 00:23:28,296
that we are using
QuickTime Player today.


440
00:23:28,296 --> 00:23:33,196
The last style is just
a Play/Pause button


441
00:23:33,196 --> 00:23:34,386
at the center of the view.


442
00:23:34,926 --> 00:23:37,196
That will also show a
circular progress indicator


443
00:23:37,196 --> 00:23:38,546
during playback.


444
00:23:40,696 --> 00:23:43,846
All controls automatically show
and hide upon user interaction.


445
00:23:45,116 --> 00:23:46,696
You can change the control
style in interface--


446
00:23:46,696 --> 00:23:48,036
builder or in code at anytime.


447
00:23:48,686 --> 00:23:53,146
For the second and
third control style,


448
00:23:53,146 --> 00:23:54,226
we also have Trim controls.


449
00:23:54,906 --> 00:23:58,686
The screenshot you can see
on the left shows the TrimUI


450
00:23:58,686 --> 00:24:01,696
for the floating
controlsStyle and the screenshot


451
00:24:01,696 --> 00:24:03,546
on the right shows the TrimUI


452
00:24:03,546 --> 00:24:06,106
for what we call inline
Trim controlsStyle.


453
00:24:07,326 --> 00:24:09,266
As you can see, the only
difference is the margin


454
00:24:09,266 --> 00:24:18,756
around the controls and the
graying on the background.


455
00:24:18,756 --> 00:24:18,823
[ Pause ]


456
00:24:18,823 --> 00:24:20,616
AVPlayerView has
dynamic controls.


457
00:24:20,936 --> 00:24:23,176
This means that if your
content has chapters,


458
00:24:23,176 --> 00:24:24,996
additional language
or subtitles,


459
00:24:24,996 --> 00:24:26,136
it will automatically display--


460
00:24:26,136 --> 00:24:29,236
adds chapter and media selection
pop-up buttons to the UI.


461
00:24:29,236 --> 00:24:35,056
Some of you might have streaming
content in your applications.


462
00:24:36,466 --> 00:24:38,586
AVPlayerView will automatically
switch to a different set


463
00:24:38,586 --> 00:24:40,526
of playback controls
when the content type


464
00:24:40,526 --> 00:24:42,666
of the current AVPlayerItem
changes to streaming.


465
00:24:42,666 --> 00:24:49,146
AVPlayerView has also
API for customization.


466
00:24:49,766 --> 00:24:51,766
For instance, if you
want to allow your users


467
00:24:51,766 --> 00:24:54,146
to share their content
from-- with an AVPlayerView,


468
00:24:54,176 --> 00:24:56,926
all you need to do is to
set one property to yes.


469
00:24:57,796 --> 00:24:59,626
AVPlayerView add the share--


470
00:24:59,626 --> 00:25:01,236
the OS X Share Button
to the UI takes care


471
00:25:01,236 --> 00:25:03,336
of everything for you.


472
00:25:03,916 --> 00:25:05,906
This includes optimizing
the content


473
00:25:05,906 --> 00:25:07,766
for the destination if needed.


474
00:25:09,836 --> 00:25:11,426
So let's switch our
focus to Trimming now.


475
00:25:11,716 --> 00:25:14,586
As I showed you earlier in
the demo, it is really easy


476
00:25:14,586 --> 00:25:17,186
to add Trimming to your
application via AVPlayerView.


477
00:25:17,976 --> 00:25:20,086
All you need to do is just
call beginTrimmingWith


478
00:25:20,086 --> 00:25:21,956
CompletionHandler and
NULL as the argument.


479
00:25:21,956 --> 00:25:25,646
But since that's not
going to really tell you


480
00:25:25,646 --> 00:25:27,906
that if it would
actually show the TrimUI,


481
00:25:27,906 --> 00:25:32,436
you should always call
canBeginTrimming first though.


482
00:25:32,656 --> 00:25:34,096
This method not only returns no


483
00:25:34,096 --> 00:25:37,746
when AVPlayer already shows
the UI, but it also makes sure


484
00:25:37,746 --> 00:25:43,276
that the current AVPlayerItem
can actually be trimmed.


485
00:25:43,426 --> 00:25:45,486
But what if you are
really interested


486
00:25:45,486 --> 00:25:49,066
in what the user
did in the TrimUI.


487
00:25:49,066 --> 00:25:52,576
We start off with exactly
the same code as before.


488
00:25:52,576 --> 00:25:55,386
This time, we are going to
implement a completion handler.


489
00:25:55,906 --> 00:26:00,046
The CompletionHandler
has just one argument


490
00:26:00,046 --> 00:26:01,076
of type AVPlayerViewTrimResult.


491
00:26:01,076 --> 00:26:04,386
The result that it will return


492
00:26:04,386 --> 00:26:06,656
to you will either be
AVPlayerViewTrimOKButton


493
00:26:06,656 --> 00:26:08,986
or AVPlayerViewTrimCancelButton.


494
00:26:09,616 --> 00:26:13,886
In the former case we apply
whatever the user chose


495
00:26:13,886 --> 00:26:17,106
in the UI, in the later case
we will set the trim selection


496
00:26:17,106 --> 00:26:18,256
before dismissing the UI.


497
00:26:18,256 --> 00:26:22,916
So I just told you
what AVPlayerView does


498
00:26:22,916 --> 00:26:24,146
when the user interacts
with the TrimUI.


499
00:26:24,146 --> 00:26:29,596
I haven't told you yet what
it does under the hood though.


500
00:26:29,706 --> 00:26:31,516
We're not replacing the
current AVPlayerItem


501
00:26:31,516 --> 00:26:32,686
or creating AVComposition.


502
00:26:33,546 --> 00:26:37,146
Instead, we use existing AV
Foundation API and functionality


503
00:26:37,146 --> 00:26:38,356
for setting the reverse


504
00:26:38,356 --> 00:26:40,576
and forwardPlaybackEndTime
on the AVPlayerItem.


505
00:26:41,236 --> 00:26:45,116
The player controls are
constantly observing these two


506
00:26:45,116 --> 00:26:47,616
values and updating
when calling me.


507
00:26:48,486 --> 00:26:50,516
One important note here,


508
00:26:50,516 --> 00:26:52,506
AVPlayerView does not
provide state restoration


509
00:26:52,506 --> 00:26:55,466
for the AVPlayer property
because we can't guarantee


510
00:26:55,466 --> 00:26:58,396
that we will be able to
restore this object for you.


511
00:26:59,326 --> 00:27:01,206
This means it is
your responsibility


512
00:27:01,206 --> 00:27:04,036
to restore the content when your
users relaunch the applications.


513
00:27:08,516 --> 00:27:10,806
And this, of course, includes
the reversePlaybackEndTime.


514
00:27:10,806 --> 00:27:14,416
So since we are just
setting some properties


515
00:27:14,416 --> 00:27:16,386
on the current AVPlayerItem
when the user interacts


516
00:27:16,386 --> 00:27:19,006
with the TrimUI the
underlying AVAsset


517
00:27:19,006 --> 00:27:21,056
of course it contains
the entire movie,


518
00:27:21,556 --> 00:27:25,936
which means that
if you use Trimming


519
00:27:25,936 --> 00:27:27,356
and the application
supports export,


520
00:27:27,356 --> 00:27:30,226
you have to set the timeRange
on the AV asset export session.


521
00:27:30,226 --> 00:27:34,076
So first, you get the reverse
and forwardPlaybackEndTime


522
00:27:34,076 --> 00:27:40,036
from the AVPlayerItem and
then you create a CMTimeRange


523
00:27:40,036 --> 00:27:41,676
and set this value
on the ExportSession.


524
00:27:42,236 --> 00:27:46,296
And this is exactly
what we do for sharing.


525
00:27:49,776 --> 00:27:51,476
So wrapping up.


526
00:27:51,786 --> 00:27:55,326
AV Kit is a new UI level Cocoa
framework for AV Foundation.


527
00:27:55,326 --> 00:27:58,226
It provides you view-level
services--


528
00:27:58,226 --> 00:28:00,606
sorry, it provides you standard
playback and trim controls


529
00:28:00,606 --> 00:28:02,036
through the AVPlayerView.


530
00:28:02,036 --> 00:28:07,506
With AV Kit you're now able to
use the power of AV Foundation


531
00:28:07,626 --> 00:28:09,536
without having to write your
own custom playback controls


532
00:28:09,536 --> 00:28:11,106
with our AVPlayer layer.


533
00:28:11,476 --> 00:28:15,226
So please consider
adopting AVPlayerView


534
00:28:15,226 --> 00:28:16,086
in your applications.


535
00:28:17,206 --> 00:28:19,246
This will make sure that we
can provide a consistent look


536
00:28:19,246 --> 00:28:20,746
and feel, not only
here in Apple's


537
00:28:20,746 --> 00:28:23,356
but across all media
playback applications in OS X.


538
00:28:23,976 --> 00:28:27,716
And if you have--
still not fully sold


539
00:28:27,716 --> 00:28:30,156
on AVPlayerView maybe
this will convince you.


540
00:28:32,176 --> 00:28:35,386
Starting on OS X Mavericks
QuickTime Player uses AV Kit


541
00:28:35,386 --> 00:28:36,926
from media playback.


542
00:28:38,536 --> 00:28:41,136
The view you see in the middle
is the same AVPlayerView


543
00:28:41,136 --> 00:28:42,496
that you can use in
your applications.


544
00:28:43,126 --> 00:28:47,106
With that, let me call Sam
back on stage to talk to you


545
00:28:47,106 --> 00:28:48,966
about moving from
QuickTime and QTKit


546
00:28:48,966 --> 00:28:55,266
to AV foundation and AV Kit.


547
00:28:55,266 --> 00:28:57,196
[ Applause ]


548
00:28:57,196 --> 00:28:57,756
>> Thank you Stefan.


549
00:28:57,906 --> 00:28:59,816e
All right.


550
00:29:00,816 --> 00:29:03,446
So for the rest of this
talk, we're going to talk


551
00:29:03,446 --> 00:29:07,876
about what's involved in
migrating an existing QuickTime


552
00:29:07,876 --> 00:29:11,716
or QTKit application over
to AV Foundation and AV Kit.


553
00:29:12,186 --> 00:29:15,316
How will you get
to AV Foundation?


554
00:29:15,426 --> 00:29:18,786
Well, it depends on how you use
QuickTime and how you use QTKit.


555
00:29:19,246 --> 00:29:21,186
For some developers, it will
be a pretty easy change,


556
00:29:21,256 --> 00:29:24,416
but for others it may
require more refactoring


557
00:29:24,416 --> 00:29:25,666
and deeper thought.


558
00:29:26,246 --> 00:29:28,616
We're not providing
an API for API swap.


559
00:29:28,616 --> 00:29:32,186
We've taken the opportunity
to change the API model


560
00:29:32,186 --> 00:29:34,096
where we think it can
make AV Foundation better.


561
00:29:35,116 --> 00:29:38,106
That said, some of the more
recently developed QTKit APIs,


562
00:29:38,106 --> 00:29:39,876
were actually developed
around the same time


563
00:29:39,876 --> 00:29:41,496
as their AV Foundation
counterparts


564
00:29:41,856 --> 00:29:43,746
and so they have a
very similar API feel.


565
00:29:44,246 --> 00:29:49,906
So, we're going to go through a
bunch of API areas and for each


566
00:29:49,906 --> 00:29:51,876
of these API areas
I will show you--


567
00:29:51,876 --> 00:29:54,896
I'll have some reminders
of the kind of QuickTime


568
00:29:54,896 --> 00:29:57,886
and QTKit APIs you would
have used and then focus


569
00:29:57,886 --> 00:30:00,736
on the AV Foundations
version and some of the things


570
00:30:00,736 --> 00:30:01,566
that make that interesting.


571
00:30:02,076 --> 00:30:07,146
So let's start with the basics.


572
00:30:07,276 --> 00:30:10,396
In QuickTime, every AV
resource in use is represented


573
00:30:10,396 --> 00:30:13,936
by capital M, movie
object and for every track,


574
00:30:14,156 --> 00:30:16,666
there is a track object
and a media object.


575
00:30:16,776 --> 00:30:19,326
And QTKit has classes
wrapping all of these.


576
00:30:20,056 --> 00:30:22,536
In AV Foundation, AV
resources are represented


577
00:30:22,536 --> 00:30:26,046
by the AVAsset class and
for every track there is


578
00:30:26,046 --> 00:30:27,066
an AVAssetTrack.


579
00:30:27,816 --> 00:30:31,226
What's different in AV
Foundation is that AVAsset


580
00:30:31,226 --> 00:30:33,476
and AVAssetTrack are immutable.


581
00:30:33,756 --> 00:30:37,016
They provide a read-only
view of the AV resource.


582
00:30:40,916 --> 00:30:44,616
QuickTime and QTKit
have a number of APIs


583
00:30:45,256 --> 00:30:48,126
for creating a movie
or QTMovie object.


584
00:30:49,056 --> 00:30:51,606
In this simplest form they
all operate synchronously


585
00:30:52,436 --> 00:30:57,026
which means that your main
thread is blocked while


586
00:30:57,566 --> 00:31:02,296
QuickTime and QTKit go off and
unload the file and parse it.


587
00:31:03,216 --> 00:31:05,506
With AV Foundation,
creating an AVAsset


588
00:31:05,506 --> 00:31:10,986
from a URL always finishes
very quickly and succeeds,


589
00:31:11,326 --> 00:31:15,816
that's because it hasn't
actually done anything yet.


590
00:31:15,816 --> 00:31:19,586
You can then use the
asynchronous property loading


591
00:31:19,786 --> 00:31:24,596
API to request that AV
Foundation load values--


592
00:31:24,596 --> 00:31:26,596
load some properties
asynchronously


593
00:31:26,886 --> 00:31:29,606
and provide a block that'll
be called when data--


594
00:31:29,906 --> 00:31:32,176
when enough data has
been read and parsed


595
00:31:32,606 --> 00:31:33,836
to produce those values.


596
00:31:35,146 --> 00:31:40,046
So this lets that happen off
on another background queue


597
00:31:40,146 --> 00:31:41,956
and lets you keep the
main thread responsive.


598
00:31:42,456 --> 00:31:45,536
[ Pause ]


599
00:31:46,036 --> 00:31:49,896
In QuickTime and QTKit, the
same movie object is the one


600
00:31:49,896 --> 00:31:54,166
that you would call to
start playback or to pause


601
00:31:54,306 --> 00:31:56,766
or to set the time or to step.


602
00:31:56,796 --> 00:31:58,256
These are called
transport controls.


603
00:31:59,516 --> 00:32:01,846
With AV Foundation,
we have separated


604
00:32:01,846 --> 00:32:05,786
out the mutable state related to
playback into playback objects.


605
00:32:06,636 --> 00:32:10,586
The principle playback object
is called AVPlayer and that's


606
00:32:10,586 --> 00:32:12,556
where you send rate changes


607
00:32:12,556 --> 00:32:14,516
and that means play
and pause as well.


608
00:32:17,126 --> 00:32:22,336
Now, AVPlayer is designed to be
able to play through a sequence


609
00:32:22,336 --> 00:32:26,756
of AVAssets, automatically
advancing


610
00:32:26,756 --> 00:32:30,026
when each reaches its
end time, in some cases


611
00:32:30,026 --> 00:32:31,256
with gapless transitions.


612
00:32:31,806 --> 00:32:36,016
So this design goal
led us to take


613
00:32:36,016 --> 00:32:41,226
out the per item state
related to playback


614
00:32:41,556 --> 00:32:43,726
into its own object
called AVPlayerItem.


615
00:32:44,456 --> 00:32:47,266
This is where you
tell-- this is the object


616
00:32:47,266 --> 00:32:52,206
that you send messages
to seek and to step.


617
00:32:52,206 --> 00:32:55,136
AVPlayer's subclass
AVQueuePlayer can play


618
00:32:55,136 --> 00:32:56,966
through a sequence
of AVPlayerItems


619
00:32:57,206 --> 00:32:59,236
and each will advance when
it reaches its end time.


620
00:33:00,436 --> 00:33:02,986
So this is an example of how
we've refactored the object


621
00:33:02,986 --> 00:33:07,666
in order to give us more
flexibility in the API.


622
00:33:07,886 --> 00:33:11,126
Another thing to know is
that AVPlayerItems default


623
00:33:11,346 --> 00:33:14,126
when you seek is to
snap to a keyframe.


624
00:33:14,706 --> 00:33:19,466
This is because keyframe is
the most efficient display


625
00:33:19,466 --> 00:33:21,926
for random access and
also the most efficient


626
00:33:21,956 --> 00:33:23,006
to start playback from.


627
00:33:23,586 --> 00:33:26,376
But there's a variant
of seekToTime


628
00:33:26,576 --> 00:33:28,596
where you can specify
a tolerance range.


629
00:33:29,576 --> 00:33:30,836
If there's a keyframe inside


630
00:33:30,836 --> 00:33:32,576
that tolerance range
then we'll snap to it.


631
00:33:32,856 --> 00:33:34,246
If there's no keyframe inside


632
00:33:34,246 --> 00:33:35,826
that tolerance range
then we'll snap--


633
00:33:35,826 --> 00:33:38,416
it will seek exactly
the time you specified.


634
00:33:38,926 --> 00:33:43,956
If you specified tolerance of
0 then we always seek exactly


635
00:33:43,956 --> 00:33:45,036
to the time you specified.


636
00:33:45,536 --> 00:33:51,706
If you've used the
QTMovieView to integrate


637
00:33:51,706 --> 00:33:53,766
into a view hierarchy
then you should check


638
00:33:53,766 --> 00:33:56,496
out the new AVPlayerView
class in AV Kit


639
00:33:57,026 --> 00:33:58,446
that Stefan demonstrated.


640
00:33:59,636 --> 00:34:02,096
One thing that's different
if you used a QTMovieView is


641
00:34:02,336 --> 00:34:05,876
that the transport control
methods are not re-exported


642
00:34:05,876 --> 00:34:07,046
by the view object.


643
00:34:07,566 --> 00:34:10,196
You make those calls directly
on the underlying AVPlayer.


644
00:34:10,876 --> 00:34:16,216
And AV Foundation provides
the AVPlayerLayer class


645
00:34:16,216 --> 00:34:19,846
for integrating into a Core
Animation layer hierarchy.


646
00:34:20,806 --> 00:34:24,505
It also provides the
AVSynchronizedLayer class


647
00:34:24,906 --> 00:34:28,416
for synchronizing Core
Animation layer animations


648
00:34:28,936 --> 00:34:31,176
to match the time
of a playerItem


649
00:34:32,556 --> 00:34:36,876
as the playerItem's time and
rate change, so will the time


650
00:34:36,876 --> 00:34:40,436
and rate of that
synchronized layer.


651
00:34:40,656 --> 00:34:43,525
We've demonstrated in
previous year's sessions how


652
00:34:43,525 --> 00:34:46,985
to use this class for
editing applications.


653
00:34:47,505 --> 00:34:49,246
But there are other
ways you could use it


654
00:34:49,246 --> 00:34:50,815
that aren't editing
applications as well.


655
00:34:51,246 --> 00:34:57,065
Another thing to know is that
in applications linked on


656
00:34:57,065 --> 00:35:02,626
or after iOS 7 or on or
after Mavericks by default,


657
00:35:02,626 --> 00:35:08,146
AVPlayerLayer and AVPlayerView
will both honor the user's


658
00:35:08,786 --> 00:35:11,796
choices for media accessibility
by-- automatically.


659
00:35:12,896 --> 00:35:14,506
This may not work
in the current seed


660
00:35:14,506 --> 00:35:15,936
but it will work fine
in the next seed.


661
00:35:16,416 --> 00:35:21,686
We have a session coming
up tomorrow on preparing


662
00:35:21,686 --> 00:35:23,416
and presenting media for
accessibility that goes


663
00:35:23,416 --> 00:35:27,896
into more details about what it
means for the playback pipeline


664
00:35:28,476 --> 00:35:30,836
to honor the user's media
accessibility options.


665
00:35:31,366 --> 00:35:37,186
Let's move on to
authoring and editing APIs.


666
00:35:39,276 --> 00:35:43,486
QuickTime has a number of high
level movie transcoding APIs


667
00:35:43,486 --> 00:35:45,086
and these are all synchronous.


668
00:35:45,636 --> 00:35:49,506
And QTMovie has a
writeToFile method


669
00:35:49,686 --> 00:35:52,336
which wraps these
synchronous APIs.


670
00:35:52,776 --> 00:35:54,466
And in QuickTime-- sorry,


671
00:35:54,466 --> 00:36:01,336
in OS 10.7 we introduced
an asynchronous


672
00:36:01,586 --> 00:36:03,026
QTExportSession API.


673
00:36:04,306 --> 00:36:05,376
Well, AV Foundation's,


674
00:36:05,376 --> 00:36:08,786
AVAssetExportSession
API is also asynchronous


675
00:36:09,296 --> 00:36:11,646
and it's internal pipeline
is deeply multithreaded.


676
00:36:12,896 --> 00:36:14,876
It's also preset
based which means


677
00:36:14,876 --> 00:36:18,216
that you can offer your users
high level options like 1280


678
00:36:18,216 --> 00:36:22,216
by 720, and let AV Foundation
choose a well tuned bit-rate


679
00:36:22,216 --> 00:36:22,866
for the encoding.


680
00:36:23,706 --> 00:36:26,966
If you need more control
or if you need access


681
00:36:26,966 --> 00:36:29,916
to the media frames--
the data that's going--


682
00:36:29,916 --> 00:36:32,306
going through the pipeline then
you can use the combination


683
00:36:32,306 --> 00:36:36,226
of the AVAssetReader and
AVAssetWriter classes.


684
00:36:40,826 --> 00:36:45,996
With QuickTime, the APIs that
you'd use for reading media data


685
00:36:45,996 --> 00:36:47,806
from a file were
different depending


686
00:36:47,806 --> 00:36:50,546
on whether you wanted the data
be decoded or not decoded.


687
00:36:51,406 --> 00:36:52,386
With AV Foundation,


688
00:36:52,426 --> 00:36:56,706
AVAssetReader provides
features for both of these.


689
00:36:57,156 --> 00:36:58,806
It depends on how
you configure it.


690
00:36:59,126 --> 00:37:01,186
When you create the
AVAssetReader output


691
00:37:01,516 --> 00:37:03,726
to decode data-- to
retrieve data from a track,


692
00:37:04,326 --> 00:37:07,856
if you pass an output settings
dictionary then we will decode


693
00:37:07,856 --> 00:37:09,366
data into the format
you request.


694
00:37:09,656 --> 00:37:13,716
If you pass a nil outputSettings
dictionary then we won't


695
00:37:13,716 --> 00:37:14,726
decode it.


696
00:37:16,616 --> 00:37:20,026
Now, I should note
that the QuickTime APIs


697
00:37:20,196 --> 00:37:23,136
for reading video
data are synchronous.


698
00:37:23,256 --> 00:37:24,646
They don't begin loading


699
00:37:24,646 --> 00:37:27,746
and decoding video data
until you request it.


700
00:37:28,686 --> 00:37:33,546
By contrast, AVAssetReaders
pipeline inside is


701
00:37:33,696 --> 00:37:34,676
deeply multithreaded.


702
00:37:37,776 --> 00:37:41,206
The file reading,
the video decoding,


703
00:37:41,206 --> 00:37:45,436
and the audio decoding
all happen asynchronously


704
00:37:45,606 --> 00:37:46,606
and in parallel.


705
00:37:49,076 --> 00:37:53,366
This means that when you-- when
you pull a new media sample


706
00:37:53,366 --> 00:37:56,196
out of the queues at the end
the latency when you make


707
00:37:56,196 --> 00:37:57,516
that request is very, very low.


708
00:37:57,916 --> 00:37:59,446
It has probably already
decoded it


709
00:37:59,676 --> 00:38:02,936
in the background while you were
working on the previous frame.


710
00:38:05,616 --> 00:38:09,586
The QuickTime APIs for writing
media files are also synchronous


711
00:38:09,586 --> 00:38:10,966
and the same with QTKit.


712
00:38:11,926 --> 00:38:14,486
AV Foundation provides
the AVAssetWriter API


713
00:38:15,086 --> 00:38:18,646
and its pipeline is, you guessed
it, deeply multithreaded.


714
00:38:20,066 --> 00:38:23,606
And you can configure it to
encode data, encode the video


715
00:38:23,606 --> 00:38:26,656
for you-- encode the audio
for you or you can use it


716
00:38:26,846 --> 00:38:31,456
to write already prepared
data to a movie file.


717
00:38:31,756 --> 00:38:34,246
AVAssetWriter also provides
you much more control


718
00:38:34,246 --> 00:38:35,336
over how you encode.


719
00:38:36,616 --> 00:38:38,836
For some developers they find


720
00:38:38,836 --> 00:38:40,456
that this control is
actually too much control


721
00:38:40,456 --> 00:38:41,806
and they want preset access.


722
00:38:42,276 --> 00:38:43,396
They'd like to be
able to use presets


723
00:38:43,396 --> 00:38:44,896
like AVAssetExportSession.


724
00:38:45,316 --> 00:38:46,646
Well, that's what we've
done in Mavericks,


725
00:38:46,906 --> 00:38:48,656
we've added
AVOutputSettingsAssistant


726
00:38:48,946 --> 00:38:51,816
which lets you use
presets as a starting point


727
00:38:51,816 --> 00:38:55,336
for picking good output
settings for AVAssetWriter.


728
00:38:57,206 --> 00:38:59,656
So, AVOutputSettingsAssistant
is new


729
00:38:59,656 --> 00:39:06,066
in Mavericks and new in iOS 7.


730
00:39:06,166 --> 00:39:09,336
Also in the session tomorrow on
preparing and presenting media


731
00:39:09,336 --> 00:39:11,686
for accessibility we'll go
into more detail about how


732
00:39:11,686 --> 00:39:15,586
to use AVAssetWriter to
construct subtitle tracks


733
00:39:16,046 --> 00:39:17,496
and alternate audio tracks.


734
00:39:17,496 --> 00:39:21,436
But let me go into more detail


735
00:39:21,436 --> 00:39:24,566
about the internal
pipeline of AVAssetWriter.


736
00:39:25,276 --> 00:39:28,466
Like I said it's deeply
multithreaded which means


737
00:39:28,806 --> 00:39:33,806
that the video encoding
and the audio encoding,


738
00:39:33,806 --> 00:39:37,026
and the file writing can
all happen asynchronously


739
00:39:37,026 --> 00:39:38,946
and in parallel with each other.


740
00:39:42,076 --> 00:39:44,146
But let's think about
how we construct movies,


741
00:39:44,596 --> 00:39:47,556
in order to construct a movie
for efficient playback we want


742
00:39:47,556 --> 00:39:49,976
to alternate, we want to
interleave, audio and video


743
00:39:49,976 --> 00:39:51,896
and any of the track types.


744
00:39:52,216 --> 00:39:54,596
This means that the
file writing queue,


745
00:39:54,596 --> 00:39:58,616
the file writing process inside
AVAssetWriter will alternate


746
00:39:58,956 --> 00:40:01,296
between the different
tracks, writing a portion


747
00:40:01,296 --> 00:40:05,096
of media data from each in turn.


748
00:40:05,296 --> 00:40:09,956
Well, this means that sometimes,
if that file writing code runs


749
00:40:09,956 --> 00:40:11,396
out of data on one track,


750
00:40:12,246 --> 00:40:15,846
then pretty soon it will
stop consuming media data


751
00:40:15,846 --> 00:40:18,576
on the other tracks until there
is more data on that track


752
00:40:18,576 --> 00:40:19,426
that it's waiting for.


753
00:40:20,336 --> 00:40:22,846
In fact, at some point it's
going to need to be able to say


754
00:40:22,846 --> 00:40:24,986
to you at the API level, "Stop.


755
00:40:24,986 --> 00:40:27,266
I'm not ready for more.


756
00:40:27,266 --> 00:40:29,876
I don't want more data on these
tracks until I have more data


757
00:40:29,876 --> 00:40:32,356
on that track," or for
you to say, "Actually,


758
00:40:32,356 --> 00:40:34,586
I'm completely done giving
you data on that other track."


759
00:40:35,686 --> 00:40:43,236
So, there is a flow control API
built into AVAssetWriter input


760
00:40:43,846 --> 00:40:45,326
where you can query to say,


761
00:40:45,326 --> 00:40:47,466
"Is this input ready
for more media data?"


762
00:40:47,526 --> 00:40:50,556
And there's also an API
utility where you can ask it


763
00:40:50,556 --> 00:40:53,716
to call a block over and
over and over just as long


764
00:40:53,716 --> 00:40:55,906
as it's ready for more input.


765
00:40:58,236 --> 00:41:02,756
If you wanted to get access to
video frames during playback,


766
00:41:03,096 --> 00:41:07,056
for example, to integrate them
into a custom OpenGL rendering,


767
00:41:07,646 --> 00:41:10,416
QuickTime and QTKit provided
a way that you could set


768
00:41:10,416 --> 00:41:13,336
up a visual context to
retrieve those video frames.


769
00:41:14,336 --> 00:41:16,236
AV Foundation's API
for doing this is


770
00:41:16,236 --> 00:41:18,406
called AVPlayerItemVideoOutput.


771
00:41:18,916 --> 00:41:22,876
And similarly, there
was also a way,


772
00:41:22,876 --> 00:41:24,786
that you could set
up an audio context.


773
00:41:25,346 --> 00:41:28,206
And the audio context was
a way that you could tap


774
00:41:28,206 --> 00:41:32,086
into the audio waveform as it
went past, either for analysis


775
00:41:32,316 --> 00:41:33,786
or even to modify the waveform


776
00:41:33,786 --> 00:41:36,386
to provide some kind
of audio effect.


777
00:41:37,576 --> 00:41:40,796
AV Foundation in Mavericks
provides this API as well.


778
00:41:41,066 --> 00:41:44,266
It's called an audio
processing tap and it's an API


779
00:41:44,316 --> 00:41:47,736
that you install an
object onto an AV audio mix


780
00:41:48,306 --> 00:41:52,016
and then you can install that AV
audio mix on to an AVPlayerItem


781
00:41:52,906 --> 00:41:55,186
or on to an
AVAssetExportSession,


782
00:41:55,776 --> 00:42:00,196
or onto an
AVAssetReaderAudioMixOutput.


783
00:42:01,086 --> 00:42:08,246
(It's like Dr. Seuss.)


784
00:42:08,436 --> 00:42:10,016
Sometimes, you just want
to get a still image


785
00:42:10,016 --> 00:42:12,296
out of a video file,


786
00:42:12,296 --> 00:42:14,496
QTKit provided a utility
method for doing this.


787
00:42:14,496 --> 00:42:16,436
AV Foundation provides
a whole class


788
00:42:16,756 --> 00:42:20,906
and this class has both a
synchronous one-shot API


789
00:42:20,906 --> 00:42:23,276
and an asynchronous batch API.


790
00:42:26,636 --> 00:42:30,646
Editing. So, all three
of these, QuickTime,


791
00:42:30,646 --> 00:42:35,086
QTKit and AV Foundation - all
provide APIs for inserting,


792
00:42:35,086 --> 00:42:39,306
deleting, and scaling segments
expressed as time ranges


793
00:42:39,806 --> 00:42:42,786
and these are really high level,
powerful APIs that you can use


794
00:42:43,146 --> 00:42:49,346
to deliver high level user
focused editing experiences.


795
00:42:49,866 --> 00:42:55,616
With QuickTime and QTKit,
these are methods on the movie


796
00:42:55,616 --> 00:42:57,066
and the QTMovie objects.


797
00:42:57,496 --> 00:42:59,706
With AV Foundation,
AVAsset is immutable.


798
00:42:59,706 --> 00:43:00,876
So it can't be there.


799
00:43:00,876 --> 00:43:03,996
Instead, we have subclass of
AVAsset called AVComposition


800
00:43:04,486 --> 00:43:07,046
and it has immutable
and mutable variants.


801
00:43:08,026 --> 00:43:12,356
Similarly, AVAssetTrack
has AVCompositionTrack


802
00:43:12,356 --> 00:43:14,546
and there's an
AVMutableCompositionTrack


803
00:43:14,546 --> 00:43:14,866
as well.


804
00:43:16,176 --> 00:43:17,126
But it is important to know


805
00:43:17,126 --> 00:43:19,706
that the API model is actually
different in AV Foundation.


806
00:43:20,416 --> 00:43:23,266
This is a bit of an
advanced topic here.


807
00:43:24,396 --> 00:43:27,516
But in all three
cases, QuickTime, QTKit,


808
00:43:27,516 --> 00:43:31,126
and AV Foundation,
these editing APIs work


809
00:43:31,206 --> 00:43:34,576
by manipulating a data
structure called an edit list.


810
00:43:35,486 --> 00:43:41,606
An edit list is part of a track
inside the corresponding objects


811
00:43:42,346 --> 00:43:46,496
and it is a data structure
that says play A for B seconds


812
00:43:46,496 --> 00:43:49,596
and then play C for
D seconds, and so on.


813
00:43:50,906 --> 00:43:55,566
Well, with QuickTime and QTKit,
to insert a segment of one movie


814
00:43:55,566 --> 00:43:58,786
into another requires a bunch
of sample table copying.


815
00:43:59,526 --> 00:44:04,916
This is because in this API, a
movie's edit list can only refer


816
00:44:04,916 --> 00:44:06,836
to that own movie's
sample tables.


817
00:44:07,396 --> 00:44:14,496
AV Foundation's AVComposition's
edit lists do not require


818
00:44:14,566 --> 00:44:17,296
that the sample table
be in the same asset.


819
00:44:17,756 --> 00:44:21,006
So, it isn't necessary for
the sample table copying


820
00:44:21,006 --> 00:44:23,776
to have occurred and that
makes it a bit more efficient


821
00:44:23,776 --> 00:44:24,656
when you're doing the editing.


822
00:44:24,886 --> 00:44:26,996
It also means that if
you insert a bunch of--


823
00:44:27,186 --> 00:44:30,006
insert a bunch of clips and then
you delete them, you're not left


824
00:44:30,006 --> 00:44:33,646
with leftover sample table
references that you don't need.


825
00:44:34,616 --> 00:44:37,936
Another way of thinking
about this is that QuickTime


826
00:44:37,936 --> 00:44:40,606
and AV Foundation
have different ways


827
00:44:40,606 --> 00:44:41,896
that they do their references.


828
00:44:42,396 --> 00:44:46,936
AV Foundation is using a
segment-level file reference


829
00:44:47,716 --> 00:44:50,736
and QuickTime and QTKit are
using a sample-level reference.


830
00:44:51,276 --> 00:44:57,196
If you have been using
the QTKit metadata API,


831
00:44:57,726 --> 00:44:59,036
then here's some good news.


832
00:44:59,516 --> 00:45:03,556
AV Foundation's AVMetadataItem
API is very similar.


833
00:45:04,086 --> 00:45:05,446
In fact, if you look up there,


834
00:45:05,446 --> 00:45:07,646
you might be hard pressed
to find a difference.


835
00:45:08,076 --> 00:45:10,406
Well, one little difference
that's on the slide is


836
00:45:10,406 --> 00:45:12,666
that it's using Objective-C
property,


837
00:45:13,026 --> 00:45:18,336
Objective-C 2 property, API's as
a way of describing the methods.


838
00:45:18,336 --> 00:45:19,276
That's not really
so interesting.


839
00:45:19,276 --> 00:45:21,386
The more interesting thing is


840
00:45:21,826 --> 00:45:26,076
that metadata is no
longer loaded eagerly.


841
00:45:28,896 --> 00:45:31,076
So, just like those
other properties


842
00:45:31,076 --> 00:45:33,496
that you can use the
asynchronous key value loading


843
00:45:33,576 --> 00:45:36,166
API, you use the
same API to request


844
00:45:36,166 --> 00:45:38,206
that the metadata be
loaded and it can be loaded


845
00:45:38,206 --> 00:45:40,496
on the background thread and
keep your main thread free


846
00:45:40,856 --> 00:45:43,966
up for user responsiveness.


847
00:45:44,486 --> 00:45:49,656
Let's move on to capture APIs.


848
00:45:49,656 --> 00:45:49,723
[ Pause ]


849
00:45:49,723 --> 00:46:00,006
The QTKit and AV Foundation
capture APIs are also broadly


850
00:46:00,006 --> 00:46:00,606
very similar.


851
00:46:01,156 --> 00:46:09,076
In both cases, you have a
capture session object and for


852
00:46:09,266 --> 00:46:12,276
that capture session
object you add inputs


853
00:46:12,886 --> 00:46:15,276
and outputs, and previews.


854
00:46:17,886 --> 00:46:20,576
Now, with QTKit and AV
Foundation, in both of those,


855
00:46:20,576 --> 00:46:26,346
there is a simple mode of the
API in which you automatically--


856
00:46:26,686 --> 00:46:28,426
sorry, in which the session
automatically helps you build


857
00:46:28,426 --> 00:46:28,966
the connections.


858
00:46:29,536 --> 00:46:32,576
When you add the
inputs and the outputs,


859
00:46:32,946 --> 00:46:34,996
it automatically builds
capture connections


860
00:46:35,176 --> 00:46:36,546
by matching media types.


861
00:46:36,756 --> 00:46:40,826
So, it links up all of the video
inputs to outputs and it links


862
00:46:40,826 --> 00:46:42,906
up all of the audio
inputs to audio outputs.


863
00:46:43,546 --> 00:46:46,776
But with AV Foundation there
is also an alternative more


864
00:46:46,776 --> 00:46:50,096
advanced form of the API, and
in this more advanced form,


865
00:46:50,476 --> 00:46:53,726
you use a different method and
you say, "No connections please.


866
00:46:53,856 --> 00:46:55,706
I don't want you to build the
connections automatically.


867
00:46:56,026 --> 00:46:58,746
I will make explicit calls
to set them up myself."


868
00:46:59,216 --> 00:47:02,346
And this is a better choice if
you have multiple video inputs,


869
00:47:02,346 --> 00:47:05,786
multiple cameras, or if
you have multiple previews,


870
00:47:06,036 --> 00:47:07,766
or if you have multiple
file outputs


871
00:47:08,836 --> 00:47:12,106
because you can construct
exactly the graph that you want


872
00:47:13,246 --> 00:47:14,996
by constructing those
connections yourself.


873
00:47:17,246 --> 00:47:23,696
So, going through the inputs
and outputs, most of the inputs


874
00:47:23,696 --> 00:47:26,296
and outputs are the same but
there are some extensions


875
00:47:26,346 --> 00:47:27,336
and some improvements.


876
00:47:28,066 --> 00:47:32,546
AV Foundation has a CaptureInput
object for capturing


877
00:47:32,546 --> 00:47:35,616
from the screen and we've
done some work in Mavericks


878
00:47:35,876 --> 00:47:38,036
to improve performance
of screen capture


879
00:47:38,136 --> 00:47:40,676
when the cursor is visible
in the captured frames.


880
00:47:41,176 --> 00:47:43,176
[ Pause ]


881
00:47:43,676 --> 00:47:48,676
In QTKit when you added
a video preview layer,


882
00:47:48,896 --> 00:47:51,176
it would automatically
create a video preview output


883
00:47:51,236 --> 00:47:53,766
and that output object
was how you configured


884
00:47:53,766 --> 00:47:54,566
certain properties.


885
00:47:56,536 --> 00:47:59,016
Well, we no longer--
in AV Foundation,


886
00:47:59,016 --> 00:48:02,976
we don't have the video preview
output object, we've folded all


887
00:48:02,976 --> 00:48:05,906
of those configuration APIs
into the video preview layer.


888
00:48:05,906 --> 00:48:08,206
So, they're just one
stop for you to access


889
00:48:08,206 --> 00:48:09,586
to get those configured.


890
00:48:10,116 --> 00:48:12,426
And the video data output


891
00:48:12,426 --> 00:48:16,636
and the audio data output
can produce both uncompressed


892
00:48:16,636 --> 00:48:19,836
or compressed data,
and if available


893
00:48:19,836 --> 00:48:21,006
on the hardware you're using,


894
00:48:21,006 --> 00:48:23,876
the video encoding will
be hardware accelerated.


895
00:48:24,286 --> 00:48:28,196
And there's also an audio file
output to write to an audio file


896
00:48:28,196 --> 00:48:30,486
like a CAF file and
there's an output


897
00:48:30,716 --> 00:48:33,776
for writing a still
image, for example,


898
00:48:33,776 --> 00:48:34,806
when you take the photograph.


899
00:48:35,976 --> 00:48:38,966
Another thing to know
about the output object is


900
00:48:38,966 --> 00:48:40,376
that whenever there's
a delegate,


901
00:48:41,616 --> 00:48:43,456
object that you can install,


902
00:48:43,456 --> 00:48:47,676
you can also specify what
dispatch queue your delegate


903
00:48:47,906 --> 00:48:52,326
callback will be called on.


904
00:48:52,326 --> 00:48:58,236
The device discovery APIs you
can see here is very similar.


905
00:48:58,236 --> 00:49:01,496
In both cases, there's an API to
get all devices, there's an API


906
00:49:01,496 --> 00:49:03,446
to get all the devices
with particular media type.


907
00:49:03,806 --> 00:49:05,386
The default device
with the media type,


908
00:49:05,716 --> 00:49:07,076
and if you already
know a unique ID,


909
00:49:07,076 --> 00:49:09,046
you can get that device as well.


910
00:49:09,606 --> 00:49:13,726
What's different with
AV Foundation is a piece


911
00:49:13,816 --> 00:49:20,056
of final deprecation with
QTKit in a 32-bit app,


912
00:49:21,076 --> 00:49:25,516
the old ancient QuickTime
sequence grabber video digitizer


913
00:49:25,516 --> 00:49:28,356
components were grandfathered
into the device input list.


914
00:49:28,896 --> 00:49:32,886
AV Foundation does not
grandfather those old sequence


915
00:49:32,886 --> 00:49:33,556
grabber components.


916
00:49:33,816 --> 00:49:37,146
It only supports the
modern DAL and HAL devices.


917
00:49:41,296 --> 00:49:43,986
And AV Foundation provides
that video preview layer


918
00:49:43,986 --> 00:49:47,316
like we discussed and
the interfaces that used


919
00:49:47,316 --> 00:49:49,646
to be configured through the
video preview output object


920
00:49:49,646 --> 00:49:52,016
and now ones you access
through the preview layer.


921
00:49:52,566 --> 00:49:55,166
There's no direct analog
to the QTKit capture view


922
00:49:55,436 --> 00:49:58,486
but you can take that layer
and put inside a view just


923
00:49:58,486 --> 00:50:01,076
like you would with any
other core animation layer.


924
00:50:02,806 --> 00:50:04,906
So we've gone through a
bunch of high level things.


925
00:50:05,146 --> 00:50:08,956
Let's dig down into
some low level stuff,


926
00:50:09,266 --> 00:50:10,566
beginning with time.


927
00:50:12,126 --> 00:50:16,626
We, in media systems, are of
the opinion that the right way


928
00:50:16,626 --> 00:50:20,886
to represent time in a media
system is as a rational number.


929
00:50:21,906 --> 00:50:25,686
Floating point numbers will
almost always introduce some


930
00:50:25,686 --> 00:50:28,686
kind of rounding error because
the numbers never have--


931
00:50:28,686 --> 00:50:30,586
never happen to be expressed--


932
00:50:30,586 --> 00:50:32,586
exactly expressible as
floating point numbers.


933
00:50:33,946 --> 00:50:35,676
And when you add this up by
the millions, they can lead


934
00:50:35,676 --> 00:50:37,166
up to measurable drift.


935
00:50:37,546 --> 00:50:39,166
So, we use rational numbers.


936
00:50:39,436 --> 00:50:42,036
And in order to support
really long media files,


937
00:50:42,036 --> 00:50:45,256
you need to use a 64-bit time
value and a 32-bit time scale.


938
00:50:45,476 --> 00:50:47,336
The time value is our
name for the numerator


939
00:50:47,336 --> 00:50:49,696
and the time scale is our
name for the denominator.


940
00:50:51,776 --> 00:50:55,586
Now, QuickTime had
a 64-bit numerator,


941
00:50:55,586 --> 00:50:58,686
32-bit denominator time
object called the TimeRecord.


942
00:50:59,176 --> 00:51:01,466
But, in the very early 1990s,


943
00:51:02,436 --> 00:51:05,016
doing 64-bit math
was really awkward.


944
00:51:05,656 --> 00:51:10,956
And so, there were shortcuts
where you'd pass a time value


945
00:51:10,956 --> 00:51:12,486
that was a just a
32-bit time value.


946
00:51:13,306 --> 00:51:15,526
And these shortcuts looked


947
00:51:15,526 --> 00:51:17,266
like they were good
conveniences 'cause, you know,


948
00:51:17,266 --> 00:51:18,996
most movies were that
short, that's fine.


949
00:51:19,216 --> 00:51:20,716
But unfortunately, they
were also shortcuts


950
00:51:20,716 --> 00:51:22,636
that were taken inside
QuickTime and that meant


951
00:51:22,636 --> 00:51:23,786
that you couldn't
really take advantage


952
00:51:23,786 --> 00:51:25,166
of that full 64-bit size.


953
00:51:25,756 --> 00:51:30,306
QTKit has a QTTime which is a
struct for the 64-bit numerator


954
00:51:30,306 --> 00:51:32,266
and 32-bit denominator
used in many of its APIs.


955
00:51:32,266 --> 00:51:35,036
It's great, but it's
still using QuickTime


956
00:51:35,036 --> 00:51:36,096
for playback and editing.


957
00:51:36,096 --> 00:51:37,226
And so, it was kind of hamstrung


958
00:51:37,226 --> 00:51:38,506
by that limitation
in the pipeline.


959
00:51:38,506 --> 00:51:42,726
But with AV Foundation
just like QTKit,


960
00:51:42,796 --> 00:51:46,556
we have a struct called CMTime
which has a 64-bit numerator,


961
00:51:46,556 --> 00:51:48,776
a 32-bit denominator, and
a bunch of other cool stuff


962
00:51:48,776 --> 00:51:50,446
that you can look
in the header file.


963
00:51:50,806 --> 00:51:53,886
And just like QTKit, there's
a time range a CMTime range


964
00:51:53,996 --> 00:51:59,526
expressed as two times-- as two
CMTimes, a start and a duration.


965
00:52:00,176 --> 00:52:03,066
And there's also a
CMTimeMapping which is expressed


966
00:52:03,066 --> 00:52:05,686
as two time ranges, a
source and a target,


967
00:52:05,686 --> 00:52:07,066
and that's used in
some editing APIs.


968
00:52:07,066 --> 00:52:12,376
But the really good news is
there's no 32-bit shortcut


969
00:52:12,376 --> 00:52:14,366
which means we didn't use
a 32-bit shortcut either


970
00:52:14,366 --> 00:52:16,686
and you can use that
full 64-bit size.


971
00:52:18,116 --> 00:52:21,136
The APIs, the objects
that represent time


972
00:52:21,136 --> 00:52:22,416
when it's moving
are very similar.


973
00:52:22,486 --> 00:52:23,916
In both cases, there's
a clock object


974
00:52:23,916 --> 00:52:26,346
that represents an external
source of moving time


975
00:52:26,866 --> 00:52:28,366
which is not under
program control


976
00:52:28,366 --> 00:52:30,846
and then there's a timebase
that you can set the rate


977
00:52:30,846 --> 00:52:32,146
and set the time and so forth.


978
00:52:32,196 --> 00:52:35,886
And the timebase's time
comes from its master


979
00:52:35,886 --> 00:52:37,936
which could be a clock
or another timebase.


980
00:52:38,386 --> 00:52:40,716
That's a model that we
like and we've continued.


981
00:52:44,496 --> 00:52:48,486
QuickTime, in some places
QTKit, would use a--


982
00:52:48,646 --> 00:52:52,516
non-opaque data structure called
the SampleDescriptionHandle


983
00:52:52,516 --> 00:52:55,096
to describe compressed data.


984
00:52:56,886 --> 00:52:59,436
Originally, it was read
and written directly


985
00:52:59,436 --> 00:53:01,426
from movie files
and that was great


986
00:53:01,426 --> 00:53:03,536
when everything was big-endian
and the file is big-endian,


987
00:53:03,536 --> 00:53:06,056
and the Mac is big-endian,
woo-hoo, but then we ported


988
00:53:06,056 --> 00:53:09,736
to Intel processors and we had
to endian flip it and we had


989
00:53:09,736 --> 00:53:12,166
to have rather complicated
rules for how you endian flip it


990
00:53:12,616 --> 00:53:15,746
and some pieces stay big-endian
in memory and that's kind


991
00:53:15,746 --> 00:53:16,876
of weird to deal with as well.


992
00:53:16,876 --> 00:53:18,896
So, we've learned that lesson


993
00:53:19,656 --> 00:53:22,796
and now we have a rather
nice FormatDescription object


994
00:53:22,796 --> 00:53:23,816
which has a clean API.


995
00:53:23,816 --> 00:53:27,926
And we also had a rather
nice SampleBuffer object


996
00:53:28,206 --> 00:53:30,876
for holding individual samples.


997
00:53:30,926 --> 00:53:32,326
It retains the format
description.


998
00:53:32,366 --> 00:53:33,896
It carries timing information.


999
00:53:34,246 --> 00:53:36,546
The data that you've
references may--


1000
00:53:36,546 --> 00:53:37,876
it doesn't have to contiguous


1001
00:53:38,036 --> 00:53:39,636
and it can even just
be a promise it's going


1002
00:53:39,636 --> 00:53:40,446
to be delivered later.


1003
00:53:41,026 --> 00:53:43,596
And it has a way to
attach key value pairs


1004
00:53:43,596 --> 00:53:47,396
of supplemental information
for other descriptive purposes.


1005
00:53:47,936 --> 00:53:53,666
If you need to encode or
decode video frames directly,


1006
00:53:53,786 --> 00:53:57,316
the AV Foundation offers
the Video Toolbox APIs


1007
00:53:57,666 --> 00:54:00,696
like the enhanced Image
Compression Manager APIs


1008
00:54:00,696 --> 00:54:02,906
that were introduced
in QuickTime 7,


1009
00:54:03,266 --> 00:54:04,926
these use core video
pixel buffers


1010
00:54:04,926 --> 00:54:08,546
for the uncompressed images.


1011
00:54:09,496 --> 00:54:12,226
They use core media sample
buffers for the compressed data


1012
00:54:12,576 --> 00:54:14,356
and there is an additional
interface


1013
00:54:14,656 --> 00:54:18,716
for transferring an image
from one pixel buffer


1014
00:54:18,716 --> 00:54:22,006
to another pixel buffer.


1015
00:54:22,186 --> 00:54:25,666
If you are still using
QuickTime's graphics importers


1016
00:54:25,666 --> 00:54:28,886
and graphics exporters for
still image support, bless you.


1017
00:54:29,256 --> 00:54:33,576
I worked really hard on those,
but it is time to wake up


1018
00:54:33,576 --> 00:54:37,396
and smell-- smell the 64-bit
native uniformly thread safe


1019
00:54:37,396 --> 00:54:39,436
coffee delivered by
the Image I/O Framework


1020
00:54:39,436 --> 00:54:43,036
and it's CGImageSource and
CGImageDestination APIs.


1021
00:54:45,876 --> 00:54:47,096
So there's the tour.


1022
00:54:47,626 --> 00:54:48,596
There's the travel guide.


1023
00:54:48,686 --> 00:54:51,596
I've actually introduced you
to quite a large number of APIs


1024
00:54:51,596 --> 00:54:53,166
but we've scratched the surface.


1025
00:54:53,166 --> 00:54:56,616
There are more AV Foundation
APIs that you can find


1026
00:54:56,616 --> 00:54:58,196
in Headers and Documentation.


1027
00:54:58,796 --> 00:55:06,366
In summary, we are deprecating
the QuickTime C framework


1028
00:55:06,366 --> 00:55:10,246
and the QTKit Objective-C
framework in Maverick.


1029
00:55:10,826 --> 00:55:14,206
This is a reminder for you
to make the transition.


1030
00:55:15,726 --> 00:55:18,086
The deprecation warnings
will appear on your screen


1031
00:55:18,086 --> 00:55:19,506
but you'll still
be able to compile


1032
00:55:19,506 --> 00:55:21,056
and your apps will still run.


1033
00:55:21,056 --> 00:55:24,086
Everybody, your apps
will still run.


1034
00:55:25,516 --> 00:55:30,136
So, AV Foundation is the
stack of media frameworks


1035
00:55:30,136 --> 00:55:32,816
that we are building and
working on and focusing


1036
00:55:32,816 --> 00:55:34,626
on in the media systems group.


1037
00:55:35,826 --> 00:55:39,296
And we're building frameworks


1038
00:55:41,876 --> 00:55:44,566
with significant
architectural advances


1039
00:55:44,566 --> 00:55:45,906
over QuickTime across the board.


1040
00:55:46,436 --> 00:55:48,086
They're better.


1041
00:55:48,086 --> 00:55:55,396
That said, we're not deprecating
the QuickTime movie file format.


1042
00:55:55,396 --> 00:55:58,446
It is still supported as
our primary file format


1043
00:55:58,446 --> 00:55:59,986
in AV Foundation and
in QuickTime player.


1044
00:56:01,036 --> 00:56:03,746
We're introducing
QTMovieModernizer in Mavericks


1045
00:56:03,746 --> 00:56:10,876
to help bring your media into
AV Foundation supported formats.


1046
00:56:12,786 --> 00:56:18,736
We have introduced a great
new view integration class


1047
00:56:19,116 --> 00:56:24,246
in AVPlayerView as
part of AV Kit.


1048
00:56:24,406 --> 00:56:28,556
Finally, we know that
developers have had a long


1049
00:56:28,556 --> 00:56:30,646
and rich history
developing with QuickTime


1050
00:56:30,976 --> 00:56:32,366
over its last 22 years.


1051
00:56:32,986 --> 00:56:35,576
And we know there are
probably some of you


1052
00:56:35,576 --> 00:56:38,676
who are using QuickTime in ways
that we haven't yet anticipated


1053
00:56:39,176 --> 00:56:40,606
in AV Foundation's family.


1054
00:56:41,856 --> 00:56:43,166
If you can't figure out how


1055
00:56:43,166 --> 00:56:48,216
to bring your QuickTime API
app forward to AV Foundation,


1056
00:56:49,066 --> 00:56:49,776
we want to hear from you.


1057
00:56:50,416 --> 00:56:51,486
We're interested
in your feedback.


1058
00:56:52,426 --> 00:56:54,756
You can come and see us
this week in the lab.


1059
00:56:55,296 --> 00:56:58,326
You can write up enhancement
requests using Apple's bug


1060
00:56:58,326 --> 00:57:03,176
reporting mechanism, and you
can send email to John Geleynse,


1061
00:57:03,176 --> 00:57:05,496
Apple's Director of
Media Evangelism.


1062
00:57:05,496 --> 00:57:06,956
His email address is
on the next slide.


1063
00:57:08,316 --> 00:57:10,846
But we are not finished
with AV Foundation.


1064
00:57:11,166 --> 00:57:12,966
We-- we'll make it
better with every release


1065
00:57:13,466 --> 00:57:15,916
and we're interested
in your feedback.


1066
00:57:16,336 --> 00:57:21,056
There's the email
address for John Geleynse.


1067
00:57:22,136 --> 00:57:24,176
There's two resources
online that I want


1068
00:57:24,176 --> 00:57:25,306
to draw your attention to,


1069
00:57:25,306 --> 00:57:27,156
one is the AV Foundation
Programming Guide


1070
00:57:27,556 --> 00:57:29,966
and the other is
called Tech Note 2300.


1071
00:57:30,286 --> 00:57:32,536
It's all about moving
QuickTime and--


1072
00:57:32,736 --> 00:57:37,496
oh, it's all about moving
QTKit code to AV Foundation.


1073
00:57:37,496 --> 00:57:39,886
There's also an AV Foundation
zone inside the Apple


1074
00:57:39,886 --> 00:57:40,806
Developer Forums.


1075
00:57:40,806 --> 00:57:44,566
You can get help from other
AV Foundation developers,


1076
00:57:44,996 --> 00:57:48,416
and sometimes if you're lucky,
from AV Foundation engineers.


1077
00:57:48,846 --> 00:57:49,796
And it's also searchable.


1078
00:57:49,796 --> 00:57:50,646
Sometimes the question


1079
00:57:50,646 --> 00:57:55,816
that you're asking has
already been asked.


1080
00:57:55,816 --> 00:57:59,946
We have three other
sessions from media systems


1081
00:58:00,006 --> 00:58:03,926
and AV Foundation
folks this week.


1082
00:58:04,376 --> 00:58:06,056
There's the preparing
and presenting media


1083
00:58:06,056 --> 00:58:09,396
for accessibility session
which we'll go into more detail


1084
00:58:09,396 --> 00:58:11,266
about what it means
honor a user's


1085
00:58:11,266 --> 00:58:12,426
accessibility preferences.


1086
00:58:13,166 --> 00:58:15,536
There is, "What's new
in camera capture?"


1087
00:58:15,536 --> 00:58:19,316
Which will focus
principally on new features


1088
00:58:19,316 --> 00:58:21,756
in AV Foundation
capture on iOS 7.


1089
00:58:21,756 --> 00:58:25,666
And there's also very exciting
session on advanced editing


1090
00:58:25,666 --> 00:58:28,886
with AV Foundation which
will introduce a new way


1091
00:58:28,886 --> 00:58:31,306
of integrating your
code directly


1092
00:58:31,306 --> 00:58:36,566
into our playback pipeline
to do fancy video effects


1093
00:58:36,566 --> 00:58:39,116
and filters limited only
by your imagination.


1094
00:58:39,586 --> 00:58:42,796
That's very exciting
feature to me.


1095
00:58:44,036 --> 00:58:45,776
Thanks for coming up.


1096
00:58:45,776 --> 00:58:46,286
Bye, bye.


1097
00:58:46,786 --> 00:58:59,990
[ Applause ]

